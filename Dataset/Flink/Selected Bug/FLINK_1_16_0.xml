<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="FLINK">
  <bug fixdate="2019-9-21 01:00:00" id="14896" opendate="2019-11-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Kinesis connector doesn&amp;#39;t shade jackson dependency</summary>
      <description>flink-kinesis-connector depends on aws java sdk which is shaded to org.apache.flink.kinesis.shaded.com.amazonaws. However, the aws sdk has a transitive dependency to jackson wich is not shaded in the artifact. This creates problem when running flink on YARN: The aws sdk requires jackson-core v2.6 but hadoop pulls in 2.3. See here. If YARN uses the loads wrong jackson version from classpath. Jod fails with2019-11-20 17:23:11,563 ERROR org.apache.flink.runtime.webmonitor.handlers.JarRunHandler - Unhandled exception.org.apache.flink.client.program.ProgramInvocationException: The program caused an error:     at org.apache.flink.client.program.OptimizerPlanEnvironment.getOptimizedPlan(OptimizerPlanEnvironment.java:93)    at org.apache.flink.client.program.PackagedProgramUtils.createJobGraph(PackagedProgramUtils.java:80)    at org.apache.flink.runtime.webmonitor.handlers.utils.JarHandlerUtils$JarHandlerContext.toJobGraph(JarHandlerUtils.java:126)    at org.apache.flink.runtime.webmonitor.handlers.JarRunHandler.lambda$getJobGraphAsync$6(JarRunHandler.java:142)    at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)    at java.lang.Thread.run(Thread.java:748)Caused by: java.lang.NoSuchMethodError: com.fasterxml.jackson.databind.ObjectMapper.enable([Lcom/fasterxml/jackson/core/JsonParser$Feature;)Lcom/fasterxml/jackson/databind/ObjectMapper;    at com.amazonaws.partitions.PartitionsLoader.&lt;clinit&gt;(PartitionsLoader.java:54)    at com.amazonaws.regions.RegionMetadataFactory.create(RegionMetadataFactory.java:30)    at com.amazonaws.regions.RegionUtils.initialize(RegionUtils.java:65)    at com.amazonaws.regions.RegionUtils.getRegionMetadata(RegionUtils.java:53)    at com.amazonaws.regions.RegionUtils.getRegion(RegionUtils.java:107)    at com.amazonaws.client.builder.AwsClientBuilder.getRegionObject(AwsClientBuilder.java:256)    at com.amazonaws.client.builder.AwsClientBuilder.setRegion(AwsClientBuilder.java:460)    at com.amazonaws.client.builder.AwsClientBuilder.configureMutableProperties(AwsClientBuilder.java:424)    at com.amazonaws.client.builder.AwsAsyncClientBuilder.build(AwsAsyncClientBuilder.java:80)...The flink-kinesis-connector should do as other connectors: shade jackson or use the flink-shaded-jackson core dependency</description>
      <version>1.9.0,1.16.0,1.15.2</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-sql-connector-kinesis.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-connectors.flink-sql-connector-kinesis.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-connectors.flink-connector-kinesis.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2022-7-20 01:00:00" id="25720" opendate="2022-1-20 00:00:00" resolution="Done">
    <buginformation>
      <summary>Support Python UDTF in Thread Mode</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.common.CommonExecPythonCorrelate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.common.CommonExecPythonCalc.java</file>
      <file type="M">flink-python.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.operators.python.table.PythonTableFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.operators.python.scalar.EmbeddedPythonScalarFunctionOperator.java</file>
      <file type="M">flink-python.setup.py</file>
      <file type="M">flink-python.pyflink.table.tests.test.udtf.py</file>
      <file type="M">flink-python.pyflink.table.tests.test.udf.py</file>
      <file type="M">flink-python.pyflink.fn.execution.utils.operation.utils.py</file>
      <file type="M">flink-python.pom.xml</file>
      <file type="M">flink-python.dev.dev-requirements.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-1-20 01:00:00" id="25725" opendate="2022-1-20 00:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Agile configurable modules in web ui</summary>
      <description>For modules like task-manager and job-manager, use an injection token to allow a configuration object customizing/overriding individual component/variable (e.g. rewrite a new chart node component and inject it through the token), increasing these modules' reusability (also a better DI practice).</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.runtime.batch.sql.CompactManagedTableITCase.java</file>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.connector.sink.TestManagedSinkCommitter.java</file>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.connector.sink.TestManagedSink.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-3-14 01:00:00" id="26125" opendate="2022-2-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Doc overhaul for the CAST behaviour</summary>
      <description>This includes: Proper documentation of the new TRY_CAST Add a CAST matrix to document which CAST tuples are supported</description>
      <version>None</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.dev.table.types.md</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-2-16 01:00:00" id="26189" opendate="2022-2-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove bundling of grizzled-slf4j from rpc-akka</summary>
      <description>This dependency is unnecessary nowadays.</description>
      <version>None</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-rpc.flink-rpc-akka.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-rpc.flink-rpc-akka.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-9-4 01:00:00" id="2619" opendate="2015-9-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some Scala Tests not being executed by Maven</summary>
      <description>Some Scala Tests are not executed by Maven. Originally this issue are reported by StephanEwen. I also executed mvn clean verify and found the same circumstance.Original post is here</description>
      <version>None</version>
      <fixedVersion>0.10.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.scala.org.apache.flink.api.scala.misc.MassiveCaseClassSortingITCase.scala</file>
      <file type="M">flink-staging.flink-scala-shell.src.test.scala.org.apache.flink.api.scala.ScalaShellITSuite.scala</file>
      <file type="M">flink-staging.flink-gelly-scala.src.test.scala.org.apache.flink.graph.scala.test.operations.GraphOperationsITCase.scala</file>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.executiongraph.TaskManagerLossFailsTasksTest.scala</file>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.jobmanager.JobManagerRegistrationTest.scala</file>
      <file type="M">flink-runtime.src.test.scala.org.apache.flink.runtime.executiongraph.ExecutionGraphRestartTest.scala</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ExecutionGraphTestUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionGraph.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-3-9 01:00:00" id="26557" opendate="2022-3-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extend CsvFormat documentation based on release-testing feedback</summary>
      <description>Incorporate feedback about the documentation from CsvFormat release testing:https://issues.apache.org/jira/browse/FLINK-26311 </description>
      <version>None</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.connectors.datastream.formats.csv.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-3-14 01:00:00" id="26638" opendate="2022-3-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reintroduce ActionFailureHandler for Elasticsearch sink connectors</summary>
      <description>In FLINK-26281 we found out that users depend on the ActionFailureHandler that was not ported over to the new unified Sink. We not want to add the failure handler back.</description>
      <version>1.16.0</version>
      <fixedVersion>1.15.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-elasticsearch7.src.main.resources.META-INF.services.org.apache.flink.table.factories.Factory</file>
      <file type="M">flink-connectors.flink-connector-elasticsearch6.src.main.resources.META-INF.services.org.apache.flink.table.factories.Factory</file>
      <file type="M">docs.content.docs.connectors.table.elasticsearch.md</file>
      <file type="M">docs.content.zh.docs.connectors.table.elasticsearch.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-3-15 01:00:00" id="26641" opendate="2022-3-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize the time of fetching job status in the job submission of session cluster</summary>
      <description>Currently, in the session cluster, the client will wait until the job initialization is finished in the job submission period. However, it will first get the job details from the `ExecutionGraphCache`. For short queries in OLAP scenarios, the job might have been finished before the cache refreshed, which increase the e2e time of fetching the result.We proposed to introduce a REST API for the job status to replace it.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.WebMonitorEndpoint.java</file>
      <file type="M">flink-runtime-web.src.test.resources.rest.api.v1.snapshot</file>
      <file type="M">docs.static.generated.rest.v1.dispatcher.yml</file>
      <file type="M">docs.layouts.shortcodes.generated.rest.v1.dispatcher.html</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.program.rest.RestClusterClientTest.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.program.rest.RestClusterClient.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-3-16 01:00:00" id="26687" opendate="2022-3-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove NiFi connector</summary>
      <description>The community voted to deprecate NiFi in 1.15 and we should remove it from 1.16 onwards.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.ci.stage.sh</file>
      <file type="M">flink-connectors.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.test.resources.NiFi.Flink.xml</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.test.java.org.apache.flink.streaming.connectors.nifi.examples.NiFiSourceTopologyExample.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.test.java.org.apache.flink.streaming.connectors.nifi.examples.NiFiSinkTopologyExample.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.main.java.org.apache.flink.streaming.connectors.nifi.StandardNiFiDataPacket.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.main.java.org.apache.flink.streaming.connectors.nifi.NiFiSource.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.main.java.org.apache.flink.streaming.connectors.nifi.NiFiSink.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.main.java.org.apache.flink.streaming.connectors.nifi.NiFiDataPacketBuilder.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.src.main.java.org.apache.flink.streaming.connectors.nifi.NiFiDataPacket.java</file>
      <file type="M">flink-connectors.flink-connector-nifi.pom.xml</file>
      <file type="M">flink-architecture-tests.pom.xml</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.pom.xml</file>
      <file type="M">docs.content.docs.connectors.datastream.overview.md</file>
      <file type="M">docs.content.docs.connectors.datastream.nifi.md</file>
      <file type="M">docs.content.zh.docs.connectors.datastream.overview.md</file>
      <file type="M">docs.content.zh.docs.connectors.datastream.nifi.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-3-16 01:00:00" id="26689" opendate="2022-3-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace TableConfig with ReadableConfig where possible</summary>
      <description>Following the removal of `nullCheck` in the code generation, we can replace TableConfig with ReadableConfig in various places, and take advantage of the new `TableConfig implments ReadableConfig` approach.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecMatch.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedTableAggsHandleFunction.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedResultFuture.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedRecordEqualiser.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedRecordComparator.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedProjection.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedOperator.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedNamespaceTableAggsHandleFunction.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedNamespaceAggsHandleFunction.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedJoinCondition.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedInput.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedHashFunction.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedFunction.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedCollector.java</file>
      <file type="M">flink-table.flink-table-runtime.src.main.java.org.apache.flink.table.runtime.generated.GeneratedAggsHandleFunction.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.plan.utils.PartitionPrunerTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.match.PatternTranslatorTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.expressions.utils.ExpressionTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.codegen.ProjectionCodeGeneratorTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.codegen.HashCodeGeneratorTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.codegen.agg.AggTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.codegen.SortCodeGeneratorTest.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.codegen.LongHashJoinGeneratorTest.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.codegen.CodeSplitTest.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.utils.PartitionPruner.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.utils.JoinUtil.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.rules.logical.PushPartitionIntoLegacyTableSourceScanRule.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.nodes.physical.batch.BatchPhysicalJoinBase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.ValuesCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.sort.SortCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.sort.ComparatorCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.ProjectionCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.over.RangeBoundComparatorCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.over.MultiFieldRangeBoundComparatorCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.OperatorCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.MatchCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.LookupJoinCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.LongHashJoinGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.InputFormatCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.HashCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.FunctionCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.ExpressionReducer.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.ExprCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.EqualiserCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.CorrelateCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.CollectorCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.CodeGeneratorContext.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.calls.ScalarOperatorGens.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.calls.FunctionGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.calls.BridgingSqlFunctionCallGen.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.CalcCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.agg.AggsHandlerCodeGenerator.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.utils.TableConfigUtils.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.utils.KeySelectorUtil.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecWindowRank.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecWindowJoin.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecWindowAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecWatermarkAssigner.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecTemporalSort.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecTemporalJoin.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecSort.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecRank.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecPythonOverAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecPythonGroupWindowAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecOverAggregate.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.aggregate.arrow.batch.BatchArrowPythonGroupAggregateFunctionOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.aggregate.arrow.batch.BatchArrowPythonGroupWindowAggregateFunctionOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.aggregate.arrow.batch.BatchArrowPythonOverWindowAggregateFunctionOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.aggregate.arrow.stream.StreamArrowPythonGroupWindowAggregateFunctionOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.aggregate.arrow.stream.StreamArrowPythonProcTimeBoundedRangeOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.aggregate.arrow.stream.StreamArrowPythonProcTimeBoundedRowsOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.aggregate.arrow.stream.StreamArrowPythonRowTimeBoundedRangeOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.aggregate.arrow.stream.StreamArrowPythonRowTimeBoundedRowsOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.aggregate.PassThroughPythonStreamGroupWindowAggregateOperator.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.scalar.arrow.ArrowPythonScalarFunctionOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.scalar.PythonScalarFunctionOperatorTest.java</file>
      <file type="M">flink-python.src.test.java.org.apache.flink.table.runtime.operators.python.table.PythonTableFunctionOperatorTest.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.abilities.source.WatermarkPushDownSpec.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecBoundedStreamScan.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecExchange.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecHashAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecHashJoin.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecHashWindowAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecLegacyTableSourceScan.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecNestedLoopJoin.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecOverAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecPythonGroupAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecPythonGroupWindowAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecPythonOverAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecRank.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecSort.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecSortAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecSortLimit.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecSortMergeJoin.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecSortWindowAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.common.CommonExecCalc.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.common.CommonExecCorrelate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.common.CommonExecExpand.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.common.CommonExecLegacySink.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.common.CommonExecLookupJoin.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.common.CommonExecPythonCalc.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.common.CommonExecPythonCorrelate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.common.CommonExecValues.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecDataStreamScan.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecGlobalGroupAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecGlobalWindowAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecGroupAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecGroupTableAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecGroupWindowAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecIncrementalGroupAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecIntervalJoin.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecJoin.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecLegacyTableSourceScan.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecLocalGroupAggregate.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecLocalWindowAggregate.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-3-20 01:00:00" id="26747" opendate="2022-3-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[JUnit5 Migration] Module: flink-external-resources</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-external-resources.flink-external-resource-gpu.src.test.java.org.apache.flink.externalresource.gpu.GPUDriverTest.java</file>
      <file type="M">flink-external-resources.flink-external-resource-gpu.src.test.java.org.apache.flink.externalresource.gpu.GPUDiscoveryScriptTest.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2022-7-23 01:00:00" id="26813" opendate="2022-3-23 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Supports ADD/MODIFY column/watermark/constraint syntax parse for ALTER TABLE</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-sql-parser.src.test.java.org.apache.flink.sql.parser.FlinkSqlParserImplTest.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.dql.SqlLoadModule.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlCreateView.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlCreateTable.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlCreateCatalog.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlAlterViewProperties.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlAlterTableReset.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlAlterTableOptions.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlAlterTable.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlAlterDatabase.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlAddReplaceColumns.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.codegen.includes.parserImpls.ftl</file>
      <file type="M">flink-table.flink-sql-parser.src.main.codegen.data.Parser.tdd</file>
      <file type="M">flink-table.flink-sql-parser-hive.src.main.java.org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveView.java</file>
      <file type="M">flink-table.flink-sql-parser-hive.src.main.java.org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable.java</file>
      <file type="M">flink-table.flink-sql-parser-hive.src.main.java.org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveViewProperties.java</file>
      <file type="M">flink-table.flink-sql-parser-hive.src.main.java.org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveTableSerDe.java</file>
      <file type="M">flink-table.flink-sql-parser-hive.src.main.java.org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveTableProps.java</file>
      <file type="M">flink-table.flink-sql-parser-hive.src.main.java.org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveTableAddReplaceColumn.java</file>
      <file type="M">flink-table.flink-sql-parser-hive.src.main.java.org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveDatabaseProps.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-3-25 01:00:00" id="26855" opendate="2022-3-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ImportError: cannot import name &amp;#39;environmentfilter&amp;#39; from &amp;#39;jinja2&amp;#39;</summary>
      <description>ar 24 17:38:39 ===========mypy checks... [SUCCESS]===========Mar 24 17:38:39 rm -rf _build/*Mar 24 17:38:39 /__w/2/s/flink-python/dev/.conda/bin/sphinx-build -b html -d _build/doctrees -a -W . _build/htmlMar 24 17:38:40 Traceback (most recent call last):Mar 24 17:38:40 File "/__w/2/s/flink-python/dev/.conda/bin/sphinx-build", line 6, in &lt;module&gt;Mar 24 17:38:40 from sphinx.cmd.build import mainMar 24 17:38:40 File "/__w/2/s/flink-python/dev/.conda/lib/python3.7/site-packages/sphinx/cmd/build.py", line 23, in &lt;module&gt;Mar 24 17:38:40 from sphinx.application import SphinxMar 24 17:38:40 File "/__w/2/s/flink-python/dev/.conda/lib/python3.7/site-packages/sphinx/application.py", line 42, in &lt;module&gt;Mar 24 17:38:40 from sphinx.highlighting import lexer_classes, lexersMar 24 17:38:40 File "/__w/2/s/flink-python/dev/.conda/lib/python3.7/site-packages/sphinx/highlighting.py", line 30, in &lt;module&gt;Mar 24 17:38:40 from sphinx.ext import doctestMar 24 17:38:40 File "/__w/2/s/flink-python/dev/.conda/lib/python3.7/site-packages/sphinx/ext/doctest.py", line 28, in &lt;module&gt;Mar 24 17:38:40 from sphinx.builders import BuilderMar 24 17:38:40 File "/__w/2/s/flink-python/dev/.conda/lib/python3.7/site-packages/sphinx/builders/__init__.py", line 24, in &lt;module&gt;Mar 24 17:38:40 from sphinx.io import read_docMar 24 17:38:40 File "/__w/2/s/flink-python/dev/.conda/lib/python3.7/site-packages/sphinx/io.py", line 42, in &lt;module&gt;Mar 24 17:38:40 from sphinx.util.rst import append_epilog, docinfo_re, prepend_prologMar 24 17:38:40 File "/__w/2/s/flink-python/dev/.conda/lib/python3.7/site-packages/sphinx/util/rst.py", line 22, in &lt;module&gt;Mar 24 17:38:40 from jinja2 import environmentfilterMar 24 17:38:40 ImportError: cannot import name 'environmentfilter' from 'jinja2' (/__w/2/s/flink-python/dev/.conda/lib/python3.7/site-packages/jinja2/__init__.py)Mar 24 17:38:40 Makefile:76: recipe for target 'html' failedMar 24 17:38:40 make: *** [html] Error 1Mar 24 17:38:40 ==========sphinx checks... [FAILED]===========https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=33717&amp;view=logs&amp;j=9cada3cb-c1d3-5621-16da-0f718fb86602&amp;t=c67e71ed-6451-5d26-8920-5a8cf9651901&amp;l=23450</description>
      <version>1.15.0,1.16.0</version>
      <fixedVersion>1.14.5,1.15.0,1.13.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.dev.lint-python.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-4-25 01:00:00" id="26864" opendate="2022-3-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Performance regression on 25.03.2022</summary>
      <description>http://codespeed.dak8s.net:8000/timeline/#/?exe=1&amp;ben=arrayKeyBy&amp;extr=on&amp;quarts=on&amp;equid=off&amp;env=2&amp;revs=200http://codespeed.dak8s.net:8000/timeline/#/?exe=1&amp;ben=remoteFilePartition&amp;extr=on&amp;quarts=on&amp;equid=off&amp;env=2&amp;revs=200http://codespeed.dak8s.net:8000/timeline/#/?exe=1&amp;ben=remoteSortPartition&amp;extr=on&amp;quarts=on&amp;equid=off&amp;env=2&amp;revs=200http://codespeed.dak8s.net:8000/timeline/#/?exe=1&amp;ben=tupleKeyBy&amp;extr=on&amp;quarts=on&amp;equid=off&amp;env=2&amp;revs=200</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.StreamTaskTest.java</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.runtime.tasks.mailbox.TaskMailboxProcessorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.StreamTask.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-3-25 01:00:00" id="26865" opendate="2022-3-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the potential failure of loading library in Thread Mode</summary>
      <description>The failure occurs in session mode.</description>
      <version>1.15.0,1.16.0</version>
      <fixedVersion>1.15.0,1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-python.setup.py</file>
      <file type="M">flink-python.pom.xml</file>
      <file type="M">flink-python.dev.dev-requirements.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-4-28 01:00:00" id="26886" opendate="2022-3-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Document reporter behavior w.r.t. scopes &amp; push/pull</summary>
      <description>The docs are lacking information for whether a reporter uses a metric identifier or the logical scope + tags, and whether they are push or pull based.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.MetricOptions.java</file>
      <file type="M">docs.content.docs.deployment.metric.reporters.md</file>
      <file type="M">docs.content.zh.docs.deployment.metric.reporters.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-4-30 01:00:00" id="26928" opendate="2022-3-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unnecessary Docker network creation in Kafka connector tests</summary>
      <description>Currently each Kafka test class will create a Docker network, which could flush the network usage on Docker host, and test would fail if all IP address in the pool of Docker are occupied. </description>
      <version>1.15.0,1.16.0</version>
      <fixedVersion>1.15.0,1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kafka.src.test.java.org.apache.flink.streaming.connectors.kafka.table.KafkaTableTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-kafka.src.test.java.org.apache.flink.streaming.connectors.kafka.KafkaTestEnvironmentImpl.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-4-1 01:00:00" id="26986" opendate="2022-4-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove deprecated string expressions in Python Table API</summary>
      <description>In FLINK-26704, it has removed the string expressions in Table API. However, there are still some APIs still using string expressions in Python Table API, however, they should not work any more as the string expressions have already been removed in the Java Table API.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.pyflink.table.window.py</file>
      <file type="M">flink-python.pyflink.table.table.py</file>
      <file type="M">flink-python.pyflink.table.schema.py</file>
      <file type="M">flink-python.pyflink.examples.table.windowing.tumble.window.py</file>
      <file type="M">flink-python.pyflink.examples.table.windowing.sliding.window.py</file>
      <file type="M">flink-python.pyflink.examples.table.windowing.session.window.py</file>
      <file type="M">flink-python.pyflink.examples.table.windowing.over.window.py</file>
      <file type="M">flink-python.pyflink.examples.table.pandas.pandas.udaf.py</file>
      <file type="M">docs.content.docs.dev.table.tableApi.md</file>
      <file type="M">docs.content.docs.dev.table.catalogs.md</file>
      <file type="M">docs.content.docs.dev.python.table.udfs.vectorized.python.udfs.md</file>
      <file type="M">docs.content.docs.dev.python.table.udfs.python.udfs.md</file>
      <file type="M">docs.content.docs.dev.python.table.python.table.api.connectors.md</file>
      <file type="M">docs.content.zh.docs.dev.table.tableApi.md</file>
      <file type="M">docs.content.zh.docs.dev.table.catalogs.md</file>
      <file type="M">docs.content.zh.docs.dev.python.table.udfs.vectorized.python.udfs.md</file>
      <file type="M">docs.content.zh.docs.dev.python.table.udfs.python.udfs.md</file>
      <file type="M">docs.content.zh.docs.dev.python.table.python.table.api.connectors.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-2 01:00:00" id="27016" opendate="2022-4-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve supporting for complex data type for Hive dialect</summary>
      <description>      There are some issue exist while involving complex data type using Hive dialect in Flink. It will throw exception when access array type in a struct. For example, such sql will fail:create table t (s6 map&lt;string, struct&lt;f20:array&lt;string&gt;&gt;&gt;);SELECT s6['key1'].f20[0] FROM nested_tbl_1;      2. Hive supports to access the field of a struct list by '.' , but it'll throw exception using Hive dialect in Flink.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.table.module.hive.HiveModuleTest.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.HiveDialectQueryITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.planner.delegation.hive.HiveParserRexNodeConverter.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.planner.delegation.hive.copy.HiveParserTypeConverter.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.module.hive.HiveModule.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-9-2 01:00:00" id="27017" opendate="2022-4-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix divide by zero exception in Hive dialect</summary>
      <description>It's support to divide by zero in Hive, but it'll throw exception while using Hive dialect in Flink.</description>
      <version>None</version>
      <fixedVersion>1.16.0,1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.HiveDialectQueryITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.planner.delegation.hive.HiveParserRexNodeConverter.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.planner.delegation.hive.copy.HiveParserSqlFunctionConverter.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2022-5-4 01:00:00" id="27048" opendate="2022-4-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add ArchUnit tests for Elasticsearch to only depend on public API</summary>
      <description>We want to ensure that the Elasticsearch connectors class level dependencies are part of the public API. To do this we want to extend the existing ArchUnit tests.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.src.main.java.org.apache.flink.architecture.ProductionCodeArchitectureBase.java</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.archunit-violations.stored.rules</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-4-7 01:00:00" id="27119" opendate="2022-4-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup JobMasters</summary>
      <description>Several tests create JobMasters but don't make sure that it is shut down. We should change the tests to use a try-with-resource statement.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmaster.JobMasterTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmaster.JobMasterSchedulerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmaster.JobMasterQueryableStateTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.jobmaster.JobMasterExecutionDeploymentReconciliationTest.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-4-8 01:00:00" id="27140" opendate="2022-4-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move JobResultStore dirty entry creation into ioExecutor</summary>
      <description>The FileSystemJobResultStore is thread-safe and, therefore, we can move the dirty entry creation into the ioExecutor</description>
      <version>1.15.0,1.16.0</version>
      <fixedVersion>1.15.1,1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.MiniDispatcher.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.dispatcher.Dispatcher.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-4-11 01:00:00" id="27167" opendate="2022-4-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deploying master snapshot failed due to generating javadoc failed</summary>
      <description>[ERROR] Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.9.1:jar (attach-javadocs) on project flink-architecture-tests-production: MavenReportException: Error while creating archive:[ERROR] Exit code: 1 - javadoc: error - class file for org.junit.platform.commons.annotation.Testable not found[ERROR] [ERROR] Command line was: /usr/lib/jvm/java-8-openjdk-amd64/jre/../bin/javadoc -Xdoclint:none @options @packages[ERROR] [ERROR] Refer to the generated Javadoc files in '/__w/1/s/flink-architecture-tests/flink-architecture-tests-production/target/apidocs' dir.[ERROR] -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException[ERROR] [ERROR] After correcting the problems, you can resume the build with the command[ERROR] mvn &lt;goals&gt; -rf :flink-architecture-tests-production##[error]Bash exited with code '1'.Finishing: Deploy maven snapshothttps://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=34493&amp;view=logs&amp;j=eca6b3a6-1600-56cc-916a-c549b3cde3ff&amp;t=e9844b5e-5aa3-546b-6c3e-5395c7c0cac7&amp;l=13852</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-4-11 01:00:00" id="27168" opendate="2022-4-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce ContinuousProcessingTimeTrigger and ContinuousEventTimeTrigger</summary>
      <description>Add continuousprocessingtimetrigger and continuouseventtimetrigger triggers</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.pyflink.datastream.window.py</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-12 01:00:00" id="27199" opendate="2022-4-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump Pulsar to 2.10.0 for fixing the unstable Pulsar test environment.</summary>
      <description>Pulsar's transaction is not stable. The standalone cluster often hangs the test, then we will meet a timeout for the tests at last.The latest Pulsar 2.10.0 drops the zookeeper and fixes a lot of issues in the Pulsar transaction. Bump to this version would resolve the current test issues.</description>
      <version>1.14.4,1.15.0,1.16.0</version>
      <fixedVersion>1.16.0,1.15.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.mock.PulsarMockRuntime.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.mock.MockZooKeeperClientFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.mock.MockPulsarService.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.mock.MockBookKeeperClientFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.PulsarSinkOptions.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.config.SinkConfiguration.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.config.PulsarSinkConfigUtils.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.config.PulsarOptions.java</file>
      <file type="M">docs.layouts.shortcodes.generated.pulsar.sink.configuration.html</file>
      <file type="M">docs.layouts.shortcodes.generated.pulsar.producer.configuration.html</file>
      <file type="M">docs.layouts.shortcodes.generated.pulsar.client.configuration.html</file>
      <file type="M">flink-test-utils-parent.flink-test-utils-junit.src.main.java.org.apache.flink.util.DockerImageVersions.java</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-pulsar.pom.xml</file>
      <file type="M">flink-connectors.flink-sql-connector-pulsar.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.split.PulsarPartitionSplit.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.start.MessageIdStartCursor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.config.SourceConfiguration.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.router.MessageKeyHash.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-4-12 01:00:00" id="27209" opendate="2022-4-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Half the Xmx and double the forkCount for unit tests</summary>
      <description>As per recent "Speeding up the test builds" discussion on the dev mailing.I'm proposing to half the memory allocated for running unit tests (as defined per &lt;test.unit.pattern&gt;**/Test.&lt;/test.unit.pattern&gt; property) but at the same time double the forkCounts for those tests. The premise is that they shouldn't need as much memory as ITCases to be stable, while increasing number of forks, should provide us with a couple of minutes improved build times.CC chesnay</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0,elasticsearch-3.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-2-21 01:00:00" id="2721" opendate="2015-9-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Tuple meta information</summary>
      <description>In Bolt.execute(Tuple input) the given input tuple contains meta information about its origin (like source component name, stream id, source task ID).This meta information in currently not provided by Flink and the corresponding methods throw an UnsupportedOperationException.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.StormTupleTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.SpoutCollectorTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.BoltWrapperTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.wrappers.BoltCollectorTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.api.FlinkTopologyTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.test.java.org.apache.flink.storm.api.FlinkOutputFieldsDeclarerTest.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.WrapperSetupHelper.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.StormTuple.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.SpoutWrapper.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.SpoutCollector.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.BoltWrapper.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.BoltCollector.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.wrappers.AbstractStormCollector.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.TwoFlinkStreamsMerger.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.StormFlinkStreamMerger.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.FlinkTopology.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.FlinkOutputFieldsDeclarer.java</file>
      <file type="M">flink-contrib.flink-storm.src.main.java.org.apache.flink.storm.api.FlinkLocalCluster.java</file>
      <file type="M">flink-contrib.flink-storm.README.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-4-13 01:00:00" id="27228" opendate="2022-4-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Redistributed modules across CI profiles</summary>
      <description>With the recent improvements around testing times it is time to redistribute the modules again to achieve a more even distribution.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.ci.stage.sh</file>
      <file type="M">tools.azure-pipelines.jobs-template.yml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-4-13 01:00:00" id="27231" opendate="2022-4-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>SQL pulsar connector lists dependencies under wrong license</summary>
      <description>Pulsar sql connector lists following dependencies under ASL2 license while they are licensed with Bouncy Castle license (variant of MIT?).- org.bouncycastle:bcpkix-jdk15on:1.69- org.bouncycastle:bcprov-ext-jdk15on:1.69- org.bouncycastle:bcprov-jdk15on:1.69- org.bouncycastle:bcutil-jdk15on:1.69</description>
      <version>1.15.0,1.16.0</version>
      <fixedVersion>1.15.0,1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-sql-connector-pulsar.src.main.resources.META-INF.NOTICE</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-4-16 01:00:00" id="27267" opendate="2022-4-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[JUnit5 Migration] Module: flink-contrib</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-contrib.flink-connector-wikiedits.src.test.java.org.apache.flink.streaming.connectors.wikiedits.WikipediaEditsSourceTest.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-4-20 01:00:00" id="27317" opendate="2022-4-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Snapshot deployment fails due to .scalafmt.conf not being found</summary>
      <description>https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=34852&amp;view=logs&amp;j=eca6b3a6-1600-56cc-916a-c549b3cde3ff&amp;t=e9844b5e-5aa3-546b-6c3e-5395c7c0cac7Cause by the maven-source-plugin jar goal forking the build and apparently messing up the working directory.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.pom.xml</file>
      <file type="M">flink-table.flink-table-planner.pom.xml</file>
      <file type="M">flink-table.flink-table-api-scala.pom.xml</file>
      <file type="M">flink-table.flink-table-api-scala-bridge.pom.xml</file>
      <file type="M">flink-streaming-scala.pom.xml</file>
      <file type="M">flink-scala.pom.xml</file>
      <file type="M">flink-libraries.flink-gelly-scala.pom.xml</file>
      <file type="M">flink-libraries.flink-gelly-examples.pom.xml</file>
      <file type="M">flink-libraries.flink-cep-scala.pom.xml</file>
      <file type="M">flink-examples.flink-examples-table.pom.xml</file>
      <file type="M">flink-examples.flink-examples-streaming.pom.xml</file>
      <file type="M">flink-examples.flink-examples-batch.pom.xml</file>
      <file type="M">flink-end-to-end-tests.flink-quickstart-test.pom.xml</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-scala.pom.xml</file>
      <file type="M">flink-connectors.flink-hcatalog.pom.xml</file>
      <file type="M">flink-connectors.flink-hadoop-compatibility.pom.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-12-21 01:00:00" id="27341" opendate="2022-4-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>TaskManager running together with JobManager are bind to 127.0.0.1</summary>
      <description>If some TaskManagers running with JobManager on the same machine while some other TaskManager not, the TaskManagers running together with JobManager would bind to localhost or 127.0.01, which makes the Netty connections across the TaskManagers fail.</description>
      <version>1.15.0,1.16.0</version>
      <fixedVersion>1.17.0,1.16.1,1.15.4</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.net.ConnectionUtils.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-10-22 01:00:00" id="2740" opendate="2015-9-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create data consumer for Apache NiFi</summary>
      <description>Create a connector to Apache NiFi to create Flink DataStreams from NiFi flows</description>
      <version>None</version>
      <fixedVersion>0.10.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-staging.flink-streaming.flink-streaming-connectors.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-10-23 01:00:00" id="2743" opendate="2015-9-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add new RNG based on XORShift algorithm</summary>
      <description>XORShift algorithm is an optimized algorithm for random number generator, implement a RNG based on it would help to improve the performance of operations where RNG is heavily used.</description>
      <version>None</version>
      <fixedVersion>0.10.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.ReservoirSamplerWithReplacement.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.ReservoirSamplerWithoutReplacement.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.PoissonSampler.java</file>
      <file type="M">flink-java.src.main.java.org.apache.flink.api.java.sampling.BernoulliSampler.java</file>
      <file type="M">flink-core.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-4-27 01:00:00" id="27431" opendate="2022-4-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow Duration for RpcTimeouts</summary>
      <description>To support the gradual migration of components to Duration we should allow the RpcTimeout annotation to also be used for Duration timeouts.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-rpc.flink-rpc-akka.src.test.java.org.apache.flink.runtime.rpc.akka.TimeoutCallStackTest.java</file>
      <file type="M">flink-rpc.flink-rpc-akka.src.main.java.org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-5-27 01:00:00" id="27433" opendate="2022-4-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>E2E log artifacts contain several thousand rocksdb logs</summary>
      <description>It would be great if we could minimize them somehow because as is they kinda break the azure UI and are just a pain (beyond taking up a lot of space). Even zipping them before the upload would be fine in my book.I also just don't get why so few e2e tests manage to create 5k files.yunta Is this caused by FLINK-23791?</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.RocksDBConfigurableOptions.java</file>
      <file type="M">flink-end-to-end-tests.test-scripts.common.sh</file>
      <file type="M">docs.layouts.shortcodes.generated.rocksdb.configurable.configuration.html</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-5-4 01:00:00" id="27485" opendate="2022-5-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Documentation build pipeline is broken</summary>
      <description>The current documentation build pipeline is broken due to two failures: It uses git command git branch --show-current which isn't supported by the installed Git version on the Docker image. We can switch to git rev-parse --abbrev-ref HEAD as an alternative The manual Hugo download and installation is outdated and doesn't add Hugo to the PATH</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.setup.docs.sh</file>
      <file type="M">.github.workflows.docs.sh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-7-6 01:00:00" id="27523" opendate="2022-5-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Runtime supports producing and consuming cached intermediate result</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.taskexecutor.TaskExecutorTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.scheduler.strategy.TestingSchedulingTopology.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.scheduler.strategy.TestingSchedulingExecutionVertex.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.scheduler.adaptive.ExecutingTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.scheduler.adapter.DefaultExecutionVertexTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.utils.TestingResourceManagerGateway.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.ResourceManagerPartitionLifecycleTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.TestingJobMasterPartitionTracker.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.TaskExecutorPartitionTrackerImplTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTrackerImplTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.NoOpResourceManagerPartitionTracker.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.NoOpJobMasterPartitionTracker.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.JobMasterPartitionTrackerImplTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.deployment.TaskDeploymentDescriptorFactoryTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.partition.ClusterPartitionReport.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.scheduler.strategy.ConsumedPartitionGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.scheduler.DefaultScheduler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.ResourceManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobmaster.JobMaster.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobgraph.JobVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.TaskExecutorPartitionTrackerImpl.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.TaskExecutorPartitionInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTrackerImpl.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTracker.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.JobMasterPartitionTrackerImpl.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.JobMasterPartitionTracker.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.DataSetMetaInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.ClusterPartitionManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.InternalExecutionGraphAccessor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.failover.flip1.partitionrelease.RegionPartitionGroupReleaseStrategy.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.EdgeManagerBuildUtil.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.deployment.TaskDeploymentDescriptorFactory.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-7-9 01:00:00" id="27556" opendate="2022-5-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Performance regression in checkpointSingleInput.UNALIGNED on 29.04.2022</summary>
      <description>http://codespeed.dak8s.net:8000/timeline/#/?exe=1&amp;ben=checkpointSingleInput.UNALIGNED&amp;extr=on&amp;quarts=on&amp;equid=off&amp;env=2&amp;revs=200</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.memory.ByteStreamStateHandle.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.filesystem.FileStateHandle.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2022-6-16 01:00:00" id="27630" opendate="2022-5-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>maven-source-plugin for table planner values connector for debug</summary>
      <description>add test source jar to reponsitory  when user use this values connector in flink-table-planner just like kafka/pulsar connector. So user can find the values source code.and we just need upload the */factories/* because it will be too large to upload all the flink-table-planner test source code. // code placeholderjust like kafka/pulsar&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-test-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;test-jar-no-fork&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;archive&gt; &lt;!-- Globally exclude maven metadata, because it may accidentally bundle files we don't intend to --&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;/archive&gt; &lt;includes&gt; &lt;include&gt;**/factories/**&lt;/include&gt; &lt;include&gt;META-INF/LICENSE&lt;/include&gt; &lt;include&gt;META-INF/NOTICE&lt;/include&gt; &lt;/includes&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-6-16 01:00:00" id="27651" opendate="2022-5-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support CREATE FUNCTION USING JAR syntax</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.operations.SqlToOperationConverterTest.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.operations.SqlToOperationConverter.java</file>
      <file type="M">flink-table.flink-table-common.src.test.java.org.apache.flink.table.functions.UserDefinedFunctionHelperTest.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.CatalogFunction.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.operations.ddl.CreateTempSystemFunctionOperation.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.catalog.FunctionCatalog.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.catalog.CatalogFunctionImpl.java</file>
      <file type="M">flink-table.flink-sql-parser.src.test.java.org.apache.flink.sql.parser.FlinkSqlParserImplTest.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.resources.org.apache.flink.sql.parser.utils.ParserResource.properties</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.utils.ParserResource.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.java.org.apache.flink.sql.parser.ddl.SqlCreateFunction.java</file>
      <file type="M">flink-table.flink-sql-parser.src.main.codegen.includes.parserImpls.ftl</file>
      <file type="M">flink-table.flink-sql-parser.src.main.codegen.data.Parser.tdd</file>
      <file type="M">flink-table.flink-sql-parser-hive.src.main.codegen.includes.parserImpls.ftl</file>
      <file type="M">flink-python.pyflink.table.tests.test.catalog.completeness.py</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-17 01:00:00" id="27659" opendate="2022-5-17 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Planner support to use jar which is registered by "USING JAR" syntax</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.utils.TableTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.runtime.utils.StreamingTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.runtime.utils.BatchTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.runtime.batch.sql.PartitionableSourceITCase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.runtime.batch.sql.BatchFileSystemITCaseBase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.plan.utils.RexNodeExtractorTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.utils.PlannerMocks.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.runtime.stream.sql.FunctionITCase.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.runtime.batch.sql.ForwardHashExchangeITCase.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.runtime.batch.sql.CompactManagedTableITCase.java</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.runtime.batch.sql.agg.LocalAggregatePushDownITCase.java</file>
      <file type="M">flink-table.flink-table-api-scala-bridge.src.test.scala.org.apache.flink.table.api.bridge.scala.internal.StreamTableEnvironmentImplTest.scala</file>
      <file type="M">flink-table.flink-table-api-scala-bridge.src.main.scala.org.apache.flink.table.api.bridge.scala.internal.StreamTableEnvironmentImpl.scala</file>
      <file type="M">flink-table.flink-table-api-java.src.test.java.org.apache.flink.table.utils.TableEnvironmentMock.java</file>
      <file type="M">flink-table.flink-table-api-java.src.test.java.org.apache.flink.table.resource.ResourceManagerTest.java</file>
      <file type="M">flink-table.flink-table-api-java.src.test.java.org.apache.flink.table.catalog.FunctionCatalogTest.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.resource.ResourceManager.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.catalog.FunctionCatalog.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.internal.TableEnvironmentImpl.java</file>
      <file type="M">flink-table.flink-table-api-java-bridge.src.test.java.org.apache.flink.table.api.bridge.java.internal.StreamTableEnvironmentImplTest.java</file>
      <file type="M">flink-table.flink-table-api-java-bridge.src.main.java.org.apache.flink.table.api.bridge.java.internal.StreamTableEnvironmentImpl.java</file>
      <file type="M">flink-table.flink-table-api-bridge-base.src.main.java.org.apache.flink.table.api.bridge.internal.AbstractStreamTableEnvironmentImpl.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.service.context.SessionContext.java</file>
      <file type="M">flink-table.flink-sql-client.src.test.resources.sql.set.q</file>
      <file type="M">flink-table.flink-sql-client.src.test.resources.sql.function.q</file>
      <file type="M">flink-table.flink-sql-client.src.test.java.org.apache.flink.table.client.gateway.utils.UserDefinedFunctions.java</file>
      <file type="M">flink-table.flink-sql-client.src.test.java.org.apache.flink.table.client.gateway.local.LocalExecutorITCase.java</file>
      <file type="M">flink-table.flink-sql-client.src.test.java.org.apache.flink.table.client.gateway.local.DependencyTest.java</file>
      <file type="M">flink-table.flink-sql-client.src.test.java.org.apache.flink.table.client.gateway.context.SessionContextTest.java</file>
      <file type="M">flink-table.flink-sql-client.src.test.java.org.apache.flink.table.client.cli.CliClientITCase.java</file>
      <file type="M">flink-table.flink-sql-client.src.main.java.org.apache.flink.table.client.gateway.context.SessionContext.java</file>
      <file type="M">flink-table.flink-sql-client.src.main.java.org.apache.flink.table.client.gateway.context.ExecutionContext.java</file>
      <file type="M">flink-table.flink-sql-client.pom.xml</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.util.UserClassLoaderJarTestUtils.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.util.FlinkUserCodeClassLoaders.java</file>
      <file type="M">flink-clients.src.main.java.org.apache.flink.client.ClientUtils.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-7-19 01:00:00" id="27692" opendate="2022-5-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support local recovery for materialized part(write, restore, discard)</summary>
      <description>Support local recovery for materialized part(write, restore, discard)</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.ChangelogPeriodicMaterializationTestBase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.TaskLocalStateStoreImplTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManagerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.taskexecutor.TaskExecutor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.TaskLocalStateStoreImpl.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.minicluster.MiniCluster.java</file>
      <file type="M">flink-state-backends.flink-statebackend-changelog.src.test.java.org.apache.flink.state.changelog.ChangelogKeyedStateBackendTest.java</file>
      <file type="M">flink-state-backends.flink-statebackend-changelog.src.main.java.org.apache.flink.state.changelog.ChangelogKeyedStateBackend.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-7-25 01:00:00" id="27767" opendate="2022-5-25 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Introduce Endpoint API and utils</summary>
      <description/>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.factories.FactoryUtil.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2022-1-25 01:00:00" id="27779" opendate="2022-5-25 00:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Connectors should not depend on `flink-table-planner`</summary>
      <description>Connector modules currently rely heavily on `flink-table-planner` as a test dependency for testing the ITCases with 'DynamicTableX' using the TableFactory to load the respective connector. There is now a better way that only requires to have `flink-table-test-utils` as a test dependency. Therefore all connectors should be migrated to using the new way.</description>
      <version>1.16.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-kinesis.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-cassandra.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kafka.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-aws-kinesis-streams.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-aws-kinesis-firehose.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-10-29 01:00:00" id="2778" opendate="2015-9-29 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add API for non-parallel non-keyed Windows</summary>
      <description>This addresses the NonParallelWindowStream section in the design doc: https://cwiki.apache.org/confluence/display/FLINK/Streams+and+Operations+on+Streams</description>
      <version>None</version>
      <fixedVersion>0.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-staging.flink-streaming.flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.StreamingScalaAPICompletenessTest.scala</file>
      <file type="M">flink-staging.flink-streaming.flink-streaming-core.src.test.java.org.apache.flink.streaming.runtime.operators.windowing.TimeWindowTranslationTest.java</file>
      <file type="M">flink-staging.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.functions.windowing.ReduceWindowFunction.java</file>
      <file type="M">flink-staging.flink-streaming.flink-streaming-core.src.main.java.org.apache.flink.streaming.api.datastream.DataStream.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-6-27 01:00:00" id="27811" opendate="2022-5-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove netty dependency in flink-test-utils</summary>
      <description>For some reason we bundle a relocated version of netty in flink-test-utils. AFAICT this should be unnecessary because nothing makes use of the relocated version.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.resources.META-INF.licenses.LICENSE.webbit</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.resources.META-INF.licenses.LICENSE.jzlib</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.resources.META-INF.licenses.LICENSE.jsr166y</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.resources.META-INF.licenses.LICENSE.base64</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-28 01:00:00" id="27822" opendate="2022-5-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Translate the doc of checkpoint/savepoint guarantees</summary>
      <description>Translate the change of FLINK-26134 </description>
      <version>1.15.0,1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.zh.docs.ops.state.savepoints.md</file>
      <file type="M">docs.content.zh.docs.ops.state.checkpoints.vs.savepoints.md</file>
      <file type="M">docs.content.zh.docs.ops.state.checkpoints.md</file>
      <file type="M">docs.content.zh.docs.concepts.stateful-stream-processing.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-31 01:00:00" id="27856" opendate="2022-5-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding pod template without spec crashes job manager</summary>
      <description>While trying to add Pod annotation through pod template in FlinkDeployment, taskmanager was keep crashing.Pod template that I used: taskManager: podTemplate: apiVersion: v1 kind: Pod metadata: annotations: iam.amazonaws.com/role: fake-role-arnIt created below ConfigMap and mounted to the deployment:apiVersion: v1data: taskmanager-pod-template.yaml: | --- apiVersion: "v1" kind: "Pod" metadata: annotations: iam.amazonaws.com/role: "fake-role-arn"kind: ConfigMapLooks like missing "spec" stanza in pod template resulted in the crash and I couldn't find any documentation that "spec" is required for pod template even for just adding metadata annotations.Adding below worked fine taskManager: podTemplate: apiVersion: v1 kind: Pod metadata: annotations: iam.amazonaws.com/role: fake-role-arn spec: {}Corresponding ConfigMapapiVersion: v1data: taskmanager-pod-template.yaml: | --- apiVersion: "v1" kind: "Pod" metadata: annotations: iam.amazonaws.com/role: "fake-role-arn" spec: containers: []</description>
      <version>None</version>
      <fixedVersion>1.16.0,1.15.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-kubernetes.src.test.java.org.apache.flink.kubernetes.utils.KubernetesUtilsTest.java</file>
      <file type="M">flink-kubernetes.src.test.java.org.apache.flink.kubernetes.KubernetesPodTemplateTestUtils.java</file>
      <file type="M">flink-kubernetes.src.main.java.org.apache.flink.kubernetes.utils.KubernetesUtils.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-10-29 01:00:00" id="2786" opendate="2015-9-29 00:00:00" resolution="Done">
    <buginformation>
      <summary>Remove Spargel from source code and update documentation in favor of Gelly</summary>
      <description>With Gelly getting more mature and ready to be top level project for Flink, we need to remove deprecated Spargel library from source and documentation.Gelly copies the library needed from Spargel so there should not be hard dependency between the 2 modules.</description>
      <version>None</version>
      <fixedVersion>0.10.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-staging.pom.xml</file>
      <file type="M">flink-staging.flink-spargel.src.test.resources.logback-test.xml</file>
      <file type="M">flink-staging.flink-spargel.src.test.resources.log4j-test.properties</file>
      <file type="M">flink-staging.flink-spargel.src.test.java.org.apache.flink.test.spargel.SpargelConnectedComponentsITCase.java</file>
      <file type="M">flink-staging.flink-spargel.src.test.java.org.apache.flink.spargel.java.SpargelTranslationTest.java</file>
      <file type="M">flink-staging.flink-spargel.src.test.java.org.apache.flink.spargel.java.SpargelCompilerTest.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.VertexUpdateFunction.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.VertexCentricIteration.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.record.VertexUpdateFunction.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.record.SpargelIteration.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.record.MessagingFunction.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.record.MessageIterator.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.record.Edge.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.OutgoingEdge.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.MessagingFunction.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.MessageIterator.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.examples.SpargelPageRankCountingVertices.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.examples.SpargelPageRank.java</file>
      <file type="M">flink-staging.flink-spargel.src.main.java.org.apache.flink.spargel.java.examples.SpargelConnectedComponents.java</file>
      <file type="M">flink-staging.flink-spargel.pom.xml</file>
      <file type="M">docs..includes.navbar.html</file>
      <file type="M">docs.libs.spargel.guide.md</file>
      <file type="M">docs.libs.gelly.guide.md</file>
      <file type="M">docs.libs.fig.spargel.example.input.png</file>
      <file type="M">docs.libs.fig.spargel.example.png</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-6-1 01:00:00" id="27861" opendate="2022-6-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce UserResourceManager to manage user defined resource</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.config.TableConfigOptions.java</file>
      <file type="M">flink-table.flink-table-api-java.pom.xml</file>
      <file type="M">flink-core.src.test.java.org.apache.flink.util.UserClassLoaderJarTestUtils.java</file>
      <file type="M">docs.layouts.shortcodes.generated.table.config.configuration.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-1 01:00:00" id="27865" opendate="2022-6-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add guide and example for configuring SASL and SSL in Kafka SQL connector document</summary>
      <description>Using SASL and SSL in Kafka connector is a common case and usually quite complex for new users that not quite familiar with the design of Kafka connector, so it would be helpful to add a guidance of how to enable these security options in Kafka connector.</description>
      <version>1.14.4,1.15.0,1.16.0</version>
      <fixedVersion>1.16.0,1.15.2,1.14.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.connectors.table.kafka.md</file>
      <file type="M">docs.content.docs.connectors.datastream.kafka.md</file>
      <file type="M">docs.content.zh.docs.connectors.table.kafka.md</file>
      <file type="M">docs.content.zh.docs.connectors.datastream.kafka.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-2 01:00:00" id="27878" opendate="2022-6-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[FLIP-232] Add Retry Support For Async I/O In DataStream API</summary>
      <description>FLIP-232: Add Retry Support For Async I/O In DataStream APIhttps://cwiki.apache.org/confluence/pages/viewpage.action?pageId=211883963</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-scala.src.test.scala.org.apache.flink.streaming.api.scala.AsyncDataStreamITCase.scala</file>
      <file type="M">flink-streaming-scala.src.main.scala.org.apache.flink.streaming.api.scala.AsyncDataStream.scala</file>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorFactory.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.async.AsyncWaitOperator.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.datastream.AsyncDataStream.java</file>
      <file type="M">docs.content.docs.dev.datastream.operators.asyncio.md</file>
      <file type="M">docs.content.zh.docs.dev.datastream.operators.asyncio.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-6-4 01:00:00" id="27895" opendate="2022-6-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable the CI test for Hive&amp;#39;s 3.x</summary>
      <description>We only enable Ci test for Hive's 2.3.9,  we also need enable the test for Hive's 3.x to guarantee the compatibility for Hive 3.x .</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.azure-pipelines.build-apache-repo.yml</file>
      <file type="M">flink-connectors.flink-connector-hive.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-10-30 01:00:00" id="2792" opendate="2015-9-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Set log level of actor messages to TRACE</summary>
      <description>Logging of received job manager actor messages happens at log level DEBUG right now. The used logger is that of the JobManager/TaskManager respectively. This means that as soon as you debug something related to the JobManager/TaskManager you are always flooded with a lot of debug messages.Therefore, I would like to set the log level to TRACE for these messages.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.scala.org.apache.flink.runtime.LogMessages.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-6-6 01:00:00" id="27920" opendate="2022-6-6 00:00:00" resolution="Done">
    <buginformation>
      <summary>Documented enums constant support ExcludeFromDocumentation annotation</summary>
      <description>if a config option has @ExcludeFromDocumentation annotation, it will not appear in the document. But for an enumeration type, sometimes we only want some of it's constant values not to appear in the document, this ticket solves this problem.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.HiveDialectQueryPlanTest.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.HiveDialectAggITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.module.hive.HiveModule.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.functions.hive.HiveSumAggFunction.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.functions.hive.HiveDeclarativeAggregateFunction.java</file>
      <file type="M">flink-metrics.flink-metrics-influxdb.src.main.java.org.apache.flink.metrics.influxdb.InfluxdbReporterOptions.java</file>
      <file type="M">flink-docs.src.test.java.org.apache.flink.docs.configuration.ConfigOptionsDocGeneratorTest.java</file>
      <file type="M">flink-docs.src.main.java.org.apache.flink.docs.configuration.ConfigOptionsDocGenerator.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-7 01:00:00" id="27931" opendate="2022-6-7 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Introduce the SqlGateway to assemble all components</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-sql-gateway.src.test.java.org.apache.flink.table.gateway.service.utils.SqlGatewayServiceExtension.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.service.context.DefaultContext.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.src.test.java.org.apache.flink.table.gateway.api.utils.MockedSqlGatewayEndpointFactory.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.src.test.java.org.apache.flink.table.gateway.api.utils.MockedSqlGatewayEndpoint.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.src.test.java.org.apache.flink.table.gateway.api.endpoint.SqlGatewayEndpointFactoryUtilsTest.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2022-7-10 01:00:00" id="27990" opendate="2022-6-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parquet format supports reporting statistics</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.catalog.CatalogStatisticsTest.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.utils.CatalogTableStatisticsConverter.java</file>
      <file type="M">flink-formats.pom.xml</file>
      <file type="M">flink-formats.flink-parquet.src.main.java.org.apache.flink.formats.parquet.vector.reader.TimestampColumnReader.java</file>
      <file type="M">flink-formats.flink-parquet.src.main.java.org.apache.flink.formats.parquet.ParquetFileFormatFactory.java</file>
      <file type="M">flink-formats.flink-parquet.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-10 01:00:00" id="27991" opendate="2022-6-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ORC format supports reporting statistics</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.utils.StatisticsReportTestBase.java</file>
      <file type="M">flink-formats.flink-orc.src.main.java.org.apache.flink.orc.OrcFileFormatFactory.java</file>
      <file type="M">flink-formats.flink-orc.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-2-10 01:00:00" id="27995" opendate="2022-6-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Janino version</summary>
      <description>Currently, the Janino version doesn't support JDK11 well.  https://lists.apache.org/thread/q052xdn1mnhjm9k4ojjjz22dk4r1xwfz</description>
      <version>1.16.0</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.pom.xml</file>
      <file type="M">flink-table.flink-table-runtime.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.CodeGenUtils.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.calcite.util.javac.JaninoCompiler.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.calcite.rel.metadata.JaninoRelMetadataProvider.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.calcite.interpreter.JaninoRexCompiler.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.calcite.adapter.enumerable.EnumerableInterpretable.java</file>
      <file type="M">flink-formats.flink-protobuf.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-10 01:00:00" id="27996" opendate="2022-6-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive dialect support INTERVAL type</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.planner.delegation.hive.SqlFunctionConverter.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.planner.delegation.hive.HiveParserTypeCheckProcFactory.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.module.hive.HiveModule.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.functions.hive.conversion.HiveInspectors.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.catalog.hive.util.HiveTypeUtil.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-6-10 01:00:00" id="28002" opendate="2022-6-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>test_connectors.py failed with "object is not an instance of declaring class" in JDK11</summary>
      <description>2022-06-10T02:43:20.7206790Z Jun 10 02:43:20 E : java.lang.IllegalArgumentException: object is not an instance of declaring class2022-06-10T02:43:20.7207481Z Jun 10 02:43:20 E at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)2022-06-10T02:43:20.7208200Z Jun 10 02:43:20 E at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)2022-06-10T02:43:20.7209003Z Jun 10 02:43:20 E at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)2022-06-10T02:43:20.7209720Z Jun 10 02:43:20 E at java.base/java.lang.reflect.Method.invoke(Method.java:566)2022-06-10T02:43:20.7210572Z Jun 10 02:43:20 E at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)2022-06-10T02:43:20.7211291Z Jun 10 02:43:20 E at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)2022-06-10T02:43:20.7212101Z Jun 10 02:43:20 E at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)2022-06-10T02:43:20.7212796Z Jun 10 02:43:20 E at java.base/java.lang.reflect.Method.invoke(Method.java:566)2022-06-10T02:43:20.7213500Z Jun 10 02:43:20 E at org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)2022-06-10T02:43:20.7214327Z Jun 10 02:43:20 E at org.apache.flink.api.python.shaded.py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)2022-06-10T02:43:20.7215097Z Jun 10 02:43:20 E at org.apache.flink.api.python.shaded.py4j.Gateway.invoke(Gateway.java:282)2022-06-10T02:43:20.7215885Z Jun 10 02:43:20 E at org.apache.flink.api.python.shaded.py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)2022-06-10T02:43:20.7216700Z Jun 10 02:43:20 E at org.apache.flink.api.python.shaded.py4j.commands.CallCommand.execute(CallCommand.java:79)2022-06-10T02:43:20.7217558Z Jun 10 02:43:20 E at org.apache.flink.api.python.shaded.py4j.GatewayConnection.run(GatewayConnection.java:238)2022-06-10T02:43:20.7218225Z Jun 10 02:43:20 E at java.base/java.lang.Thread.run(Thread.java:829)https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=36508&amp;view=logs&amp;j=e92ecf6d-e207-5a42-7ff7-528ff0c5b259&amp;t=40fc352e-9b4c-5fd8-363f-628f24b01ec2</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.pyflink.util.java.utils.py</file>
      <file type="M">flink-python.pyflink.table.environment.settings.py</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2022-8-21 01:00:00" id="28151" opendate="2022-6-21 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Allow to cancel the Operation for the HiveServer2 Endpoint</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.table.endpoint.hive.util.HiveServer2EndpointExtension.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.table.endpoint.hive.HiveServer2EndpointStatementITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.table.endpoint.hive.HiveServer2EndpointITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.endpoint.hive.HiveServer2Endpoint.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-21 01:00:00" id="28163" opendate="2022-6-21 00:00:00" resolution="Done">
    <buginformation>
      <summary>Introduce the statement related API for REST endpoint</summary>
      <description>It includes executeStatement, fetchResults API in the FLIP-91.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-sql-gateway.src.test.java.org.apache.flink.table.gateway.rest.OperationCaseITTest.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.rest.SqlGatewayRestEndpoint.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.src.main.java.org.apache.flink.table.gateway.api.results.ResultSet.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.pom.xml</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.src.main.java.org.apache.flink.architecture.rules.TableApiRules.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-21 01:00:00" id="28164" opendate="2022-6-21 00:00:00" resolution="Done">
    <buginformation>
      <summary>Introduce utilities API for REST endpint</summary>
      <description>It includes heartbeat, get_info, api_versions API in the REST endpoint.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.rest.SqlGatewayRestEndpoint.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-11-21 01:00:00" id="28165" opendate="2022-6-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove include_hadoop_aws profile</summary>
      <description>The profile should be merged into the default configurations, because it was specific for Hadoop 2.6+ but we upgrade Hadoop to 2.8.5.</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.azure-pipelines.build-apache-repo.yml</file>
      <file type="M">flink-yarn.src.test.java.org.apache.flink.yarn.YarnFileStageTestS3ITCase.java</file>
      <file type="M">flink-yarn.pom.xml</file>
      <file type="M">azure-pipelines.yml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-6-21 01:00:00" id="28173" opendate="2022-6-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Multiple Parquet format tests are failing with NoSuchMethodError</summary>
      <description>Jun 21 02:44:38 java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)VJun 21 02:44:38 at org.apache.hadoop.conf.Configuration.set(Configuration.java:1357)Jun 21 02:44:38 at org.apache.hadoop.conf.Configuration.set(Configuration.java:1338)Jun 21 02:44:38 at org.apache.hadoop.conf.Configuration.readFields(Configuration.java:3798)Jun 21 02:44:38 at org.apache.flink.formats.parquet.utils.SerializableConfiguration.readObject(SerializableConfiguration.java:50)Jun 21 02:44:38 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)Jun 21 02:44:38 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)Jun 21 02:44:42 [ERROR] Run 1: com.google.common.base.Preconditions.checkState(ZLjava/lang/String;I)VJun 21 02:44:42 [ERROR] Run 2: com.google.common.base.Preconditions.checkState(ZLjava/lang/String;I)VJun 21 02:44:42 [INFO] Jun 21 02:44:42 [ERROR] ParquetColumnarRowSplitReaderTest.testProjectJun 21 02:44:42 [ERROR] Run 1: com.google.common.base.Preconditions.checkState(ZLjava/lang/String;I)VJun 21 02:44:42 [ERROR] Run 2: com.google.common.base.Preconditions.checkState(ZLjava/lang/String;I)VJun 21 02:44:42 [INFO] Jun 21 02:44:42 [ERROR] ParquetColumnarRowSplitReaderTest.testReachEndJun 21 02:44:42 [ERROR] Run 1: com.google.common.base.Preconditions.checkState(ZLjava/lang/String;I)VJun 21 02:44:42 [ERROR] Run 2: com.google.common.base.Preconditions.checkState(ZLjava/lang/String;I)VJun 21 02:44:42 [INFO] Jun 21 02:44:42 [ERROR] AvroParquetRecordFormatTest.testCreateGenericReader:161-&gt;createReader:269 » NoSuchMethodJun 21 02:44:42 [ERROR] AvroParquetRecordFormatTest.testCreateReflectReader:133-&gt;createReader:269 » NoSuchMethodJun 21 02:44:42 [ERROR] AvroParquetRecordFormatTest.testCreateSpecificReader:118-&gt;createReader:269 » NoSuchMethodJun 21 02:44:42 [ERROR] AvroParquetRecordFormatTest.testReadWithRestoreGenericReader:203-&gt;restoreReader:293 » NoSuchMethodJun 21 02:44:42 [ERROR] AvroParquetRecordFormatTest.testReflectReadFromGenericRecords:147-&gt;createReader:269 » NoSuchMethodJun 21 02:44:42 [ERROR] ParquetRowDataWriterTest.testCompression:126 » NoSuchMethod com.google.common....Jun 21 02:44:42 [ERROR] ParquetRowDataWriterTest.testTypes:117-&gt;innerTest:168 » NoSuchMethod com.googl...Jun 21 02:44:42 [ERROR] SerializableConfigurationTest.testResource:45 » NoSuchMethod com.google.common...Jun 21 02:44:42 [INFO] Jun 21 02:44:42 [ERROR] Tests run: 31, Failures: 0, Errors: 24, Skipped: 0Jun 21 02:44:42 [INFO] https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=36979&amp;view=logs&amp;j=7e3d33c3-a462-5ea8-98b8-27e1aafe4ceb&amp;t=ef77f8d1-44c8-5ee2-f175-1c88f61de8c0&amp;l=16375</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-formats.flink-parquet.pom.xml</file>
      <file type="M">flink-formats.flink-orc.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-6-21 01:00:00" id="28175" opendate="2022-6-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve LicenseChecker output</summary>
      <description>The license checker output is difficult to parse for people who aren't too familiar with it. They just get bombarded with 200 log lines, that are too long, with too much redundant information, with no quick way to identify whether they are relevant for a particular change (e.g., module) without any guidance on whether something is critical or not.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.ci.java-ci-tools.src.main.java.org.apache.flink.tools.ci.licensecheck.NoticeFileChecker.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-21 01:00:00" id="28182" opendate="2022-6-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support Avro generic record decoder in PyFlink</summary>
      <description>Avro generic record decoder is useful for format like parquet-avro, which enables PyFlink users read parquet files into python native objects within a given avro schema.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.utils.PythonTypeUtils.java</file>
      <file type="M">flink-python.setup.py</file>
      <file type="M">flink-python.pyflink.proto.flink-fn-execution.proto</file>
      <file type="M">flink-python.pyflink.fn.execution.flink.fn.execution.pb2.py</file>
      <file type="M">flink-python.pyflink.fn.execution.coder.impl.slow.py</file>
      <file type="M">flink-python.pyflink.fn.execution.coder.impl.fast.pyx</file>
      <file type="M">flink-python.pyflink.fn.execution.coder.impl.fast.pxd</file>
      <file type="M">flink-python.pyflink.fn.execution.coders.py</file>
      <file type="M">flink-python.pyflink.datastream.utils.py</file>
      <file type="M">flink-python.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-6-22 01:00:00" id="28195" opendate="2022-6-22 00:00:00" resolution="Done">
    <buginformation>
      <summary>Annotate Python3.6 as deprecated in PyFlink 1.16</summary>
      <description>Python 3.6 extended support end on 23 December 2021. We plan that PyFlink 1.16 will be the last version support Python3.6.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.setup.py</file>
      <file type="M">flink-python.tox.ini</file>
      <file type="M">flink-python.dev.lint-python.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-6-23 01:00:00" id="28217" opendate="2022-6-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump mysql-connector-java from 8.0.27 to 8.0.28</summary>
      <description>We should bump our test dependency for mysql-connector-java to make sure that we support the latest version of MySQLThis will also address CVE-2022-21363 and CVE-2021-22569</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-jdbc.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-6-27 01:00:00" id="28259" opendate="2022-6-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>flink-parquet doesn&amp;#39;t compile on M1 mac without rosetta</summary>
      <description>Compiling Flink 1.16-SNAPSHOT fails on an M1 Mac (apple silicon) without the rosetta translation layer, because the automatically downloaded "protoc-3.17.3-osx-aarch_64.exe" file is actually just a copy of "protoc-3.17.3-osx-x86_64.exe". (as you can read here: https://github.com/os72/protoc-jar/issues/93)This is the error:[ERROR] Failed to execute goal org.xolstice.maven.plugins:protobuf-maven-plugin:0.5.1:test-compile (default) on project flink-parquet: An error occurred while invoking protoc. Error while executing process. Cannot run program "/Users/rmetzger/Projects/flink/flink-formats/flink-parquet/target/protoc-plugins/protoc-3.17.3-osx-aarch_64.exe": error=86, Bad CPU type in executable -&gt; [Help 1]</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-python.src.main.resources.META-INF.NOTICE</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-7-30 01:00:00" id="28314" opendate="2022-6-30 00:00:00" resolution="Done">
    <buginformation>
      <summary>[UI] Introduce "Cluster Environment" tab under history server</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.detail.job-overview-drawer-detail.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.customize.refresh-download.refresh-download.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.customize.refresh-download.refresh-download.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.customize.refresh-download.refresh-download.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.common.navigation.navigation.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.thread-dump.task-manager-thread-dump.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.thread-dump.task-manager-thread-dump.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.task-manager.module.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.task-manager.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.task-manager.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.stdout.task-manager-stdout.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.stdout.task-manager-stdout.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.stdout.task-manager-stdout.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.status.task-manager-status.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.status.task-manager-status.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.status.task-manager-status.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.metrics.task-manager-metrics.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.metrics.task-manager-metrics.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.metrics.task-manager-metrics.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.logs.task-manager-logs.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.logs.task-manager-logs.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.log-list.task-manager-log-list.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.log-list.task-manager-log-list.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.log-detail.task-manager-log-detail.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.log-detail.task-manager-log-detail.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.log-detail.task-manager-log-detail.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.list.task-manager-list.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.list.task-manager-list.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.list.task-manager-list.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.watermarks.job-overview-drawer-watermarks.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.watermarks.job-overview-drawer-watermarks.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.watermarks.job-overview-drawer-watermarks.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.taskmanagers.job-overview-drawer-taskmanagers.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.taskmanagers.job-overview-drawer-taskmanagers.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.taskmanagers.job-overview-drawer-taskmanagers.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.subtasks.job-overview-drawer-subtasks.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.subtasks.job-overview-drawer-subtasks.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.subtasks.job-overview-drawer-subtasks.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.list.job-overview-list.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.job-overview.module.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.drawer.job-overview-drawer.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.detail.job-overview-drawer-detail.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.app.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.app.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.configuration.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.job-manager.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.configuration.job-manager-configuration.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.configuration.job-manager-configuration.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.configuration.job-manager-configuration.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.job-manager.config.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.metrics.job-manager-metrics.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.job-routing.module.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.job.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.job.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.job.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.job.module.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.drawer.job-overview-drawer.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.job-overview.config.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.status.job-status.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.status.job-status.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.status.job-status.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.overview.overview.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.overview.overview.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.submit.submit.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.task-manager.config.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.services.job-manager.service.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.customize.job-list.job-list.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.share.module.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.job-detail.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.job-manager.module.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.log-detail.job-manager-log-detail.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.log-detail.job-manager-log-detail.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.log-detail.job-manager-log-detail.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.log-list.job-manager-log-list.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.log-list.job-manager-log-list.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.log-list.job-manager-log-list.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.logs.job-manager-logs.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.logs.job-manager-logs.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.metrics.job-manager-metrics.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.metrics.job-manager-metrics.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.stdout.job-manager-stdout.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.stdout.job-manager-stdout.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.thread-dump.job-manager-thread-dump.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job-manager.thread-dump.job-manager-thread-dump.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.job-local.service.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.accumulators.job-overview-drawer-accumulators.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.accumulators.job-overview-drawer-accumulators.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.accumulators.job-overview-drawer-accumulators.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.backpressure.job-overview-drawer-backpressure.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.backpressure.job-overview-drawer-backpressure.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.backpressure.job-overview-drawer-backpressure.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.detail.job-overview-drawer-detail.component.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-30 01:00:00" id="28315" opendate="2022-6-30 00:00:00" resolution="Done">
    <buginformation>
      <summary>[UI] Introduce aggregate stats in tables of the subtasks and taskmanagers</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.share.module.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.pipes.humanize-bytes.pipe.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.services.job.service.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.task-manager-local.service.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.taskmanagers.table-action.taskmanagers-table-action.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.taskmanagers.table-action.taskmanagers-table-action.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.taskmanagers.table-action.taskmanagers-table-action.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.subtasks.table-action.subtasks-table-action.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.subtasks.job-overview-drawer-subtasks.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.subtasks.job-overview-drawer-subtasks.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.subtasks.job-overview-drawer-subtasks.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.job-overview.module.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.job-overview.config.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.modules.completed-job.completed-job.module.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.public-api.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.job-vertex-task-manager.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.job-subtask.ts</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-30 01:00:00" id="28316" opendate="2022-6-30 00:00:00" resolution="Done">
    <buginformation>
      <summary>[UI] add external JM and TM log links under history server</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.styles.rewrite.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.share.module.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.customize.task-badge.task-badge.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.common.status.job-status.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.common.status.job-status.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.common.status.job-status.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.services.task-manager.service.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.services.job-manager.service.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.modules.completed-job.completed-job.module.ts</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-30 01:00:00" id="28329" opendate="2022-6-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>List top 15 biggest directories in terms of used disk space</summary>
      <description>We are having the situation where a lot of disk space gets used by both Bash and Java E2E tests. In order to identify which tests aren't properly cleaning up, it would be good if we output the top 15 directories which are the biggest in used disk space</description>
      <version>None</version>
      <fixedVersion>1.16.0,1.15.2,1.14.6</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.ci.controller.utils.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test-runner-common.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-11-30 01:00:00" id="28330" opendate="2022-6-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove old delegation token framework code when new is working fine</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.YarnClusterDescriptor.java</file>
      <file type="M">flink-yarn.src.main.java.org.apache.flink.yarn.Utils.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-1 01:00:00" id="28355" opendate="2022-7-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Python Bash e2e tests don&amp;#39;t clean-up after they&amp;#39;ve ran, causing disk space issues</summary>
      <description>The Bash based E2E tests that are used in Python aren't cleaned-up after they've ran. These cause disk space issues further downstream.See the CI run from https://github.com/apache/flink/pull/20114 for results, for example:&amp;#8211; When starting with the Bash e2e tests08:47:10 ##[group]Top 15 biggest directories in terms of used disk spaceJul 01 08:47:12 3983560 .Jul 01 08:47:12 1266692 ./flink-end-to-end-testsJul 01 08:47:12 624568 ./flink-distJul 01 08:47:12 624180 ./flink-dist/targetJul 01 08:47:12 500076 ./flink-dist/target/flink-1.16-SNAPSHOT-binJul 01 08:47:12 500072 ./flink-dist/target/flink-1.16-SNAPSHOT-bin/flink-1.16-SNAPSHOTJul 01 08:47:12 460812 ./flink-connectorsJul 01 08:47:12 392588 ./.gitJul 01 08:47:12 366396 ./.git/objectsJul 01 08:47:12 366388 ./.git/objects/packJul 01 08:47:12 349272 ./flink-tableJul 01 08:47:12 335592 ./.git/objects/pack/pack-38d46915823ebec2bc660fd160e5cfca5bc3e567.packJul 01 08:47:12 293044 ./flink-dist/target/flink-1.16-SNAPSHOT-bin/flink-1.16-SNAPSHOT/optJul 01 08:47:12 251272 ./flink-filesystemsJul 01 08:47:12 246596 ./flink-end-to-end-tests/flink-streaming-kinesis-testhttps://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=37425&amp;view=logs&amp;j=ef799394-2d67-5ff4-b2e5-410b80c9c0af&amp;t=860bfb5d-81b0-5968-f128-2a8b5362110d&amp;l=664&amp;#8211; After completing all Bash bashed e2e tests:2022-07-01T10:20:17.3594718Z Jul 01 10:20:17 ##[group]Top 15 biggest directories in terms of used disk space2022-07-01T10:20:18.7520631Z Jul 01 10:20:18 5425892 .2022-07-01T10:20:18.7521823Z Jul 01 10:20:18 1521472 ./flink-end-to-end-tests2022-07-01T10:20:18.7522566Z Jul 01 10:20:18 1242528 ./flink-python2022-07-01T10:20:18.7523244Z Jul 01 10:20:18 952336 ./flink-python/dev2022-07-01T10:20:18.7524159Z Jul 01 10:20:18 878764 ./flink-python/dev/.conda2022-07-01T10:20:18.7524870Z Jul 01 10:20:18 834200 ./flink-python/dev/.conda/lib2022-07-01T10:20:18.7525619Z Jul 01 10:20:18 726528 ./flink-python/dev/.conda/lib/python3.72022-07-01T10:20:18.7526397Z Jul 01 10:20:18 683256 ./flink-python/dev/.conda/lib/python3.7/site-packages2022-07-01T10:20:18.7527101Z Jul 01 10:20:18 624568 ./flink-dist2022-07-01T10:20:18.7527768Z Jul 01 10:20:18 624180 ./flink-dist/target2022-07-01T10:20:18.7528494Z Jul 01 10:20:18 500076 ./flink-dist/target/flink-1.16-SNAPSHOT-bin2022-07-01T10:20:18.7529298Z Jul 01 10:20:18 500072 ./flink-dist/target/flink-1.16-SNAPSHOT-bin/flink-1.16-SNAPSHOT2022-07-01T10:20:18.7530046Z Jul 01 10:20:18 460812 ./flink-connectors2022-07-01T10:20:18.7530546Z Jul 01 10:20:18 392588 ./.git2022-07-01T10:20:18.7531014Z Jul 01 10:20:18 366396 ./.git/objectshttps://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=37425&amp;view=logs&amp;j=ef799394-2d67-5ff4-b2e5-410b80c9c0af&amp;t=860bfb5d-81b0-5968-f128-2a8b5362110d&amp;l=9631</description>
      <version>1.16.0,1.15.2,1.14.6</version>
      <fixedVersion>1.16.0,1.15.2,1.14.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.dev.lint-python.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.pyflink.yarn.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.pyflink.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test.kubernetes.pyflink.application.sh</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2022-7-5 01:00:00" id="28388" opendate="2022-7-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Python doc build breaking nightly docs</summary>
      <description>For the past 5 days the nightly doc builds via GHA are broken:https://github.com/apache/flink/actions/workflows/docs.ymlException occurred: File "/root/flink/flink-python/pyflink/java_gateway.py", line 86, in launch_gateway raise Exception("It's launching the PythonGatewayServer during Python UDF execution "Exception: It's launching the PythonGatewayServer during Python UDF execution which is unexpected. It usually happens when the job codes are in the top level of the Python script file and are not enclosed in a `if name == 'main'` statement.The full traceback has been saved in /tmp/sphinx-err-3thh_wi2.log, if you want to report the issue to the developers.Please also report this if it was a user error, so that a better error message can be provided next time.A bug report can be filed in the tracker at &lt;https://github.com/sphinx-doc/sphinx/issues&gt;. Thanks!Makefile:76: recipe for target 'html' failedmake: *** [html] Error 2==========sphinx checks... [FAILED]===========Error: Process completed with exit code 1.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.dev.lint-python.sh</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-8-6 01:00:00" id="28417" opendate="2022-7-6 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add interface and default implementation for cache in lookup table</summary>
      <description>Add interfaces for cache in lookup table, including LookupCache, a default implementation DefaultLookupCache, and cache related metric group</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.MetricNames.java</file>
      <file type="M">flink-metrics.flink-metrics-core.src.main.java.org.apache.flink.metrics.groups.UnregisteredMetricsGroup.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-7-6 01:00:00" id="28426" opendate="2022-7-6 00:00:00" resolution="Done">
    <buginformation>
      <summary>PyFlink provides M1 wheel package</summary>
      <description>In FLINK-25188, pyflink has provided the support of M1 on MacOS. We also need to provide M1 wheel package.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.azure-pipelines.build-python-wheels.yml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2022-8-11 01:00:00" id="28492" opendate="2022-7-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support "ANALYZE TABLE" execution</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.runtime.batch.sql.TableSourceITCase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.factories.TestValuesCatalog.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.operations.SqlToOperationConverter.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.stats.Date.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.stats.CatalogTableStatistics.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.stats.CatalogColumnStatisticsDataString.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.stats.CatalogColumnStatisticsDataLong.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.stats.CatalogColumnStatisticsDataDouble.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.stats.CatalogColumnStatisticsDataDate.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.stats.CatalogColumnStatisticsDataBoolean.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.stats.CatalogColumnStatisticsDataBinary.java</file>
      <file type="M">flink-table.flink-table-common.src.main.java.org.apache.flink.table.catalog.stats.CatalogColumnStatistics.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.internal.TableEnvironmentImpl.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-11 01:00:00" id="28493" opendate="2022-7-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add document to describe "ANALYZE TABLE" syntax</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.dev.table.sql.overview.md</file>
      <file type="M">docs.content.zh.docs.dev.table.sql.overview.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-11 01:00:00" id="28495" opendate="2022-7-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix typos or mistakes of Flink CEP Document in the official website</summary>
      <description>1. "how you can migrate your job from an older Flink version to Flink-1.3." -&gt; "how you can migrate your job from an older Flink version to Flink-1.13."2. "Will generate the following matches for an input sequence: C D A1 A2 A3 D A4 B. with combinations enabled: { C A1 B}, {C A1 A2 B}, {C A1 A3 B}, {C A1 A4 B}, {C A1 A2 A3 B}, {C A1 A2 A4 B}, {C A1 A3 A4 B}, {C A1 A2 A3 A4 B}" -&gt; "Will generate the following matches for an input sequence: C D A1 A2 A3 D A4 B. with combinations enabled: {C A1 B}, {C A1 A2 B}, {C A1 A3 B}, {C A1 A4 B}, {C A1 A2 A3 B}, {C A1 A2 A4 B}, {C A1 A3 A4 B}, {C A1 A2 A3 A4 B}, {C A2 B}, {C A2 A3 B}, {C A2 A4 B}, {C A2 A3 A4 B}, {C A3 B}, {C A3 A4 B}, {C A4 B}"3. "For SKIP_TO_FIRST/LAST there are two options how to handle cases when there are no elements mapped to the specified variable." -&gt; "For SKIP_TO_FIRST/LAST there are two options how to handle cases when there are no events mapped to the PatternName."</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.libs.cep.md</file>
      <file type="M">docs.content.zh.docs.libs.cep.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-7-14 01:00:00" id="28544" opendate="2022-7-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Elasticsearch6SinkE2ECase failed with no space left on device</summary>
      <description>2022-07-13T02:49:13.5455800Z Jul 13 02:49:13 [ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 49.38 s &lt;&lt;&lt; FAILURE! - in org.apache.flink.streaming.tests.Elasticsearch6SinkE2ECase2022-07-13T02:49:13.5465965Z Jul 13 02:49:13 [ERROR] org.apache.flink.streaming.tests.Elasticsearch6SinkE2ECase Time elapsed: 49.38 s &lt;&lt;&lt; ERROR!2022-07-13T02:49:13.5466765Z Jul 13 02:49:13 java.lang.RuntimeException: Failed to build JobManager image2022-07-13T02:49:13.5467621Z Jul 13 02:49:13 at org.apache.flink.connector.testframe.container.FlinkTestcontainersConfigurator.configureJobManagerContainer(FlinkTestcontainersConfigurator.java:67)2022-07-13T02:49:13.5468645Z Jul 13 02:49:13 at org.apache.flink.connector.testframe.container.FlinkTestcontainersConfigurator.configure(FlinkTestcontainersConfigurator.java:147)2022-07-13T02:49:13.5469564Z Jul 13 02:49:13 at org.apache.flink.connector.testframe.container.FlinkContainers$Builder.build(FlinkContainers.java:197)2022-07-13T02:49:13.5470467Z Jul 13 02:49:13 at org.apache.flink.connector.testframe.container.FlinkContainerTestEnvironment.&lt;init&gt;(FlinkContainerTestEnvironment.java:88)2022-07-13T02:49:13.5471424Z Jul 13 02:49:13 at org.apache.flink.connector.testframe.container.FlinkContainerTestEnvironment.&lt;init&gt;(FlinkContainerTestEnvironment.java:51)2022-07-13T02:49:13.5472504Z Jul 13 02:49:13 at org.apache.flink.streaming.tests.ElasticsearchSinkE2ECaseBase.&lt;init&gt;(ElasticsearchSinkE2ECaseBase.java:58)2022-07-13T02:49:13.5473388Z Jul 13 02:49:13 at org.apache.flink.streaming.tests.Elasticsearch6SinkE2ECase.&lt;init&gt;(Elasticsearch6SinkE2ECase.java:36)2022-07-13T02:49:13.5474161Z Jul 13 02:49:13 at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)2022-07-13T02:49:13.5474905Z Jul 13 02:49:13 at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)2022-07-13T02:49:13.5475756Z Jul 13 02:49:13 at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)2022-07-13T02:49:13.5476734Z Jul 13 02:49:13 at java.lang.reflect.Constructor.newInstance(Constructor.java:423)2022-07-13T02:49:13.5477495Z Jul 13 02:49:13 at org.junit.platform.commons.util.ReflectionUtils.newInstance(ReflectionUtils.java:550)2022-07-13T02:49:13.5478313Z Jul 13 02:49:13 at org.junit.jupiter.engine.execution.ConstructorInvocation.proceed(ConstructorInvocation.java:56)2022-07-13T02:49:13.5479220Z Jul 13 02:49:13 at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)2022-07-13T02:49:13.5480165Z Jul 13 02:49:13 at org.junit.jupiter.api.extension.InvocationInterceptor.interceptTestClassConstructor(InvocationInterceptor.java:73)2022-07-13T02:49:13.5481038Z Jul 13 02:49:13 at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)2022-07-13T02:49:13.5481944Z Jul 13 02:49:13 at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)2022-07-13T02:49:13.5482875Z Jul 13 02:49:13 at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)2022-07-13T02:49:13.5483764Z Jul 13 02:49:13 at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)2022-07-13T02:49:13.5484642Z Jul 13 02:49:13 at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)2022-07-13T02:49:13.5486123Z Jul 13 02:49:13 at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)2022-07-13T02:49:13.5488185Z Jul 13 02:49:13 at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:77)2022-07-13T02:49:13.5488883Z Jul 13 02:49:13 at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeTestClassConstructor(ClassBasedTestDescriptor.java:355)2022-07-13T02:49:13.5490237Z Jul 13 02:49:13 at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateTestClass(ClassBasedTestDescriptor.java:302)2022-07-13T02:49:13.5491099Z Jul 13 02:49:13 at org.junit.jupiter.engine.descriptor.ClassTestDescriptor.instantiateTestClass(ClassTestDescriptor.java:79)2022-07-13T02:49:13.5491840Z Jul 13 02:49:13 at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateAndPostProcessTestInstance(ClassBasedTestDescriptor.java:280)2022-07-13T02:49:13.5492618Z Jul 13 02:49:13 at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$4(ClassBasedTestDescriptor.java:272)2022-07-13T02:49:13.5493228Z Jul 13 02:49:13 at java.util.Optional.orElseGet(Optional.java:267)2022-07-13T02:49:13.5493835Z Jul 13 02:49:13 at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$5(ClassBasedTestDescriptor.java:271)2022-07-13T02:49:13.5494551Z Jul 13 02:49:13 at org.junit.jupiter.engine.execution.TestInstancesProvider.getTestInstances(TestInstancesProvider.java:31)2022-07-13T02:49:13.5495253Z Jul 13 02:49:13 at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$before$2(ClassBasedTestDescriptor.java:197)2022-07-13T02:49:13.5495940Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)2022-07-13T02:49:13.5496616Z Jul 13 02:49:13 at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:196)2022-07-13T02:49:13.5497286Z Jul 13 02:49:13 at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:80)2022-07-13T02:49:13.5497973Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148)2022-07-13T02:49:13.5498653Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)2022-07-13T02:49:13.5499323Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)2022-07-13T02:49:13.5500024Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)2022-07-13T02:49:13.5500655Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)2022-07-13T02:49:13.5501345Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)2022-07-13T02:49:13.5535107Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)2022-07-13T02:49:13.5535791Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)2022-07-13T02:49:13.5538031Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)2022-07-13T02:49:13.5538994Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:129)2022-07-13T02:49:13.5539797Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)2022-07-13T02:49:13.5540481Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)2022-07-13T02:49:13.5541154Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)2022-07-13T02:49:13.5541784Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)2022-07-13T02:49:13.5542410Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)2022-07-13T02:49:13.5543090Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)2022-07-13T02:49:13.5543930Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)2022-07-13T02:49:13.5544575Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)2022-07-13T02:49:13.5545351Z Jul 13 02:49:13 at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)2022-07-13T02:49:13.5546083Z Jul 13 02:49:13 at java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)2022-07-13T02:49:13.5546615Z Jul 13 02:49:13 at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)2022-07-13T02:49:13.5547162Z Jul 13 02:49:13 at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)2022-07-13T02:49:13.5547713Z Jul 13 02:49:13 at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)2022-07-13T02:49:13.5548444Z Jul 13 02:49:13 at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)2022-07-13T02:49:13.5549641Z Jul 13 02:49:13 Caused by: org.apache.flink.connector.testframe.container.ImageBuildException: Failed to build image "flink-configured-jobmanager"2022-07-13T02:49:13.5550318Z Jul 13 02:49:13 at org.apache.flink.connector.testframe.container.FlinkImageBuilder.build(FlinkImageBuilder.java:234)2022-07-13T02:49:13.5551080Z Jul 13 02:49:13 at org.apache.flink.connector.testframe.container.FlinkTestcontainersConfigurator.configureJobManagerContainer(FlinkTestcontainersConfigurator.java:65)2022-07-13T02:49:13.5551656Z Jul 13 02:49:13 ... 57 more2022-07-13T02:49:13.5552744Z Jul 13 02:49:13 Caused by: java.lang.RuntimeException: com.github.dockerjava.api.exception.DockerClientException: Could not build image: ApplyLayer exit status 1 stdout: stderr: write /opt/flink/opt/flink-s3-fs-presto-1.16-SNAPSHOT.jar: no space left on device2022-07-13T02:49:13.5553633Z Jul 13 02:49:13 at org.rnorth.ducttape.timeouts.Timeouts.callFuture(Timeouts.java:68)2022-07-13T02:49:13.5554224Z Jul 13 02:49:13 at org.rnorth.ducttape.timeouts.Timeouts.getWithTimeout(Timeouts.java:43)2022-07-13T02:49:13.5554761Z Jul 13 02:49:13 at org.testcontainers.utility.LazyFuture.get(LazyFuture.java:45)2022-07-13T02:49:13.5555373Z Jul 13 02:49:13 at org.apache.flink.connector.testframe.container.FlinkImageBuilder.buildBaseImage(FlinkImageBuilder.java:252)2022-07-13T02:49:13.5706429Z Jul 13 02:49:13 at org.apache.flink.connector.testframe.container.FlinkImageBuilder.build(FlinkImageBuilder.java:206)2022-07-13T02:49:13.5707070Z Jul 13 02:49:13 ... 58 more2022-07-13T02:49:13.5712449Z Jul 13 02:49:13 Caused by: com.github.dockerjava.api.exception.DockerClientException: Could not build image: ApplyLayer exit status 1 stdout: stderr: write /opt/flink/opt/flink-s3-fs-presto-1.16-SNAPSHOT.jar: no space left on device2022-07-13T02:49:13.5765291Z Jul 13 02:49:13 at com.github.dockerjava.api.command.BuildImageResultCallback.getImageId(BuildImageResultCallback.java:78)2022-07-13T02:49:13.5766129Z Jul 13 02:49:13 at com.github.dockerjava.api.command.BuildImageResultCallback.awaitImageId(BuildImageResultCallback.java:50)2022-07-13T02:49:13.5766802Z Jul 13 02:49:13 at org.testcontainers.images.builder.ImageFromDockerfile.resolve(ImageFromDockerfile.java:147)2022-07-13T02:49:13.5767436Z Jul 13 02:49:13 at org.testcontainers.images.builder.ImageFromDockerfile.resolve(ImageFromDockerfile.java:40)2022-07-13T02:49:13.5768029Z Jul 13 02:49:13 at org.testcontainers.utility.LazyFuture.getResolvedValue(LazyFuture.java:17)2022-07-13T02:49:13.5768573Z Jul 13 02:49:13 at org.testcontainers.utility.LazyFuture.get(LazyFuture.java:39)2022-07-13T02:49:13.5769083Z Jul 13 02:49:13 at java.util.concurrent.FutureTask.run(FutureTask.java:266)2022-07-13T02:49:13.5769625Z Jul 13 02:49:13 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)2022-07-13T02:49:13.5770223Z Jul 13 02:49:13 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)2022-07-13T02:49:13.5771000Z Jul 13 02:49:13 at java.lang.Thread.run(Thread.java:750)2022-07-13T02:49:13.5771336Z Jul 13 02:49:13 https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=38110&amp;view=logs&amp;j=87489130-75dc-54e4-1f45-80c30aa367a3&amp;t=73da6d75-f30d-5d5a-acbe-487a9dcff678</description>
      <version>1.16.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.dev.lint-python.sh</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-15 01:00:00" id="28559" opendate="2022-7-15 00:00:00" resolution="Done">
    <buginformation>
      <summary>Support DataStream PythonKeyedProcessOperator in Thread Mode</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.table.runtime.operators.python.table.EmbeddedPythonTableFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.EmbeddedPythonProcessOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.AbstractOneInputEmbeddedPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.AbstractEmbeddedDataStreamPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.python.chain.PythonOperatorChainingOptimizer.java</file>
      <file type="M">flink-python.setup.py</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.operation.utils.py</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.operations.py</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.converters.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.runtime.context.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.process.function.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.operations.py</file>
      <file type="M">flink-python.pyflink.datastream.tests.test.data.stream.py</file>
      <file type="M">flink-python.pyflink.datastream.state.py</file>
      <file type="M">flink-python.pyflink.datastream.data.stream.py</file>
      <file type="M">flink-python.pom.xml</file>
      <file type="M">flink-python.dev.dev-requirements.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-10-15 01:00:00" id="2856" opendate="2015-10-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce flink.version property into quickstart archetype</summary>
      <description>With the quickstarts we're currently creating, users have to manually change all the dependencies if they're changing the flink version.I propose to introduce a property for setting the flink version.</description>
      <version>None</version>
      <fixedVersion>0.10.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.change-version</file>
      <file type="M">flink-quickstart.flink-quickstart-scala.src.main.resources.archetype-resources.pom.xml</file>
      <file type="M">flink-quickstart.flink-quickstart-java.src.main.resources.archetype-resources.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-18 01:00:00" id="28585" opendate="2022-7-18 00:00:00" resolution="Done">
    <buginformation>
      <summary>Speculative execution for InputFormat sources</summary>
      <description>This task enables InputFormat sources for speculative execution.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.SpeculativeExecutionVertexTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.scheduler.ExecutionGraphHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.SpeculativeExecutionVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ExecutionVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.Execution.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-18 01:00:00" id="28588" opendate="2022-7-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance REST API for Speculative Execution</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.job.SubtaskExecutionAttemptDetailsInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.JobVertexDetailsInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.JobVertexBackPressureInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.AggregatedTaskDetailsInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandlerTest.java</file>
      <file type="M">flink-runtime-web.src.test.resources.rest.api.v1.snapshot</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.messages.webmonitor.ClusterOverview.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.ResourceManager.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.resourcemanager.ResourceOverview.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.messages.ClusterOverviewWithVersion.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.ResourceManagerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.resourcemanager.utils.TestingResourceManagerGateway.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.messages.ClusterOverviewWithVersionTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.webmonitor.TestingRestfulGateway.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServerArchiveFetcher.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.messages.webmonitor.JobDetails.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.dump.MetricDumpSerialization.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.dump.QueryScopeInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.InternalOperatorMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.metrics.groups.TaskMetricGroup.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherImpl.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.metrics.MetricStore.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.util.MutableIOMetrics.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.messages.webmonitor.JobDetailsTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.dump.MetricDumpSerializerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.metrics.dump.QueryScopeInfoTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.metrics.MetricFetcherTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.legacy.metrics.MetricStoreTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.AccessExecutionVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ArchivedExecutionVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.ArchivedSpeculativeExecutionVertex.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.executiongraph.SpeculativeExecutionVertex.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.executiongraph.ArchivedExecutionGraphTestUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.taskmanager.TaskManagerDetailsInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.taskmanager.TaskManagerInfo.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandlerTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.taskmanager.TaskManagerInfoTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.AbstractSubtaskAttemptHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobDetailsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobVertexBackPressureInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.job.SubtaskExecutionAttemptDetailsInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.webmonitor.threadinfo.JobVertexThreadInfoTracker.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-18 01:00:00" id="28589" opendate="2022-7-18 00:00:00" resolution="Done">
    <buginformation>
      <summary>Enhance Web UI for Speculative Execution</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.subtasks.job-overview-drawer-subtasks.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.subtasks.job-overview-drawer-subtasks.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.subtasks.job-overview-drawer-subtasks.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.backpressure.job-overview-drawer-backpressure.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.backpressure.job-overview-drawer-backpressure.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.backpressure.job-overview-drawer-backpressure.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.job-vertex.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.job-backpressure.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.share.module.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.status.task-manager-status.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.status.task-manager-status.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.task-manager.list.task-manager-list.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.task-manager.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.overview.statistic.overview-statistic.component.less</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.overview.statistic.overview-statistic.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.overview.ts</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-19 01:00:00" id="28599" opendate="2022-7-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adding FlinkJoinToMultiJoinRule to support translating left/right outer join to multi join</summary>
      <description>Now, Flink use Calcite's rule JOIN_TO_MULTI_JOIN to convert multiple joins into a join set, which can be used by join reorder. However, calcite's rule can not adapte to all outer joins. For left or right outer join, if they meet certain conditions, it can also be converted to multi join. </description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.runtime.batch.sql.join.JoinITCase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.plan.rules.logical.FlinkJoinToMultiJoinRuleTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.plan.common.JoinReorderTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.stream.sql.join.JoinReorderTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.rules.logical.FlinkJoinToMultiJoinRuleTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.join.JoinReorderTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.rules.FlinkBatchRuleSets.scala</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-12-21 01:00:00" id="28617" opendate="2022-7-21 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Support stop job statement in SqlGatewayService</summary>
      <description/>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.java.org.apache.flink.test.util.TestUtils.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.test.java.org.apache.flink.table.gateway.service.SqlGatewayServiceITCase.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.service.utils.Constants.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.service.operation.OperationExecutor.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-21 01:00:00" id="28628" opendate="2022-7-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Introduce operation execution plugin</summary>
      <description>Hive dialect may has his own operation execution logic for some operations. So, it'll be better introduce a operation excution plugin to delegate Hive or other dialects's execution logic.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.delegation.PlannerBase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.resources.META-INF.services.org.apache.flink.table.factories.Factory</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.delegation.ParserFactory.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.delegation.DefaultParserFactory.java</file>
      <file type="M">flink-table.flink-table-api-java.src.test.java.org.apache.flink.table.utils.PlannerMock.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.delegation.Planner.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.internal.TableEnvironmentImpl.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.HiveDialectITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.resources.META-INF.services.org.apache.flink.table.factories.Factory</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.planner.delegation.hive.HiveParserFactory.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2022-8-26 01:00:00" id="28688" opendate="2022-7-26 00:00:00" resolution="Done">
    <buginformation>
      <summary>Support DataStream PythonWindowOperator in Thread Mode</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.AbstractTwoInputEmbeddedPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.AbstractOneInputEmbeddedPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.python.chain.PythonOperatorChainingOptimizer.java</file>
      <file type="M">flink-python.setup.py</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.operation.utils.py</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.operations.py</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.converters.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.window.window.operator.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.timerservice.impl.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.state.impl.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.runtime.context.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.process.function.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.operations.py</file>
      <file type="M">flink-python.pyflink.datastream.tests.test.window.py</file>
      <file type="M">flink-python.pyflink.datastream.data.stream.py</file>
      <file type="M">flink-python.pom.xml</file>
      <file type="M">flink-python.dev.dev-requirements.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-7-27 01:00:00" id="28698" opendate="2022-7-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>The display order of aggregated metrics should follow the order of task state transitions</summary>
      <description> Currently, the display order of task state duration is INITIALIZING, CREATED, SCHEDULED, RUNNING, DEPLOYING. I think it would be more reasonable to change to CAEATED, SCHEDULED, DEPLOYING, INITIALIZING, RUNNING, which is follow the order of task state transitions.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.common.table-aggregated-metrics.table-aggregated-metrics.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.subtasks.job-overview-drawer-subtasks.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.subtasks.job-overview-drawer-subtasks.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.job-vertex.ts</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2022-8-29 01:00:00" id="28745" opendate="2022-7-29 00:00:00" resolution="Done">
    <buginformation>
      <summary>Support DataStream PythonCoProcessOperator and PythonKeyedCoProcessOperator in Thread Mode</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.EmbeddedPythonProcessOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.AbstractOneInputEmbeddedPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.AbstractEmbeddedDataStreamPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.python.chain.PythonOperatorChainingOptimizer.java</file>
      <file type="M">flink-python.setup.py</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.operation.utils.py</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.operations.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.process.function.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.operations.py</file>
      <file type="M">flink-python.pyflink.datastream.tests.test.data.stream.py</file>
      <file type="M">flink-python.pyflink.datastream.data.stream.py</file>
      <file type="M">flink-python.pom.xml</file>
      <file type="M">flink-python.dev.dev-requirements.txt</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2022-10-1 01:00:00" id="28768" opendate="2022-8-1 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update JUnit5 to v5.9.1</summary>
      <description>Junit 5.9.0 is releasedwith release notes https://junit.org/junit5/docs/current/release-notes/#release-notes-5.9.0</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.RestExternalHandlersITCase.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JarHandlerParameterTest.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.handlers.JarDeleteHandlerTest.java</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-common.src.test.java.org.apache.flink.dist.DynamicParameterITCase.java</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-common-kafka.src.test.java.org.apache.flink.tests.util.kafka.SmokeKafkaITCase.java</file>
      <file type="M">flink-clients.src.test.java.org.apache.flink.client.cli.CliFrontendSavepointTest.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-8-2 01:00:00" id="28774" opendate="2022-8-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow user to configure whether to enable sort or not when it&amp;#39;s for dynamic parition writing for HiveSource</summary>
      <description>In HiveSource, when it's for inserting into dynamic parition, it'll always add a sort node which may be time consuming.It'll be better to allow users  to configure whether to add a sort or not in the case for inserting into dynamic parition.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.HiveTableSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.connectors.hive.HiveTableSink.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.connectors.hive.HiveOptions.java</file>
      <file type="M">docs.content.docs.connectors.table.hive.hive.read.write.md</file>
      <file type="M">docs.content.zh.docs.connectors.table.hive.hive.read.write.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-2 01:00:00" id="28780" opendate="2022-8-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>function docs of dayofmonth is not correct</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.data.sql.functions.zh.yml</file>
      <file type="M">docs.data.sql.functions.yml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-3 01:00:00" id="28782" opendate="2022-8-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support FileSink compaction in PyFlink</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.pyflink.datastream.connectors.tests.test.connectors.py</file>
      <file type="M">flink-python.pyflink.datastream.connectors.file.system.py</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-3 01:00:00" id="28788" opendate="2022-8-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support SideOutput in Thread Mode</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.process.AbstractExternalDataStreamPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.EmbeddedPythonWindowOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.EmbeddedPythonProcessOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.EmbeddedPythonKeyedProcessOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.EmbeddedPythonKeyedCoProcessOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.EmbeddedPythonCoProcessOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.AbstractTwoInputEmbeddedPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.AbstractOneInputEmbeddedPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.AbstractEmbeddedDataStreamPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.DataStreamPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.python.util.PythonConfigUtil.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.python.chain.PythonOperatorChainingOptimizer.java</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.operation.utils.py</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.operations.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.process.function.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.operations.py</file>
      <file type="M">flink-python.pyflink.datastream.tests.test.window.py</file>
      <file type="M">flink-python.pyflink.datastream.tests.test.data.stream.py</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-3 01:00:00" id="28791" opendate="2022-8-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>flink-sql-gateway-test does not compile on Java 11</summary>
      <description>Could not find artifact jdk.tools:jdk.tools:jar:1.7</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.flink-sql-gateway-test.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2022-8-4 01:00:00" id="28814" opendate="2022-8-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update postgres driver because of CVE-2022-31197</summary>
      <description>More details about CVE at pgjdbc repo page https://github.com/pgjdbc/pgjdbc/security/advisories/GHSA-r38f-c4h4-hqq2</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-jdbc.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-4 01:00:00" id="28815" opendate="2022-8-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Translate the "Real Time Reporting with the Table API" page into Chinese</summary>
      <description>Page "Real Time Reporting with the Table API" need to be translated in Chinese.I will be pleasure to take this PR.PS:Also willing fix a typo on page "Fraud Detection with the DataStream API"  in chinese with the same PR.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.zh.docs.try-flink.table.api.md</file>
      <file type="M">docs.content.zh.docs.try-flink.datastream.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-5 01:00:00" id="28836" opendate="2022-8-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support broadcast in Thread Mode</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.runtime.translators.python.PythonKeyedBroadcastStateTransformationTranslator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.runtime.translators.python.PythonBroadcastStateTransformationTranslator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.AbstractTwoInputEmbeddedPythonFunctionOperator.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.operators.python.embedded.AbstractOneInputEmbeddedPythonFunctionOperator.java</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.operation.utils.py</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.operations.py</file>
      <file type="M">flink-python.pyflink.fn.execution.embedded.converters.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.state.impl.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.process.function.py</file>
      <file type="M">flink-python.pyflink.fn.execution.datastream.embedded.operations.py</file>
      <file type="M">flink-python.pyflink.datastream.tests.test.data.stream.py</file>
      <file type="M">flink-python.pyflink.datastream.data.stream.py</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-8-8 01:00:00" id="28857" opendate="2022-8-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Document for DataStream Cache API</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.dev.datastream.operators.overview.md</file>
      <file type="M">docs.content.zh.docs.dev.datastream.operators.overview.md</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2022-8-11 01:00:00" id="28916" opendate="2022-8-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add e2e test for create function using jar syntax</summary>
      <description>Add e2e test for create function using jar syntax that using remote hdfs jar</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-sql.src.test.java.org.apache.flink.table.sql.codegen.UsingRemoteJarITCase.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-8-11 01:00:00" id="28932" opendate="2022-8-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Builder#withConfiguration instead of deprecated EnvironmentSettings#fromConfiguration</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.service.context.SessionContext.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-12 01:00:00" id="28936" opendate="2022-8-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix RSET endpoint can not serialize CHAR(0)</summary>
      <description>The current implementation doesn't align with the FLIP. We need to introduce a new serializer to fix this.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-sql-gateway.src.test.java.org.apache.flink.table.gateway.rest.StatementCaseITTest.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.cli.SqlGatewayOptionsParser.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.src.test.java.org.apache.flink.table.gateway.api.results.JsonResultSetSerDeTest.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.src.main.java.org.apache.flink.table.gateway.api.results.ResultSet.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.src.main.java.org.apache.flink.table.gateway.api.results.JsonResultSetSerializer.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.src.main.java.org.apache.flink.table.gateway.api.results.JsonResultSetDeserializer.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.src.main.java.org.apache.flink.table.gateway.api.results.ColumnInfo.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-12 01:00:00" id="28938" opendate="2022-8-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix HiveServer2 Endpoint can not set variable correctly</summary>
      <description>Hive JDBC URL also supports Hive variable replacement. But the current implementation doesn't finish this.   HiveServer2 Endoint should thorw exception to notify users if users tries to fetch logs.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.planner.delegation.hive.copy.HiveSetProcessor.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.endpoint.hive.util.HiveJdbcParameterUtils.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.table.endpoint.hive.HiveServer2EndpointITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.endpoint.hive.HiveServer2Endpoint.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-15 01:00:00" id="28955" opendate="2022-8-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>YARNHighAvailabilityITCase compile failed in hadoop3</summary>
      <description>It looks like we have not resolved the problem in hadoop3. This problem was not exposed before due to another test that failed to compile under hadoop3https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=39951&amp;view=logs&amp;j=b1fcf054-9138-5463-c73c-a49979b9ac2a&amp;t=9291ac46-dd95-5135-b799-3839e65a86912022-08-14T00:36:43.9971481Z [ERROR] COMPILATION ERROR : 2022-08-14T00:36:43.9972508Z [INFO] -------------------------------------------------------------2022-08-14T00:36:43.9973460Z [ERROR] /__w/3/s/flink-yarn-tests/src/test/java/org/apache/flink/yarn/YARNHighAvailabilityITCase.java:[53,31] package org.apache.curator.test does not exist2022-08-14T00:36:43.9974493Z [ERROR] /__w/3/s/flink-yarn-tests/src/test/java/org/apache/flink/yarn/YARNHighAvailabilityITCase.java:[106,20] cannot find symbol2022-08-14T00:36:43.9975371Z symbol: class TestingServer2022-08-14T00:36:43.9975818Z location: class org.apache.flink.yarn.YARNHighAvailabilityITCase2022-08-14T00:36:43.9976253Z [INFO] 2 errors</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn-tests.pom.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-9-15 01:00:00" id="28971" opendate="2022-8-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adds user documentation for the new LOOKUP hint</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.dev.table.sql.queries.hints.md</file>
      <file type="M">docs.content.zh.docs.dev.table.sql.queries.hints.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-15 01:00:00" id="28972" opendate="2022-8-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add methods of StartCursor and StopCursor to align the Java</summary>
      <description>Add fromPublishTime in the StartCursor classAdd afterEventTime and afterPublishTime in the StopCursor class</description>
      <version>1.14.5,1.15.1,1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.pyflink.datastream.connectors.tests.test.pulsar.py</file>
      <file type="M">flink-python.pyflink.datastream.connectors.pulsar.py</file>
      <file type="M">docs.content.docs.connectors.datastream.pulsar.md</file>
      <file type="M">docs.content.zh.docs.connectors.datastream.pulsar.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-16 01:00:00" id="28986" opendate="2022-8-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>UNNEST function with nested filter fails to generate plan</summary>
      <description>How to reproduceadd the following case to TableEnvironmentITCase@Testdef debug(): Unit = { tEnv.executeSql( s""" |CREATE TEMPORARY TABLE source_kafka_wip_his_all ( | GUID varchar, | OPERATION varchar, | PRODUCTID varchar, | LOTNO varchar, | SERIALNO varchar, | QUERYSERIALNO varchar, | SERIALNO1 varchar, | SERIALNO2 varchar, | WIPORDERNO varchar, | WIPORDERTYPE varchar, | VIRTUALLOT varchar, | PREOPERATION varchar, | NORMALPREOPERATION varchar, | PROCESSID varchar, | EQUIPMENT varchar, | INBOUNDDATE varchar, | OUTBOUNDDATE varchar, | REWORK varchar, | REWORKPROCESSID varchar, | CONTAINER varchar, | WIPCONTENTCLASSID varchar, | STATUSCODE varchar, | WIPSTATUS varchar, | TESTPROCESSID varchar, | TESTORDERTYPE varchar, | TESTORDER varchar, | TEST varchar, | SORTINGPROCESSID varchar, | SORTINGORDERTYPE varchar, | SORTINGORDER varchar, | SORTING varchar, | MINO varchar, | GROUPCODE varchar, | HIGHLOWGROUP varchar, | PRODUCTNO varchar, | FACILITY varchar, | WIPLINE varchar, | CHILDEQUCODE varchar, | STATION varchar, | QTY varchar, | PASS_FLAG varchar, | DEFECTCODELIST varchar, | ISFIRST varchar, | PARALIST ARRAY&lt;ROW(GUID string,WIP_HIS_GUID string,QUERYSERIALNO string,OPERATION string,REWORKPROCESSID string,CHARACTERISTIC string,CHARACTERISTICREVISION string,CHARACTERISTICTYPE string,CHARACTERISTICCLASS string,UPPERCONTROLLIMIT string,TARGETVALUE string,LOWERCONTROLLIMIT string,TESTVALUE string,TESTATTRIBUTE string,TESTINGSTARTDATE string,TESTFINISHDATE string,UOMCODE string,DEFECTCODE string,SPECPARAMID string,STATION string,GP_TIME string,REFERENCEID string,LASTUPDATEON string,LASTUPDATEDBY string,CREATEDON string,CREATEDBY string,ACTIVE string,LASTDELETEON string,LASTDELETEDBY string,LASTREACTIVATEON string,LASTREACTIVATEDBY string,ARCHIVEID string,LASTARCHIVEON string,LASTARCHIVEDBY string,LASTRESTOREON string,LASTRESTOREDBY string,ROWVERSIONSTAMP string)&gt;, | REFERENCEID varchar, | LASTUPDATEON varchar, | LASTUPDATEDBY varchar, | CREATEDON varchar, | CREATEDBY varchar, | ACTIVE varchar, | LASTDELETEON varchar, | LASTDELETEDBY varchar, | LASTREACTIVATEON varchar, | LASTREACTIVATEDBY varchar, | ARCHIVEID varchar, | LASTARCHIVEON varchar, | LASTARCHIVEDBY varchar, | LASTRESTOREON varchar, | LASTRESTOREDBY varchar, | ROWVERSIONSTAMP varchar, | proctime as PROCTIME() | ) with ( | 'connector' = 'datagen' |) |""".stripMargin) tEnv.executeSql( s""" |create TEMPORARY view transform_main_data as |select | r.GUID as wip_his_guid, | r.EQUIPMENT as equipment, | r.WIPLINE as wipline, | r.STATION as station, | cast(r.PROCESSID as decimal) as processid, | r.PRODUCTNO as productno, | t.TESTFINISHDATE as testfinishdate, | t.OPERATION as operation, | t.CHARACTERISTIC as characteristic, | t.LOWERCONTROLLIMIT as lowercontrollimit, | t.UPPERCONTROLLIMIT as uppercontrollimit, | t.TARGETVALUE as targetvalue, | t.DEFECTCODE as defectcode, | t.TESTVALUE as testvalue, | t.CHARACTERISTICTYPE as characteristictype, | proctime | from | (select | GUID, | EQUIPMENT, | WIPLINE, | STATION, | PROCESSID, | PRODUCTNO, | PARALIST, | proctime | FROM source_kafka_wip_his_all) r | cross join | unnest(PARALIST) as t (GUID,WIP_HIS_GUID,QUERYSERIALNO,OPERATION,REWORKPROCESSID,CHARACTERISTIC,CHARACTERISTICREVISION,CHARACTERISTICTYPE,CHARACTERISTICCLASS,UPPERCONTROLLIMIT,TARGETVALUE,LOWERCONTROLLIMIT,TESTVALUE,TESTATTRIBUTE,TESTINGSTARTDATE,TESTFINISHDATE,UOMCODE,DEFECTCODE,SPECPARAMID,STATION,GP_TIME,REFERENCEID,LASTUPDATEON,LASTUPDATEDBY,CREATEDON,CREATEDBY,ACTIVE,LASTDELETEON,LASTDELETEDBY,LASTREACTIVATEON,LASTREACTIVATEDBY,ARCHIVEID,LASTARCHIVEON,LASTARCHIVEDBY,LASTRESTOREON,LASTRESTOREDBY,ROWVERSIONSTAMP) | where t.CHARACTERISTICTYPE = '2' |""".stripMargin) tEnv.executeSql( s""" |explain plan for |select * from transform_main_data |where operation not in ('G1208','G1209','G1211','G1213','G1206','G1207','G1214','G1215','G1282','G1292','G1216') |""".stripMargin).print()} Stacktraceorg.apache.flink.table.api.TableException: Cannot generate a valid execution plan for the given query: LogicalProject(inputs=[0..3], exprs=[[CAST($4):DECIMAL(10, 0), $5, $23, $11, $13, $19, $17, $18, $25, $20, $15, $7]])+- LogicalCorrelate(correlation=[$cor1], joinType=[inner], requiredColumns=[{6}])   :- LogicalProject(inputs=[0], exprs=[[$14, $36, $38, $13, $34, $43, PROCTIME()]])   :  +- LogicalTableScan(table=[[default_catalog, default_database, source_kafka_wip_his_all]])   +- LogicalFilter(condition=[AND(SEARCH($7, Sarg[_UTF-16LE'2':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"]:VARCHAR(2147483647) CHARACTER SET "UTF-16LE"), SEARCH($3, Sarg[(-∞.._UTF-16LE'G1206'), (_UTF-16LE'G1206'.._UTF-16LE'G1207'), (_UTF-16LE'G1207'.._UTF-16LE'G1208'), (_UTF-16LE'G1208'.._UTF-16LE'G1209'), (_UTF-16LE'G1209'.._UTF-16LE'G1211'), (_UTF-16LE'G1211'.._UTF-16LE'G1213'), (_UTF-16LE'G1213'.._UTF-16LE'G1214'), (_UTF-16LE'G1214'.._UTF-16LE'G1215'), (_UTF-16LE'G1215'.._UTF-16LE'G1216'), (_UTF-16LE'G1216'.._UTF-16LE'G1282'), (_UTF-16LE'G1282'.._UTF-16LE'G1292'), (_UTF-16LE'G1292'..+∞)]:CHAR(5) CHARACTER SET "UTF-16LE"))])      +- Uncollect         +- LogicalProject(exprs=[[$cor1.PARALIST]])            +- LogicalValues(type=[RecordType(INTEGER ZERO)], tuples=[[{ 0 }]])This exception indicates that the query uses an unsupported SQL feature.Please check the documentation for the set of currently supported SQL features.org.apache.flink.table.api.TableException: Cannot generate a valid execution plan for the given query: LogicalProject(inputs=[0..3], exprs=[[CAST($4):DECIMAL(10, 0), $5, $23, $11, $13, $19, $17, $18, $25, $20, $15, $7]])+- LogicalCorrelate(correlation=[$cor1], joinType=[inner], requiredColumns=[{6}]) :- LogicalProject(inputs=[0], exprs=[[$14, $36, $38, $13, $34, $43, PROCTIME()]]) : +- LogicalTableScan(table=[[default_catalog, default_database, source_kafka_wip_his_all]]) +- LogicalFilter(condition=[AND(SEARCH($7, Sarg[_UTF-16LE'2':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"]:VARCHAR(2147483647) CHARACTER SET "UTF-16LE"), SEARCH($3, Sarg[(-∞.._UTF-16LE'G1206'), (_UTF-16LE'G1206'.._UTF-16LE'G1207'), (_UTF-16LE'G1207'.._UTF-16LE'G1208'), (_UTF-16LE'G1208'.._UTF-16LE'G1209'), (_UTF-16LE'G1209'.._UTF-16LE'G1211'), (_UTF-16LE'G1211'.._UTF-16LE'G1213'), (_UTF-16LE'G1213'.._UTF-16LE'G1214'), (_UTF-16LE'G1214'.._UTF-16LE'G1215'), (_UTF-16LE'G1215'.._UTF-16LE'G1216'), (_UTF-16LE'G1216'.._UTF-16LE'G1282'), (_UTF-16LE'G1282'.._UTF-16LE'G1292'), (_UTF-16LE'G1292'..+∞)]:CHAR(5) CHARACTER SET "UTF-16LE"))]) +- Uncollect +- LogicalProject(exprs=[[$cor1.PARALIST]]) +- LogicalValues(type=[RecordType(INTEGER ZERO)], tuples=[[{ 0 }]])This exception indicates that the query uses an unsupported SQL feature.Please check the documentation for the set of currently supported SQL features.    at org.apache.flink.table.planner.plan.optimize.program.FlinkVolcanoProgram.optimize(FlinkVolcanoProgram.scala:70)    at org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram.$anonfun$optimize$1(FlinkChainedProgram.scala:59)    at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:156)    at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:156)    at scala.collection.Iterator.foreach(Iterator.scala:937)    at scala.collection.Iterator.foreach$(Iterator.scala:937)    at scala.collection.AbstractIterator.foreach(Iterator.scala:1425)    at scala.collection.IterableLike.foreach(IterableLike.scala:70)    at scala.collection.IterableLike.foreach$(IterableLike.scala:69)    at scala.collection.AbstractIterable.foreach(Iterable.scala:54)    at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:156)    at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:154)    at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104)    at org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram.optimize(FlinkChainedProgram.scala:55)    at org.apache.flink.table.planner.plan.optimize.StreamCommonSubGraphBasedOptimizer.optimizeTree(StreamCommonSubGraphBasedOptimizer.scala:176)    at org.apache.flink.table.planner.plan.optimize.StreamCommonSubGraphBasedOptimizer.doOptimize(StreamCommonSubGraphBasedOptimizer.scala:83)    at org.apache.flink.table.planner.plan.optimize.CommonSubGraphBasedOptimizer.optimize(CommonSubGraphBasedOptimizer.scala:87)    at org.apache.flink.table.planner.delegation.PlannerBase.optimize(PlannerBase.scala:315)    at org.apache.flink.table.planner.delegation.PlannerBase.getExplainGraphs(PlannerBase.scala:527)    at org.apache.flink.table.planner.delegation.StreamPlanner.explain(StreamPlanner.scala:96)    at org.apache.flink.table.planner.delegation.StreamPlanner.explain(StreamPlanner.scala:51)    at org.apache.flink.table.api.internal.TableEnvironmentImpl.explainInternal(TableEnvironmentImpl.java:695)    at org.apache.flink.table.api.internal.TableEnvironmentImpl.executeInternal(TableEnvironmentImpl.java:1356)    at org.apache.flink.table.api.internal.TableEnvironmentImpl.executeSql(TableEnvironmentImpl.java:733)    at org.apache.flink.table.api.TableEnvironmentITCase.debug(TableEnvironmentITCase.scala:695)    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    at java.lang.reflect.Method.invoke(Method.java:498)    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)    at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)    at org.apache.flink.util.TestNameProvider$1.evaluate(TestNameProvider.java:45)    at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)    at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)    at org.junit.runners.Suite.runChild(Suite.java:128)    at org.junit.runners.Suite.runChild(Suite.java:27)    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)    at org.junit.rules.RunRules.evaluate(RunRules.java:20)    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)    at org.junit.runner.JUnitCore.run(JUnitCore.java:137)    at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)    at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)    at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235)    at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54)Caused by: org.apache.calcite.plan.RelOptPlanner$CannotPlanException: There are not enough rules to produce a node with desired properties: convention=LOGICAL, FlinkRelDistributionTraitDef=any, MiniBatchIntervalTraitDef=None: 0, ModifyKindSetTraitDef=[NONE], UpdateKindTraitDef=[NONE].Missing conversion is Uncollect[convention: NONE -&gt; LOGICAL]There is 1 empty subset: rel#485:RelSubset#4.LOGICAL.any.None: 0.[NONE].[NONE], the relevant part of the original plan is as follows460:Uncollect  458:LogicalProject(subset=[rel#459:RelSubset#3.NONE.any.None: 0.[NONE].[NONE]], PARALIST=[$cor1.PARALIST])    17:LogicalValues(subset=[rel#457:RelSubset#2.NONE.any.None: 0.[NONE].[NONE]], tuples=[[{ 0 }]])</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.runtime.stream.sql.UnnestITCase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.plan.common.UnnestTestBase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.stream.sql.UnnestTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.rules.logical.LogicalUnnestRuleTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.batch.sql.UnnestTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.rules.FlinkStreamRuleSets.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.rules.FlinkBatchRuleSets.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-16 01:00:00" id="28990" opendate="2022-8-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix BatchPhysicalDynamicFilteringDataCollector with empty output type</summary>
      <description>When dpp fact side have calc node, and partition key index was changed in calc node, BatchPhysicalDynamicFilteringDataCollector will be set with a empty output type, which will throw exception in HiveSourceDynamicFileEnumerator  while check argument:Preconditions.checkArgument(rowType.getFieldCount() == dynamicFilterPartitionKeys.size()); in method setDynamicFilteringData  </description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.rules.physical.batch.DynamicPartitionPruningRuleTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.plan.rules.physical.batch.DynamicPartitionPruningRuleTest.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.rules.physical.batch.DynamicPartitionPruningRule.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-16 01:00:00" id="28994" opendate="2022-8-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable withCredentials for Flink UI</summary>
      <description>Some environments require cookies to authenticate the Flink UI. By enabling the withCredentials flag, Angular will send cookies along with the request.</description>
      <version>None</version>
      <fixedVersion>1.16.0,1.15.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.app.interceptor.ts</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2022-8-17 01:00:00" id="29007" opendate="2022-8-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>UsingRemoteJarITCase failed with NPE in hadoop3</summary>
      <description>2022-08-17T03:01:45.9844224Z Aug 17 03:01:45 [ERROR] UsingRemoteJarITCase.testUdfInRemoteJar Time elapsed: 1.319 s &lt;&lt;&lt; FAILURE!2022-08-17T03:01:45.9844747Z Aug 17 03:01:45 org.opentest4j.MultipleFailuresError: 2022-08-17T03:01:45.9845163Z Aug 17 03:01:45 Multiple Failures (2 failures)2022-08-17T03:01:45.9845669Z Aug 17 03:01:45 java.lang.AssertionError: Test failed org/apache/hadoop/hdfs/HdfsConfiguration2022-08-17T03:01:45.9846199Z Aug 17 03:01:45 java.lang.NullPointerException: &lt;no message&gt;2022-08-17T03:01:45.9846801Z Aug 17 03:01:45 at org.junit.vintage.engine.execution.TestRun.getStoredResultOrSuccessful(TestRun.java:196)2022-08-17T03:01:45.9847582Z Aug 17 03:01:45 at org.junit.vintage.engine.execution.RunListenerAdapter.fireExecutionFinished(RunListenerAdapter.java:226)2022-08-17T03:01:45.9848377Z Aug 17 03:01:45 at org.junit.vintage.engine.execution.RunListenerAdapter.testFinished(RunListenerAdapter.java:192)2022-08-17T03:01:45.9849199Z Aug 17 03:01:45 at org.junit.vintage.engine.execution.RunListenerAdapter.testFinished(RunListenerAdapter.java:79)2022-08-17T03:01:45.9849972Z Aug 17 03:01:45 at org.junit.runner.notification.SynchronizedRunListener.testFinished(SynchronizedRunListener.java:87)2022-08-17T03:01:45.9850715Z Aug 17 03:01:45 at org.junit.runner.notification.RunNotifier$9.notifyListener(RunNotifier.java:225)2022-08-17T03:01:45.9851413Z Aug 17 03:01:45 at org.junit.runner.notification.RunNotifier$SafeNotifier.run(RunNotifier.java:72)2022-08-17T03:01:45.9852105Z Aug 17 03:01:45 at org.junit.runner.notification.RunNotifier.fireTestFinished(RunNotifier.java:222)2022-08-17T03:01:45.9852828Z Aug 17 03:01:45 at org.junit.internal.runners.model.EachTestNotifier.fireTestFinished(EachTestNotifier.java:38)2022-08-17T03:01:45.9853510Z Aug 17 03:01:45 at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:372)2022-08-17T03:01:45.9854156Z Aug 17 03:01:45 at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)2022-08-17T03:01:45.9854864Z Aug 17 03:01:45 at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)2022-08-17T03:01:45.9855512Z Aug 17 03:01:45 at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)2022-08-17T03:01:45.9856125Z Aug 17 03:01:45 at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)2022-08-17T03:01:45.9856751Z Aug 17 03:01:45 at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)2022-08-17T03:01:45.9857372Z Aug 17 03:01:45 at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)2022-08-17T03:01:45.9857977Z Aug 17 03:01:45 at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)2022-08-17T03:01:45.9858581Z Aug 17 03:01:45 at org.junit.runners.ParentRunner.run(ParentRunner.java:413)2022-08-17T03:01:45.9859177Z Aug 17 03:01:45 at org.junit.runners.Suite.runChild(Suite.java:128)2022-08-17T03:01:45.9859726Z Aug 17 03:01:45 at org.junit.runners.Suite.runChild(Suite.java:27)2022-08-17T03:01:45.9860299Z Aug 17 03:01:45 at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)2022-08-17T03:01:45.9860905Z Aug 17 03:01:45 at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)2022-08-17T03:01:45.9861508Z Aug 17 03:01:45 at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)2022-08-17T03:01:45.9862134Z Aug 17 03:01:45 at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)2022-08-17T03:01:45.9862831Z Aug 17 03:01:45 at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)2022-08-17T03:01:45.9863477Z Aug 17 03:01:45 at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)2022-08-17T03:01:45.9864128Z Aug 17 03:01:45 at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)2022-08-17T03:01:45.9864729Z Aug 17 03:01:45 at org.junit.runners.ParentRunner.run(ParentRunner.java:413)2022-08-17T03:01:45.9865289Z Aug 17 03:01:45 at org.junit.runner.JUnitCore.run(JUnitCore.java:137)2022-08-17T03:01:45.9865851Z Aug 17 03:01:45 at org.junit.runner.JUnitCore.run(JUnitCore.java:115)2022-08-17T03:01:45.9866564Z Aug 17 03:01:45 at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:42)2022-08-17T03:01:45.9867293Z Aug 17 03:01:45 at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:80)2022-08-17T03:01:45.9868004Z Aug 17 03:01:45 at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:72)2022-08-17T03:01:45.9868759Z Aug 17 03:01:45 at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)2022-08-17T03:01:45.9869577Z Aug 17 03:01:45 at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)2022-08-17T03:01:45.9870401Z Aug 17 03:01:45 at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)2022-08-17T03:01:45.9871369Z Aug 17 03:01:45 at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)2022-08-17T03:01:45.9872223Z Aug 17 03:01:45 at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)2022-08-17T03:01:45.9872988Z Aug 17 03:01:45 at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)2022-08-17T03:01:45.9873698Z Aug 17 03:01:45 at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)2022-08-17T03:01:45.9874486Z Aug 17 03:01:45 at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)2022-08-17T03:01:45.9875313Z Aug 17 03:01:45 at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)2022-08-17T03:01:45.9876099Z Aug 17 03:01:45 at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)2022-08-17T03:01:45.9876922Z Aug 17 03:01:45 at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)2022-08-17T03:01:45.9877736Z Aug 17 03:01:45 at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)2022-08-17T03:01:45.9878501Z Aug 17 03:01:45 at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)2022-08-17T03:01:45.9879214Z Aug 17 03:01:45 at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)2022-08-17T03:01:45.9879881Z Aug 17 03:01:45 at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)2022-08-17T03:01:45.9880543Z Aug 17 03:01:45 at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)2022-08-17T03:01:45.9881179Z Aug 17 03:01:45 Suppressed: java.lang.AssertionError: Test failed org/apache/hadoop/hdfs/HdfsConfiguration2022-08-17T03:01:45.9881755Z Aug 17 03:01:45 at org.junit.Assert.fail(Assert.java:89)2022-08-17T03:01:45.9882395Z Aug 17 03:01:45 at org.apache.flink.table.sql.codegen.UsingRemoteJarITCase.createHDFS(UsingRemoteJarITCase.java:88)2022-08-17T03:01:45.9883166Z Aug 17 03:01:45 at org.apache.flink.table.sql.codegen.UsingRemoteJarITCase.before(UsingRemoteJarITCase.java:68)2022-08-17T03:01:45.9883816Z Aug 17 03:01:45 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)2022-08-17T03:01:45.9884518Z Aug 17 03:01:45 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)2022-08-17T03:01:45.9885230Z Aug 17 03:01:45 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)2022-08-17T03:01:45.9885853Z Aug 17 03:01:45 at java.lang.reflect.Method.invoke(Method.java:498)2022-08-17T03:01:45.9886488Z Aug 17 03:01:45 at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)2022-08-17T03:01:45.9887212Z Aug 17 03:01:45 at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)2022-08-17T03:01:45.9887921Z Aug 17 03:01:45 at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)2022-08-17T03:01:45.9888632Z Aug 17 03:01:45 at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)2022-08-17T03:01:45.9889325Z Aug 17 03:01:45 at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)2022-08-17T03:01:45.9889993Z Aug 17 03:01:45 at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)2022-08-17T03:01:45.9890671Z Aug 17 03:01:45 at org.apache.flink.util.ExternalResource$1.evaluate(ExternalResource.java:48)2022-08-17T03:01:45.9891333Z Aug 17 03:01:45 at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)2022-08-17T03:01:45.9891997Z Aug 17 03:01:45 at org.apache.flink.util.TestNameProvider$1.evaluate(TestNameProvider.java:45)2022-08-17T03:01:45.9892716Z Aug 17 03:01:45 at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)2022-08-17T03:01:45.9893333Z Aug 17 03:01:45 at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)2022-08-17T03:01:45.9893995Z Aug 17 03:01:45 at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)2022-08-17T03:01:45.9894654Z Aug 17 03:01:45 at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)2022-08-17T03:01:45.9895132Z Aug 17 03:01:45 ... 39 more2022-08-17T03:01:45.9895540Z Aug 17 03:01:45 Suppressed: java.lang.NullPointerException2022-08-17T03:01:45.9896168Z Aug 17 03:01:45 at org.apache.flink.table.sql.codegen.UsingRemoteJarITCase.destroyHDFS(UsingRemoteJarITCase.java:95)2022-08-17T03:01:45.9896836Z Aug 17 03:01:45 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)2022-08-17T03:01:45.9897442Z Aug 17 03:01:45 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)2022-08-17T03:01:45.9898150Z Aug 17 03:01:45 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)2022-08-17T03:01:45.9898792Z Aug 17 03:01:45 at java.lang.reflect.Method.invoke(Method.java:498)2022-08-17T03:01:45.9899423Z Aug 17 03:01:45 at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)2022-08-17T03:01:45.9900141Z Aug 17 03:01:45 at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)2022-08-17T03:01:45.9900850Z Aug 17 03:01:45 at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)2022-08-17T03:01:45.9901552Z Aug 17 03:01:45 at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46)2022-08-17T03:01:45.9902219Z Aug 17 03:01:45 at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)2022-08-17T03:01:45.9902895Z Aug 17 03:01:45 at org.apache.flink.util.ExternalResource$1.evaluate(ExternalResource.java:48)2022-08-17T03:01:45.9903554Z Aug 17 03:01:45 at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)2022-08-17T03:01:45.9904220Z Aug 17 03:01:45 at org.apache.flink.util.TestNameProvider$1.evaluate(TestNameProvider.java:45)2022-08-17T03:01:45.9904859Z Aug 17 03:01:45 at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)2022-08-17T03:01:45.9905473Z Aug 17 03:01:45 at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)2022-08-17T03:01:45.9906283Z Aug 17 03:01:45 at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)2022-08-17T03:01:45.9907052Z Aug 17 03:01:45 at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)2022-08-17T03:01:45.9907534Z Aug 17 03:01:45 ... 39 more2022-08-17T03:01:45.9907852Z Aug 17 03:01:45 2022-08-17T03:01:46.2525312Z Aug 17 03:01:46 [INFO] 2022-08-17T03:01:46.2526850Z Aug 17 03:01:46 [INFO] Results:2022-08-17T03:01:46.2527307Z Aug 17 03:01:46 [INFO] 2022-08-17T03:01:46.2527708Z Aug 17 03:01:46 [ERROR] Failures: 2022-08-17T03:01:46.2528297Z Aug 17 03:01:46 [ERROR] UsingRemoteJarITCase.testCreateCatalogFunctionUsingRemoteJar2022-08-17T03:01:46.2528903Z Aug 17 03:01:46 [ERROR] Run 1: Multiple Failures (2 failures)2022-08-17T03:01:46.2529519Z Aug 17 03:01:46 java.lang.AssertionError: Test failed org/apache/hadoop/hdfs/HdfsConfiguration2022-08-17T03:01:46.2551750Z Aug 17 03:01:46 java.lang.NullPointerException: &lt;no message&gt;2022-08-17T03:01:46.2552413Z Aug 17 03:01:46 [ERROR] Run 2: Multiple Failures (2 failures)2022-08-17T03:01:46.2553047Z Aug 17 03:01:46 java.lang.AssertionError: Test failed org/apache/hadoop/hdfs/HdfsConfiguration2022-08-17T03:01:46.2553670Z Aug 17 03:01:46 java.lang.NullPointerException: &lt;no message&gt;2022-08-17T03:01:46.2554125Z Aug 17 03:01:46 [INFO] 2022-08-17T03:01:46.2554658Z Aug 17 03:01:46 [ERROR] UsingRemoteJarITCase.testCreateTemporaryCatalogFunctionUsingRemoteJar2022-08-17T03:01:46.2555270Z Aug 17 03:01:46 [ERROR] Run 1: Multiple Failures (2 failures)2022-08-17T03:01:46.2555862Z Aug 17 03:01:46 java.lang.AssertionError: Test failed org/apache/hadoop/hdfs/HdfsConfiguration2022-08-17T03:01:46.2556665Z Aug 17 03:01:46 java.lang.NullPointerException: &lt;no message&gt;2022-08-17T03:01:46.2557198Z Aug 17 03:01:46 [ERROR] Run 2: Multiple Failures (2 failures)2022-08-17T03:01:46.2557800Z Aug 17 03:01:46 java.lang.AssertionError: Test failed org/apache/hadoop/hdfs/HdfsConfiguration2022-08-17T03:01:46.2558407Z Aug 17 03:01:46 java.lang.NullPointerException: &lt;no message&gt;2022-08-17T03:01:46.2558865Z Aug 17 03:01:46 [INFO] 2022-08-17T03:01:46.2559376Z Aug 17 03:01:46 [ERROR] UsingRemoteJarITCase.testCreateTemporarySystemFunctionUsingRemoteJar2022-08-17T03:01:46.2559989Z Aug 17 03:01:46 [ERROR] Run 1: Multiple Failures (2 failures)2022-08-17T03:01:46.2560589Z Aug 17 03:01:46 java.lang.AssertionError: Test failed org/apache/hadoop/hdfs/HdfsConfiguration2022-08-17T03:01:46.2561194Z Aug 17 03:01:46 java.lang.NullPointerException: &lt;no message&gt;2022-08-17T03:01:46.2561726Z Aug 17 03:01:46 [ERROR] Run 2: Multiple Failures (2 failures)2022-08-17T03:01:46.2562317Z Aug 17 03:01:46 java.lang.AssertionError: Test failed org/apache/hadoop/hdfs/HdfsConfiguration2022-08-17T03:01:46.2562926Z Aug 17 03:01:46 java.lang.NullPointerException: &lt;no message&gt;2022-08-17T03:01:46.2563375Z Aug 17 03:01:46 [INFO] 2022-08-17T03:01:46.2563836Z Aug 17 03:01:46 [ERROR] UsingRemoteJarITCase.testUdfInRemoteJar2022-08-17T03:01:46.2564373Z Aug 17 03:01:46 [ERROR] Run 1: Multiple Failures (2 failures)2022-08-17T03:01:46.2564979Z Aug 17 03:01:46 java.lang.AssertionError: Test failed org/apache/hadoop/hdfs/HdfsConfiguration2022-08-17T03:01:46.2565573Z Aug 17 03:01:46 java.lang.NullPointerException: &lt;no message&gt;2022-08-17T03:01:46.2566104Z Aug 17 03:01:46 [ERROR] Run 2: Multiple Failures (2 failures)2022-08-17T03:01:46.2566702Z Aug 17 03:01:46 java.lang.AssertionError: Test failed org/apache/hadoop/hdfs/HdfsConfiguration2022-08-17T03:01:46.2567306Z Aug 17 03:01:46 java.lang.NullPointerException: &lt;no message&gt;2022-08-17T03:01:46.2567755Z Aug 17 03:01:46 [INFO] 2022-08-17T03:01:46.2568104Z Aug 17 03:01:46 [INFO] 2022-08-17T03:01:46.2568576Z Aug 17 03:01:46 [ERROR] Tests run: 6, Failures: 4, Errors: 0, Skipped: 0https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=40084&amp;view=logs&amp;j=87489130-75dc-54e4-1f45-80c30aa367a3&amp;t=73da6d75-f30d-5d5a-acbe-487a9dcff678</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-sql.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-17 01:00:00" id="29009" opendate="2022-8-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>flink-end-to-end-tests-sql compile failed in hadoop3</summary>
      <description>2022-08-17T00:39:13.9082097Z Dependency convergence error for com.nimbusds:nimbus-jose-jwt:4.41.1 paths to dependency are:2022-08-17T00:39:13.9082987Z +-org.apache.flink:flink-end-to-end-tests-sql:1.16-SNAPSHOT2022-08-17T00:39:13.9083712Z +-org.apache.hadoop:hadoop-common:3.1.32022-08-17T00:39:13.9084340Z +-org.apache.hadoop:hadoop-auth:3.1.32022-08-17T00:39:13.9084963Z +-com.nimbusds:nimbus-jose-jwt:4.41.12022-08-17T00:39:13.9085616Z and2022-08-17T00:39:13.9086212Z +-org.apache.flink:flink-end-to-end-tests-sql:1.16-SNAPSHOT2022-08-17T00:39:13.9086864Z +-org.apache.hadoop:hadoop-common:3.1.32022-08-17T00:39:13.9087499Z +-org.apache.kerby:kerb-simplekdc:1.0.12022-08-17T00:39:13.9088125Z +-org.apache.kerby:kerb-client:1.0.12022-08-17T00:39:13.9088753Z +-org.apache.kerby:token-provider:1.0.12022-08-17T00:39:13.9089381Z +-com.nimbusds:nimbus-jose-jwt:3.102022-08-17T00:39:13.9089596Z 2022-08-17T00:39:13.9090061Z [WARNING] Rule 0: org.apache.maven.plugins.enforcer.DependencyConvergence failed with message:2022-08-17T00:39:13.9090651Z Failed while enforcing releasability. See above detailed error message.https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=40084&amp;view=logs&amp;j=b1fcf054-9138-5463-c73c-a49979b9ac2a&amp;t=9291ac46-dd95-5135-b799-3839e65a8691</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-sql.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-17 01:00:00" id="29012" opendate="2022-8-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>flink function doc is not correct</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.data.sql.functions.zh.yml</file>
      <file type="M">docs.data.sql.functions.yml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-9-18 01:00:00" id="29020" opendate="2022-8-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add document for CTAS feature</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.dev.table.sql.create.md</file>
      <file type="M">docs.content.zh.docs.dev.table.sql.create.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-9-18 01:00:00" id="29022" opendate="2022-8-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add document for CREATE FUNCTION USING JAR feature</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.dev.table.sql.create.md</file>
      <file type="M">docs.content.zh.docs.dev.table.sql.create.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-9-18 01:00:00" id="29023" opendate="2022-8-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Updating Jar statement document</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0,1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.zh.docs.dev.table.sql.create.md</file>
      <file type="M">docs.content.docs.dev.table.sql.jar.md</file>
      <file type="M">docs.content.docs.dev.table.sourcesSinks.md</file>
      <file type="M">docs.content.docs.dev.table.catalogs.md</file>
      <file type="M">docs.content.zh.docs.dev.table.sql.jar.md</file>
      <file type="M">docs.content.zh.docs.dev.table.sourcesSinks.md</file>
      <file type="M">docs.content.zh.docs.dev.table.catalogs.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-18 01:00:00" id="29028" opendate="2022-8-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the missing cache api in Python DataStream API</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.pyflink.datastream.stream.execution.environment.py</file>
      <file type="M">flink-python.pyflink.datastream.data.stream.py</file>
      <file type="M">docs.content.docs.dev.datastream.operators.overview.md</file>
      <file type="M">docs.content.zh.docs.dev.datastream.operators.overview.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-18 01:00:00" id="29029" opendate="2022-8-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the bug of CSV format doesn&amp;#39;t work in Thread Mode</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.test.java.org.apache.flink.streaming.api.utils.PythonTypeUtilsTest.java</file>
      <file type="M">flink-python.src.main.java.org.apache.flink.streaming.api.utils.PythonTypeUtils.java</file>
      <file type="M">flink-python.pyflink.datastream.formats.tests.test.csv.py</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-18 01:00:00" id="29036" opendate="2022-8-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Code examples on the Data Sources page have errors</summary>
      <description>While reviewing the Data Source, some examples are slightly out of date.As an example, FutureNotifier doesn't exist any more.This page (as well as some javadoc) could be reviewed for correctness.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.SourceOperator.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.connector.source.SourceReaderContext.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.connector.source.SourceReader.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.connector.source.ReaderOutput.java</file>
      <file type="M">docs.content.docs.dev.datastream.sources.md</file>
      <file type="M">docs.content.zh.docs.dev.datastream.sources.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-19 01:00:00" id="29041" opendate="2022-8-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add utility to test POJO compliance without any Kryo usage</summary>
      <description>Add a variant of the test util added in FLINK-28636 that additionally asserts that Kryo is not used for any contained field.</description>
      <version>None</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.test.java.org.apache.flink.types.PojoTestUtilsTest.java</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.src.main.java.org.apache.flink.types.PojoTestUtils.java</file>
      <file type="M">docs.content.docs.dev.datastream.fault-tolerance.serialization.types.serialization.md</file>
      <file type="M">docs.content.zh.docs.dev.datastream.fault-tolerance.serialization.types.serialization.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-9-20 01:00:00" id="29047" opendate="2022-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[3.1] Shade the Flink-Kubernetes Fabric8 Kubernetes dependency with org.apache.flink.shaded prefix</summary>
      <description>For supporting stepDecorators plugin mechanism, we load the plugin via existing Flink plugin from plugins directory. And make it like SPI. So we need to shade the Flink kubernetes(Fabric8) as a whitelist for loading the said Classes during SPI loading instance. Due to some/most part of plugins need depends on the existing Flink Fabric8 dependency. So we need to load the said classes in parent classloader, won't load all classes from Plugin jars.</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-kubernetes.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-8-22 01:00:00" id="29059" opendate="2022-8-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>The existing column stats are deleted incorrectly when analyze table for partial columns</summary>
      <description>If there are three columns named `a, b, c` with column stats already exists,  I just analyze column `a` using `Analyze table xxx FOR COLUMNS a`, the existing column stats of `b, c` will be reset back to empty.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.runtime.batch.sql.AnalyzeTableITCase.java</file>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.api.internal.AnalyzeTableUtil.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-8-23 01:00:00" id="29081" opendate="2022-8-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Join Hint cannot be identified by lowercase</summary>
      <description>The following sql can reproduce this bug:select /+ bRoadCasT(t1) */ from t1 join t1 as t3 on t1.a = t3.a;</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.optimize.JoinHintResolverTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.optimize.ClearQueryBlockAliasResolverTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.hints.batch.ShuffleMergeJoinHintTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.hints.batch.ShuffleHashJoinHintTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.hints.batch.NestLoopJoinHintTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.hints.batch.BroadcastJoinHintTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.plan.hints.batch.JoinHintTestBase.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.hint.FlinkHints.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.calcite.sql2rel.SqlToRelConverter.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-8-23 01:00:00" id="29087" opendate="2022-8-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Jdbc connector sql ITCase failed when run in idea</summary>
      <description>java.lang.NoSuchFieldError: CORRELATE    at org.apache.flink.table.planner.hint.FlinkHintStrategies.createHintStrategyTable(FlinkHintStrategies.java:91)    at org.apache.flink.table.planner.delegation.PlannerContext.lambda$getSqlToRelConverterConfig$1(PlannerContext.java:288)    at java.util.Optional.orElseGet(Optional.java:267)    at org.apache.flink.table.planner.delegation.PlannerContext.getSqlToRelConverterConfig(PlannerContext.java:283)    at org.apache.flink.table.planner.delegation.PlannerContext.createFrameworkConfig(PlannerContext.java:146)    at org.apache.flink.table.planner.delegation.PlannerContext.&lt;init&gt;(PlannerContext.java:124)    at org.apache.flink.table.planner.delegation.PlannerBase.&lt;init&gt;(PlannerBase.scala:121)    at org.apache.flink.table.planner.delegation.StreamPlanner.&lt;init&gt;(StreamPlanner.scala:65)    at org.apache.flink.table.planner.delegation.DefaultPlannerFactory.create(DefaultPlannerFactory.java:65)    at org.apache.flink.table.factories.PlannerFactoryUtil.createPlanner(PlannerFactoryUtil.java:58)    at org.apache.flink.table.api.internal.TableEnvironmentImpl.create(TableEnvironmentImpl.java:308)    at org.apache.flink.table.api.TableEnvironment.create(TableEnvironment.java:93)    at org.apache.flink.connector.jdbc.catalog.MySqlCatalogITCase.setup(MySqlCatalogITCase.java:159)    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    at java.lang.reflect.Method.invoke(Method.java:498)    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)    at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)    at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)    at org.junit.runners.Suite.runChild(Suite.java:128)    at org.junit.runners.Suite.runChild(Suite.java:27)    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)    at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)    at org.junit.runner.JUnitCore.run(JUnitCore.java:137)    at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)    at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)    at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)    at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)    at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235)    at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54)</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-jdbc.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-8-24 01:00:00" id="29096" opendate="2022-8-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>json_value when the path has blank, the result is not right</summary>
      <description>      </description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.resources.json.json-value.json</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.functions.JsonFunctionsITCase.java</file>
      <file type="M">flink-connectors.flink-connector-jdbc.src.main.java.org.apache.flink.connector.jdbc.catalog.JdbcCatalog.java</file>
      <file type="M">docs.data.sql.functions.zh.yml</file>
      <file type="M">docs.data.sql.functions.yml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-9-26 01:00:00" id="29113" opendate="2022-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Join hint with invalid table name mixed with valid names will not raise an error</summary>
      <description> add a  BROADCAST hint to tpch q2 with a non exists table 'supp' works fine, while a single invalid table name 'supp' will raise an error ```sqlexplain  SELECT /*+ BROADCAST(partsupp,supp) */ s_acctbal,  s_name,  n_name,  p_partkey,  p_mfgr,  s_address,  s_phone,  s_commentFROM  part,  supplier,  partsupp,  nation,  regionWHERE  p_partkey = ps_partkey  AND s_suppkey = ps_suppkey  AND p_size = 15  AND p_type LIKE '%BRASS'  AND s_nationkey = n_nationkey  AND n_regionkey = r_regionkey  AND r_name = 'EUROPE'  AND ps_supplycost = (    SELECT min(ps_supplycost)    FROM      partsupp, supplier,      nation, region    WHERE      p_partkey = ps_partkey      AND s_suppkey = ps_suppkey      AND s_nationkey = n_nationkey      AND n_regionkey = r_regionkey      AND r_name = 'EUROPE'  )ORDER BY  s_acctbal DESC,  n_name,  s_name,  p_partkeyLIMIT 100```</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0,1.17.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.plan.stream.sql.join.LookupJoinTest.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.plan.hints.batch.JoinHintTestBase.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.optimize.JoinHintResolver.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-9-26 01:00:00" id="29118" opendate="2022-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove default_catalog in the HiveServer2 Endpoint</summary>
      <description>Hive only has one Catalog. We don't require the default_catalog. Hive JDBC Driver also doesn't support multiple catalogs.  </description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-sql-gateway.src.test.java.org.apache.flink.table.gateway.service.SqlGatewayServiceITCase.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.test.java.org.apache.flink.table.gateway.service.context.SessionContextTest.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.service.session.SessionManager.java</file>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.service.context.SessionContext.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.src.test.java.org.apache.flink.table.gateway.api.session.SessionEnvironmentTest.java</file>
      <file type="M">flink-table.flink-sql-gateway-api.src.main.java.org.apache.flink.table.gateway.api.session.SessionEnvironment.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.table.endpoint.hive.HiveServer2EndpointStatementITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.table.endpoint.hive.HiveServer2EndpointITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.endpoint.hive.HiveServer2Endpoint.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-9-26 01:00:00" id="29120" opendate="2022-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unexpected join hint propagation into view</summary>
      <description>As expected, Join Hint should only affects the current query block, and does not affect the Join strategy in subquery and view.But current implementation behaviors inconsistently:use source tables of flink-tpch-test, the following join hint takes effect unexpectedlyFlink SQL&gt; create temporary view v1 as SELECT&gt;    p_name,&gt;    p_mfgr,&gt;    p_brand,&gt;    p_type,&gt;    s_name,&gt;    s_address&gt;  FROM&gt;    part,&gt;    supplier&gt;  WHERE p_partkey = s_suppkey;[INFO] Execute statement succeed. Flink SQL&gt; explain SELECT /*+ SHUFFLE_MERGE(part)  */ * from v1;== Abstract Syntax Tree ==LogicalProject(p_name=[$1], p_mfgr=[$2], p_brand=[$3], p_type=[$4], s_name=[$10], s_address=[$11])+- LogicalFilter(condition=[=($0, $9)])   +- LogicalJoin(condition=[true], joinType=[inner], joinHints=[[[SHUFFLE_MERGE inheritPath:[0, 0] options:[part]]]])      :- LogicalTableScan(table=[[default_catalog, default_database, part]])      +- LogicalTableScan(table=[[default_catalog, default_database, supplier]])== Optimized Physical Plan ==Calc(select=[p_name, p_mfgr, p_brand, p_type, s_name, s_address])+- SortMergeJoin(joinType=[InnerJoin], where=[=(p_partkey, s_suppkey)], select=[p_partkey, p_name, p_mfgr, p_brand, p_type, s_suppkey, s_name, s_address])   :- Exchange(distribution=[hash[p_partkey]])   :  +- TableSourceScan(table=[[default_catalog, default_database, part, project=[p_partkey, p_name, p_mfgr, p_brand, p_type], metadata=[]]], fields=[p_partkey, p_name, p_mfgr, p_brand, p_type])   +- Exchange(distribution=[hash[s_suppkey]])      +- TableSourceScan(table=[[default_catalog, default_database, supplier, project=[s_suppkey, s_name, s_address], metadata=[]]], fields=[s_suppkey, s_name, s_address])== Optimized Execution Plan ==Calc(select=[p_name, p_mfgr, p_brand, p_type, s_name, s_address])+- SortMergeJoin(joinType=[InnerJoin], where=[(p_partkey = s_suppkey)], select=[p_partkey, p_name, p_mfgr, p_brand, p_type, s_suppkey, s_name, s_address])   :- Exchange(distribution=[hash[p_partkey]])   :  +- TableSourceScan(table=[[default_catalog, default_database, part, project=[p_partkey, p_name, p_mfgr, p_brand, p_type], metadata=[]]], fields=[p_partkey, p_name, p_mfgr, p_brand, p_type])   +- Exchange(distribution=[hash[s_suppkey]])      +- TableSourceScan(table=[[default_catalog, default_database, supplier, project=[s_suppkey, s_name, s_address], metadata=[]]], fields=[s_suppkey, s_name, s_address]) without hintFlink SQL&gt; explain SELECT * from v1;== Abstract Syntax Tree ==LogicalProject(p_name=[$1], p_mfgr=[$2], p_brand=[$3], p_type=[$4], s_name=[$10], s_address=[$11])+- LogicalFilter(condition=[=($0, $9)])   +- LogicalJoin(condition=[true], joinType=[inner])      :- LogicalTableScan(table=[[default_catalog, default_database, part]])      +- LogicalTableScan(table=[[default_catalog, default_database, supplier]])== Optimized Physical Plan ==Calc(select=[p_name, p_mfgr, p_brand, p_type, s_name, s_address])+- HashJoin(joinType=[InnerJoin], where=[=(p_partkey, s_suppkey)], select=[p_partkey, p_name, p_mfgr, p_brand, p_type, s_suppkey, s_name, s_address], isBroadcast=[true], build=[right])   :- TableSourceScan(table=[[default_catalog, default_database, part, project=[p_partkey, p_name, p_mfgr, p_brand, p_type], metadata=[]]], fields=[p_partkey, p_name, p_mfgr, p_brand, p_type])   +- Exchange(distribution=[broadcast])      +- TableSourceScan(table=[[default_catalog, default_database, supplier, project=[s_suppkey, s_name, s_address], metadata=[]]], fields=[s_suppkey, s_name, s_address])== Optimized Execution Plan ==Calc(select=[p_name, p_mfgr, p_brand, p_type, s_name, s_address])+- MultipleInput(readOrder=[1,0], members=[\nHashJoin(joinType=[InnerJoin], where=[(p_partkey = s_suppkey)], select=[p_partkey, p_name, p_mfgr, p_brand, p_type, s_suppkey, s_name, s_address], isBroadcast=[true], build=[right])\n:- [#1] TableSourceScan(table=[[default_catalog, default_database, part, project=[p_partkey, p_name, p_mfgr, p_brand, p_type], metadata=[]]], fields=[p_partkey, p_name, p_mfgr, p_brand, p_type])\n+- [#2] Exchange(distribution=[broadcast])\n])   :- TableSourceScan(table=[[default_catalog, default_database, part, project=[p_partkey, p_name, p_mfgr, p_brand, p_type], metadata=[]]], fields=[p_partkey, p_name, p_mfgr, p_brand, p_type])   +- Exchange(distribution=[broadcast])      +- TableSourceScan(table=[[default_catalog, default_database, supplier, project=[s_suppkey, s_name, s_address], metadata=[]]], fields=[s_suppkey, s_name, s_address])  </description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.optimize.JoinHintResolverTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.optimize.ClearQueryBlockAliasResolverTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.hints.batch.ShuffleMergeJoinHintTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.hints.batch.ShuffleHashJoinHintTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.hints.batch.NestLoopJoinHintTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.resources.org.apache.flink.table.planner.plan.hints.batch.BroadcastJoinHintTest.xml</file>
      <file type="M">flink-table.flink-table-planner.src.test.java.org.apache.flink.table.planner.plan.hints.batch.JoinHintTestBase.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.calcite.FlinkPlannerImpl.scala</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-10-29 01:00:00" id="29126" opendate="2022-8-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix spliting file optimization doesn&amp;#39;t work for orc format</summary>
      <description>FLINK-27338 try to improve file spliting for orc format. But it doesn't work for a making  mistake in judge whether the table is stored as orc format or not. We should fix it.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0,1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.PartitionMonitorTest.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.HiveSourceFileEnumeratorTest.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.connectors.hive.HiveSourceFileEnumerator.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.connectors.hive.HiveSourceBuilder.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.connectors.hive.HiveOptions.java</file>
      <file type="M">docs.content.docs.connectors.table.hive.hive.read.write.md</file>
      <file type="M">docs.content.zh.docs.connectors.table.hive.hive.read.write.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-9-31 01:00:00" id="29148" opendate="2022-8-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add docs for SQL Gateway</summary>
      <description>Add basic doc for SQL Gateway.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0,1.17.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.endpoint.hive.HiveServer2EndpointConfigOptions.java</file>
      <file type="M">docs.content.docs.dev.table.overview.md</file>
      <file type="M">docs.content.docs.dev.table.hiveCompatibility.hiveserver2.md</file>
      <file type="M">docs.content.zh.docs.dev.table.hiveCompatibility.hiveserver2.md</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-9-2 01:00:00" id="29185" opendate="2022-9-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failed to execute USING JAR in Hive Dialect</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0,1.17.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-api-java.src.main.java.org.apache.flink.table.catalog.FunctionCatalog.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.connectors.hive.HiveDialectITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.planner.delegation.hive.parse.HiveParserDDLSemanticAnalyzer.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.planner.delegation.hive.HiveParser.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-9-5 01:00:00" id="29196" opendate="2022-9-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>flink-python NOTICE is incorrect</summary>
      <description>We should check the licensing of the 1.16 release.https://cwiki.apache.org/confluence/display/FLINK/Licensing </description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-python.src.main.resources.META-INF.licenses.LICENSE.jzlib</file>
      <file type="M">flink-python.src.main.resources.META-INF.licenses.LICENSE.bouncycastle</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-9-6 01:00:00" id="29211" opendate="2022-9-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive 2.3.9 NOTICE is incorrect</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-sql-connector-hive-2.3.9.src.main.resources.META-INF.NOTICE</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-9-8 01:00:00" id="29228" opendate="2022-9-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Align the schema of the HiveServer2 getMetadata with JDBC</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.table.endpoint.hive.HiveServer2EndpointITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.endpoint.hive.HiveServer2Schemas.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-9-8 01:00:00" id="29229" opendate="2022-9-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix HiveServer2 Endpoint doesn&amp;#39;t support execute statements in sync mode</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-sql-gateway.src.main.java.org.apache.flink.table.gateway.service.SqlGatewayServiceImpl.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.test.java.org.apache.flink.table.endpoint.hive.HiveServer2EndpointITCase.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.endpoint.hive.util.ThriftObjectConversions.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.table.endpoint.hive.HiveServer2Endpoint.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2022-9-14 01:00:00" id="29299" opendate="2022-9-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix the network memory size calculation issue in fine-grained resource mode</summary>
      <description>After FLINK-28663, one intermediate dataset can be consumed by multiple consumers, there is a case where one vertex can consume one intermediate dataset multiple times. However, currently in fine-grained resource mode, when computing the required network buffer size, the intermediate dataset is used as key to record the size of network buffer per input gate, which means it may allocate less network buffers than needed if two input gate of the same vertex consumes the same intermediate dataset.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.scheduler.SsgNetworkMemoryCalculationUtilsTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.shuffle.TaskInputsOutputsDescriptor.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.shuffle.NettyShuffleMaster.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.scheduler.SsgNetworkMemoryCalculationUtils.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-10-20 01:00:00" id="29350" opendate="2022-9-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add a section for moving planner jar in Hive dependencies page</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0,1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.dev.table.hive-compatibility.hive-dialect.queries.transform.md</file>
      <file type="M">docs.content.docs.dev.table.hive-compatibility.hive-dialect.queries.sub-queries.md</file>
      <file type="M">docs.content.docs.dev.table.hive-compatibility.hive-dialect.queries.lateral-view.md</file>
      <file type="M">docs.content.docs.dev.table.hive-compatibility.hive-dialect.queries.join.md</file>
      <file type="M">docs.content.docs.dev.table.hive-compatibility.hive-dialect.overview.md</file>
      <file type="M">docs.content.docs.dev.table.hive-compatibility.hive-dialect.insert.md</file>
      <file type="M">docs.content.docs.dev.table.hive-compatibility.hive-dialect.drop.md</file>
      <file type="M">docs.content.docs.dev.table.hive-compatibility.hive-dialect.create.md</file>
      <file type="M">docs.content.docs.dev.table.hive-compatibility.hive-dialect.alter.md</file>
      <file type="M">docs.content.docs.connectors.table.hive.overview.md</file>
      <file type="M">docs.content.zh.docs.dev.table.hive-compatibility.hive-dialect.queries.transform.md</file>
      <file type="M">docs.content.zh.docs.dev.table.hive-compatibility.hive-dialect.queries.sub-queries.md</file>
      <file type="M">docs.content.zh.docs.dev.table.hive-compatibility.hive-dialect.queries.lateral-view.md</file>
      <file type="M">docs.content.zh.docs.dev.table.hive-compatibility.hive-dialect.queries.join.md</file>
      <file type="M">docs.content.zh.docs.dev.table.hive-compatibility.hive-dialect.overview.md</file>
      <file type="M">docs.content.zh.docs.dev.table.hive-compatibility.hive-dialect.insert.md</file>
      <file type="M">docs.content.zh.docs.dev.table.hive-compatibility.hive-dialect.drop.md</file>
      <file type="M">docs.content.zh.docs.dev.table.hive-compatibility.hive-dialect.create.md</file>
      <file type="M">docs.content.zh.docs.dev.table.hive-compatibility.hive-dialect.alter.md</file>
      <file type="M">docs.content.zh.docs.connectors.table.hive.overview.md</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2022-9-22 01:00:00" id="29389" opendate="2022-9-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update documentation of JDBC and HBase lookup table for new caching options</summary>
      <description>Update documentation of JDBC and HBase lookup table for new caching options</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.connectors.table.jdbc.md</file>
      <file type="M">docs.content.docs.connectors.table.hbase.md</file>
      <file type="M">docs.content.zh.docs.connectors.table.jdbc.md</file>
      <file type="M">docs.content.zh.docs.connectors.table.hbase.md</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2022-10-28 01:00:00" id="29455" opendate="2022-9-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add OperatorIdentifier</summary>
      <description>Add a class for identifying operators, that supports both uids and uidhashes, and integrate into the low-level APIs.</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-libraries.flink-state-processing-api.src.main.java.org.apache.flink.state.api.WindowSavepointReader.java</file>
      <file type="M">flink-libraries.flink-state-processing-api.src.main.java.org.apache.flink.state.api.SavepointWriter.java</file>
      <file type="M">flink-libraries.flink-state-processing-api.src.main.java.org.apache.flink.state.api.SavepointReader.java</file>
      <file type="M">flink-libraries.flink-state-processing-api.src.main.java.org.apache.flink.state.api.runtime.metadata.SavepointMetadataV2.java</file>
      <file type="M">flink-libraries.flink-state-processing-api.src.main.java.org.apache.flink.state.api.EvictingWindowSavepointReader.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-10-28 01:00:00" id="29458" opendate="2022-9-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>When two tables have the same field, do not specify the table name,Exception will be thrown：SqlValidatorException :Column &amp;#39;currency&amp;#39; is ambiguous</summary>
      <description>When two tables are join, the two tables have the same field. When querying select, an exception will be thrown if the table name is not specifiedexception contentColumn 'currency' is ambiguous。 </description>
      <version>1.16.0</version>
      <fixedVersion>1.17.0,1.16.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.dev.table.sql.queries.joins.md</file>
      <file type="M">docs.content.zh.docs.dev.table.sql.queries.joins.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-4-30 01:00:00" id="2946" opendate="2015-10-30 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Add orderBy() to Table API</summary>
      <description>In order to implement a FLINK-2099 prototype that uses the Table APIs code generation facilities, the Table API needs a sorting feature.I would implement it the next days. Ideas how to implement such a sorting feature are very welcome. Is there any more efficient way instead of .sortPartition(...).setParallism(1)? Is it better to sort locally on the nodes first and finally sort on one node afterwards?</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-test-utils.src.main.java.org.apache.flink.test.util.TestBaseUtils.java</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.table.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.rules.FlinkRuleSets.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetRel.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.BatchScan.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.expressions.ExpressionParser.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.scala.table.expressionDsl.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-10-29 01:00:00" id="29468" opendate="2022-9-29 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update jackson-bom to 2.13.4</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.16.0,1.15.3,elasticsearch-3.0.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-python.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-kubernetes.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-formats.flink-sql-avro.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-formats.flink-sql-avro-confluent-registry.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-gs-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-fs-hadoop-shaded.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-azure-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-aws-kinesis-firehose.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.resources.META-INF.NOTICE</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-10-30 01:00:00" id="29477" opendate="2022-9-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ClassCastException when collect primitive array to Python</summary>
      <description>How to reproduce this bug:ds = env.from_collection([1, 2], type_info=Types.PRIMITIVE_ARRAY(Types.INT()))ds.execute_and_collect()got:java.lang.ClassCastException: class [I cannot be cast to class [Ljava.lang.Object</description>
      <version>1.16.0,1.15.2</version>
      <fixedVersion>1.16.0,1.15.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.src.main.java.org.apache.flink.api.common.python.PythonBridgeUtils.java</file>
      <file type="M">flink-python.pyflink.datastream.tests.test.data.stream.py</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-10-30 01:00:00" id="29483" opendate="2022-9-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>flink python udf arrow in thread model bug</summary>
      <description/>
      <version>1.16.0,1.15.2</version>
      <fixedVersion>1.16.0,1.17.0,1.15.3</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.common.CommonExecPythonCalc.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-10-4 01:00:00" id="29502" opendate="2022-10-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update the Hadoop implementation for filesystems to 3.3.4</summary>
      <description>Flink currently uses Hadoop version 3.3.2 for the Flink filesystem implementations. Upgrading this to version 3.3.4 will resolve some CVEs like https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-25168 (which Flink is not affected by)</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-filesystems.pom.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.pom.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.pom.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-base.pom.xml</file>
      <file type="M">flink-filesystems.flink-oss-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-oss-fs-hadoop.pom.xml</file>
      <file type="M">flink-filesystems.flink-gs-fs-hadoop.pom.xml</file>
      <file type="M">flink-filesystems.flink-fs-hadoop-shaded.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-fs-hadoop-shaded.pom.xml</file>
      <file type="M">flink-filesystems.flink-azure-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-azure-fs-hadoop.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-10-5 01:00:00" id="29508" opendate="2022-10-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Some NOTICE files are not checked for correctness</summary>
      <description>We have 3 modules that are not being deployed (and thus auto-excluded since FLINK-29301) which are still relevant for production though.We should amend the checker to take into account whether the non-deployed module is bundled by another deployed module.</description>
      <version>1.16.0</version>
      <fixedVersion>1.16.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.ci.flink-ci-tools.src.test.java.org.apache.flink.tools.ci.licensecheck.NoticeFileCheckerTest.java</file>
      <file type="M">tools.ci.flink-ci-tools.src.main.java.org.apache.flink.tools.ci.licensecheck.NoticeFileChecker.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-10-5 01:00:00" id="29511" opendate="2022-10-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sort properties/schemas in OpenAPI spec</summary>
      <description>The properties/schema order is currently based on whatever order they were looked up, which varies as the spec is being extended.Sort them by name to prevent this.</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-docs.src.main.java.org.apache.flink.docs.rest.OpenApiSpecGenerator.java</file>
      <file type="M">docs.static.generated.rest.v1.sql.gateway.yml</file>
      <file type="M">docs.static.generated.rest.v1.dispatcher.yml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-10-5 01:00:00" id="29514" opendate="2022-10-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump Minikdc to v3.2.4</summary>
      <description>Bump Minikdc to v3.2.4 to remove false positive scans on CVEs like CVE-2021-29425 and CVE-2020-15250</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-yarn-tests.pom.xml</file>
      <file type="M">flink-test-utils-parent.flink-test-utils.pom.xml</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-hbase.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-10-6 01:00:00" id="29517" opendate="2022-10-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update documentation about DATE_FORMAT to state that it&amp;#39;s supported in Table API</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.expressions.TemporalTypesTest.scala</file>
      <file type="M">docs.data.sql.functions.zh.yml</file>
      <file type="M">docs.data.sql.functions.yml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-3 01:00:00" id="2955" opendate="2015-11-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add operations introduction in Table API page.</summary>
      <description>On the Table API page, there is no formal introduction of current supported operations, it should be nice to have it.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.libs.table.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-10-10 01:00:00" id="29568" opendate="2022-10-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove unnecessary whitespace in request/response blocks</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-docs.src.main.java.org.apache.flink.docs.rest.RestAPIDocGenerator.java</file>
      <file type="M">docs.layouts.shortcodes.generated.rest.v1.sql.gateway.html</file>
      <file type="M">docs.layouts.shortcodes.generated.rest.v1.dispatcher.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-10-10 01:00:00" id="29569" opendate="2022-10-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace usages of deprecated expand shortcode</summary>
      <description>The expand shortcode is deprecated; use &lt;details&gt; instead.</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-docs.src.main.java.org.apache.flink.docs.rest.RestAPIDocGenerator.java</file>
      <file type="M">docs.layouts.shortcodes.generated.rest.v1.sql.gateway.html</file>
      <file type="M">docs.layouts.shortcodes.generated.rest.v1.dispatcher.html</file>
      <file type="M">docs.content.docs.dev.table.sql.queries.overview.md</file>
      <file type="M">docs.content.docs.dev.table.common.md</file>
      <file type="M">docs.content.zh.docs.dev.table.sql.queries.overview.md</file>
      <file type="M">docs.assets..custom.scss</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-11-13 01:00:00" id="29624" opendate="2022-10-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade org.apache.commons:commons-lang3 from 3.3.2 to 3.12.0</summary>
      <description>Upgrade org.apache.commons:commons-lang3 from 3.3.2 to 3.12.0 to avoid being falsely flagged for CVEs CVE-2021-29425 and CVE-2020-15250</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.UnalignedCheckpointRescaleITCase.java</file>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.UnalignedCheckpointITCase.java</file>
      <file type="M">flink-table.flink-sql-parser-hive.src.main.java.org.apache.flink.sql.parser.hive.ddl.HiveDDLUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobgraph.jsonplan.JsonPlanGenerator.java</file>
      <file type="M">flink-runtime.pom.xml</file>
      <file type="M">flink-optimizer.src.main.java.org.apache.flink.optimizer.plandump.PlanJSONDumpGenerator.java</file>
      <file type="M">flink-formats.flink-csv.src.main.java.org.apache.flink.formats.csv.CsvFormatFactory.java</file>
      <file type="M">flink-formats.flink-csv.src.main.java.org.apache.flink.formats.csv.CsvFileFormatFactory.java</file>
      <file type="M">flink-formats.flink-csv.src.main.java.org.apache.flink.formats.csv.CsvCommons.java</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-fs-hadoop-shaded.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-dist.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-core.pom.xml</file>
      <file type="M">flink-connectors.flink-sql-connector-kinesis.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-connectors.flink-sql-connector-hive-3.1.3.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-connectors.flink-sql-connector-hbase-2.2.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-connectors.flink-connector-pulsar.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-11-13 01:00:00" id="29628" opendate="2022-10-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bump aws-java-sdk-s3 to 1.12.319</summary>
      <description>As reported by Dependabot in https://github.com/apache/flink/pull/20285</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-yarn.pom.xml</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-base.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-12-4 01:00:00" id="2963" opendate="2015-11-4 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Dependence on SerializationUtils#deserialize() should be avoided</summary>
      <description>There is a problem with `SerializationUtils` from Apache CommonsLang. Here is an open issue where the class will throw a`ClassNotFoundException` even if the class is in the classpath in amultiple-classloader environment:https://issues.apache.org/jira/browse/LANG-1049 state = (HashMap&lt;String, Serializable&gt;) SerializationUtils.deserialize(bais);./flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/NonKeyedWindowOperator.java state = (HashMap&lt;String, Serializable&gt;) SerializationUtils.deserialize(bais);./flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/WindowOperator.java return SerializationUtils.deserialize(message);./flink-streaming-java/src/main/java/org/apache/flink/streaming/util/serialization/JavaDefaultStringSchema.java T copied = SerializationUtils.deserialize(SerializationUtils./flink-streaming-java/src/test/java/org/apache/flink/streaming/util/MockOutput.javaWe should move away from SerializationUtils.deserialize()</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.maven.checkstyle.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-10-14 01:00:00" id="29638" opendate="2022-10-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update jackson bom because of CVE-2022-42003</summary>
      <description>There is a CVE-2022-42003 fixed in 2.13.4.1 and 2.14.0-rc1https://nvd.nist.gov/vuln/detail/CVE-2022-42003P.S. It seems there will not be 2.14.0 release until end of October according to https://github.com/FasterXML/jackson-databind/issues/3590#issuecomment-1270363915</description>
      <version>1.16.0,1.17.0,1.15.2</version>
      <fixedVersion>1.16.0,1.17.0,1.15.3</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-python.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-kubernetes.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-formats.flink-sql-avro.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-formats.flink-sql-avro-confluent-registry.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-presto.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-s3-fs-hadoop.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-filesystems.flink-fs-hadoop-shaded.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-connectors.flink-connector-kinesis.src.main.resources.META-INF.NOTICE</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-11-14 01:00:00" id="29644" opendate="2022-10-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reference Kubernetes operator from Flink Kubernetes deploy docs</summary>
      <description>Currently the Flink deployment/resource provider docs provide some information for the Standalone and Native Kubernetes integration without any reference to the operator. We should provide a bit more visibility and value to the users by directly proposing to use the operator when considering Flink on Kubernetes. We should make the point that for most users the easiest way to use Flink on Kubernetes is probably through the operator (where they can now benefit from both standalone and native integration under the hood). This should help us avoid cases where a new user completely misses the existence of the operator when starting out based on the Flink docs.</description>
      <version>1.16.0,1.17.0,1.15.3</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.deployment.resource-providers.standalone.kubernetes.md</file>
      <file type="M">docs.content.docs.deployment.resource-providers.native.kubernetes.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-10-19 01:00:00" id="29684" opendate="2022-10-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[UI] Upgrade runtime web Angular framework and associated deps to v14</summary>
      <description>Angular framework and NG-ZORRO both have released their stable v14 versions. It is a good time to bump them to the latest.</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.tsconfig.json</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.customize.job-list.job-list.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.customize.job-chart.job-chart.service.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.customize.job-chart.job-chart.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.common.resize.resize.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.share.common.navigation.navigation.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.services.status.service.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.submit.submit.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.job-overview.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.app.module.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.package.json</file>
      <file type="M">flink-runtime-web.web-dashboard.package-lock.json</file>
      <file type="M">flink-runtime-web.web-dashboard.angular.json</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2022-10-28 01:00:00" id="29788" opendate="2022-10-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>StatefulJobWBroadcastStateMigrationITCase failed in native savepoints</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.17.0,1.16.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.utils.SnapshotMigrationTestBase.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-11-31 01:00:00" id="29812" opendate="2022-10-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove deprecated Netty API usages</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.RestServerEndpointITCase.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.netty.NettyConnectionManagerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestServerEndpointConfiguration.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.RestClient.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.util.KeepAliveWrite.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.util.HandlerUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.util.HandlerRedirectUtils.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.router.RouterHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.FileUploadHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.NettyServer.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.netty.NettyClient.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.testutils.HttpTestClient.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.utils.WebFrontendBootstrap.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.PipelineErrorHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.HttpRequestHandler.java</file>
      <file type="M">flink-runtime-web.src.main.java.org.apache.flink.runtime.webmonitor.history.HistoryServerStaticFileServerHandler.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-runtime.src.test.java.org.apache.flink.queryablestate.network.KvStateServerTest.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-client-java.src.main.java.org.apache.flink.queryablestate.network.Client.java</file>
      <file type="M">flink-queryable-state.flink-queryable-state-client-java.src.main.java.org.apache.flink.queryablestate.network.AbstractServerBase.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-7-6 01:00:00" id="2985" opendate="2015-11-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow different field names for unionAll() in Table API</summary>
      <description>The recently merged `unionAll` operator checks if the field names of the left and right side are equal. Actually, this is not necessary. The union operator in SQL checks only the types and uses the names of left side.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.util.serialization.JsonRowDeserializationSchema.java</file>
      <file type="M">flink-streaming-connectors.flink-connector-kafka-base.src.main.java.org.apache.flink.streaming.connectors.kafka.KafkaTableSource.java</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.stream.table.UnionITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.table.SetOperatorsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.test.scala.org.apache.flink.api.scala.batch.sql.SetOperatorsITCase.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.TypeConverter.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.typeutils.RowTypeInfo.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.schema.TableSourceTable.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.nodes.dataset.DataSetAggregate.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.plan.logical.operators.scala</file>
      <file type="M">flink-libraries.flink-table.src.main.scala.org.apache.flink.api.table.codegen.CodeGenerator.scala</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-3-2 01:00:00" id="29852" opendate="2022-11-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adaptive Scheduler duplicates operators for each parallel instance in the Web UI</summary>
      <description>All the operators in the DAG are shown repeatedly</description>
      <version>1.16.0,1.16.1</version>
      <fixedVersion>1.17.0,1.16.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.scheduler.adaptive.AdaptiveSchedulerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.scheduler.adaptive.CreatingExecutionGraph.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-2-3 01:00:00" id="29859" opendate="2022-11-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>TPC-DS end-to-end test with adaptive batch scheduler failed due to oo non-empty .out files.</summary>
      <description>Nov 03 02:02:12 &amp;#91;FAIL&amp;#93; 'TPC-DS end-to-end test with adaptive batch scheduler' failed after 21 minutes and 44 seconds! Test exited with exit code 0 but the logs contained errors, exceptions or non-empty .out files https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=42766&amp;view=logs&amp;s=ae4f8708-9994-57d3-c2d7-b892156e7812&amp;j=af184cdd-c6d8-5084-0b69-7e9c67b35f7a</description>
      <version>1.16.0,1.17.0</version>
      <fixedVersion>1.17.0,1.16.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-end-to-end-tests.test-scripts.test.tpcds.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.test-runner-common.sh</file>
      <file type="M">flink-end-to-end-tests.test-scripts.common.sh</file>
      <file type="M">flink-end-to-end-tests.run-nightly-tests.sh</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2022-11-7 01:00:00" id="29920" opendate="2022-11-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Minor reformat Kafka connector documentation</summary>
      <description>We used some HTML tag in the documentation which does not interpret Markdown format nicely. This fixes this by replacing with Markdown tags.</description>
      <version>1.16.0</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.connectors.table.kafka.md</file>
      <file type="M">docs.content.zh.docs.connectors.table.kafka.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-12-11 01:00:00" id="29996" opendate="2022-11-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Link to the task manager&amp;#39;s thread dump page in the backpressure tab</summary>
      <description>Currently, we have a complex steps to find the thread dump of backpressured tasks, however, this could be simplified with a link in the backpressure tab of web UI.</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.backpressure.job-overview-drawer-backpressure.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.backpressure.job-overview-drawer-backpressure.component.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-12-11 01:00:00" id="29997" opendate="2022-11-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Link to the taskmanager page in the expired sub-task of checkpoint tab</summary>
      <description>Currently, when we debug why some of the sub-tasks cannot complete the checkpoints in time, we have a complex steps to find which task manager containing such logs. This could be simplified via a direct link.</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.checkpoints.subtask.job-checkpoints-subtask.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.checkpoints.subtask.job-checkpoints-subtask.component.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-12-11 01:00:00" id="29998" opendate="2022-11-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make the backpressure tab could be sort by the busy percent</summary>
      <description>Currently, we cannot sort the backpressure tab to see which task is busiest.</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.backpressure.job-overview-drawer-backpressure.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.backpressure.job-overview-drawer-backpressure.component.html</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-11-16 01:00:00" id="30041" opendate="2022-11-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Setup conjars https mirror</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.ci.google-mirror-settings.xml</file>
      <file type="M">tools.ci.alibaba-mirror-settings.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-11-16 01:00:00" id="30044" opendate="2022-11-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Deduplicate plugin parser loops</summary>
      <description>The flink-ci-tools parse the output of various modules and each have their own looping logic to that end, that are pretty much identical though.</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">tools.ci.flink-ci-tools.src.test.java.org.apache.flink.tools.ci.utils.deploy.DeployParserTest.java</file>
      <file type="M">tools.ci.flink-ci-tools.src.main.java.org.apache.flink.tools.ci.utils.shade.ShadeParser.java</file>
      <file type="M">tools.ci.flink-ci-tools.src.main.java.org.apache.flink.tools.ci.utils.deploy.DeployParser.java</file>
      <file type="M">tools.ci.flink-ci-tools.src.main.java.org.apache.flink.tools.ci.utils.dependency.DependencyParser.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-11-12 01:00:00" id="3005" opendate="2015-11-12 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Commons-collections object deserialization remote command execution vulnerability</summary>
      <description>http://foxglovesecurity.com/2015/11/06/what-do-weblogic-websphere-jboss-jenkins-opennms-and-your-application-have-in-common-this-vulnerability/TL;DR: If you have commons-collections on your classpath and accept and process Java object serialization data, then you may have an exploitable remote command execution vulnerability.Brief search in code base for ObjectInputStream reveals several places where the vulnerability exists.</description>
      <version>None</version>
      <fixedVersion>0.10.1,1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-11-18 01:00:00" id="30079" opendate="2022-11-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stop using deprecated TM options in doc</summary>
      <description>The option ConfigConstants.TASK_MANAGER_MEMORY_FRACTION_KEY was deprecated and configuring it should have no effect now. However, in the documentation we still reference it and show in example code. This can be replaced with TaskManagerOptions.MANAGED_MEMORY_FRACTION.</description>
      <version>1.16.0</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.dev.dataset.local.execution.md</file>
      <file type="M">docs.content.zh.docs.dev.dataset.local.execution.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-12-21 01:00:00" id="30116" opendate="2022-11-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t Show Env Vars in Web UI</summary>
      <description>As discussed and agreed upon in &amp;#91;1&amp;#93;, we'd like to revert &amp;#91;2&amp;#93; and not show any environment variables in the Web UI for security reasons. &amp;#91;1&amp;#93; https://lists.apache.org/thread/rjgk15bqttvblp60zry4n5pw4xjw7q9k &amp;#91;2&amp;#93; https://issues.apache.org/jira/browse/FLINK-28311</description>
      <version>1.16.0</version>
      <fixedVersion>1.17.0,1.16.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.job.JobManagerJobEnvironmentHeaders.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.EnvironmentInfo.java</file>
      <file type="M">flink-runtime-web.src.test.resources.rest.api.v1.snapshot</file>
      <file type="M">docs.static.generated.rest.v1.dispatcher.yml</file>
      <file type="M">docs.layouts.shortcodes.generated.rest.v1.dispatcher.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-1-23 01:00:00" id="30169" opendate="2022-11-23 00:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Adds version switcher in PyFlink API doc</summary>
      <description>Adds version switcher in PyFlink API doc</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-11-24 01:00:00" id="30180" opendate="2022-11-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove the description of Filesystem supporting for the lookup in the Supported Connectors section</summary>
      <description>In the Supported Connectors section, the graph shows that the Filesystem connector supports the lookup source. Actually, it doesn't.So I want to remove this description.  </description>
      <version>1.16.0</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">docs.content.docs.connectors.table.overview.md</file>
      <file type="M">docs.content.zh.docs.connectors.table.overview.md</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2022-12-30 01:00:00" id="30250" opendate="2022-11-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>The flame graph type is wrong</summary>
      <description>When the flame graph type is switched from On-CPU to Mixed. It still show the graph of On-CPU.Root cause:When click the other types, the web frontend will call the requestFlameGraph and update the graphType. However, the graphType is the old type during requestFlameGraph. So the graph type show the new type, but the flame graph is the result of old type. code link</description>
      <version>1.15.0,1.16.0,1.17.0</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.flamegraph.job-overview-drawer-flamegraph.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.overview.flamegraph.job-overview-drawer-flamegraph.component.html</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.interfaces.job-flamegraph.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.components.flame-graph.flame-graph.component.ts</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2022-12-2 01:00:00" id="30286" opendate="2022-12-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Run rat plugin in validate phase</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">tools.ci.compile.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-7-17 01:00:00" id="3034" opendate="2015-11-17 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Redis SInk Connector</summary>
      <description>Flink does not provide a sink connector for Redis.See FLINK-3033</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-connectors.pom.xml</file>
      <file type="M">docs.apis.streaming.fault.tolerance.md</file>
      <file type="M">docs.apis.streaming.connectors.index.md</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-12-10 01:00:00" id="30358" opendate="2022-12-10 00:00:00" resolution="Done">
    <buginformation>
      <summary>Show the task manager id on the exception history page</summary>
      <description>At present, the web UI exception history page only displays the TM host and port. However, we generally need to search for problems according to the pod name or container ID.Therefore, it is more convenient to add resource id (pod name on k8s, container id on yarn) to the location column and a link to the task manager id to jump to the task manager page.</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.exceptions.job-exceptions.component.ts</file>
      <file type="M">flink-runtime-web.web-dashboard.src.app.pages.job.exceptions.job-exceptions.component.html</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.JobExceptionsInfoWithHistoryTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.messages.JobExceptionsInfoWithHistoryNoRootTest.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.rest.handler.job.JobExceptionsHandlerTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobExceptionsInfoWithHistory.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.messages.JobExceptionsInfo.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler.java</file>
      <file type="M">flink-runtime-web.src.test.resources.rest.api.v1.snapshot</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2022-1-13 01:00:00" id="30392" opendate="2022-12-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase the default value of cluster.thread-dump.stacktrace-max-depth</summary>
      <description>Currently, the thread dump function still have the default stack-trace depth as 8, which is the same as before. However, the default value is really too small for developers to know the actual thread info.From our experiences, we can set this value as 24.</description>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.test.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGeneratorTest.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.ResultPartitionFactoryTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.partition.ResultPartitionFactory.java</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.configuration.ClusterOptions.java</file>
      <file type="M">docs.layouts.shortcodes.generated.expert.cluster.section.html</file>
      <file type="M">docs.layouts.shortcodes.generated.cluster.configuration.html</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-12-13 01:00:00" id="30397" opendate="2022-12-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove Pulsar connector from master branch</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.delayer.MessageDelayer.java</file>
      <file type="M">tools.ci.flink-ci-tools.src.main.java.org.apache.flink.tools.ci.licensecheck.JarFileChecker.java</file>
      <file type="M">flink-python.pom.xml</file>
      <file type="M">tools.maven.suppressions.xml</file>
      <file type="M">tools.ci.stage.sh</file>
      <file type="M">pom.xml</file>
      <file type="M">flink-test-utils-parent.flink-test-utils-junit.src.main.java.org.apache.flink.util.DockerImageVersions.java</file>
      <file type="M">flink-end-to-end-tests.pom.xml</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-pulsar.src.test.resources.log4j2-test.properties</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-pulsar.src.test.java.org.apache.flink.tests.util.pulsar.source.FailoverSubscriptionContext.java</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-pulsar.src.test.java.org.apache.flink.tests.util.pulsar.source.ExclusiveSubscriptionContext.java</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-pulsar.src.test.java.org.apache.flink.tests.util.pulsar.PulsarSourceUnorderedE2ECase.java</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-pulsar.src.test.java.org.apache.flink.tests.util.pulsar.PulsarSourceOrderedE2ECase.java</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-pulsar.src.test.java.org.apache.flink.tests.util.pulsar.PulsarSinkE2ECase.java</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-pulsar.src.test.java.org.apache.flink.tests.util.pulsar.common.PulsarContainerTestEnvironment.java</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-pulsar.src.test.java.org.apache.flink.tests.util.pulsar.common.FlinkContainerWithPulsarEnvironment.java</file>
      <file type="M">flink-end-to-end-tests.flink-end-to-end-tests-pulsar.pom.xml</file>
      <file type="M">flink-docs.src.main.java.org.apache.flink.docs.util.ConfigurationOptionLocator.java</file>
      <file type="M">flink-docs.pom.xml</file>
      <file type="M">flink-connectors.pom.xml</file>
      <file type="M">flink-connectors.flink-sql-connector-pulsar.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-connectors.flink-sql-connector-pulsar.src.main.resources.META-INF.licences.LICENSE.bouncycastle</file>
      <file type="M">flink-connectors.flink-sql-connector-pulsar.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.resources.protobuf.sample.message.proto</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.resources.log4j2-test.properties</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.resources.archunit.properties</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.source.UnorderedSourceTestSuiteBase.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.source.PulsarSourceTestContext.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.source.PulsarPartitionDataWriter.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.source.KeyedPulsarPartitionDataWriter.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.source.cases.SingleTopicConsumingContext.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.source.cases.SharedSubscriptionContext.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.source.cases.MultipleTopicConsumingContext.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.source.cases.KeySharedSubscriptionContext.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.sink.PulsarSinkTestContext.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.sink.PulsarPartitionDataReader.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.SampleData.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.PulsarRuntimeUtils.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.PulsarRuntimeOperator.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.PulsarRuntime.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.mock.SameThreadOrderedSafeExecutor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.mock.PulsarMockRuntime.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.mock.NonClosableMockBookKeeper.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.mock.MockPulsarService.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.mock.MockBookKeeperClientFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.mock.BlankBrokerInterceptor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.runtime.container.PulsarContainerRuntime.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.PulsarTestSuiteBase.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.PulsarTestEnvironment.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.PulsarTestContextFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.PulsarTestContext.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.PulsarTestCommonUtils.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.function.ControlSource.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.extension.TestOrderlinessExtension.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.testutils.extension.SubType.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.split.PulsarPartitionSplitSerializerTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.reader.split.PulsarUnorderedPartitionSplitReaderTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.reader.split.PulsarPartitionSplitReaderTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.reader.split.PulsarOrderedPartitionSplitReaderTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.reader.source.PulsarUnorderedSourceReaderTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.reader.source.PulsarSourceReaderTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.reader.source.PulsarOrderedSourceReaderTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.reader.deserializer.PulsarDeserializationSchemaTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.PulsarUnorderedSourceITCase.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.PulsarSourceITCase.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.PulsarSourceBuilderTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.enumerator.topic.TopicRangeTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.enumerator.topic.TopicPartitionTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.enumerator.topic.TopicNameUtilsTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.enumerator.topic.range.TopicRangeUtilsTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.enumerator.topic.range.SplitRangeGeneratorTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.enumerator.subscriber.PulsarSubscriberTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.enumerator.PulsarSourceEnumStateSerializerTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.enumerator.PulsarSourceEnumeratorTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.StopCursorTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.enumerator.assigner.SplitAssignerTestBase.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.enumerator.assigner.SharedSplitAssignerTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.source.enumerator.assigner.NonSharedSplitAssignerTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.sink.writer.topic.TopicProducerRegisterTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.sink.writer.topic.TopicMetadataListenerTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.sink.writer.router.RoundRobinTopicRouterTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.sink.writer.router.KeyHashTopicRouterTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.sink.writer.PulsarWriterTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.sink.PulsarSinkITCase.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.sink.PulsarSinkBuilderTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.sink.committer.PulsarCommittableSerializerTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.common.schema.PulsarSchemaUtilsTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.common.schema.PulsarSchemaTypeSerializerTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.common.schema.PulsarSchemaTypeInformationTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.common.schema.PulsarSchemaTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.common.schema.factories.ProtobufSchemaFactoryTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.common.schema.factories.ProtobufNativeSchemaFactoryTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.common.schema.factories.KeyValueSchemaFactoryTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.common.schema.factories.JSONSchemaFactoryTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.common.schema.factories.AvroSchemaFactoryTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.common.config.PulsarConfigValidatorTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.common.config.PulsarConfigurationTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.connector.pulsar.common.config.PulsarConfigBuilderTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.test.java.org.apache.flink.architecture.TestCodeArchitectureTest.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.split.PulsarPartitionSplitState.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.split.PulsarPartitionSplitSerializer.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.split.PulsarPartitionSplit.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.split.PulsarUnorderedPartitionSplitReader.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.split.PulsarPartitionSplitReaderBase.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.split.PulsarOrderedPartitionSplitReader.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.source.PulsarUnorderedSourceReader.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.source.PulsarSourceReaderBase.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.source.PulsarOrderedSourceReader.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.PulsarSourceReaderFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.fetcher.PulsarUnorderedFetcherManager.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.fetcher.PulsarOrderedFetcherManager.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.fetcher.PulsarFetcherManagerBase.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.emitter.PulsarRecordEmitter.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.deserializer.PulsarTypeInformationWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.deserializer.PulsarSchemaWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.deserializer.PulsarDeserializationSchemaWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.deserializer.PulsarDeserializationSchemaInitializationContext.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.reader.deserializer.PulsarDeserializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.PulsarSourceOptions.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.PulsarSourceBuilder.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.PulsarSource.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.topic.TopicRange.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.topic.TopicPartition.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.topic.TopicNameUtils.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.topic.TopicMetadata.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.topic.range.TopicRangeUtils.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.topic.range.SplitRangeGenerator.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.topic.range.RangeGenerator.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.topic.range.FullRangeGenerator.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.topic.range.FixedRangeGenerator.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.topic.range.FixedKeysRangeGenerator.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.subscriber.PulsarSubscriber.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.subscriber.impl.TopicPatternSubscriber.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.subscriber.impl.TopicListSubscriber.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.subscriber.impl.BasePulsarSubscriber.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.PulsarSourceEnumStateSerializer.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.PulsarSourceEnumState.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.PulsarSourceEnumerator.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.stop.PublishTimestampStopCursor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.stop.NeverStopCursor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.stop.MessageIdStopCursor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.stop.LatestMessageStopCursor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.stop.EventTimestampStopCursor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.StopCursor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.start.TimestampStartCursor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.start.MessageIdStartCursor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.StartCursor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.MessageIdUtils.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.cursor.CursorPosition.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.assigner.SplitAssignerFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.assigner.SplitAssignerBase.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.assigner.SplitAssigner.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.assigner.SharedSplitAssigner.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.assigner.NonSharedSplitAssigner.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.enumerator.assigner.KeySharedSplitAssigner.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.config.SourceConfiguration.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.config.PulsarSourceConfigUtils.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.config.PulsarConsumerBuilder.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.source.config.CursorVerification.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.topic.TopicProducerRegister.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.topic.TopicMetadataListener.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.serializer.PulsarSerializationSchemaWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.serializer.PulsarSerializationSchema.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.serializer.PulsarSchemaWrapper.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.router.TopicRoutingMode.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.router.TopicRouter.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.router.RoundRobinTopicRouter.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.router.MessageKeyHash.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.router.KeyHashTopicRouter.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.PulsarWriter.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.message.PulsarMessageBuilder.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.message.PulsarMessage.java</file>
      <file type="M">docs.setup.docs.sh</file>
      <file type="M">docs.config.toml</file>
      <file type="M">docs.content.zh.docs.connectors.datastream.pulsar.md</file>
      <file type="M">docs.content.docs.connectors.datastream.pulsar.md</file>
      <file type="M">docs.layouts.shortcodes.generated.pulsar.admin.configuration.html</file>
      <file type="M">docs.layouts.shortcodes.generated.pulsar.client.configuration.html</file>
      <file type="M">docs.layouts.shortcodes.generated.pulsar.consumer.configuration.html</file>
      <file type="M">docs.layouts.shortcodes.generated.pulsar.producer.configuration.html</file>
      <file type="M">docs.layouts.shortcodes.generated.pulsar.sink.configuration.html</file>
      <file type="M">docs.layouts.shortcodes.generated.pulsar.source.configuration.html</file>
      <file type="M">flink-architecture-tests.flink-architecture-tests-production.pom.xml</file>
      <file type="M">flink-architecture-tests.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-pulsar.archunit-violations.3ac3a1dc-681f-4213-9990-b7b3298a20bc</file>
      <file type="M">flink-connectors.flink-connector-pulsar.archunit-violations.f4d91193-72ba-4ce4-ad83-98f780dce581</file>
      <file type="M">flink-connectors.flink-connector-pulsar.archunit-violations.stored.rules</file>
      <file type="M">flink-connectors.flink-connector-pulsar.pom.xml</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.config.PulsarClientFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.config.PulsarConfigBuilder.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.config.PulsarConfiguration.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.config.PulsarConfigValidator.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.config.PulsarOptions.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.metrics.MetricNames.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.metrics.ProducerMetricsInterceptor.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.factories.AvroSchemaFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.factories.BaseStructSchemaFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.factories.JSONSchemaFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.factories.KeyValueSchemaFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.factories.PrimitiveSchemaFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.factories.ProtobufNativeSchemaFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.factories.ProtobufSchemaFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.factories.StringSchemaFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.PulsarSchema.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.PulsarSchemaFactory.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.PulsarSchemaTypeInformation.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.PulsarSchemaTypeSerializer.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.schema.PulsarSchemaUtils.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.utils.PulsarExceptionUtils.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.utils.PulsarSerdeUtils.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.common.utils.PulsarTransactionUtils.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.committer.PulsarCommittable.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.committer.PulsarCommittableSerializer.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.committer.PulsarCommitter.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.config.PulsarSinkConfigUtils.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.config.SinkConfiguration.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.PulsarSink.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.PulsarSinkBuilder.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.PulsarSinkOptions.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.context.PulsarSinkContext.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.context.PulsarSinkContextImpl.java</file>
      <file type="M">flink-connectors.flink-connector-pulsar.src.main.java.org.apache.flink.connector.pulsar.sink.writer.delayer.FixedMessageDelayer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2022-12-15 01:00:00" id="30424" opendate="2022-12-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add source operator restore readerState log to distinguish split is from newPartitions or split state</summary>
      <description>When a job start firstly, we can find 'assignPartitions' from log。but if source recover from state, we can not distinguish the newPartitions is from timed discover thread or from reader task state.  We can add a helper log to distinguish and confirm the reader using split state in recover situation.  it's very useful for troubleshooting.  </description>
      <version>1.16.0,1.15.3,1.16.1</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.SourceOperator.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2022-1-23 01:00:00" id="30491" opendate="2022-12-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive table partition supports to deserialize later during runtime</summary>
      <description/>
      <version>1.16.0</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.connectors.hive.util.HivePartitionUtils.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.connectors.hive.HiveSourceFileEnumerator.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.connectors.hive.HiveSourceDynamicFileEnumerator.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.connectors.hive.HiveSourceBuilder.java</file>
      <file type="M">flink-connectors.flink-connector-hive.src.main.java.org.apache.flink.connectors.hive.HiveSource.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-11-21 01:00:00" id="3056" opendate="2015-11-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show bytes sent/received as MBs/GB and so on in web interface</summary>
      <description>It would be great if the web interface would round show the bytes in an appropriate (=human readable) unit.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-runtime-web.web-dashboard.web.partials.taskmanager.taskmanager.metrics.html</file>
      <file type="M">flink-runtime-web.web-dashboard.web.partials.taskmanager.index.html</file>
      <file type="M">flink-runtime-web.web-dashboard.web.partials.jobs.job.plan.node.subtasks.html</file>
      <file type="M">flink-runtime-web.web-dashboard.web.partials.jobs.job.plan.node-list.overview.html</file>
      <file type="M">flink-runtime-web.web-dashboard.web.js.index.js</file>
      <file type="M">flink-runtime-web.web-dashboard.app.scripts.common.filters.coffee</file>
      <file type="M">flink-runtime-web.web-dashboard.app.partials.taskmanager.taskmanager.metrics.jade</file>
      <file type="M">flink-runtime-web.web-dashboard.app.partials.taskmanager.index.jade</file>
      <file type="M">flink-runtime-web.web-dashboard.app.partials.jobs.job.plan.node.subtasks.jade</file>
      <file type="M">flink-runtime-web.web-dashboard.app.partials.jobs.job.plan.node-list.overview.jade</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2023-1-6 01:00:00" id="30586" opendate="2023-1-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix calcCodeGen failed if calc with like condition contains double quotation mark</summary>
      <description>If I write a sql like "SELECT * FROM MyTable WHERE b LIKE '%"%'" in Flink-1.16 as'like' condition contains double quotation mark, it will cause code gen failed because wrong code generated by codeGen.   </description>
      <version>1.16.0</version>
      <fixedVersion>1.17.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.runtime.stream.sql.CalcITCase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.test.scala.org.apache.flink.table.planner.runtime.batch.sql.CalcITCase.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.GenerateUtils.scala</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2023-8-11 01:00:00" id="30636" opendate="2023-1-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Typo fix: "to to" -&gt; "to"</summary>
      <description>There's a surprising number of occurrences of "to to" in JavaDoc and the like, where it actually should just be "to".</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-tests.src.test.java.org.apache.flink.test.checkpointing.ProcessingTimeWindowCheckpointingITCase.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.utils.RelShuttles.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.nodes.physical.stream.StreamPhysicalSink.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.nodes.physical.stream.StreamPhysicalLegacySink.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.nodes.physical.batch.BatchPhysicalSink.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.plan.nodes.physical.batch.BatchPhysicalLegacySink.scala</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecSink.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecLegacySink.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.common.CommonExecLegacySink.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecSink.java</file>
      <file type="M">flink-table.flink-table-planner.src.main.java.org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecLegacySink.java</file>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.functions.source.ContinuousFileReaderOperator.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.snapshot.RocksDBFullSnapshotResources.java</file>
      <file type="M">flink-runtime.src.test.java.org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannelTest.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.state.internal.InternalListState.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.jobgraph.tasks.TaskOperatorEventGateway.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.iterative.task.IterationHeadTask.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.io.network.api.TaskEventHandler.java</file>
      <file type="M">flink-runtime.src.main.java.org.apache.flink.runtime.execution.Environment.java</file>
      <file type="M">flink-runtime-web.src.test.java.org.apache.flink.runtime.webmonitor.testutils.HttpTestClient.java</file>
      <file type="M">flink-python.pyflink.datastream.state.py</file>
      <file type="M">flink-core.src.main.java.org.apache.flink.api.common.state.ListState.java</file>
      <file type="M">docs.content.docs.dev.table.hive-compatibility.hive-dialect.insert.md</file>
      <file type="M">docs.content.zh.docs.dev.table.hive-compatibility.hive-dialect.insert.md</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2023-1-28 01:00:00" id="30808" opendate="2023-1-28 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>MultipleInputITCase failed with AdaptiveBatch Scheduler</summary>
      <description>MultipleInputITCase#testRelatedInputs failed with AdaptiveBatch Scheduler.java.lang.UnsupportedOperationException: Forward partitioning does not allow change of parallelism. Upstream operation: Calc[10]-14 parallelism: 1, downstream operation: HashJoin[15]-20 parallelism: 3 You must use another partitioning strategy, such as broadcast, rebalance, shuffle or global.</description>
      <version>1.16.0,1.17.0</version>
      <fixedVersion>1.17.0,1.16.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.graph.StreamGraph.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2023-7-9 01:00:00" id="30984" opendate="2023-2-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove explicit cast required by 3.1.x janino</summary>
      <description>This is a follow up task.Currently in 3.1.x Janino there is  https://github.com/janino-compiler/janino/issues/188 leading to fail several Flink tests. Once it is fixed on janino side WAs should be removed together with janino's update</description>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Technical Debt</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-table.pom.xml</file>
      <file type="M">flink-table.flink-table-runtime.src.main.resources.META-INF.NOTICE</file>
      <file type="M">flink-table.flink-table-planner.src.main.scala.org.apache.flink.table.planner.codegen.CodeGenUtils.scala</file>
      <file type="M">flink-formats.flink-protobuf.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  
  
  <bug fixdate="2023-4-24 01:00:00" id="31912" opendate="2023-4-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade bytebuddy to 14.4.1</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">flink-end-to-end-tests.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2023-4-24 01:00:00" id="31915" opendate="2023-4-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Python API incorrectly passes env.java.opts as single argument</summary>
      <description>The python API passes all java options as a single string argument, which typically means that the JVM will reject them.</description>
      <version>1.16.0</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-python.pyflink.pyflink.gateway.server.py</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2023-5-25 01:00:00" id="31934" opendate="2023-4-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove mocking in RocksDB tests</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.18.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBInitTest.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.test.java.org.apache.flink.contrib.streaming.state.RocksDBAsyncSnapshotTest.java</file>
      <file type="M">flink-state-backends.flink-statebackend-rocksdb.src.main.java.org.apache.flink.contrib.streaming.state.EmbeddedRocksDBStateBackend.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2016-2-11 01:00:00" id="3216" opendate="2016-1-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Define pattern specification</summary>
      <description>In order to detect event patterns we first have to define the pattern. This issue tracks the progress of implementing a user facing API to define event patterns. Patterns should support the following operations next(): The given event has to follow directly after the preceding eventfollowedBy(): The given event has to follow the preceding event. There might occur other events in-between every(): In a follow-by relationship a starting event can be matched with multiple successive events. Consider the pattern a → b where → denotes the follow-by relationship. The event sequence a, b, b can be matched as a, b or a, (b), b where the first b is left out. The essential question is whether a is allowed to match multiple times or only the first time. The method every specifies exactly that. Every events in a pattern can match with multiple successive events. This makes only sense in a follow-by relationship, though. followedByEvery(): Similar to followedBy just that the specified element can be matched with multiple successive events or(): Alternative event which can be matched instead of the original event: every(“e1”).where().or(“e2”).where() within(): Defines a time interval in which the pattern has to be completed, otherwise an incomplete pattern can be emitted (timeout case)</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">flink-streaming-java.src.main.java.org.apache.flink.streaming.api.operators.StreamOperator.java</file>
      <file type="M">flink-libraries.pom.xml</file>
    </fixedFiles>
  </bug>
</bugrepository>