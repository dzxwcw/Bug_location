<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="NUTCH">
  <bug id="1468" opendate="2012-9-9 00:00:00" fixdate="2012-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Redirects that are external links not adhering to db.ignore.external.links</summary>
      <description>Patch attached for this.Hi,Likely this is a question for Ferdy but if anyone else has inputthat'd be great. When running a crawl that I would expect to becontained to a single domain I'm seeing the crawler jump out to otherdomains. I'm using the trunk of Nutch 2.x which includes the followingcommit: https://github.com/apache/nutch/commit/c5e2236f36a881ee7fec97aff3baf9bb32b40200The goal is to perform a focused crawl against a single domain andrestrict the crawler from expanding beyond that domain. I've set thedb.ignore.external.links property to true. I do not want to add aregex to regex-urlfilter.txt as I will be adding several thousandurls. The domain that I am crawling has documents with outlinks thatare still within the domain but then redirect to external domains.cat urls/seed.txthttp://www.ci.watertown.ma.us/cat conf/nutch-site.xml... &lt;property&gt; &lt;name&gt;db.ignore.external.links&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;If true, outlinks leading from a page to external hosts will be ignored. This is an effective way to limit the crawl to include only initially injected hosts, without creating complex URLFilters. &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;plugin.includes&lt;/name&gt; &lt;value&gt;protocol-http|urlfilter-regex|parse-(html|tika)|index-(basic|anchor)|urlnormalizer-(pass|regex|basic)|scoring-opic&lt;/value&gt; &lt;description&gt;Regular expression naming plugin directory names to include. Any plugin not matching this expression is excluded. In any case you need at least include the nutch-extensionpoints plugin. By default Nutch includes crawling just HTML and plain text via HTTP, and basic indexing and search plugins. In order to use HTTPS please enable protocol-httpclient, but be aware of possible intermittentproblems with the underlying commons-httpclient library. &lt;/description&gt; &lt;/property&gt;...Runningbin/nutch crawl urls -depth 8 -topN 100000results in the the crawl eventually fetching and parsing documents ondomains external to the only link in the seed.txt file.I would not expect to see urls like the following in my logs and inthe HBase webpage table:fetching http://www.masshome.com/tourism.htmlParsing http://www.disabilityinfo.org/I'm reviewing the code changes but am still getting up to speed on thecode base. Any ideas while I continue to dig around? Configurationissue or code?Thanks,Matt</description>
      <version>2.1</version>
      <fixedVersion>2.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1491" opendate="2012-11-6 00:00:00" fixdate="2012-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>UTF-8 non-character codepoints in title</summary>
      <description>This is the same problem as NUTCH-1026 but for the title field. The attached patch just uses the same solution for this field too.</description>
      <version>2.1</version>
      <fixedVersion>1.6,2.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.indexer.solr.SolrWriter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1493" opendate="2012-11-7 00:00:00" fixdate="2012-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Error adding field &amp;#39;contentLength&amp;#39;=&amp;#39;&amp;#39; during solrindex using index-more</summary>
      <description>The contentLength can be an empty string (I assume this is possible because of NUTCH-1096), but solr does not accept this. The attached patch just checks for empty string contentLength and does not try to index it.</description>
      <version>1.6,2.1,2.2</version>
      <fixedVersion>1.6,2.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.plugin.index-more.src.java.org.apache.nutch.indexer.more.MoreIndexingFilter.java</file>
    </fixedFiles>
  </bug>
  <bug id="1510" opendate="2012-12-21 00:00:00" fixdate="2012-12-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to Hadoop 1.1.1</summary>
      <description></description>
      <version>1.6,2.1</version>
      <fixedVersion>1.7,2.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ivy.ivy.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1514" opendate="2013-1-6 00:00:00" fixdate="2013-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Phase out the deprecated configuration properties (if possible)</summary>
      <description>In reference to &amp;#91;0&amp;#93;, the deprecated configuration properties can be removed (only if possible without affecting the functionality).&amp;#91;0&amp;#93; : http://mail-archives.apache.org/mod_mbox/nutch-user/201301.mbox/%3CCAFKhtFwvM7w-cVusGZWKeGdcWrVShPtBdfTdcn1NNpM1Z2-ovA@mail.gmail.com%3E</description>
      <version>1.6,2.1</version>
      <fixedVersion>1.7,2.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.indexer-csv.src.java.org.apache.nutch.indexwriter.csv.package-info.java</file>
      <file type="M">conf.index-writers.xml.template</file>
      <file type="M">src.java.org.apache.nutch.crawl.Generator.java</file>
      <file type="M">src.java.org.apache.nutch.crawl.AbstractFetchSchedule.java</file>
      <file type="M">conf.nutch-default.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">src.plugin.indexer-csv.src.test.org.apache.nutch.indexwriter.csv.TestCSVIndexWriter.java</file>
      <file type="M">src.plugin.indexer-csv.src.java.org.apache.nutch.indexwriter.csv.CSVIndexWriter.java</file>
    </fixedFiles>
  </bug>
  <bug id="1527" opendate="2013-2-9 00:00:00" fixdate="2013-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Port nutch-elasticsearch-indexer to Nutch</summary>
      <description>The source repos for this can be found here &amp;#91;0&amp;#93;.This issue should be inline with the work already done by Julien and others over at NUTCH-1047.&amp;#91;0&amp;#93; https://github.com/ctjmorgan/nutch-elasticsearch-indexer</description>
      <version>1.6,2.1</version>
      <fixedVersion>1.7</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.build.xml</file>
      <file type="M">conf.nutch-default.xml</file>
      <file type="M">conf.log4j.properties</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">ivy.ivy.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1577" opendate="2013-5-31 00:00:00" fixdate="2013-5-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add target for creating eclipse project</summary>
      <description>Currently, loading Nutch source code in Eclipse as a project is cumbersome and involves lot of manual steps as given over wiki. It would be great to automate this. Adding a ant target to do that would remove burden off from developers.</description>
      <version>1.6,2.1</version>
      <fixedVersion>1.7,2.2</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1578" opendate="2013-5-31 00:00:00" fixdate="2013-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to Hadoop 1.2.0</summary>
      <description>Hadoop 1.2.0 finally has the ability to run mappers in parallel when running in local mode. In trunk at least the generator seems to run slightly faster.</description>
      <version>None</version>
      <fixedVersion>1.7,2.2.1</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ivy.ivy.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="891" opendate="2010-8-19 00:00:00" fixdate="2010-4-19 01:00:00" resolution="Invalid">
    <buginformation>
      <summary>Nutch build should not depend on unversioned local deps</summary>
      <description>The fix in NUTCH-873 introduces an unknown variable to the build process. Since local ivy artifacts are unversioned, different people that install Gora jars at different points in time will use the same artifact id but in fact the artifacts (jars) will differ because they will come from different revisions of Gora sources. Therefore Nutch builds based on the same svn rev. won't be repeatable across different environments.As much as it pains the ivy purists until Gora publishes versioned artifacts I'd like to revert the fix in NUTCH-873 and add again Gora jars built from a known external rev. We can add a README that contains commit id from Gora.</description>
      <version>2.1</version>
      <fixedVersion>2.2</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.subcollection.src.java.org.apache.nutch.collection.Subcollection.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
