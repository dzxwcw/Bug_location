<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="NUTCH">
  <bug id="1244" opendate="2012-1-5 00:00:00" fixdate="2012-1-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CrawlDBDumper to filter by regex</summary>
      <description>The CrawlDBDumper tool should be able to filter records by an option regular expression.</description>
      <version>None</version>
      <fixedVersion>1.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.crawl.CrawlDbReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1264" opendate="2012-2-1 00:00:00" fixdate="2012-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Configurable indexing plugin (index-metadata)</summary>
      <description>We currently have several plugins already distributed or proposed which do very comparable things : parse-meta NUTCH-809 to generate metadata fields in parse-metadata and index them headings NUTCH-1005 to generate headings fields in parse-metadata and index them index-extra NUTCH-422 to index configurable fields urlmeta NUTCH-855 to propagate metadata from the seeds to the outlinks and index them index-static NUTCH-940 to generate configurable static fieldsAll these plugins have in common that they allow to extract information from various sources and generate fields from them and are largely redundant. Instead this issue proposes to have a single plugin allowing to generate configurable fields from : static values parse metadata content metadata crawldb metadataand let the other plugins focus on the parsing and extraction of the values to index. This will make the addition of new fields simpler by relying on a stable common plugin instead of multiplying the code in various plugins.This plugin will replace index-extra NUTCH-422 and will serve as a basis for further improvements.</description>
      <version>1.5</version>
      <fixedVersion>1.5</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.build.xml</file>
      <file type="M">conf.nutch-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1273" opendate="2012-2-14 00:00:00" fixdate="2012-4-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix [deprecation] javac warnings</summary>
      <description>As part of this task, these warnings should be resolved, however this particular strand of warnings can either be resolved by adding@SuppressWarnings("deprecation")or by actually upgrading our class usage to rely upon non-deprecated classes. Which option is more appropriate for the project?</description>
      <version>nutchgora,1.5</version>
      <fixedVersion>1.7,2.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.protocol-file.src.java.org.apache.nutch.protocol.file.FileResponse.java</file>
      <file type="M">src.java.org.apache.nutch.tools.arc.ArcSegmentCreator.java</file>
      <file type="M">src.java.org.apache.nutch.segment.SegmentReader.java</file>
      <file type="M">src.java.org.apache.nutch.protocol.Content.java</file>
      <file type="M">src.java.org.apache.nutch.plugin.PluginManifestParser.java</file>
      <file type="M">src.java.org.apache.nutch.plugin.PluginDescriptor.java</file>
      <file type="M">src.java.org.apache.nutch.parse.ParseSegment.java</file>
      <file type="M">src.java.org.apache.nutch.crawl.NutchWritable.java</file>
      <file type="M">src.java.org.apache.nutch.crawl.LinkDbReader.java</file>
      <file type="M">src.java.org.apache.nutch.crawl.CrawlDbReader.java</file>
      <file type="M">src.java.org.apache.nutch.crawl.CrawlDatum.java</file>
    </fixedFiles>
  </bug>
  <bug id="1276" opendate="2012-2-14 00:00:00" fixdate="2012-2-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix [dep-ann]</summary>
      <description>Generally speaking these are more straightforward than others as it should be a case of either annotating using@Deprecatedor of course replacing the deprecated class method with another non-deprecated implementation. Hopefully most of these occurrences will be resolved within NUTCH-1273</description>
      <version>nutchgora,1.5</version>
      <fixedVersion>nutchgora,1.5</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.nutch.crawl.CrawlDBTestUtil.java</file>
      <file type="M">src.java.org.apache.nutch.parse.OutlinkExtractor.java</file>
      <file type="M">src.java.org.apache.nutch.net.protocols.ProtocolException.java</file>
      <file type="M">src.java.org.apache.nutch.crawl.MapWritable.java</file>
    </fixedFiles>
  </bug>
  <bug id="1277" opendate="2012-2-14 00:00:00" fixdate="2012-5-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix [fallthrough] javac warnings</summary>
      <description>This usually occurs when we have an instance where a switch statement(s) fall through (that is, one or more break statements are missing).We need to determine where a simple@SuppressWarnings("fallthrough")is required or whether we need to include the break statements in switch blocks</description>
      <version>nutchgora,1.5</version>
      <fixedVersion>1.7,2.2</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.fetcher.OldFetcher.java</file>
      <file type="M">src.java.org.apache.nutch.fetcher.Fetcher.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1307" opendate="2012-3-8 00:00:00" fixdate="2012-3-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve formatting of ant targets for clearer project help</summary>
      <description>This is a trivial formatting issue I will submit a patch shortly and fix it.</description>
      <version>nutchgora,1.5</version>
      <fixedVersion>nutchgora,1.5</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1341" opendate="2012-4-19 00:00:00" fixdate="2012-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NotModified time set to now but page not modified</summary>
      <description>Servers tend to respond with incorrect or no value for LastModified. By comparing signatures or when (fetch.getStatus() == CrawlDatum.STATUS_FETCH_NOTMODIFIED) the reducer correctly sets the db_notmodified status for the CrawlDatum. The modifiedTime value, however, is not set accordingly.</description>
      <version>1.5</version>
      <fixedVersion>1.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.crawl.CrawlDbReducer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1346" opendate="2012-4-24 00:00:00" fixdate="2012-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Follow outlinks to ignore external</summary>
      <description>The follow outlinks feature already respects the db.ignore.external.links setting. However, this means that outlinks of fetched pages that are external are not saved in parse data. There should be a new setting to prevent the outlink follower from going external but still storing external outlinks.</description>
      <version>1.5</version>
      <fixedVersion>1.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.fetcher.Fetcher.java</file>
      <file type="M">conf.nutch-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1352" opendate="2012-5-7 00:00:00" fixdate="2012-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve regex urlfilters/normalizers synchronization</summary>
      <description>I noticed that during fetching a lot of the time the fetcherthreads are blocking on a monitor because of outlink normalizing/filtering. The cause of this: Some of the regex plugins use single lock synchronization.This patch improves throughput by removing synchronization locks and replace them with threadlocals were needed.It has been extensively tested in production. I will commit this later today when no objection.</description>
      <version>None</version>
      <fixedVersion>nutchgora,1.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.urlnormalizer-regex.src.java.org.apache.nutch.net.urlnormalizer.regex.RegexURLNormalizer.java</file>
      <file type="M">src.plugin.urlnormalizer-basic.src.java.org.apache.nutch.net.urlnormalizer.basic.BasicURLNormalizer.java</file>
      <file type="M">src.plugin.urlfilter-regex.src.java.org.apache.nutch.urlfilter.regex.RegexURLFilter.java</file>
      <file type="M">src.plugin.lib-regex-filter.src.java.org.apache.nutch.urlfilter.api.RegexURLFilterBase.java</file>
      <file type="M">src.plugin.lib-regex-filter.src.java.org.apache.nutch.urlfilter.api.RegexRule.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1360" opendate="2012-5-9 00:00:00" fixdate="2012-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Suport the storing of IP address connected to when web crawling</summary>
      <description>Simple issue enabling us to capture the specific IP address of the host which we connect to to fetch a page.</description>
      <version>nutchgora,1.5</version>
      <fixedVersion>2.3,1.8</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.protocol-http.src.java.org.apache.nutch.protocol.http.Http.java</file>
      <file type="M">src.plugin.protocol-ftp.src.java.org.apache.nutch.protocol.ftp.FtpResponse.java</file>
      <file type="M">src.plugin.protocol-ftp.src.java.org.apache.nutch.protocol.ftp.Client.java</file>
      <file type="M">src.plugin.protocol-file.src.java.org.apache.nutch.protocol.file.FileResponse.java</file>
      <file type="M">src.plugin.protocol-http.src.java.org.apache.nutch.protocol.http.HttpResponse.java</file>
      <file type="M">src.plugin.lib-http.src.java.org.apache.nutch.protocol.http.api.HttpBase.java</file>
      <file type="M">src.java.org.apache.nutch.metadata.HttpHeaders.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">conf.nutch-default.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1376" opendate="2012-5-22 00:00:00" fixdate="2012-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add description parameter to every ant task</summary>
      <description>This is really really easy to implement and makes the task of identifying ant target's a piece of cake</description>
      <version>nutchgora,1.5</version>
      <fixedVersion>1.6,2.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1381" opendate="2012-6-4 00:00:00" fixdate="2012-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow to override default subcollection field name</summary>
      <description>The subcollection filter by default uses the subcollection field name but since NUTCH-1266 allows to override it per subcollection. This issue should introduce a configuration directive to override the default field name globally.</description>
      <version>1.5</version>
      <fixedVersion>1.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.subcollection.src.java.org.apache.nutch.indexer.subcollection.SubcollectionIndexingFilter.java</file>
      <file type="M">conf.nutch-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1385" opendate="2012-6-11 00:00:00" fixdate="2012-6-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>More robust plug-in order properties in "nutch-site.xml"</summary>
      <description>When listing multiple scoring filters in certain properties (listed below) in "nutch-site.xml", it is vital that no spaces/newlines/tabs are placed in front of the value content.E.g.:This is fine:&lt;value&gt;org.apache.nutch.scoring.opic.OPICScoringFilter myFilter&lt;/value&gt;Either of these will generate an exception:&lt;value&gt; org.apache.nutch.scoring.opic.OPICScoringFilter myFilter&lt;/value&gt;&lt;value&gt;org.apache.nutch.scoring.opic.OPICScoringFiltermyFilter&lt;/value&gt;Affects these properties in "nutch-site.xml": indexingfilter.order urlnormalizer.order urlfilter.order htmlparsefilter.order scoring.filter.orderSolution: replaced {order.split("\\s+")} to {order.trim().split("\\s+")}. Patch provided.</description>
      <version>1.5</version>
      <fixedVersion>1.6</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.scoring.ScoringFilters.java</file>
      <file type="M">src.java.org.apache.nutch.parse.HtmlParseFilters.java</file>
      <file type="M">src.java.org.apache.nutch.net.URLNormalizers.java</file>
      <file type="M">src.java.org.apache.nutch.net.URLFilters.java</file>
      <file type="M">src.java.org.apache.nutch.indexer.IndexingFilters.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1386" opendate="2012-6-12 00:00:00" fixdate="2012-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Headings filter not to add empty values</summary>
      <description>Headings filter can add empty values and doesn't trim the headings.</description>
      <version>1.5</version>
      <fixedVersion>1.6</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.headings.src.java.org.apache.nutch.parse.headings.HeadingsParseFilter.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1398" opendate="2012-6-15 00:00:00" fixdate="2012-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to Hadoop 1.0.3</summary>
      <description></description>
      <version>1.5</version>
      <fixedVersion>1.5.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ivy.ivy.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1404" opendate="2012-6-19 00:00:00" fixdate="2012-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nutch script fails to find job file in deploy mode</summary>
      <description>See http://lucene.472066.n3.nabble.com/Nutch-1-5-Deploy-Mode-Doesn-t-Work-like-Nutch-1-4-Deploy-Mode-tp3990169.html</description>
      <version>nutchgora,1.5</version>
      <fixedVersion>nutchgora,1.5.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.bin.nutch</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1409" opendate="2012-6-22 00:00:00" fixdate="2012-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove deprecated properties db.{default,max}.fetch.interval, generate.max.per.host.by.ip</summary>
      <description>1) Remove deprecated properties from nutch-default.xml (generate.max.per.host and db.default.fetch.interval).2) The already removed properties generate.max.per.host.by.ip and db.max.fetch.interval are still used in source code.</description>
      <version>None</version>
      <fixedVersion>2.3,1.10</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.crawl.Generator.java</file>
      <file type="M">src.java.org.apache.nutch.crawl.CrawlDbReducer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1465" opendate="2012-9-4 00:00:00" fixdate="2012-7-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support sitemaps in Nutch</summary>
      <description>I recently came across this rather stagnant codebase&amp;#91;0&amp;#93; which is ASL v2.0 licensed and appears to have been used successfully to parse sitemaps as per the discussion here&amp;#91;1&amp;#93;.&amp;#91;0&amp;#93; http://sourceforge.net/projects/sitemap-parser/&amp;#91;1&amp;#93; http://lucene.472066.n3.nabble.com/Support-for-Sitemap-Protocol-and-Canonical-URLs-td630060.html</description>
      <version>None</version>
      <fixedVersion>1.14</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.bin.nutch</file>
      <file type="M">ivy.ivy.xml</file>
      <file type="M">conf.nutch-default.xml</file>
      <file type="M">conf.log4j.properties</file>
    </fixedFiles>
  </bug>
</bugrepository>
