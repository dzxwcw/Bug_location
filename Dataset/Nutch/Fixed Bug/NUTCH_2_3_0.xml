<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="NUTCH">
  <bug id="1724" opendate="2014-2-10 00:00:00" fixdate="2014-2-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LinkDBReader to support regex output filtering</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.10</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.crawl.LinkDbReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1729" opendate="2014-2-20 00:00:00" fixdate="2014-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to Tika 1.5</summary>
      <description></description>
      <version>2.3,1.8</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.parse-tika.plugin.xml</file>
      <file type="M">src.plugin.parse-tika.ivy.xml</file>
      <file type="M">ivy.ivy.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1736" opendate="2014-3-15 00:00:00" fixdate="2014-6-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Can&amp;#39;t fetch page if http response header contains Transfer-Encodingï¼šchunked</summary>
      <description>fetching: http://szs.mof.gov.cn/zhengwuxinxi/zhengcefabu/201402/t20140224_1046354.htmlFetch failed with protocol status: EXCEPTION: java.io.IOException: unzipBestEffort returned null</description>
      <version>2.3,1.8</version>
      <fixedVersion>2.3,1.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.protocol-http.src.java.org.apache.nutch.protocol.http.HttpResponse.java</file>
      <file type="M">src.java.org.apache.nutch.metadata.HttpHeaders.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1863" opendate="2014-9-28 00:00:00" fixdate="2014-12-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add JSON format dump output to readdb command</summary>
      <description>Opening up the ability for third parties to consume Nutch crawldb data as JSON would be a poisitive thing IMHO.This issue should improve the readdb functionality of both 1.X to enable JSON dumps of crawldb data.</description>
      <version>2.3,1.10</version>
      <fixedVersion>1.17</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.crawl.CrawlDbReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="1873" opendate="2014-10-10 00:00:00" fixdate="2014-5-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Solr IndexWriter/Job to report number of docs indexed.</summary>
      <description>It is annoying when reading logs to NOT know how many docs were indexed at a certain point in time. Of course i could go to the Solr server and see this... if I have access to the URL, but this is not always the case. I do however always have access to the logs.</description>
      <version>2.3,1.10</version>
      <fixedVersion>1.11</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.indexer.IndexingJob.java</file>
      <file type="M">src.java.org.apache.nutch.indexer.IndexerMapReduce.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1920" opendate="2015-1-16 00:00:00" fixdate="2015-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Nutch to use Java 1.7</summary>
      <description>In order to build the Nutch Javadoc securely, we rely upon no less than Java version 7u25 or greater. See NUTCH-1590.indexer-elastic also requires a JDK 1.7 in order compile.We should make the upgrade and state support for Java 1.7 based on the following announcement from OracleEnd of Public Updates for Oracle JDK 7The April 2015 CPU release will be the last Oracle JDK 7 publicly available update. For more information, and details on how to receive longer term support for Oracle JDK 7, please see the Oracle Java SE Support Roadmap.</description>
      <version>2.3,1.10</version>
      <fixedVersion>1.10,2.3.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">default.properties</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1928" opendate="2015-1-30 00:00:00" fixdate="2015-2-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Indexing filter of documents by the MIME type</summary>
      <description>This allows to filter the indexed documents by the MIME type property of the crawled content. Basically this will allow you to restrict the MIME type of the contents that will be stored in Solr/Elasticsearch index without the need to restrict the crawling/parsing process, so no need to use URLFilter plugin family. Also this address one particular corner case when certain URLs doesn't have any format to filter such as some RSS feeds (http://www.awesomesite.com/feed) and it will end in your index mixed with all your HTML content.A configuration can file specified on the mimetype.filter.file property in the nutch-site.xml. This file use the same format as the urlfilter-suffix plugin. If no mimetype.filter.file key is found an allow all policy is used instead, so all your crawled documents will be indexed.</description>
      <version>None</version>
      <fixedVersion>1.10</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.build.xml</file>
      <file type="M">default.properties</file>
      <file type="M">conf.nutch-default.xml</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="1941" opendate="2015-2-11 00:00:00" fixdate="2015-3-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optional rolling http.agent.name&amp;#39;s</summary>
      <description>In some scenarios, even whilst adhering to fetcher.crawl.delay, web admins can block your fetcher based merely on your crawler name. I propose the ability to implement rolling http.agent.name's which could be substituted every 5 seconds for example. This would mean that successive requests to the same domain would be sent with different http.agent.name. This behavior should be off by default.</description>
      <version>2.3,1.9</version>
      <fixedVersion>1.10,2.3.1</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.protocol-httpclient.src.java.org.apache.nutch.protocol.httpclient.HttpResponse.java</file>
      <file type="M">src.plugin.protocol-httpclient.src.java.org.apache.nutch.protocol.httpclient.Http.java</file>
      <file type="M">src.plugin.lib-http.src.java.org.apache.nutch.protocol.http.api.HttpBase.java</file>
      <file type="M">conf.nutch-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1981" opendate="2015-4-2 00:00:00" fixdate="2015-4-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade icu4j</summary>
      <description>The icu4j version from 2009 is causing some compatibility issues with custom plugins we're developing. Please upgrade to a more recent version.I'm attaching a patch to this issue. Nutch builds and all tests pass without source code changes.</description>
      <version>2.3,1.9</version>
      <fixedVersion>1.10,2.3.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ivy.ivy.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2042" opendate="2015-6-18 00:00:00" fixdate="2015-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>parse-html increase chunk size used to detect charset</summary>
      <description>The chunk used to detect the encoding of a document is set to 2000 bytes. Although it is definitely best practice to "define" the character set on top, 2000 bytes are sometimes not enough: 20 longer &lt;link&gt; elements pointing to javascript and css libs may "hide" the &lt;meta&gt; element containing content type and encoding. Same problem has been observed in TIKA-357 and solved by increasing the buffer size to 8 kB.</description>
      <version>2.3,1.10</version>
      <fixedVersion>2.3.1,1.12</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.parse-html.src.java.org.apache.nutch.parse.html.HtmlParser.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2077" opendate="2015-8-12 00:00:00" fixdate="2015-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to Tika 1.10</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.11,2.3.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.parse-tika.plugin.xml</file>
      <file type="M">src.plugin.parse-tika.ivy.xml</file>
      <file type="M">ivy.ivy.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="2129" opendate="2015-10-1 00:00:00" fixdate="2015-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Track Protocol Status in Crawl Datum</summary>
      <description>It's become necessary on a few crawls that I run to get protocol status code stats. After speaking with lewismc it seemed that there might not be a super convenient way of doing this as is, but it would be great to be able to add the functionality necessary to pull this information out.</description>
      <version>2.3,1.10</version>
      <fixedVersion>1.11</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.protocol-ftp.src.java.org.apache.nutch.protocol.ftp.Ftp.java</file>
      <file type="M">src.plugin.lib-http.src.java.org.apache.nutch.protocol.http.api.HttpBase.java</file>
      <file type="M">src.java.org.apache.nutch.metadata.Nutch.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
