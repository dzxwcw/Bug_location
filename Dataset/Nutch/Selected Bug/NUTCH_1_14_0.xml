<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="NUTCH">
  
  
  
  <bug fixdate="2017-1-14 01:00:00" id="2461" opendate="2017-11-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Generate passes the data to when maxCount == 0</summary>
      <description>The generator checks condition if (maxCount &gt; 0) : line 421 and stop the generation when amount per host exceeds maxCount( continue : line 455)but when maxCount == 0 it goes directly to line 465 :output.collect(key, entry);It is obviously not correct, the correct solution would be to add if(maxCount == 0){ continue;}at line 380.</description>
      <version>1.14</version>
      <fixedVersion>1.15</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.crawl.Generator.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-4-22 01:00:00" id="2501" opendate="2018-1-22 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>allow to set Java heap size when using crawl script in distributed mode</summary>
      <description/>
      <version>1.14</version>
      <fixedVersion>1.17</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.bin.nutch</file>
      <file type="M">src.bin.crawl</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-1-23 01:00:00" id="2502" opendate="2018-1-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Any23 Plugin: Add Content-Type filtering</summary>
      <description>It should be possible to filter based on a document's Content-Type when using Any23 extractors.</description>
      <version>None</version>
      <fixedVersion>1.15</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.any23.src.test.org.apache.nutch.any23.TestAny23ParseFilter.java</file>
      <file type="M">src.plugin.any23.src.java.org.apache.nutch.any23.Any23ParseFilter.java</file>
      <file type="M">conf.nutch-default.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-1-31 01:00:00" id="2508" opendate="2018-1-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Misleading documentation about http.proxy.exception.list</summary>
      <description>The description about http.proxy.exception.list states that domains as well as URLs can be configured to be excluded from being routed through a pre-configured proxy. This is misleading since only hosts are being checked when using this feature.</description>
      <version>None</version>
      <fixedVersion>1.15</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.nutch-default.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2018-4-7 01:00:00" id="2527" opendate="2018-3-7 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>URL filter: provide rules to exclude localhost and private address spaces</summary>
      <description>While checking the log files of a large web crawl, I've found hundreds of (luckily failed) requests of local or private content:2018-02-18 04:48:34,022 INFO [FetcherThread] org.apache.nutch.fetcher.Fetcher: fetching http://127.0.0.42/ ...018-02-18 04:48:34,022 INFO [FetcherThread] org.apache.nutch.fetcher.Fetcher: fetch of http://127.0.0.42/ failed with: java.net.ConnectException: Connection refused (Connection refused)URLs pointing to localhost, loop-back addresses, private address spaces should be blocked for a wider web crawl where links are not controlled to avoid that information is leaked by links or redirects pointing to web interfaces of services running on the crawling machines (e.g., HDFS, Hadoop YARN).Of course, this must be optional. For testing it's quite common to crawl your local machine.</description>
      <version>2.3.1,1.14</version>
      <fixedVersion>2.4,1.15</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.regex-urlfilter.txt.template</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  
  
  <bug fixdate="2018-6-24 01:00:00" id="2583" opendate="2018-5-24 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Upgrading Nutch&amp;#39;s dependencies</summary>
      <description>Hi, It would be nice to be able to upgrade all of Nutch's dependencies to the latest possible available.I've attached an Ivy.xml with the latest possible dependencies without breaking the compile. I've tested it with a few runs of the "crawl script", so far it seems to work, it generates, it fetches, it parses, it indexes to Solr..... Increasing any of this dependencies breaks the compile. PS: I haven't touched any of the Hadoop stuff and don't remember if I touched the testing part or not.</description>
      <version>1.14</version>
      <fixedVersion>1.15</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ivy.ivy.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-6-8 01:00:00" id="2595" opendate="2018-6-8 00:00:00" resolution="Implemented">
    <buginformation>
      <summary>Upgrade crawler-commons dependency to 0.10</summary>
      <description>See CHANGES</description>
      <version>1.14</version>
      <fixedVersion>1.15</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ivy.ivy.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-11-20 01:00:00" id="2606" opendate="2018-6-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>MIME detection is wrong for plain-text documents send as Content-Type "application/msword"</summary>
      <description>Plain-text documents send as Content-Type "application/msword" are tried to parse as Word documents. The MIME detection should be fixed, so that these are correctly identified as plain-text documents. See NUTCH-2603 and https://www.atnf.csiro.au/computing/software/gipsy/doc/update.doc</description>
      <version>1.14</version>
      <fixedVersion>1.16</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.test.org.apache.nutch.util.TestMimeUtil.java</file>
      <file type="M">src.java.org.apache.nutch.util.MimeUtil.java</file>
    </fixedFiles>
  </bug>
  
  
  
</bugrepository>