<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="NUTCH">
  
  <bug fixdate="2013-8-20 01:00:00" id="1629" opendate="2013-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>there is no need to fail on empty lines in seed file when injecting.</summary>
      <description>right now, if there is an empty line in a seed file, TableUtil.reversUrl would throw an exception that would kill the inject job.</description>
      <version>1.7,2.2.1</version>
      <fixedVersion>2.3,1.8</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.crawl.Injector.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-6-26 01:00:00" id="1633" opendate="2013-8-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>slf4j is provided by hadoop and should not be included in the job file.</summary>
      <description>there are two issues with including slf4j in the job file. the minor of the two is that slf4j starts issuing warnings when it finds more than on instances in the classpath( GORA-272 ). the bigger issue happens when the versions of the slf4j in hadoop and nutch are not compatible (ex. hadoop 1.1.1 &amp; nutch 2.1) which results in all nutch jobs to crash.</description>
      <version>1.7,2.2.1</version>
      <fixedVersion>2.3,1.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-3-30 01:00:00" id="1645" opendate="2013-9-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Junit Test Case for Adaptive Fetch Schedule class</summary>
      <description>Currently there is not Test Case for Adaptive Fetch Schedule. Junit test Writes for its.</description>
      <version>2.2.1</version>
      <fixedVersion>2.3,1.9</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-1-2 01:00:00" id="1660" opendate="2013-11-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Index filter for Page&amp;#39;s latitude and longitude</summary>
      <description>I see some discuss about page's ip storing. I think If we have page's ip, we can index page's geo position as latitude and longitude. That use for location based searches. icebergx5 I know you have a patch about this in your secret patches Can you share us ?</description>
      <version>2.2.1</version>
      <fixedVersion>1.10</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.plugin.index-geoip.plugin.xml</file>
      <file type="M">src.plugin.build.xml</file>
      <file type="M">src.java.org.apache.nutch.indexer.IndexingFiltersChecker.java</file>
      <file type="M">default.properties</file>
      <file type="M">conf.solrindex-mapping.xml</file>
      <file type="M">conf.schema.xml</file>
      <file type="M">conf.schema-solr4.xml</file>
      <file type="M">conf.nutch-default.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2013-7-11 01:00:00" id="1684" opendate="2013-12-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ParseMeta to be added before fetch schedulers are run</summary>
      <description>FetchSchedulers cannot operate on parseMeta in the CrawlDatum because it is added after the schedulers have run.</description>
      <version>None</version>
      <fixedVersion>1.11</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.crawl.CrawlDbReducer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-2-31 01:00:00" id="1721" opendate="2014-1-31 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to Crawler commons 0.3</summary>
      <description/>
      <version>1.7,2.2,2.2.1</version>
      <fixedVersion>2.3,1.8</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ivy.ivy.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-2-10 01:00:00" id="1724" opendate="2014-2-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>LinkDBReader to support regex output filtering</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.10</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.crawl.LinkDbReader.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-4-16 01:00:00" id="1759" opendate="2014-4-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to Crawler Commons 0.4</summary>
      <description>We recently releaed CC 0.4. We should upgrade.</description>
      <version>1.8,2.2.1</version>
      <fixedVersion>2.3,1.9</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ivy.ivy.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-7-21 01:00:00" id="1785" opendate="2014-5-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ability to index raw content</summary>
      <description>Some use-cases require Nutch to actually write the raw content a configured indexing back-end. Since Content is never read, a plugin is out of the question and therefore we need to force IndexJob to process Content as well.</description>
      <version>None</version>
      <fixedVersion>1.11</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.java.org.apache.nutch.indexer.IndexingJob.java</file>
      <file type="M">src.java.org.apache.nutch.indexer.IndexerMapReduce.java</file>
      <file type="M">ivy.ivy.xml</file>
      <file type="M">conf.schema.xml</file>
      <file type="M">conf.schema-solr4.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2014-10-30 01:00:00" id="1866" opendate="2014-9-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>ant eclipse target should not delete runtime</summary>
      <description>This is a pretty nasty bug which can really screw things up for you.The eclipse target should not delete runtime whenever invoked... this is terrible.</description>
      <version>1.9,2.2.1</version>
      <fixedVersion>2.3,1.10</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-10-16 01:00:00" id="1876" opendate="2014-10-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade to Crawler Commons 0.5</summary>
      <description>We just released crawler commons 0.5We should upgrade here in Nutch.https://code.google.com/p/crawler-commons/</description>
      <version>1.9,2.2.1</version>
      <fixedVersion>2.3,1.10</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ivy.ivy.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-12-16 01:00:00" id="1877" opendate="2014-10-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Suffix URL filter to ignore query string by default</summary>
      <description>Suffix URL filter entry: .mp3Does not filter out: http://www.example.org/file.mp3?a=b</description>
      <version>1.9,2.2.1</version>
      <fixedVersion>2.3,1.10</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.suffix-urlfilter.txt.template</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2006-2-27 01:00:00" id="188" opendate="2006-1-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add searchable mailing list links to http://lucene.apache.org/nutch/mailing_lists.html</summary>
      <description>Post links to searchable mail archives on nutch.org</description>
      <version>None</version>
      <fixedVersion>0.8</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">src.web.include.footer.html</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  
</bugrepository>