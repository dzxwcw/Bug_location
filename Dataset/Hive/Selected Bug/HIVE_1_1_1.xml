<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HIVE">
  
  <bug fixdate="2015-5-2 01:00:00" id="10579" opendate="2015-5-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix -Phadoop-1 build</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.BucketingSortingReduceSinkOptimizer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-5-2 01:00:00" id="10583" opendate="2015-5-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Switch precommit from ASF to Github repo to avoid clone failures</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">dev-support.jenkins-execute-hms-test.sh</file>
      <file type="M">dev-support.jenkins-execute-build.sh</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2015-6-19 01:00:00" id="10748" opendate="2015-5-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace StringBuffer with StringBuilder where possible</summary>
      <description>I found 40 places in Hive where "new StringBuffer(" is used."Where possible, it is recommended that StringBuilder be used in preference to StringBuffer as it will be faster under most implementations"https://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.auth.HttpAuthUtils.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.lazy.TestLazySimpleSerDe.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.Worker.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.Initiator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.TableScanDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PlanUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.FilterDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.SparkProcessAnalyzeTable.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ProcessAnalyzeTable.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.spark.SparkReduceSinkMapJoinProc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ReduceSinkMapJoinProc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMRTableScan1.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.RelOptHiveTable.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizedBatchUtil.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezJobMonitor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.SparkJobMonitor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExplainTask.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HivePreparedStatement.java</file>
      <file type="M">hcatalog.streaming.src.test.org.apache.hive.hcatalog.streaming.TestStreaming.java</file>
      <file type="M">hcatalog.streaming.src.java.org.apache.hive.hcatalog.streaming.HiveEndPoint.java</file>
      <file type="M">hcatalog.streaming.src.java.org.apache.hive.hcatalog.streaming.DelimitedInputWriter.java</file>
      <file type="M">hcatalog.core.src.test.java.org.apache.hive.hcatalog.data.TestJsonSerDe.java</file>
      <file type="M">hcatalog.core.src.main.java.org.apache.hive.hcatalog.common.HCatException.java</file>
      <file type="M">common.src.test.org.apache.hadoop.hive.common.type.TestHiveVarchar.java</file>
      <file type="M">common.src.test.org.apache.hadoop.hive.common.type.TestHiveBaseChar.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.jsonexplain.tez.TezJsonParser.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-5-27 01:00:00" id="10835" opendate="2015-5-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Concurrency issues in JDBC driver</summary>
      <description>Though JDBC specification specifies that "Each Connection object can create multiple Statement objects that may be used concurrently by the program", but that does not work in current Hive JDBC driver. In addition, there also exist race conditions between DatabaseMetaData, Statement and ResultSet as long as they make RPC calls to HS2 using same Thrift transport, which happens within a connection.So we need a connection level lock to serialize all these RPC calls in a connection.</description>
      <version>0.13.0,0.13.1,0.14.0,0.14.1,0.15.0,1.0.0,1.0.1,1.1.0,1.1.1,1.2.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveStatement.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveQueryResultSet.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveConnection.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniHS2.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-8-30 01:00:00" id="11409" opendate="2015-7-30 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Calcite Operator To Hive Operator (Calcite Return Path): add SEL before UNION</summary>
      <description>Two purpose: (1) to ensure that the data type of non-primary branch (the 1st branch is the primary branch) of union can be casted to that of the primary branch; (2) to make UnionProcessor optimizer work; (3) if the SEL is redundant, it will be removed by IdentidyProjectRemover optimizer.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.translator.HiveOpConverter.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-9-20 01:00:00" id="11613" opendate="2015-8-20 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>schematool should return non zero exit status for info command, if state is inconsistent</summary>
      <description>schematool -info just prints the version information, but it is not easy to consume the validity of the state from a tool as the exit code is 0 even if the schema version has mismatch.</description>
      <version>1.0.0,1.1.1,1.2.1</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">beeline.src.java.org.apache.hive.beeline.HiveSchemaTool.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-9-21 01:00:00" id="11614" opendate="2015-8-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Calcite Operator To Hive Operator (Calcite Return Path): ctas after order by has problem</summary>
      <description/>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.CalcitePlanner.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.translator.PlanModifierForReturnPath.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-8-24 01:00:00" id="11633" opendate="2015-8-24 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>import tool should print help by default</summary>
      <description>It took me a while to figure out that I need to supply some command to make import work, and I had to read the sources... it should output help by default</description>
      <version>None</version>
      <fixedVersion>hbase-metastore-branch,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.hbase.HBaseImport.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-8-27 01:00:00" id="11664" opendate="2015-8-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make tez container logs work with new log4j2 changes</summary>
      <description>MiniTezCliDriver should log container logs to syslog file. With new log4j2 changes this file is not created anymore.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">data.conf.tez.hive-site.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-9-3 01:00:00" id="11723" opendate="2015-9-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrect string literal escaping</summary>
      <description>When I execute the following queriesCREATE TABLE t_hive (f1 STRING);INSERT INTO t_hive VALUES ('Cooper\'s');SELECT * FROM t_hive;via the Hive shell or through HiveServer2 directly (via impyla), I would expect that the result to beCooper'sbut instead I actually getCooper\'sActually, I'm not sure how that INSERT query is not even a syntax error.</description>
      <version>1.1.1,1.2.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-9-14 01:00:00" id="11810" opendate="2015-9-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: Exception is ignored if MiniLlap cluster fails to start</summary>
      <description/>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2015-10-6 01:00:00" id="12042" opendate="2015-10-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: update some out files</summary>
      <description/>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.groupby.reduce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.vectorized.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.dynamic.partition.pruning.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.explainuser.1.q.out</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2015-10-8 01:00:00" id="12073" opendate="2015-10-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: disable session reuse for MiniTez cluster</summary>
      <description>See HIVE-12072</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.QTestUtil.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2015-4-9 01:00:00" id="12079" opendate="2015-10-9 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add units tests for HiveServer2 LDAP filters added in HIVE-7193</summary>
      <description>HIVE-11866 adds a test framework that uses an in-memory ldap server for unit tests. Need to add unit tests for user and group filtering feature added in HIVE-7193.</description>
      <version>1.1.1</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.test.org.apache.hive.service.auth.TestLdapAtnProviderWithMiniDS.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2015-1-14 01:00:00" id="12664" opendate="2015-12-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bug in reduce deduplication optimization causing ArrayOutOfBoundException</summary>
      <description>The optimisation check for reduce deduplication only checks the first child node for join and the check itself also contains a major bug causing ArrayOutOfBoundException no matter what.Sample data table form:timeuserhostpathreferercodeagentsizemethodintstringstringstringstringbigintstringbigintstringSample querySELECT t1.host, COUNT(DISTINCT t1.`date`) AS login_count, MAX(t2.code) AS code, unix_timestamp() AS timeFROM ( SELECT HOST, MIN(time) AS DATE FROM www_access WHERE HOST IS NOT NULL GROUP BY HOST ) t1JOIN ( SELECT HOST, MIN(time) AS code FROM www_access WHERE HOST IS NOT NULL GROUP BY HOST ) t2 ON t1.host = t2.hostGROUP BY t1.host</description>
      <version>1.1.1,1.2.1</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.correlation.ReduceSinkDeDuplication.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-1-6 01:00:00" id="12788" opendate="2016-1-6 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Setting hive.optimize.union.remove to TRUE will break UNION ALL with aggregate functions</summary>
      <description>See the test case below:0: jdbc:hive2://localhost:10000/default&gt; create table test (a int);0: jdbc:hive2://localhost:10000/default&gt; insert overwrite table test values (1);0: jdbc:hive2://localhost:10000/default&gt; set hive.optimize.union.remove=true;No rows affected (0.01 seconds)0: jdbc:hive2://localhost:10000/default&gt; set hive.mapred.supports.subdirectories=true;No rows affected (0.007 seconds)0: jdbc:hive2://localhost:10000/default&gt; SELECT COUNT(1) FROM test UNION ALL SELECT COUNT(1) FROM test;+----------+--+| _u1._c0 |+----------+--++----------+--+UNION ALL without COUNT function will work as expected:0: jdbc:hive2://localhost:10000/default&gt; select * from test UNION ALL SELECT * FROM test;+--------+--+| _u1.a |+--------+--+| 1 || 1 |+--------+--+Run the same query without setting hive.mapred.supports.subdirectories and hive.optimize.union.remove to true will give correct result:0: jdbc:hive2://localhost:10000/default&gt; set hive.optimize.union.remove;+-----------------------------------+--+| set |+-----------------------------------+--+| hive.optimize.union.remove=false |+-----------------------------------+--+0: jdbc:hive2://localhost:10000/default&gt; SELECT COUNT(1) FROM test UNION ALL SELECT COUNT(1) FROM test;+----------+--+| _u1._c0 |+----------+--+| 1 || 1 |+----------+--+</description>
      <version>1.1.1</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.StatsOptimizer.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-5-15 01:00:00" id="13525" opendate="2016-4-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HoS hangs when job is empty</summary>
      <description>Observed in local tests. This should be the cause of HIVE-13402.</description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.RemoteDriver.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainerSerDe.java</file>
      <file type="M">pom.xml</file>
      <file type="M">data.conf.spark.standalone.hive-site.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-5-19 01:00:00" id="13794" opendate="2016-5-19 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>HIVE_RPC_QUERY_PLAN should always be set when generating LLAP splits</summary>
      <description>This option was being added in the test, but really should be set any time we are generating the LLAP input splits.</description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSplits.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniLlap.java</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2016-11-2 01:00:00" id="15108" opendate="2016-11-2 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>allow Hive script to skip hadoop version check and HBase classpath</summary>
      <description>Both will be performed by default, as before</description>
      <version>None</version>
      <fixedVersion>2.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hive</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2018-2-18 01:00:00" id="18478" opendate="2018-1-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Data files deleted from temp table should not be recycled to CM path</summary>
      <description>Drop TEMP table operation invokes deleteDir which moves the file to $CMROOT which is not needed as temp tables need not be replicated</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.src.test.java.org.apache.hadoop.hive.metastore.minihms.AbstractMetaStoreService.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.Warehouse.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-1-18 01:00:00" id="18479" opendate="2018-1-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create tests to cover dropPartition methods</summary>
      <description>The following methods of IMetaStoreClientÂ are covered in this Jira:- boolean dropPartition(String, String, List&lt;String&gt;, boolean)- boolean dropPartition(String, String, List&lt;String&gt;, PartitionDropOptions)- boolean dropPartition(String, String, String, boolean)</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.src.test.java.org.apache.hadoop.hive.metastore.minihms.AbstractMetaStoreService.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2010-12-13 01:00:00" id="1848" opendate="2010-12-13 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>bug in MAPJOIN</summary>
      <description>explainFROM srcpart cJOIN srcpart dON ( c.key=d.key AND c.ds='2008-04-08' AND d.ds='2008-04-08')SELECT /*+ MAPJOIN(d) */ DISTINCT c.campaign_id;The above query throws an error:FAILED: Error in semantic analysis: line 0:-1 Invalid Function TOK_MAPJOIN</description>
      <version>None</version>
      <fixedVersion>0.7.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  
</bugrepository>