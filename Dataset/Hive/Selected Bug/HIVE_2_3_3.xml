<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HIVE">
  
  
  <bug fixdate="2018-3-23 01:00:00" id="18788" opendate="2018-2-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up inputs in JDBC PreparedStatement</summary>
      <description/>
      <version>None</version>
      <fixedVersion>2.3.3,3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HivePreparedStatement.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcDriver2.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-3-7 01:00:00" id="18888" opendate="2018-3-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace synchronizedMap with ConcurrentHashMap</summary>
      <description>There are a bunch of places that use Collections.synchronizedMap instead of ConcurrentHashMap which are better. We should search/replace the uses.</description>
      <version>2.3.3,3.0.0</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DynamicValueRegistryTez.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-3-7 01:00:00" id="18889" opendate="2018-3-7 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>update all parts of Hive to use the same Guava version</summary>
      <description/>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">storage-api.pom.xml</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.metrics.JvmPauseMonitor.java</file>
      <file type="M">standalone-metastore.pom.xml</file>
    </fixedFiles>
  </bug>
  
  
  <bug fixdate="2011-1-26 01:00:00" id="1929" opendate="2011-1-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Find a way to disable owner grants</summary>
      <description/>
      <version>None</version>
      <fixedVersion>0.7.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.CreateTableAutomaticGrant.java</file>
      <file type="M">conf.hive-default.xml</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-4-26 01:00:00" id="19338" opendate="2018-4-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>isExplicitAnalyze method may be incorrect in BasicStatsTask</summary>
      <description>It relies on a specific ctor being used, however this ctor is used on non-analyze paths too.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.BasicStatsWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.TaskCompiler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.SparkProcessAnalyzeTable.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ProcessAnalyzeTable.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMRTableScan1.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  <bug fixdate="2019-1-3 01:00:00" id="21082" opendate="2019-1-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>In HPL/SQL, declare statement does not support variable of type character</summary>
      <description>In the following HPL/SQL programs:DECLARE a character(5); SET a = 'b';when the type of variable 'a' is CHARACTER, it cannot be assigned a value successfully. The support for the character type should be added to DECLARE statement.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hplsql.src.test.java.org.apache.hive.hplsql.TestHplsqlLocal.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.Var.java</file>
      <file type="M">hplsql.src.main.antlr4.org.apache.hive.hplsql.Hplsql.g4</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-7-14 01:00:00" id="21874" opendate="2019-6-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement add partitions related methods on temporary table</summary>
      <description>IMetaStoreClient exposes the following add partition related methods:Partition add_partition(Partition partition);int add_partitions(List&lt;Partition&gt; partitions);int add_partitions_pspec(PartitionSpecProxy partitionSpec);List&lt;Partition&gt; add_partitions(List&lt;Partition&gt; partitions, boolean ifNotExists, boolean needResults);These methods should be implemented in order to handle addition of partitions to temporary tables.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.metastore-server.src.test.java.org.apache.hadoop.hive.metastore.client.TestAddPartitionsFromPartSpec.java</file>
      <file type="M">standalone-metastore.metastore-server.src.test.java.org.apache.hadoop.hive.metastore.client.TestAddPartitions.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-9-14 01:00:00" id="21875" opendate="2019-6-14 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement drop partition related methods on temporary tables</summary>
      <description>IMetaStoreClient exposes the following methods related to dropping partitions:boolean dropPartition(String db_name, String tbl_name, List&lt;String&gt; part_vals, boolean deleteData);boolean dropPartition(String catName, String db_name, String tbl_name, List&lt;String&gt; part_vals, boolean deleteData);boolean dropPartition(String db_name, String tbl_name, List&lt;String&gt; part_vals, PartitionDropOptions options);boolean dropPartition(String catName, String db_name, String tbl_name, List&lt;String&gt; part_vals, PartitionDropOptions options);List&lt;Partition&gt; dropPartitions(String dbName, String tblName, List&lt;ObjectPair&lt;Integer, byte[]&gt;&gt; partExprs, boolean deleteData, boolean ifExists);List&lt;Partition&gt; dropPartitions(String catName, String dbName, String tblName, List&lt;ObjectPair&lt;Integer, byte[]&gt;&gt; partExprs, boolean deleteData, boolean ifExists);List&lt;Partition&gt; dropPartitions(String dbName, String tblName, List&lt;ObjectPair&lt;Integer, byte[]&gt;&gt; partExprs, boolean deleteData, boolean ifExists, boolean needResults);List&lt;Partition&gt; dropPartitions(String catName, String dbName, String tblName, List&lt;ObjectPair&lt;Integer, byte[]&gt;&gt; partExprs, boolean deleteData, boolean ifExists, boolean needResults);List&lt;Partition&gt; dropPartitions(String dbName, String tblName, List&lt;ObjectPair&lt;Integer, byte[]&gt;&gt; partExprs, PartitionDropOptions options);List&lt;Partition&gt; dropPartitions(String catName, String dbName, String tblName, List&lt;ObjectPair&lt;Integer, byte[]&gt;&gt; partExprs, PartitionDropOptions options);boolean dropPartition(String db_name, String tbl_name, String name, boolean deleteData);boolean dropPartition(String catName, String db_name, String tbl_name, String name, boolean deleteData)</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.metastore-server.src.test.java.org.apache.hadoop.hive.metastore.client.TestDropPartitions.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2011-6-3 01:00:00" id="2191" opendate="2011-6-3 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow optional [inner] on equi-join.</summary>
      <description>Lot's of databases including mysql support an optional "inner" keyword to explicitely select an equi-join.As shown in the mysql docs: http://dev.mysql.com/doc/refman/5.1/en/join.htmlFor completeness/portability we should allow this.</description>
      <version>None</version>
      <fixedVersion>0.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.Hive.g</file>
      <file type="M">docs.xdocs.language.manual.joins.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-7-21 01:00:00" id="21911" opendate="2019-6-21 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pluggable LlapMetricsListener on Tez side to disable / resize Daemons</summary>
      <description>We need to have a way to plug in different listeners which act upon the LlapDaemon statistics.This listener should be able to disable / resize the LlapDaemons based on health data.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-tez.src.test.org.apache.hadoop.hive.llap.tezplugins.metrics.TestLlapMetricsCollector.java</file>
      <file type="M">llap-tez.src.java.org.apache.hadoop.hive.llap.tezplugins.metrics.LlapMetricsCollector.java</file>
      <file type="M">llap-tez.src.java.org.apache.hadoop.hive.llap.tezplugins.LlapTaskSchedulerService.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-1-18 01:00:00" id="22659" opendate="2019-12-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>JClouds needs to be updated to 2.1.3 in ptest</summary>
      <description>Since a couple of days ptest responded 404 to test queries coming in from jenkins side.I took a look into the issue and saw this exception on hiveptest-server-upstream side:Caused by: java.lang.IllegalStateException: zone https://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-central1-d not present in [https://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-east1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-east1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-east1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-east2-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-east2-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-east2-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-northeast1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-northeast1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-northeast1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-northeast2-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-northeast2-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-northeast2-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-south1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-south1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-south1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-southeast1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-southeast1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-southeast1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/australia-southeast1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/australia-southeast1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/australia-southeast1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-north1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-north1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-north1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west1-dhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west2-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west2-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west2-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west3-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west3-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west3-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west4-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west4-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west4-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west6-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west6-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west6-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/northamerica-northeast1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/northamerica-northeast1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/northamerica-northeast1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/southamerica-east1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/southamerica-east1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/southamerica-east1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-central1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-central1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-central1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-central1-fhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-east1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-east1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-east1-dhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-east4-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-east4-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-east4-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-west1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-west1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-west1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-west2-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-west2-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-west2-a] Debugging into the issue, it seems like that when we we put our cloud context in place for test execution, some default values originating from default templates are matched with actual GCP capabilities - and I guess zone us-central-1d was decommissioned in real-life, hence the exception.I upgraded jclouds version from 2.1.0 to 2.1.3 on server side and retried running Tomcat with this new installation. It seems to have fixed the issue. NO PRECOMMIT TESTS </description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.pom.xml</file>
    </fixedFiles>
  </bug>
</bugrepository>