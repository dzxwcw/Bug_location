<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HIVE">
  <bug fixdate="2019-8-27 01:00:00" id="22148" opendate="2019-8-27 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>S3A delegation tokens are not added in the job config of the Compactor.</summary>
      <description>Compactor job does not have the s3 delegation tokens, required to contact s3 and causes the job to fail.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-9-11 01:00:00" id="22195" opendate="2019-9-11 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Configure authentication type for Zookeeper when different from the default cluster wide</summary>
      <description>This could be useful in case when cluster is kerberized, but Zookeeper is not.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.metastore-server.src.main.java.org.apache.hadoop.hive.metastore.security.ZooKeeperTokenStore.java</file>
      <file type="M">service.src.java.org.apache.hive.service.server.HS2ActivePassiveHARegistryClient.java</file>
      <file type="M">service.src.java.org.apache.hive.service.server.HiveServer2.java</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.registry.impl.ZookeeperUtils.java</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.registry.impl.ZkRegistryBase.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-11-18 01:00:00" id="22217" opendate="2019-9-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Better Logging for Hive JAR Reload</summary>
      <description>Troubleshooting Hive Reloadable Auxiliary JARs has always been difficult.Add logging to at least confirm which JAR files are being loaded.</description>
      <version>2.3.6,3.2.0</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-11-23 01:00:00" id="22230" opendate="2019-9-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add support for filtering partitions on temporary tables</summary>
      <description>We need support for filtering partitions on temporary tables. In order to achieve this, SessionHiveMetastoreClient must implement the following methods:public List&lt;Partition&gt; listPartitionsByFilter(String catName, String dbName, String tableName,String filter, int maxParts)public int getNumPartitionsByFilter(String catName, String dbName, String tableName, String filter)public PartitionSpecProxy listPartitionSpecsByFilter(String catName, String dbName, String tblName, String filter, int maxParts)public PartitionValuesResponse listPartitionValues(PartitionValuesRequest request)</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.metastore-server.src.test.java.org.apache.hadoop.hive.metastore.client.TestListPartitions.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.metadata.TestSessionHiveMetastoreClientListPartitionsTempTable.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.metadata.TestSessionHiveMetastoreClientGetPartitionsTempTable.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.metastore.TestMetastoreExpr.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.TempTable.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.PartitionTree.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-9-23 01:00:00" id="22231" opendate="2019-9-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive query with big size via knox fails with Broken pipe Write failed</summary>
      <description>Posting large data through knox is causing the Broken pipe (Write failed) java.net.SocketException. Issue here that HS2 is responding with 401 even before complete query is transferred. HS2 has to wait until all the data is received and then respond with 401. That way knox can re-open the connection and send the negotiate header with the data.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.thrift.ThriftHttpServlet.java</file>
    </fixedFiles>
  </bug>
  
  
  
  <bug fixdate="2019-9-25 01:00:00" id="22241" opendate="2019-9-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement UDF to interpret date/timestamp using its internal representation and Gregorian-Julian hybrid calendar</summary>
      <description>UDF that converts a date/timestamp to new proleptic Gregorian calendar (ISO 8601 standard), which is produced by extending the Gregorian calendar backward to dates preceding its official introduction in 1582, assuming that its internal days/milliseconds since epoch is calculated using legacy Gregorian-Julian hybrid calendar, i.e., calendar that supports both the Julian and Gregorian calendar systems with the support of a single discontinuity, which corresponds by default to the Gregorian date when the Gregorian calendar was instituted.</description>
      <version>None</version>
      <fixedVersion>3.1.3,3.2.0,4.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.show.functions.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2019-9-25 01:00:00" id="22243" opendate="2019-9-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Align Apache Thrift version to 0.9.3-1 in standalone-metastore as well</summary>
      <description>Thrift was bumped to 0.9.3-1 in HIVE-21173, but standalone-metastore was left out of this.Thanks for pointing this out Ashutosh Bapat!</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2019-9-25 01:00:00" id="22244" opendate="2019-9-25 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Added default ACLs for znodes on a non-kerberized cluster</summary>
      <description>Set default ACLs for znodes on a non-kerberized cluster: Create/Read/Delete/Write/Admin to the world</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.metastore-server.src.main.java.org.apache.hadoop.hive.metastore.security.ZooKeeperTokenStore.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  <bug fixdate="2020-2-16 01:00:00" id="22736" opendate="2020-1-16 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support replication across multiple encryption zones</summary>
      <description/>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.metastore-server.src.main.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">standalone-metastore.metastore-server.src.main.java.org.apache.hadoop.hive.metastore.HiveAlterHandler.java</file>
      <file type="M">standalone-metastore.metastore-common.src.main.java.org.apache.hadoop.hive.metastore.ReplChangeManager.java</file>
      <file type="M">standalone-metastore.metastore-common.src.main.java.org.apache.hadoop.hive.metastore.conf.MetastoreConf.java</file>
      <file type="M">standalone-metastore.metastore-common.pom.xml</file>
      <file type="M">shims.common.src.main.java.org.apache.hadoop.hive.shims.HadoopShims.java</file>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.Cleaner.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ImportSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.ddl.table.storage.AlterTableUnarchiveOperation.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.ddl.table.storage.AlterTableSetLocationOperation.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.ddl.table.storage.AlterTableArchiveUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.ddl.table.storage.AlterTableArchiveOperation.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.ddl.table.create.CreateTableOperation.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniHS2.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcDriver2.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.metadata.TestAlterTableMetadata.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.metastore.TestReplChangeManager.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.metastore.cache.TestCachedStoreUpdateUsingEvents.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  
  
  
  
  
  
  
  
</bugrepository>