<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository name="HIVE">
  
  <bug fixdate="2015-4-23 01:00:00" id="10467" opendate="2015-4-23 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Switch to GIT repository on Jenkins precommit tests</summary>
      <description/>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.metastore.execute-test-on-lxc.sh</file>
      <file type="M">dev-support.jenkins-execute-hms-test.sh</file>
      <file type="M">dev-support.jenkins-execute-build.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-1-26 01:00:00" id="1105" opendate="2010-1-26 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add service script for starting metastore server</summary>
      <description>The instructions on this page recommend running Java directly in order to start the metastore:http://wiki.apache.org/hadoop/Hive/AdminManual/MetastoreAdminSince we already have a generic service-starter script, it would be nice to be able to do this instead:hive --service metastoreI've written a metastore.sh for this purpose.</description>
      <version>0.4.1</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">bin.ext.help.sh</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-7-15 01:00:00" id="1411" opendate="2010-6-15 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>DataNucleus throws NucleusException if core-3.1.1 JAR appears more than once on CLASSPATH</summary>
      <description>DataNucleus barfs when the core-3.1.1 JAR file appears more than once on the CLASSPATH:2010-03-06 12:33:25,565 ERROR exec.DDLTask (SessionState.java:printError(279)) - FAILED: Error in metadata: javax.jdo.JDOFatalInter nalException: Unexpected exception caught. NestedThrowables: java.lang.reflect.InvocationTargetException org.apache.hadoop.hive.ql.metadata.HiveException: javax.jdo.JDOFatalInternalException: Unexpected exception caught. NestedThrowables: java.lang.reflect.InvocationTargetException at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:258) at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:879) at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:103) at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:379) at org.apache.hadoop.hive.ql.Driver.run(Driver.java:285) at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:123) at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:181) at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:287) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.hadoop.util.RunJar.main(RunJar.java:156) Caused by: javax.jdo.JDOFatalInternalException: Unexpected exception caught. NestedThrowables: java.lang.reflect.InvocationTargetException at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1186)at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:803) at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:698) at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:164) at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:181)at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:125) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:104) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:62) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:130)at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:146)at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:118) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.(HiveMetaStore.java:100) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.(HiveMetaStoreClient.java:74) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:783) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:794) at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:252) ... 12 more Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)at java.lang.reflect.Method.invoke(Method.java:597) at javax.jdo.JDOHelper$16.run(JDOHelper.java:1956) at java.security.AccessController.doPrivileged(Native Method) at javax.jdo.JDOHelper.invoke(JDOHelper.java:1951) at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1159)... 28 more Caused by: org.datanucleus.exceptions.NucleusException: Plugin (Bundle) "org.eclipse.jdt.core" is already registered. Ensure you do nt have multiple JAR versions of the same plugin in the classpath. The URL "file:/Users/hadop/hadoop-0.20.1+152/build/ivy/lib/Hadoo p/common/core-3.1.1.jar" is already registered, and you are trying to register an identical plugin located at URL "file:/Users/hado p/hadoop-0.20.1+152/lib/core-3.1.1.jar." at org.datanucleus.plugin.NonManagedPluginRegistry.registerBundle(NonManagedPluginRegistry.java:437)at org.datanucleus.plugin.NonManagedPluginRegistry.registerBundle(NonManagedPluginRegistry.java:343)at org.datanucleus.plugin.NonManagedPluginRegistry.registerExtensions(NonManagedPluginRegistry.java:227)at org.datanucleus.plugin.NonManagedPluginRegistry.registerExtensionPoints(NonManagedPluginRegistry.java:159)at org.datanucleus.plugin.PluginManager.registerExtensionPoints(PluginManager.java:82) at org.datanucleus.OMFContext.(OMFContext.java:164) at org.datanucleus.OMFContext.(OMFContext.java:145) at org.datanucleus.ObjectManagerFactoryImpl.initialiseOMFContext(ObjectManagerFactoryImpl.java:143)at org.datanucleus.jdo.JDOPersistenceManagerFactory.initialiseProperties(JDOPersistenceManagerFactory.java:317)at org.datanucleus.jdo.JDOPersistenceManagerFactory.(JDOPersistenceManagerFactory.java:261)at org.datanucleus.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:174)... 36 more 2010-03-06 12:33:25,575 ERROR ql.Driver (SessionState.java:printError(279)) - FAILED: Execution Error, return code 1 from org.apach e.hadoop.hive.ql.exec.DDLTask 2010-03-06 12:42:30,457 ERROR exec.DDLTask (SessionState.java:printError(279)) - FAILED: Error in metadata: javax.jdo.JDOFatalInter nalException: Unexpected exception caught. NestedThrowables: java.lang.reflect.InvocationTargetException org.apache.hadoop.hive.ql.metadata.HiveException: javax.jdo.JDOFatalInternalException: Unexpected exception caught. NestedThrowables:</description>
      <version>0.4.0,0.4.1,0.5.0</version>
      <fixedVersion>0.6.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hive-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2016-8-5 01:00:00" id="14444" opendate="2016-8-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade qtest execution framework to junit4 - migrate most of them</summary>
      <description>this is the second step..migrating all exiting qtestgen generated tests to junit4it might be possible that not all will get migrated in this ticket...I will leave out the problematic ones...</description>
      <version>None</version>
      <fixedVersion>2.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.templates.TestPerfCliDriver.vm</file>
      <file type="M">ql.src.test.templates.TestParseNegative.vm</file>
      <file type="M">ql.src.test.templates.TestNegativeCliDriver.vm</file>
      <file type="M">ql.src.test.templates.TestCompareCliDriver.vm</file>
      <file type="M">ql.src.test.templates.TestCliDriver.vm</file>
      <file type="M">ql.src.test.templates.TestBeeLineDriver.vm</file>
      <file type="M">pom.xml</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.QTestUtil.java</file>
      <file type="M">itests.qtest.pom.xml</file>
      <file type="M">itests.qtest-spark.pom.xml</file>
      <file type="M">itests.qtest-accumulo.pom.xml</file>
      <file type="M">hbase-handler.src.test.templates.TestHBaseNegativeCliDriver.vm</file>
      <file type="M">hbase-handler.src.test.templates.TestHBaseCliDriver.vm</file>
      <file type="M">ant.src.org.apache.hadoop.hive.ant.QTestGenTask.java</file>
      <file type="M">ant.src.org.apache.hadoop.hive.ant.antlib.xml</file>
    </fixedFiles>
  </bug>
  
  <bug fixdate="2010-12-8 01:00:00" id="1842" opendate="2010-12-8 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add the local flag to all the map red tasks, if the query is running locally.</summary>
      <description/>
      <version>0.4.1</version>
      <fixedVersion>0.7.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2018-1-10 01:00:00" id="18420" opendate="2018-1-10 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP IO: InputStream may return 0 bytes</summary>
      <description>This is probably caused by some other issue as it implies a 0-sized range being in the list. However, it's good to handle this correctly for now.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReaderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2014-9-5 01:00:00" id="8010" opendate="2014-9-5 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>[CBO] Handle nested types</summary>
      <description>need to handle ExprNodeFieldDesc</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.cbo.correctness.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.RexNodeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.ASTConverter.java</file>
    </fixedFiles>
  </bug>
  <bug fixdate="2009-11-18 01:00:00" id="940" opendate="2009-11-18 00:00:00" resolution="Fixed">
    <buginformation>
      <summary>restrict creation of partitions with empty partition keys</summary>
      <description>create table pc (a int) partitioned by (b string, c string);alter table pc add partition (b="f", c='');above alter cmd fails but actually creates a partition with name 'b=f/c=' but describe partition on the same name fails. creation of such partitions should not be allowed.</description>
      <version>0.3.0,0.4.0,0.4.1,0.5.0,0.6.0</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>