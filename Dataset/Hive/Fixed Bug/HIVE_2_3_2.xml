<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HIVE">
  <bug id="17429" opendate="2017-9-1 00:00:00" fixdate="2017-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive JDBC doesn&amp;#39;t return rows when querying Impala</summary>
      <description>The Hive JDBC driver used to return a result set when querying Impala. Now, instead, it gets data back but interprets the data as query logs instead of a resultSet. This causes many issues (we see complaints about beeline as well as test failures).This appears to be a regression introduced with asynchronous operation against Hive.Ideally, we could make both behaviors work. I have a simple patch that should fix the problem.</description>
      <version>2.1.0,2.2.0,2.3.0,2.3.1,2.3.2</version>
      <fixedVersion>2.1.0,2.1.1,2.2.1,2.3.4,2.4.0,3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveStatement.java</file>
    </fixedFiles>
  </bug>
  <bug id="1743" opendate="2010-10-22 00:00:00" fixdate="2010-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Group-by to determine equals of Keys in reverse order</summary>
      <description>When processing group-by, in reduce side, keys are ordered. Comparing equality of two keys can be more efficient in reverse order.</description>
      <version>None</version>
      <fixedVersion>0.7.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.ListObjectsEqualComparer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPOr.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNotEqual.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFBaseCompare.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="17931" opendate="2017-10-30 00:00:00" fixdate="2017-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement Parquet vectorization reader for Array type</summary>
      <description>Parquet vectorized reader can't support array type, it should be supported to improve the performance when the query with array type.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.parquet.VectorizedColumnReaderTestBase.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.parquet.vector.VectorizedPrimitiveColumnReader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.parquet.vector.VectorizedParquetRecordReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="17932" opendate="2017-10-30 00:00:00" fixdate="2017-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove option to control partition level basic stats fetching</summary>
      <description>disabling the fetching of partition stats(hive.stats.fetch.partition.stats) may cause problematic cases to arise for partitioned tables...the user might just want to disable the cbo instead tweaking the fetching of partition stats.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.queries.clientpositive.columnStatsUpdateForStatsOptimizer.2.q</file>
      <file type="M">ql.src.test.queries.clientpositive.columnStatsUpdateForStatsOptimizer.1.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.StatsUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.RelOptHiveTable.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="1794" opendate="2010-11-16 00:00:00" fixdate="2010-11-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>GenericUDFOr and GenericUDFAnd cannot receive boolean typed object</summary>
      <description>If a UDF returns Java's native boolean and passed into a logic AND or OR. The execution will break.</description>
      <version>None</version>
      <fixedVersion>0.7.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPOr.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPAnd.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="18118" opendate="2017-11-21 00:00:00" fixdate="2017-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Explain Extended should indicate if a file being read is an EC file</summary>
      <description>We already print out the files Hive will read in the explain extended command, we just have to modify it to say whether or not its an EC file.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.src.test.java.org.apache.hadoop.hive.metastore.utils.TestMetaStoreUtils.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.common.StatsSetupConst.java</file>
      <file type="M">ql.src.test.results.clientpositive.unset.table.view.property.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.show.tblproperties.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.materialized.view.describe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.materialized.view.create.rewrite.multi.db.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.materialized.view.create.rewrite.dummy.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.materialized.view.create.rewrite.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.materialized.view.create.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.erasurecoding.erasure.simple.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.druid.druidmini.mv.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.beeline.materialized.view.create.rewrite.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.unset.table.property.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.erasure.simple.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.StatsUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.BasicStatsTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.BasicStatsNoJobTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.TableDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.Statistics.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PlanUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PartitionDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.stats.annotation.StatsRulesProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.spark.SparkMapJoinOptimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.formatting.TextMetaDataFormatter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.formatting.MetaDataFormatUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hive.jdbc.miniHS2.MiniHS2.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.QTestUtil.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniHS2.java</file>
      <file type="M">common.src.java.org.apache.hive.common.util.HiveStringUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="18263" opendate="2017-12-11 00:00:00" fixdate="2017-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ptest execution are multiple times slower sometimes due to dying executor slaves</summary>
      <description>PreCommit-HIVE-Build job has been seen running very long from time to time. Usually it should take about 1.5 hours, but in some cases it took over 4-5 hours.Looking in the logs of one such execution I've seen that some commands that were sent to test executing slaves returned 255. Here this typically means that there is unknown return code for the remote call since hiveptest-server can't reach these slaves anymore.In the hiveptest-server logs it is seen that some slaves were killed while running the job normally, and here is why: Hive's ptest-server checks periodically in every 60 minutes the status of slaves. It also keeps track of slaves that were terminated. If upon such check it is found that a slave that was already killed (mTerminatedHosts map contains its IP) is still running, it will try and terminate it again. The server also maintains a file on its local FS that contains the IP of hosts that were used before. (This probably for resilience reasons) This file is read when tomcat server starts and if any of the IPs in the file are seen as running slaves, ptest will terminate these first so it can begin with a fresh start The IPs of these terminated instances already make their way into mTerminatedHosts upon initialization... The cloud provider may reuse some older IPs, so it is not too rare that the same IP that belonged to a terminated host is assigned to a new one.This is problematic: Hive ptest's slave caretaker thread kicks in every 60 minutes and might see a running host that has the same IP as an old slave had which was terminated at startup. It will think that this host should be terminated since it already tried 60 minutes ago as its IP is in mTerminatedHostsWe have to fix this by making sure that if a new slave is created, we check the contents of mTerminatedHosts and remove this IP from it if it is there.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.src.main.java.org.apache.hive.ptest.execution.context.CloudExecutionContextProvider.java</file>
    </fixedFiles>
  </bug>
  <bug id="18326" opendate="2017-12-21 00:00:00" fixdate="2017-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP Tez scheduler - only preempt tasks if there&amp;#39;s a dependency between them</summary>
      <description>It is currently possible for e.g. two sides of a union (or a join for that matter) to have slightly different priorities. We don't want to preempt running tasks on one side in favor of the other side in such cases.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-tez.src.java.org.apache.hadoop.hive.llap.tezplugins.LlapTaskSchedulerService.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="18414" opendate="2018-1-9 00:00:00" fixdate="2018-1-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>upgrade to tez-0.9.1</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18415" opendate="2018-1-9 00:00:00" fixdate="2018-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Lower "Updating Partition Stats" Logging Level</summary>
      <description>org.apache.hadoop.hive.metastore.utils.MetaStoreUtilsLOG.warn("Updating partition stats fast for: " + part.getTableName());...LOG.warn("Updated size to " + params.get(StatsSetupConst.TOTAL_SIZE));This logging produces many lines of WARN log messages in my log file and it's not clear to me what the issue is here. Why is this a warning and how should I respond to address this warning?DEBUG is probably more appropriate for a utility class. Please lower.</description>
      <version>1.2.2,2.2.0,2.3.2,3.0.0</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.metastore-server.src.main.java.org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="18421" opendate="2018-1-10 00:00:00" fixdate="2018-2-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorized execution handles overflows in a different manner than non-vectorized execution</summary>
      <description>In vectorized execution arithmetic operations which cause integer overflows can give wrong results. Issue is reproducible in both Orc and parquet.Simple test case to reproduce this issueset hive.vectorized.execution.enabled=true;create table parquettable (t1 tinyint, t2 tinyint) stored as parquet;insert into parquettable values (-104, 25), (-112, 24), (54, 9);select t1, t2, (t1-t2) as diff from parquettable where (t1-t2) &lt; 50 order by diff desc;+-------+-----+-------+| t1 | t2 | diff |+-------+-----+-------+| -104 | 25 | 127 || -112 | 24 | 120 || 54 | 9 | 45 |+-------+-----+-------+When vectorization is turned off the same query produces only one row.</description>
      <version>2.1.1,2.2.0,2.3.2,3.0.0</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">vector-code-gen.src.org.apache.hadoop.hive.tools.GenVectorTestCode.java</file>
      <file type="M">vector-code-gen.src.org.apache.hadoop.hive.tools.GenVectorCode.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorMathFunctions.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorArithmeticExpressions.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestUnaryMinus.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPPlus.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNegative.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPMultiply.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPMod.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPMinus.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorExpressionDescriptor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.PosModLongToLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.PosModDoubleToDouble.java</file>
      <file type="M">ql.src.gen.vectorization.TestTemplates.TestClass.txt</file>
      <file type="M">ql.src.gen.vectorization.ExpressionTemplates.ScalarArithmeticColumn.txt</file>
      <file type="M">ql.src.gen.vectorization.ExpressionTemplates.ColumnUnaryMinus.txt</file>
      <file type="M">ql.src.gen.vectorization.ExpressionTemplates.ColumnDivideColumn.txt</file>
      <file type="M">ql.src.gen.vectorization.ExpressionTemplates.ColumnArithmeticScalar.txt</file>
      <file type="M">ql.src.gen.vectorization.ExpressionTemplates.ColumnArithmeticColumn.txt</file>
      <file type="M">itests.hive-jmh.src.main.java.org.apache.hive.benchmark.vectorization.VectorizedArithmeticBench.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="18529" opendate="2018-1-24 00:00:00" fixdate="2018-1-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorization: Add a debug config option to disable scratch column reuse</summary>
      <description>Debugging scratch column reuse is particularly painful and slow, adding a config allows for this to be done without rebuilds.</description>
      <version>2.3.2,3.0.0</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties.orig</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="18557" opendate="2018-1-26 00:00:00" fixdate="2018-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>q.outs: fix issues caused by q.out_spark files</summary>
      <description>HIVE-18061 caused some issues in yetus check by introducing q.out_spark files.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18596" opendate="2018-1-31 00:00:00" fixdate="2018-2-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Synchronize value of hive.spark.client.connect.timeout across unit tests</summary>
      <description>hive.spark.client.connect.timeout is set to 30 seconds for TestMiniSparkOnYarnCliDriver but it left at the default value for all other tests. We should use the same value (30 seconds) for all other tests.We have seen flaky tests due to failure to establish the remote within the allotted timeout. This could be due to the fact that we run our tests in the cloud so maybe occasional network delays are more common.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.src.test.java.org.apache.hive.spark.client.TestSparkClient.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.java</file>
      <file type="M">data.conf.spark.standalone.hive-site.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18597" opendate="2018-1-31 00:00:00" fixdate="2018-2-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: Always package the log4j2 API jar for org.apache.log4j</summary>
      <description>The log4j 1 and 2.x jars have NDC classes with identical package names. // log4j-1.2-API needed for NDC org.apache.log4j.NDC.class,Queries fail with java.lang.ClassCastException: org.apache.log4j.NDC$DiagnosticContext cannot be cast to java.lang.String at org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable.setMDCFromNDC(TaskRunnerCallable.java:312) ~[hive-llap-server-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]If the service driver packages the log4j1.x jar instead of the 2.x API shim jar.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cli.LlapServiceDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="18598" opendate="2018-2-1 00:00:00" fixdate="2018-2-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disallow NOT NULL constraints to be ENABLED/ENFORCED with EXTERNAL table</summary>
      <description>HIVE-16605 is enabling/enforcing NOT NULL constraint. But since Hive do not manage the data for external tables and can not enforce constraints it doesn't make sense to allow NOT NULL constraints to be enabled/enforced on external table.User can still specify RELY to signal optimizer for constraint related optimizations.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="18611" opendate="2018-2-2 00:00:00" fixdate="2018-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid memory allocation of aggregation buffer during stats computation</summary>
      <description>Bloom filter aggregation buffer may result in allocation of upto ~594MB array which is unnecessary.</description>
      <version>2.3.2,3.0.0</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">storage-api.src.java.org.apache.hive.common.util.BloomKFilter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBloomFilter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.stats.annotation.StatsRulesProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="18612" opendate="2018-2-2 00:00:00" fixdate="2018-2-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Build subprocesses under Yetus in Ptest use 1.7 jre instead of 1.8</summary>
      <description>As per this jira comment made by Yetus maven plugins that want to use java executable are seeing a 1.7 java binary. In this particular case Yetus sets JAVA_HOME to a 1.8 JDK installation, and thus maven uses that, but any subsequent java executes will use the JRE which they see on PATH.This should be fixed by adding the proper java/bin (that of JAVA_HOME setting) to PATH.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.src.main.resources.yetus-exec.vm</file>
    </fixedFiles>
  </bug>
  <bug id="18626" opendate="2018-2-5 00:00:00" fixdate="2018-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Repl load "with" clause does not pass config to tasks</summary>
      <description>The "with" clause in repl load suppose to pass custom hive config entries to replication. However, the config is only effective in BootstrapEventsIterator, but not the generated tasks (such as MoveTask, DDLTask).</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ImportTableDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ReplicationSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.repl.bootstrap.load.table.LoadTable.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.repl.bootstrap.load.table.LoadPartitions.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.repl.bootstrap.load.LoadDatabase.java</file>
    </fixedFiles>
  </bug>
  <bug id="18627" opendate="2018-2-6 00:00:00" fixdate="2018-2-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PPD: Handle FLOAT boxing differently for single/double precision constants</summary>
      <description>Constants like 0.1 and 0.3 are differently boxed based on intermediate precision of the compiler codepath.Disabling CBO produces 0.1BD constants which fail to box correctly to Double/Float.Enabling CBO fixes this issue, but cannot be applied all queries in Hive.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">errata.txt</file>
    </fixedFiles>
  </bug>
  <bug id="18651" opendate="2018-2-8 00:00:00" fixdate="2018-4-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Expose additional Spark metrics</summary>
      <description>There have been multiples additional metrics that get collected via Spark (such as executor CPU time spent). We should expose them in HoS.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.src.test.java.org.apache.hive.spark.client.TestMetricsCollection.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.Metrics.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.MetricsCollection.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.spark.TestSparkTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.impl.SparkMetricsUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.Statistic.SparkStatisticsNames.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="18652" opendate="2018-2-8 00:00:00" fixdate="2018-6-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Print Spark metrics on console</summary>
      <description>For Hive-on-MR, each MR job launched prints out some stats about the job:INFO : 2018-02-07 17:51:11,218 Stage-1 map = 0%, reduce = 0%INFO : 2018-02-07 17:51:18,396 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 1.87 secINFO : 2018-02-07 17:51:25,742 Stage-1 map = 100%, reduce = 100%, Cumulative CPU 4.34 secINFO : MapReduce Total cumulative CPU time: 4 seconds 340 msecINFO : Ended Job = job_1517865654989_0004INFO : MapReduce Jobs Launched:INFO : Stage-Stage-1: Map: 1 Reduce: 1 Cumulative CPU: 4.34 sec HDFS Read: 7353 HDFS Write: 151 SUCCESSINFO : Total MapReduce CPU Time Spent: 4 seconds 340 msecWe should do the same for Hive-on-Spark.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.src.test.java.org.apache.hive.spark.client.TestMetricsCollection.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.ShuffleWriteMetrics.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.ShuffleReadMetrics.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.InputMetrics.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.MetricsCollection.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.impl.SparkMetricsUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.Statistic.SparkStatisticsNames.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.Statistic.SparkStatisticGroup.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkTask.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.exec.spark.TestSparkStatistics.java</file>
    </fixedFiles>
  </bug>
  <bug id="18671" opendate="2018-2-9 00:00:00" fixdate="2018-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>lock not released after Hive on Spark query was cancelled</summary>
      <description>When cancel the query is running on spark, the SparkJobMonitor can not return, therefore the locks hold by the query can not be released. When enable debug in log, you will see many log info as following:2018-02-09 08:27:09,613 INFO org.apache.hadoop.hive.ql.exec.spark.status.SparkJobMonitor: [HiveServer2-Background-Pool: Thread-80]: state = CANCELLED2018-02-09 08:27:10,613 INFO org.apache.hadoop.hive.ql.exec.spark.status.SparkJobMonitor: [HiveServer2-Background-Pool: Thread-80]: state = CANCELLED</description>
      <version>2.3.2</version>
      <fixedVersion>2.4.0,3.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.wm.TestTrigger.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.wm.Action.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.spark.TestSparkTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.RemoteSparkJobMonitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="18674" opendate="2018-2-9 00:00:00" fixdate="2018-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>update Hive to use ORC 1.4.3</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="18706" opendate="2018-2-13 00:00:00" fixdate="2018-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ensure each Yetus execution has its own separate working dir</summary>
      <description>Currently all Yetus executions started asynchronously by ptest are using the same working directory.This is not a problem in most of the cases because Yetus finishes in less than 30 minutes for small patches. For some oversized patches however, this may take more time than ptest test execution and thus overlapping with the next build.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.src.main.resources.yetus-exec.vm</file>
      <file type="M">testutils.ptest2.src.main.resources.source-prep.vm</file>
      <file type="M">testutils.ptest2.src.main.java.org.apache.hive.ptest.execution.YetusPhase.java</file>
    </fixedFiles>
  </bug>
  <bug id="18786" opendate="2018-2-23 00:00:00" fixdate="2018-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE in Hive windowing functions</summary>
      <description>When I run a Hive query with windowing functions, if there's enough data I get an NPE.For example something like this query might break:select id, created_date, max(created_date) over (partition by id) latest_created_any from ...The only workaround I've found is to remove the windowing functions entirely.The stacktrace looks suspiciously similar to HIVE-15278, but I'm in hive-2.3.2 which appears to have the bugfix applied.  Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) &lt;some row data here&gt;       at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:297)        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:317)        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:185)       ... 14 more Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) &lt;some row data here&gt;        at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:365)       at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:287)        ... 16 moreCaused by: java.lang.NullPointerException         at org.apache.hadoop.hive.ql.exec.persistence.PTFRowContainer.first(PTFRowContainer.java:115)         at org.apache.hadoop.hive.ql.exec.PTFPartition.iterator(PTFPartition.java:114)         at org.apache.hadoop.hive.ql.udf.ptf.BasePartitionEvaluator.getPartitionAgg(BasePartitionEvaluator.java:200)         at org.apache.hadoop.hive.ql.udf.ptf.WindowingTableFunction.evaluateFunctionOnPartition(WindowingTableFunction.java:155)         at org.apache.hadoop.hive.ql.udf.ptf.WindowingTableFunction.iterator(WindowingTableFunction.java:538)         at org.apache.hadoop.hive.ql.exec.PTFOperator$PTFInvocation.finishPartition(PTFOperator.java:349)         at org.apache.hadoop.hive.ql.exec.PTFOperator.process(PTFOperator.java:123)         at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:897)         at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:95)         at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource$GroupIterator.next(ReduceRecordSource.java:356)</description>
      <version>2.3.2,2.3.3</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.java</file>
    </fixedFiles>
  </bug>
  <bug id="18788" opendate="2018-2-23 00:00:00" fixdate="2018-3-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up inputs in JDBC PreparedStatement</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.3.3,3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HivePreparedStatement.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcDriver2.java</file>
    </fixedFiles>
  </bug>
  <bug id="18944" opendate="2018-3-13 00:00:00" fixdate="2018-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Groupping sets position is set incorrectly during DPP</summary>
      <description>groupingSetsPosition is set to -1 in case there are no grouping sets; however DPP calls the constructor with 0 this could potentially trigger an unwanted emittion of a summary row2018-03-13T05:58:16,226 ERROR [TezTR-881987_1_5_1_1_0] tez.TezProcessor: java.lang.RuntimeException: Hive Runtime Error while closing operators: 0 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.close(ReduceRecordProcessor.java:407) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:284) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:250) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374) at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73) at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962) at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61) at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Caused by: java.lang.ArrayIndexOutOfBoundsException: 0 at org.apache.hadoop.hive.ql.exec.vector.VectorHashKeyWrapperBatch.setLongValue(VectorHashKeyWrapperBatch.java:994) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeHashAggregate.close(VectorGroupByOperator.java:461) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.closeOp(VectorGroupByOperator.java:1179) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:722) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:746) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:746) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.close(ReduceRecordProcessor.java:383)</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.DynamicPartitionPruningOptimization.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="19042" opendate="2018-3-24 00:00:00" fixdate="2018-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>set MALLOC_ARENA_MAX for LLAP</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.bin.runLlapDaemon.sh</file>
    </fixedFiles>
  </bug>
  <bug id="19083" opendate="2018-3-30 00:00:00" fixdate="2018-4-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make partition clause optional for INSERT</summary>
      <description>Partition clause should be optional for INSERT INTO VALUES INSERT OVERWRITE INSERT SELECT</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.dynamic.partition.insert.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.dynamic.partition.insert.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="19394" opendate="2018-5-3 00:00:00" fixdate="2018-5-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WM_TRIGGER trigger creation failed with type cast from Integer to Boolean</summary>
      <description>During testing of the new WM feature and the Hive metastore is created using Postgresql, I've discovered a bug when creating a new trigger. For exampleCREATE RESOURCE PLAN plan_1 WITH QUERY_PARALLELISM=4;CREATE POOL plan_1.slow WITH ALLOC_FRACTION=0.5, QUERY_PARALLELISM=2, SCHEDULING_POLICY='fair';ALTER POOL plan_1.default SET ALLOC_FRACTION=0.5, QUERY_PARALLELISM=2, SCHEDULING_POLICY='fifo';CREATE TRIGGER plan_1.trigger_1 WHEN S3A_BYTES_READ &gt; 268435456 DO MOVE TO slow;Right at the CREATE TRIGGER statement, an error will occurError while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:Insert of object "org.apache.hadoop.hive.metastore.model.MWMTrigger@5c5ae5d8" using statement "INSERT INTO "WM_TRIGGER" ("TRIGGER_ID","ACTION_EXPRESSION","IS_IN_UNMANAGED","NAME","RP_ID","TRIGGER_EXPRESSION") VALUES (?,?,?,?,?,?)" failed : ERROR: column "IS_IN_UNMANAGED" is of type boolean but expression is of type integer Hint: You will need to rewrite or cast the expression. Position: 129) at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:543) ~[datanucleus-api-jdo-4.2.4.jar:?] at org.datanucleus.api.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:729) ~[datanucleus-api-jdo-4.2.4.jar:?] at org.datanucleus.api.jdo.JDOPersistenceManager.makePersistent(JDOPersistenceManager.java:749) ~[datanucleus-api-jdo-4.2.4.jar:?] at org.apache.hadoop.hive.metastore.ObjectStore.createWMTrigger(ObjectStore.java:11218) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_151] at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_151] at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT] at com.sun.proxy.$Proxy37.createWMTrigger(Unknown Source) ~[?:?] at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_wm_trigger(HiveMetaStore.java:7846) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_151] at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT] at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT] at com.sun.proxy.$Proxy39.create_wm_trigger(Unknown Source) ~[?:?] at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createWMTrigger(HiveMetaStoreClient.java:3062) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_151] at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:212) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT] at com.sun.proxy.$Proxy40.createWMTrigger(Unknown Source) ~[?:?] at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createWMTrigger(HiveMetaStoreClient.java:3062) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_151] at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:212) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT] at com.sun.proxy.$Proxy40.createWMTrigger(Unknown Source) ~[?:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_151] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_151] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_151] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_151] at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2722) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT] at com.sun.proxy.$Proxy40.createWMTrigger(Unknown Source) ~[?:?] at org.apache.hadoop.hive.ql.metadata.Hive.createWMTrigger(Hive.java:5048) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT] ... 22 moreApparently, Postgres doesn't automatically cast int to boolean.hive=# create table example (active BOOLEAN);CREATE TABLEhive=# \d+ example; Table "public.example" Column | Type | Modifiers | Storage | Stats target | Description--------+---------+-----------+---------+--------------+------------- active | boolean | | plain | |hive=# insert into example (active) values (0);ERROR: column "active" is of type boolean but expression is of type integerLINE 1: insert into example (active) values (0); ^HINT: You will need to rewrite or cast the expression.Adding a ' quote and the insert statement will be okayhive=# insert into example (active) values ('0');INSERT 0 1hive=# select * from example; active-------- f(1 row)The fix is to change the IS_IN_UNMANAGED field in Postgres from boolean to integer (smallint) since that is what it's being done in derby schema.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.src.main.sql.postgres.hive-schema-3.0.0.postgres.sql</file>
      <file type="M">standalone-metastore.src.main.sql.postgres.upgrade-2.3.0-to-3.0.0.postgres.sql</file>
    </fixedFiles>
  </bug>
  <bug id="1962" opendate="2011-2-5 00:00:00" fixdate="2011-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>make a libthrift.jar and libfb303.jar in dist package for backward compatibility</summary>
      <description>We have seen an internal user that relies on Hive's distribution library libthrift.jar. After the upgrade of thrift jar to 0.5.0, the jar file is renamed to thrift-0.5.0.jar and similarly for the fb303 jar. We can ask the user to change their dependency to thrift-0.5.0.jar, but later when we upgrade to a new version, the dependency breaks again. It's desirable to create a symlink in the dist/lib directory to link libthrift.jar to thrift-${thrift.version}.jar and the same for fb303.</description>
      <version>None</version>
      <fixedVersion>0.7.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="19639" opendate="2018-5-21 00:00:00" fixdate="2018-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>a transactional Hive table cannot be imported as an external table</summary>
      <description>When transactional table is imported to a external table, the table should be imported as a non transactional table, as external tables cannot be transactional.</description>
      <version>None</version>
      <fixedVersion>3.1.0,4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.llap.mm.exim.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.mm.exim.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ImportSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.AcidUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="19649" opendate="2018-5-22 00:00:00" fixdate="2018-6-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up inputs in JDBC PreparedStatement. Add unit tests.</summary>
      <description>Add unit tests for feature that was implemented in HIVE-18788.The integration tests are present, but it will be useful to catch errors during module build.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.src.test.org.apache.hive.jdbc.TestHivePreparedStatement.java</file>
    </fixedFiles>
  </bug>
  <bug id="1965" opendate="2011-2-7 00:00:00" fixdate="2011-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Auto convert mapjoin should not throw exception if the top operator is union operator.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.java</file>
    </fixedFiles>
  </bug>
  <bug id="19766" opendate="2018-6-1 00:00:00" fixdate="2018-7-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show the number of rows inserted when execution engine is Spark</summary>
      <description>Currently when insert query is run, the beeline output shows No rows affected.The logic to show the number of rows inserted is now present when execution engine is MR.This Jira is to make this work with Spark.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="19768" opendate="2018-6-1 00:00:00" fixdate="2018-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Utility to convert tables to conform to Hive strict managed tables mode</summary>
      <description>Create a utility that can check existing hive tables and convert them if necessary to conform to strict managed tables mode. Managed non-transactional ORC tables will be converted to full transactional tables Managed non-transactional tables of other types will be converted to insert-only transactional tables Tables with non-native storage/schema will be converted to external tables.</description>
      <version>None</version>
      <fixedVersion>3.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="19951" opendate="2018-6-20 00:00:00" fixdate="2018-7-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorization: Need to disable encoded LLAP I/O for ORC when there is data type conversion (Schema Evolution)</summary>
      <description>Currently, reading encoded ORC data does not support data type conversion. So, encoded reading and cache populating needs to be disabled.</description>
      <version>None</version>
      <fixedVersion>3.1.0,4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="20039" opendate="2018-6-30 00:00:00" fixdate="2018-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bucket pruning: Left Outer Join on bucketed table gives wrong result</summary>
      <description>Left outer join on bucketed table on certain cases gives wrong results.Depending on the order in which the table-scans are walked through, the FilterPruner might end up using the wrong table scan's table properties on the other table.</description>
      <version>2.3.2,3.0.0</version>
      <fixedVersion>3.2.0,4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.FixedBucketPruningOptimizer.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="20065" opendate="2018-7-3 00:00:00" fixdate="2018-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>metastore should not rely on jackson 1.x</summary>
      <description>somehow jackson 1.x is on the classpath in some ide-s ...and somehow 1.x org.codehaus jackson is being used from a dozen of classes - meanwhile the pom.xml doesn't mention it at all; but only a fasterxml's 2.9.0....I don't know where it gets the jackson 1.x implementation; but I think it shouldn't rely on that...</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.src.test.java.org.apache.hadoop.hive.metastore.messaging.json.TestJSONMessageDeserializer.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.PartitionFiles.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONOpenTxnMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONMessageFactory.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONMessageDeserializer.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONInsertMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONDropTableMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONDropPartitionMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONDropFunctionMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONDropDatabaseMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONDropConstraintMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONDropCatalogMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONCreateTableMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONCreateFunctionMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONCreateDatabaseMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONCreateCatalogMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONCommitTxnMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONAlterTableMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONAlterPartitionMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONAlterDatabaseMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONAllocWriteIdMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONAddUniqueConstraintMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONAddPrimaryKeyMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONAddPartitionMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONAddNotNullConstraintMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONAddForeignKeyMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONAcidWriteMessage.java</file>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.messaging.json.JSONAbortTxnMessage.java</file>
    </fixedFiles>
  </bug>
  <bug id="20191" opendate="2018-7-17 00:00:00" fixdate="2018-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PreCommit patch application doesn&amp;#39;t fail if patch is empty</summary>
      <description>I've created some backport tickets to branch-3 (e.g. HIVE-20181) and made the mistake of uploading the patch files with wrong filename (. instead of - between version and branch).These get applied on master, where they're already present, since git apply with -3 won't fail if patch is already there. Tests are run on master instead of failing.I think the patch application should fail if the patch is empty and branch selection logic should probably fail too if the patch name is malformed.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.src.main.resources.smart-apply-patch.sh</file>
      <file type="M">dev-support.jenkins-common.sh</file>
    </fixedFiles>
  </bug>
  <bug id="20212" opendate="2018-7-19 00:00:00" fixdate="2018-7-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hiveserver2 in http mode emitting metric default.General.open_connections incorrectly</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.2.0,4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.thrift.ThriftHttpCLIService.java</file>
    </fixedFiles>
  </bug>
  <bug id="20213" opendate="2018-7-19 00:00:00" fixdate="2018-7-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade Calcite to 1.17.0</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>3.2.0,4.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.union.offcbo.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stat.estimate.related.col.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.subquery.views.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.subquery.scalar.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.subquery.multi.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.spark.explainuser.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.pcr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.constprog.semijoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.perf.tez.query74.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.perf.tez.query4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.perf.tez.query11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.perf.spark.query74.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.perf.spark.query4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.perf.spark.query11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.pcr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.vectorized.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.subquery.views.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.subquery.scalar.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.subquery.multi.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.explainuser.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.constprog.semijoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.join.preds.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.druid.topn.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.druid.timeseries.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.druid.intervals.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.druid.druid.basic2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.druid.druidmini.test1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.druid.druidmini.floorTime.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.druid.druidmini.extractTime.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.druid.druidmini.expressions.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.rules.HiveAggregateJoinTransposeRule.java</file>
      <file type="M">pom.xml</file>
      <file type="M">jdbc-handler.pom.xml</file>
      <file type="M">druid-handler.src.test.org.apache.hadoop.hive.druid.TestHiveDruidQueryBasedInputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="20399" opendate="2018-8-16 00:00:00" fixdate="2018-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CTAS w/a custom table location that is not fully qualified fails for MM tables</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
    </fixedFiles>
  </bug>
  <bug id="204" opendate="2008-12-31 00:00:00" fixdate="2008-5-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Provide option to run hadoop via TestMiniMR</summary>
      <description>Right now MapRedTask does an exec on the hadoop command line. This prevents us from stepping through query execution code. If there were an option to run hadoop via MiniMR, this will create tasks within the same VM and so allows stepping into the execution code. See, src/test/org/apache/hadoop/mapred/TestMiniMRWithDFS.java in the hadoop source code for an example.</description>
      <version>None</version>
      <fixedVersion>0.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.templates.TestCliDriver.vm</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.QTestUtil.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExecDriver.java</file>
      <file type="M">ql.build.xml</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.properties</file>
      <file type="M">build-common.xml</file>
      <file type="M">ant.src.org.apache.hadoop.hive.ant.QTestGenTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="2040" opendate="2011-3-10 00:00:00" fixdate="2011-3-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>the retry logic in Hive&amp;#39;s concurrency is not working correctly.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.lockmgr.HiveLockObj.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.lockmgr.HiveLockMode.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.lockmgr.HiveLockManager.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
    </fixedFiles>
  </bug>
  <bug id="20400" opendate="2018-8-16 00:00:00" fixdate="2018-8-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>create table should always use a fully qualified path to avoid potential FS ambiguity</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.test.org.apache.hive.service.cli.CLIServiceTest.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.EximUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="20555" opendate="2018-9-13 00:00:00" fixdate="2018-9-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HiveServer2: Preauthenticated subject for http transport is not retained for entire duration of http communication in some cases</summary>
      <description>As implemented in HIVE-8705, for http transport, we add the logged in subject's credentials in the http header via a request interceptor. The request interceptor doesn't seem to be getting used for some http traffic (e.g. knox ssl in the same rpc). It would also be better to cache the logged in subject for the duration of the whole session.</description>
      <version>2.3.2,3.1.0</version>
      <fixedVersion>3.1.2,3.2.0,4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.auth.HttpAuthUtils.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HttpKerberosRequestInterceptor.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="20659" opendate="2018-9-29 00:00:00" fixdate="2018-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update commons-compress to 1.18 due to security issues</summary>
      <description>Currently most Hive version depends on commons-compress 1.9 or 1.4. Those versions have several security issues: https://commons.apache.org/proper/commons-compress/security-reports.htmlI propose to upgrade all commons-compress dependencies in all Hive (sub-)projects to at least 1.18. This will also make it easier for future extensions to Hive (serde, udfs, etc.) that have dependencies to commons-compress (e.g. https://github.com/zuinnote/hadoopoffice/wiki) to integrate into Hive without upgrading the commons-compress library manually in the Hive lib folder.</description>
      <version>1.2.1,2.3.2,3.1.0,3.0.0</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="20694" opendate="2018-10-5 00:00:00" fixdate="2018-10-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Additional unit tests for VectorizedOrcAcidRowBatchReader min max key evaluation</summary>
      <description>Follow up to HIVE-20664 and HIVE-20635.Additional unit tests for VectorizedOrcAcidRowBatchReader.findMinMaxKeys and VectorizedOrcAcidRowBatchReader.findOriginalMinMaxKeys related to split and stripe boundaries - particularly the case when a split is completely within an ORC stripe.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestVectorizedOrcAcidRowBatchReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="20772" opendate="2018-10-18 00:00:00" fixdate="2018-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>record per-task CPU counters in LLAP</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.decode.EncodedDataConsumer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.counters.QueryFragmentCounters.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LowLevelCacheCounters.java</file>
      <file type="M">llap-common.src.java.org.apache.hadoop.hive.llap.LlapUtil.java</file>
      <file type="M">llap-common.src.java.org.apache.hadoop.hive.llap.counters.LlapIOCounters.java</file>
    </fixedFiles>
  </bug>
  <bug id="20829" opendate="2018-10-29 00:00:00" fixdate="2018-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JdbcStorageHandler range split throws NPE</summary>
      <description>2018-10-29T06:37:14,982 ERROR [HiveServer2-Background-Pool: Thread-44466]: operation.Operation (:()) - Error running hive query:org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 1, vertexId=vertex_1540588928441_0121_2_00, diagnostics=[Vertex vertex_1540588928441_0121_2_00 [Map 1] killed/failed due to:ROOT_INPUT_INIT_FAILURE, Vertex Input: employees initializer failed, vertex=vertex_1540588928441_0121_2_00 [Map 1], java.lang.NullPointerException at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.initialize(HiveSplitGenerator.java:272) at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:278) at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:269) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:269) at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:253) at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108) at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41) at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)]Vertex killed, vertexName=Reducer 2, vertexId=vertex_1540588928441_0121_2_01, diagnostics=[Vertex received Kill in INITED state., Vertex vertex_1540588928441_0121_2_01 [Reducer 2] killed/failed due to:OTHER_VERTEX_FAILURE]DAG did not succeed due to VERTEX_FAILURE. failedVertices:1 killedVertices:1 at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:335) ~[hive-service-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:228) ~[hive-service-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at org.apache.hive.service.cli.operation.SQLOperation.access$700(SQLOperation.java:87) ~[hive-service-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork$1.run(SQLOperation.java:318) ~[hive-service-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_161] at javax.security.auth.Subject.doAs(Subject.java:422) ~[?:1.8.0_161] at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) ~[hadoop-common-3.1.1.3.0.3.0-150.jar:?] at org.apache.hive.service.cli.operation.SQLOperation$BackgroundWork.run(SQLOperation.java:338) ~[hive-service-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_161] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_161] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_161] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_161] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_161] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_161] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_161]Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Vertex failed, vertexName=Map 1, vertexId=vertex_1540588928441_0121_2_00, diagnostics=[Vertex vertex_1540588928441_0121_2_00 [Map 1] killed/failed due to:ROOT_INPUT_INIT_FAILURE, Vertex Input: employees initializer failed, vertex=vertex_1540588928441_0121_2_00 [Map 1], java.lang.NullPointerException at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.initialize(HiveSplitGenerator.java:272) at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:278) at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:269) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:269) at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:253) at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108) at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41) at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)]Vertex killed, vertexName=Reducer 2, vertexId=vertex_1540588928441_0121_2_01, diagnostics=[Vertex received Kill in INITED state., Vertex vertex_1540588928441_0121_2_01 [Reducer 2] killed/failed due to:OTHER_VERTEX_FAILURE]DAG did not succeed due to VERTEX_FAILURE. failedVertices:1 killedVertices:1 at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:240) ~[hive-exec-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:210) ~[hive-exec-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:97) ~[hive-exec-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2707) ~[hive-exec-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:2378) ~[hive-exec-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:2054) ~[hive-exec-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1752) ~[hive-exec-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1746) ~[hive-exec-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:157) ~[hive-exec-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:226) ~[hive-service-3.1.0.3.0.3.0-150.jar:3.1.0.3.0.3.0-150] ... 13 more</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc-handler.src.main.java.org.apache.hive.storage.jdbc.JdbcInputSplit.java</file>
      <file type="M">jdbc-handler.src.main.java.org.apache.hive.storage.jdbc.JdbcInputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="21009" opendate="2018-12-5 00:00:00" fixdate="2018-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LDAP - Specify binddn for ldap-search</summary>
      <description>When user accounts cannot do an LDAP search, there is currently no way of specifying a custom binddn to use for the ldap-search.So I'm missing something like that:hive.server2.authentication.ldap.bindn=cn=ldapuser,ou=user,dc=examplehive.server2.authentication.ldap.bindnpw=password</description>
      <version>2.1.0,2.1.1,2.2.0,2.3.0,2.3.1,2.3.2</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.test.org.apache.hive.service.auth.TestLdapAuthenticationProviderImpl.java</file>
      <file type="M">service.src.java.org.apache.hive.service.auth.LdapAuthenticationProviderImpl.java</file>
      <file type="M">service.pom.xml</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="21082" opendate="2019-1-3 00:00:00" fixdate="2019-1-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>In HPL/SQL, declare statement does not support variable of type character</summary>
      <description>In the following HPL/SQL programs:DECLARE a character(5); SET a = 'b';when the type of variable 'a' is CHARACTER, it cannot be assigned a value successfully. The support for the character type should be added to DECLARE statement.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hplsql.src.test.java.org.apache.hive.hplsql.TestHplsqlLocal.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.Var.java</file>
      <file type="M">hplsql.src.main.antlr4.org.apache.hive.hplsql.Hplsql.g4</file>
    </fixedFiles>
  </bug>
  <bug id="2142" opendate="2011-5-2 00:00:00" fixdate="2011-5-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Jobs do not get killed even when they created too many files.</summary>
      <description>Click to add description</description>
      <version>None</version>
      <fixedVersion>0.8.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.HadoopJobExecHelper.java</file>
    </fixedFiles>
  </bug>
  <bug id="21621" opendate="2019-4-17 00:00:00" fixdate="2019-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Kafka Clients to recent release 2.2.0</summary>
      <description>all in the title update Kafka Storage Handler to the most recent clients library.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">kafka-handler.src.test.org.apache.hadoop.hive.kafka.KafkaBrokerResource.java</file>
      <file type="M">kafka-handler.src.java.org.apache.hadoop.hive.kafka.HiveKafkaProducer.java</file>
      <file type="M">kafka-handler.pom.xml</file>
      <file type="M">itests.qtest.pom.xml</file>
      <file type="M">itests.qtest-druid.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="21874" opendate="2019-6-14 00:00:00" fixdate="2019-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement add partitions related methods on temporary table</summary>
      <description>IMetaStoreClient exposes the following add partition related methods:Partition add_partition(Partition partition);int add_partitions(List&lt;Partition&gt; partitions);int add_partitions_pspec(PartitionSpecProxy partitionSpec);List&lt;Partition&gt; add_partitions(List&lt;Partition&gt; partitions, boolean ifNotExists, boolean needResults);These methods should be implemented in order to handle addition of partitions to temporary tables.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.metastore-server.src.test.java.org.apache.hadoop.hive.metastore.client.TestAddPartitionsFromPartSpec.java</file>
      <file type="M">standalone-metastore.metastore-server.src.test.java.org.apache.hadoop.hive.metastore.client.TestAddPartitions.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="21875" opendate="2019-6-14 00:00:00" fixdate="2019-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement drop partition related methods on temporary tables</summary>
      <description>IMetaStoreClient exposes the following methods related to dropping partitions:boolean dropPartition(String db_name, String tbl_name, List&lt;String&gt; part_vals, boolean deleteData);boolean dropPartition(String catName, String db_name, String tbl_name, List&lt;String&gt; part_vals, boolean deleteData);boolean dropPartition(String db_name, String tbl_name, List&lt;String&gt; part_vals, PartitionDropOptions options);boolean dropPartition(String catName, String db_name, String tbl_name, List&lt;String&gt; part_vals, PartitionDropOptions options);List&lt;Partition&gt; dropPartitions(String dbName, String tblName, List&lt;ObjectPair&lt;Integer, byte[]&gt;&gt; partExprs, boolean deleteData, boolean ifExists);List&lt;Partition&gt; dropPartitions(String catName, String dbName, String tblName, List&lt;ObjectPair&lt;Integer, byte[]&gt;&gt; partExprs, boolean deleteData, boolean ifExists);List&lt;Partition&gt; dropPartitions(String dbName, String tblName, List&lt;ObjectPair&lt;Integer, byte[]&gt;&gt; partExprs, boolean deleteData, boolean ifExists, boolean needResults);List&lt;Partition&gt; dropPartitions(String catName, String dbName, String tblName, List&lt;ObjectPair&lt;Integer, byte[]&gt;&gt; partExprs, boolean deleteData, boolean ifExists, boolean needResults);List&lt;Partition&gt; dropPartitions(String dbName, String tblName, List&lt;ObjectPair&lt;Integer, byte[]&gt;&gt; partExprs, PartitionDropOptions options);List&lt;Partition&gt; dropPartitions(String catName, String dbName, String tblName, List&lt;ObjectPair&lt;Integer, byte[]&gt;&gt; partExprs, PartitionDropOptions options);boolean dropPartition(String db_name, String tbl_name, String name, boolean deleteData);boolean dropPartition(String catName, String db_name, String tbl_name, String name, boolean deleteData)</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.metastore-server.src.test.java.org.apache.hadoop.hive.metastore.client.TestDropPartitions.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="2191" opendate="2011-6-3 00:00:00" fixdate="2011-6-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow optional [inner] on equi-join.</summary>
      <description>Lot's of databases including mysql support an optional "inner" keyword to explicitely select an equi-join.As shown in the mysql docs: http://dev.mysql.com/doc/refman/5.1/en/join.htmlFor completeness/portability we should allow this.</description>
      <version>None</version>
      <fixedVersion>0.8.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.Hive.g</file>
      <file type="M">docs.xdocs.language.manual.joins.xml</file>
    </fixedFiles>
  </bug>
  <bug id="21911" opendate="2019-6-21 00:00:00" fixdate="2019-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pluggable LlapMetricsListener on Tez side to disable / resize Daemons</summary>
      <description>We need to have a way to plug in different listeners which act upon the LlapDaemon statistics.This listener should be able to disable / resize the LlapDaemons based on health data.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-tez.src.test.org.apache.hadoop.hive.llap.tezplugins.metrics.TestLlapMetricsCollector.java</file>
      <file type="M">llap-tez.src.java.org.apache.hadoop.hive.llap.tezplugins.metrics.LlapMetricsCollector.java</file>
      <file type="M">llap-tez.src.java.org.apache.hadoop.hive.llap.tezplugins.LlapTaskSchedulerService.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="21912" opendate="2019-6-21 00:00:00" fixdate="2019-7-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement BlacklistingLlapMetricsListener</summary>
      <description>We should implement a DaemonStatisticsHandler which: If a node average response time is bigger than 150% (configurable) of the other nodes If the other nodes has enough empty executors to handle the requestsThen disables the limping node.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-tez.src.test.org.apache.hadoop.hive.llap.tezplugins.metrics.TestLlapMetricsCollector.java</file>
      <file type="M">llap-tez.src.java.org.apache.hadoop.hive.llap.tezplugins.metrics.LlapMetricsCollector.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorInfo.java</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.llap.registry.impl.LlapZookeeperRegistryImpl.java</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.llap.registry.impl.LlapRegistryService.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="21979" opendate="2019-7-10 00:00:00" fixdate="2019-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestReplication tests time out regularily</summary>
      <description>I think we should add TestTableLevelReplicationScenarios and friends to be executed in isolationfrom a recent ptest execution:[INFO] Running org.apache.hadoop.hive.ql.TestCreateUdfEntities[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 150.413 s - in org.apache.hadoop.hive.ql.TestCreateUdfEntities[INFO] Running org.apache.hadoop.hive.ql.txn.compactor.TestCleanerWithReplication[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.084 s - in org.apache.hadoop.hive.ql.txn.compactor.TestCleanerWithReplication[INFO] Running org.apache.hadoop.hive.ql.txn.compactor.TestCrudCompactorOnTez[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 61.062 s - in org.apache.hadoop.hive.ql.txn.compactor.TestCrudCompactorOnTez[INFO] Running org.apache.hadoop.hive.ql.TestWarehouseExternalDir[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 57.568 s - in org.apache.hadoop.hive.ql.TestWarehouseExternalDir[INFO] Running org.apache.hadoop.hive.ql.parse.TestReplicationOfHiveStreaming[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 348.769 s - in org.apache.hadoop.hive.ql.parse.TestReplicationOfHiveStreaming[INFO] Running org.apache.hadoop.hive.ql.parse.TestExportImport[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.089 s - in org.apache.hadoop.hive.ql.parse.TestExportImport[INFO] Running org.apache.hadoop.hive.ql.parse.TestTableLevelReplicationScenarios[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,044.666 s - in org.apache.hadoop.hive.ql.parse.TestTableLevelReplicationScenarios[INFO] Running org.apache.hadoop.hive.ql.parse.TestReplicationScenariosExternalTables[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 225.734 s - in org.apache.hadoop.hive.ql.parse.TestReplicationScenariosExternalTables[INFO] Running org.apache.hadoop.hive.ql.parse.TestReplAcrossInstancesWithJsonMessageFormat</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.conf.deployed.master-mr2.properties</file>
    </fixedFiles>
  </bug>
  <bug id="22659" opendate="2019-12-18 00:00:00" fixdate="2019-1-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JClouds needs to be updated to 2.1.3 in ptest</summary>
      <description>Since a couple of days ptest responded 404 to test queries coming in from jenkins side.I took a look into the issue and saw this exception on hiveptest-server-upstream side:Caused by: java.lang.IllegalStateException: zone https://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-central1-d not present in [https://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-east1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-east1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-east1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-east2-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-east2-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-east2-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-northeast1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-northeast1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-northeast1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-northeast2-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-northeast2-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-northeast2-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-south1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-south1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-south1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-southeast1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-southeast1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/asia-southeast1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/australia-southeast1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/australia-southeast1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/australia-southeast1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-north1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-north1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-north1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west1-dhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west2-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west2-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west2-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west3-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west3-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west3-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west4-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west4-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west4-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west6-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west6-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/europe-west6-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/northamerica-northeast1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/northamerica-northeast1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/northamerica-northeast1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/southamerica-east1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/southamerica-east1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/southamerica-east1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-central1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-central1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-central1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-central1-fhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-east1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-east1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-east1-dhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-east4-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-east4-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-east4-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-west1-ahttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-west1-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-west1-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-west2-chttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-west2-bhttps://www.googleapis.com/compute/v1/projects/gcp-hive-upstream/zones/us-west2-a] Debugging into the issue, it seems like that when we we put our cloud context in place for test execution, some default values originating from default templates are matched with actual GCP capabilities - and I guess zone us-central-1d was decommissioned in real-life, hence the exception.I upgraded jclouds version from 2.1.0 to 2.1.3 on server side and retried running Tomcat with this new installation. It seems to have fixed the issue. NO PRECOMMIT TESTS </description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.pom.xml</file>
    </fixedFiles>
  </bug>
</bugrepository>
