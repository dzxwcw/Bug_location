<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HIVE">
  <bug id="10835" opendate="2015-5-27 00:00:00" fixdate="2015-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Concurrency issues in JDBC driver</summary>
      <description>Though JDBC specification specifies that "Each Connection object can create multiple Statement objects that may be used concurrently by the program", but that does not work in current Hive JDBC driver. In addition, there also exist race conditions between DatabaseMetaData, Statement and ResultSet as long as they make RPC calls to HS2 using same Thrift transport, which happens within a connection.So we need a connection level lock to serialize all these RPC calls in a connection.</description>
      <version>0.13.0,0.13.1,0.14.0,0.14.1,0.15.0,1.0.0,1.0.1,1.1.0,1.1.1,1.2.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveStatement.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveQueryResultSet.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveConnection.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniHS2.java</file>
    </fixedFiles>
  </bug>
  <bug id="11605" opendate="2015-8-19 00:00:00" fixdate="2015-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrect results with bucket map join in tez.</summary>
      <description>In some cases, we aggressively try to convert to a bucket map join and this ends up producing incorrect results.</description>
      <version>1.0.0,1.0.1,1.2.0</version>
      <fixedVersion>1.0.2,1.2.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.bucket.map.join.tez1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket.map.join.tez1.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.bucket.map.join.tez1.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ReduceSinkMapJoinProc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.java</file>
    </fixedFiles>
  </bug>
  <bug id="11654" opendate="2015-8-26 00:00:00" fixdate="2015-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>After HIVE-10289, HBase metastore tests failing</summary>
      <description>After the latest merge from trunk a number of the HBase unit tests are failing.</description>
      <version>None</version>
      <fixedVersion>hbase-metastore-branch,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.hbase.TestHBaseStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.hbase.HBaseUtils.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.hbase.HBaseStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.hbase.HBaseReadWrite.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.metastore.hbase.TestHBaseAggrStatsCacheIntegration.java</file>
    </fixedFiles>
  </bug>
  <bug id="11655" opendate="2015-8-26 00:00:00" fixdate="2015-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>clean build on the branch appears to be broken</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">storage-api.src.java.org.apache.hadoop.hive.common.io.DiskRangeList.java</file>
    </fixedFiles>
  </bug>
  <bug id="11664" opendate="2015-8-27 00:00:00" fixdate="2015-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make tez container logs work with new log4j2 changes</summary>
      <description>MiniTezCliDriver should log container logs to syslog file. With new log4j2 changes this file is not created anymore.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">data.conf.tez.hive-site.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11689" opendate="2015-8-29 00:00:00" fixdate="2015-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>minor flow changes to ORC split generation</summary>
      <description>There are two changes that would help future work on split PPD into HBase metastore. 1) Move non-HDFS split strategy determination logic into main thread from threadpool.2) Instead of iterating thru the futures and waiting, use CompletionService to get futures in order of completion. That might be useful by itself.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="11816" opendate="2015-9-14 00:00:00" fixdate="2015-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade groovy to 2.4.4</summary>
      <description>Groovy 2.4.4 is the latest release and the first done under ASF.Also there are some issues with old Groovy like CVE-2015-3253, which doesn't seem to affect Hive itself but might affect applications depending on Hive that get leaked classpath artifacts.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12026" opendate="2015-10-2 00:00:00" fixdate="2015-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add test case to check permissions when truncating partition</summary>
      <description>Add to the tests added during HIVE-9474, for TRUNCATE PARTITION</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.security.FolderPermissionBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="12027" opendate="2015-10-2 00:00:00" fixdate="2015-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>simplify file metadata cache ppd api</summary>
      <description>I made it unwieldy for iterator model when the number of files is too large. Fix it. Not shipped anywhere yet.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GrantRevokeRoleRequest.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TUserDefinedTypeEntry.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TUnionTypeEntry.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TTypeQualifiers.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TTypeDesc.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TTableSchema.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TStructTypeEntry.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TStringValue.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TStringColumn.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TStatus.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TSessionHandle.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TRowSet.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TRow.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TRenewDelegationTokenResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TRenewDelegationTokenReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TPrimitiveTypeEntry.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TOperationHandle.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TOpenSessionResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TOpenSessionReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TMapTypeEntry.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TI64Value.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TI64Column.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TI32Value.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TI32Column.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TI16Value.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TI16Column.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.THandleIdentifier.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetTypeInfoResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetTypeInfoReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetTableTypesResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetTableTypesReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetTablesResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetTablesReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetSchemasResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetSchemasReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetResultSetMetadataResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetResultSetMetadataReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetOperationStatusResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetOperationStatusReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetInfoResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetInfoReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetFunctionsResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetFunctionsReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetDelegationTokenResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetDelegationTokenReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetColumnsResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetColumnsReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetCatalogsResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TGetCatalogsReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TFetchResultsResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TFetchResultsReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TExecuteStatementResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TExecuteStatementReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TDoubleValue.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TDoubleColumn.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TColumnDesc.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TCloseSessionResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TCloseSessionReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TCloseOperationResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TCloseOperationReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TCLIService.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TCancelOperationResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TCancelOperationReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TCancelDelegationTokenResp.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TCancelDelegationTokenReq.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TByteValue.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TByteColumn.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TBoolValue.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TBoolColumn.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TBinaryColumn.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hive.service.cli.thrift.TArrayTypeEntry.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.service.ThriftHive.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.service.HiveServerException.java</file>
      <file type="M">service.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.service.HiveClusterStatus.java</file>
      <file type="M">serde.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.serde.test.ThriftTestObj.java</file>
      <file type="M">serde.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.serde.test.InnerStruct.java</file>
      <file type="M">serde.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.serde2.thrift.test.SetIntString.java</file>
      <file type="M">serde.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.serde2.thrift.test.MiniStruct.java</file>
      <file type="M">serde.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.serde2.thrift.test.MegaStruct.java</file>
      <file type="M">serde.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.serde2.thrift.test.IntString.java</file>
      <file type="M">serde.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.serde2.thrift.test.Complex.java</file>
      <file type="M">ql.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.ql.plan.api.Task.java</file>
      <file type="M">ql.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.ql.plan.api.Stage.java</file>
      <file type="M">ql.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.ql.plan.api.QueryPlan.java</file>
      <file type="M">ql.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.ql.plan.api.Query.java</file>
      <file type="M">ql.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.ql.plan.api.Operator.java</file>
      <file type="M">ql.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.ql.plan.api.Graph.java</file>
      <file type="M">ql.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.ql.plan.api.Adjacency.java</file>
      <file type="M">metastore.src.gen.thrift.gen-rb.hive.metastore.types.rb</file>
      <file type="M">metastore.src.gen.thrift.gen-py.hive.metastore.ttypes.py</file>
      <file type="M">metastore.src.gen.thrift.gen-py.hive.metastore.ThriftHiveMetastore.py</file>
      <file type="M">metastore.src.gen.thrift.gen-php.metastore.Types.php</file>
      <file type="M">metastore.src.gen.thrift.gen-php.metastore.ThriftHiveMetastore.php</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Version.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.UnlockRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.UnknownTableException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.UnknownPartitionException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.UnknownDBException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Type.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.TxnOpenException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.TxnInfo.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.TxnAbortedException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.TableStatsResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.TableStatsRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Table.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.StringColumnStatsData.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.StorageDescriptor.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.SkewedInfo.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ShowLocksResponseElement.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ShowLocksResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ShowLocksRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ShowCompactResponseElement.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ShowCompactResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ShowCompactRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.SetPartitionsStatsRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.SerDeInfo.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Schema.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.RolePrincipalGrant.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Role.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ResourceUri.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PutFileMetadataResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PutFileMetadataRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PrivilegeGrantInfo.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PrivilegeBag.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PrincipalPrivilegeSet.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PartitionWithoutSD.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PartitionsStatsResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PartitionsStatsRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PartitionSpecWithSharedSD.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PartitionSpec.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PartitionsByExprResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PartitionsByExprRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PartitionListComposingSpec.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Partition.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Order.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.OpenTxnsResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.OpenTxnRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.NotificationEventResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.NotificationEventRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.NotificationEvent.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.NoSuchTxnException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.NoSuchObjectException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.NoSuchLockException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.MetaException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.MetadataPpdResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.LongColumnStatsData.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.LockResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.LockRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.LockComponent.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.InvalidPartitionException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.InvalidOperationException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.InvalidObjectException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.InvalidInputException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.InsertEventRequestData.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.IndexAlreadyExistsException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Index.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.HiveObjectRef.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.HiveObjectPrivilege.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.HeartbeatTxnRangeResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.HeartbeatTxnRangeRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.HeartbeatRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GrantRevokeRoleResponse.java</file>
      <file type="M">metastore.if.hive.metastore.thrift</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.hive.metastore.types.cpp</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.hive.metastore.types.h</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.ThriftHiveMetastore.cpp</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.ThriftHiveMetastore.h</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.AbortTxnRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.AddDynamicPartitions.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.AddPartitionsRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.AddPartitionsResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.AggrStats.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.AlreadyExistsException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.BinaryColumnStatsData.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.BooleanColumnStatsData.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.CheckLockRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ClearFileMetadataRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ClearFileMetadataResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ColumnStatistics.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ColumnStatisticsDesc.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ColumnStatisticsObj.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.CommitTxnRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.CompactionRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ConfigValSecurityException.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.CurrentNotificationEventId.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Database.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Date.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.DateColumnStatsData.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Decimal.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.DecimalColumnStatsData.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.DoubleColumnStatsData.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.DropPartitionsExpr.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.DropPartitionsRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.DropPartitionsResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.EnvironmentContext.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.FieldSchema.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.FireEventRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.FireEventResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Function.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetAllFunctionsResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetFileMetadataByExprRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetFileMetadataByExprResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetFileMetadataRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetFileMetadataResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetOpenTxnsInfoResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetOpenTxnsResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetPrincipalsInRoleRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetPrincipalsInRoleResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetRoleGrantsForPrincipalRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetRoleGrantsForPrincipalResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GrantRevokePrivilegeRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GrantRevokePrivilegeResponse.java</file>
    </fixedFiles>
  </bug>
  <bug id="12201" opendate="2015-10-16 00:00:00" fixdate="2015-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tez settings need to be shown in set -v output when execution engine is tez.</summary>
      <description>The set -v output currently shows configurations for yarn, hdfs etc. but does not show tez settings when tez is set as the execution engine.</description>
      <version>1.0.1,1.2.1</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.SetProcessor.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="12204" opendate="2015-10-16 00:00:00" fixdate="2015-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tez queries stopped running with ApplicationNotRunningException</summary>
      <description>In some error cases, if hive can no longer submit DAGs to tez, there is no use retrying to submit. We need to exit by throwing exception in this case.</description>
      <version>1.0.1,1.2.1,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.tez.TestTezSessionPool.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="12315" opendate="2015-11-2 00:00:00" fixdate="2015-11-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>vectorization_short_regress.q has a wrong result issue for a double calculation</summary>
      <description>I suspect it is related to the fancy optimizations in vectorized double divide that try to quickly process the batch without checking each row for null. public static void setNullAndDivBy0DataEntriesDouble( DoubleColumnVector v, boolean selectedInUse, int[] sel, int n, DoubleColumnVector denoms) { assert v.isRepeating || !denoms.isRepeating; v.noNulls = false; double[] vector = denoms.vector; if (v.isRepeating &amp;&amp; (v.isNull[0] = (v.isNull[0] || vector[0] == 0))) { v.vector[0] = DoubleColumnVector.NULL_VALUE;</description>
      <version>0.14.0,1.0.1,1.1.1,1.2.1,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.NullUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="12345" opendate="2015-11-5 00:00:00" fixdate="2015-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Followup for HIVE-9013 : Hidden conf vars still visible through beeline</summary>
      <description>HIVE-9013 introduced the ability to hide certain conf variables when output through the "set" command. However, there still exists one further bug in it that causes these variables to still be visible through beeline connecting to HS2, wherein HS2 exposes hidden variables such as the HS2's metastore password when "set" is run.</description>
      <version>None</version>
      <fixedVersion>1.2.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcDriver2.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="12485" opendate="2015-11-20 00:00:00" fixdate="2015-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Secure HS2 web UI with kerberos</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.server.HiveServer2.java</file>
      <file type="M">common.src.java.org.apache.hive.http.HttpServer.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="12537" opendate="2015-11-28 00:00:00" fixdate="2015-12-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RLEv2 doesn&amp;#39;t seem to work</summary>
      <description>Perhaps I'm doing something wrong or is actually working as expected.Putting 1 million constant int32 values produces an ORC file of 1MB. Surprisingly, 1 million consecutive ints produces a much smaller file.Code and FileDump attached.ObjectInspector inspector = ObjectInspectorFactory.getReflectionObjectInspector( Integer.class, ObjectInspectorFactory.ObjectInspectorOptions.JAVA);Writer w = OrcFile.createWriter(new Path("/tmp/my.orc"), OrcFile.writerOptions(new Configuration()) .compress(CompressionKind.NONE) .inspector(inspector) .encodingStrategy(OrcFile.EncodingStrategy.COMPRESSION) .version(OrcFile.Version.V_0_12) );for (int i = 0; i &lt; 1000000; ++i) { w.addRow(123);}w.close();</description>
      <version>0.14.0,1.0.1,1.1.1,1.2.1,1.3.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.outer.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.llap.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.file.dump.q.out</file>
      <file type="M">ql.src.test.resources.orc-file-has-null.out</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestVectorOrcFile.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.java.orig</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcFile.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RunLengthIntegerWriterV2.java</file>
    </fixedFiles>
  </bug>
  <bug id="12591" opendate="2015-12-4 00:00:00" fixdate="2015-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP cache counters displays -ve value for CacheCapacityUsed</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.cache.TestLowLevelLrfuCachePolicy.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.metrics.LlapDaemonCacheMetrics.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LowLevelCacheMemoryManager.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.BuddyAllocator.java</file>
    </fixedFiles>
  </bug>
  <bug id="12738" opendate="2015-12-23 00:00:00" fixdate="2015-12-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>subquery with NOT IN failing due to ClassCastException</summary>
      <description>create table student( name string, age int, gpa double)create table voter( name string, age int, registration string, contributions float)select * from student where not student.age in(select age from voter) order by age;Fails in Tez &amp;#8211; Vectorized Reduce.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="12905" opendate="2016-1-21 00:00:00" fixdate="2016-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Issue with mapjoin in tez under certain conditions</summary>
      <description>In a specific case where we have an outer join followed by another join on the same key and the non-outer side of the outer join is empty, hive-on-tez produces incorrect results.</description>
      <version>1.0.1,1.2.1,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.mapjoin.fast.VectorMapJoinFastTableContainer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.mapjoin.fast.VectorMapJoinFastHashTableLoader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.HashTableLoader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HashTableLoader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainerSerDe.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.MapJoinKey.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.MapJoinBytesTableContainer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.HybridHashTableContainer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.HashMapWrapper.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="13138" opendate="2016-2-24 00:00:00" fixdate="2016-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add client to communicate with interface, initial split setup</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFGetSplits.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.llap.LlapInputSplit.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.llap.LlapInputFormat.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon.java</file>
      <file type="M">llap-common.src.protobuf.LlapDaemonProtocol.proto</file>
      <file type="M">llap-common.src.gen.protobuf.gen-java.org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.LlapInputFormat.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="13140" opendate="2016-2-24 00:00:00" fixdate="2016-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Wire the client to submit execution fragments</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.tez.dag.api.TaskSpecBuilder.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFGetSplits.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.llap.SubmitWorkInfo.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.llap.LlapInputSplit.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.ext.LlapTaskUmbilicalExternalClient.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.LlapInputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="13461" opendate="2016-4-8 00:00:00" fixdate="2016-4-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP output format service not actually registered in LLAP registry</summary>
      <description>Should have been done in HIVE-13305, but missed this part.</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.llap.LlapRecordReader.java</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.llap.registry.impl.LlapZookeeperRegistryImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="9684" opendate="2015-2-13 00:00:00" fixdate="2015-2-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrect disk range computation in ORC because of optional stream kind</summary>
      <description>HIVE-9593 changed all required fields in ORC protobuf message to optional field. But DiskRange computation and stream creation code assumes existence of stream kind everywhere. This leads to incorrect calculation of diskranges resulting in out of range exceptions. The proper fix is to check if stream kind exists using stream.hasKind() before adding the stream to disk range computation.</description>
      <version>1.0.0,1.0.1,1.1.0</version>
      <fixedVersion>1.0.0,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.FileDump.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
