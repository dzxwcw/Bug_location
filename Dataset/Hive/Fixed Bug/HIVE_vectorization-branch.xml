<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HIVE">
  <bug id="4370" opendate="2013-4-17 00:00:00" fixdate="2013-4-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change ORC tree readers to return batches of rows instead of a row</summary>
      <description>Change ORC Record reader and Tree readers to return a set of Rows instead of a row.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RunLengthIntegerReader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.DynamicByteArray.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector.java</file>
    </fixedFiles>
  </bug>
  <bug id="4381" opendate="2013-4-18 00:00:00" fixdate="2013-4-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement vectorized aggregation expressions</summary>
      <description>Vectorized implementation for sum, min, max, average and count.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.CodeGen.java</file>
    </fixedFiles>
  </bug>
  <bug id="4383" opendate="2013-4-19 00:00:00" fixdate="2013-4-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement vectorized string column-scalar filters</summary>
      <description>Create patch for implementing string columns compared with scalars as vectorized filters, and apply it to vectorization branch.</description>
      <version>None</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorStringExpressions.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.CodeGen.java</file>
    </fixedFiles>
  </bug>
  <bug id="4385" opendate="2013-4-19 00:00:00" fixdate="2013-4-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement vectorized LIKE filter</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorStringExpressions.java</file>
    </fixedFiles>
  </bug>
  <bug id="4451" opendate="2013-4-30 00:00:00" fixdate="2013-6-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add support for string column type vector aggregates: COUNT, MIN and MAX</summary>
      <description>Extend the vector aggregates operations to support string types.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorGroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFCount.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.CodeGen.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFCountLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFCountDouble.java</file>
    </fixedFiles>
  </bug>
  <bug id="4452" opendate="2013-4-30 00:00:00" fixdate="2013-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add support for COUNT(*) in vector aggregates</summary>
      <description>COUNT must count NULL values</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorGroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="4453" opendate="2013-4-30 00:00:00" fixdate="2013-4-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Input format to read vector data from ORC</summary>
      <description>We need an input format to read vector data from ORC.</description>
      <version>None</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcSerde.java</file>
    </fixedFiles>
  </bug>
  <bug id="4509" opendate="2013-5-6 00:00:00" fixdate="2013-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Integer division should be cast to double.</summary>
      <description>In current hive, the division always returns a double. Also, division by zero returns infinity following java semantics.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorFilterOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.LongColumnVector.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.CodeGen.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongScalarDivideLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColDivideLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColDivideLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExecDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="451" opendate="2009-4-28 00:00:00" fixdate="2009-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support ORDER BY xxx DESC</summary>
      <description>We support SORT BY xxx DESC, but not ORDER BY xxx DESC. We should support it.</description>
      <version>None</version>
      <fixedVersion>0.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.udf.case.column.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.regex.col.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.udf.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.order2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.order.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input22.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.order.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.Hive.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="4512" opendate="2013-5-6 00:00:00" fixdate="2013-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The vectorized plan is not picking right expression class for string concatenation.</summary>
      <description>The vectorized plan is not picking right expression class for string concatenation.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringConcatScalarCol.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringConcatColScalar.java</file>
    </fixedFiles>
  </bug>
  <bug id="4514" opendate="2013-5-6 00:00:00" fixdate="2013-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handle constants in projection</summary>
      <description>Support for constants in the projections is required.</description>
      <version>None</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.VectorizedOrcSerde.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.VectorizedOrcInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.CommonOrcInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="4539" opendate="2013-5-10 00:00:00" fixdate="2013-5-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Move test utils and fix build to remove false test failures</summary>
      <description>The ant test target tries to run all classes in the test hierarchy, and fails if a type is found that is not a test. we need to consolidate the vectorization test utilities, and exclude them from execution.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorSelectOperator.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorizedRowGroupGenUtil.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorFilterExpressions.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorArithmeticExpressions.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestUnaryMinus.java</file>
      <file type="M">build-common.xml</file>
    </fixedFiles>
  </bug>
  <bug id="4541" opendate="2013-5-10 00:00:00" fixdate="2013-8-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Run check-style on the branch and fix style issues.</summary>
      <description>We should run check style on the entire branch and fix issues before the branch is merged back to the trunk.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColSubtractLongScalar.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.util.VectorizedRowGroupGenUtil.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.util.FakeVectorRowBatchFromObjectIterables.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorSelectOperator.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorizedRowBatchCtx.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorizationContext.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorGroupByOperator.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorFilterOperator.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorTimestampExpressions.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorScalarColArithmetic.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorLogicalExpressions.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorFilterExpressions.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorExpressionWriters.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorArithmeticExpressions.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestUnaryMinus.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestConstantVectorExpression.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.IUDFUnaryString.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizedSerde.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatchCtx.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorHashKeyWrapperBatch.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFYearLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFWeekOfYearLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFUnixTimeStampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFTimestampFieldLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFSecondLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFMonthLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFMinuteLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFHourLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFDayOfMonthLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFVar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFSum.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMaxString.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMax.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFAvg.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.ScalarArithmeticColumn.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.FilterScalarCompareColumn.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.FilterColumnCompareScalar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.FilterColumnCompareColumn.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.ColumnUnaryMinus.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.ColumnCompareScalar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.ColumnArithmeticScalar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.ColumnArithmeticColumn.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.CodeGen.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringUpper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringUnaryUDF.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringSubstrColStartLen.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringSubstrColStart.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringLower.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringLength.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringExpr.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.LongScalarDivideLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.LongColDivideLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.LongColDivideLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.IsNull.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.IsNotNull.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.IdentityExpression.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongScalarSubtractLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongScalarSubtractDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongScalarMultiplyLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongScalarMultiplyDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongScalarModuloLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongScalarModuloDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongScalarDivideDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongScalarAddLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongScalarAddDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColUnaryMinus.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColSubtractLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColSubtractLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColSubtractDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColSubtractDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColNotEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColMultiplyLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColMultiplyLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColMultiplyDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColMultiplyDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColModuloLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColModuloLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColModuloDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColModuloDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColLessEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColLessDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColGreaterEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColGreaterDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColDivideDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColDivideDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColAddLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColAddLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColAddDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.LongColAddDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongScalarNotEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongScalarNotEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongScalarLessLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongScalarLessEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongScalarLessEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongScalarLessDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongScalarGreaterLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongScalarGreaterEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongScalarGreaterEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongScalarGreaterDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongScalarEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongScalarEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColNotEqualLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColNotEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColNotEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColNotEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColLessLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColLessLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColLessEqualLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColLessEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColLessEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColLessEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColLessDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColLessDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColGreaterLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColGreaterLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColGreaterEqualLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColGreaterEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColGreaterEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColGreaterEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColGreaterDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColGreaterDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColEqualLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterLongColEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleScalarNotEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleScalarNotEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleScalarLessLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleScalarLessEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleScalarLessEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleScalarLessDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleScalarGreaterLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleScalarGreaterEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleScalarGreaterEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleScalarGreaterDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleScalarEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleScalarEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColNotEqualLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColNotEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColNotEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColNotEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColLessLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColLessLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColLessEqualLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColLessEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColLessEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColLessEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColLessDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColLessDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColGreaterLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColGreaterLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColGreaterEqualLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColGreaterEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColGreaterEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColGreaterEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColGreaterDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColGreaterDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColEqualLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColEqualLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.FilterDoubleColEqualDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleScalarSubtractLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleScalarSubtractDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleScalarMultiplyLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleScalarMultiplyDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleScalarModuloLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleScalarModuloDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleScalarDivideLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleScalarDivideDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleScalarAddLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleScalarAddDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColUnaryMinus.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.ColumnExpression.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxString.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinString.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorAggregateExpression.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorUDAFCount.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorUDAFCountStar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.ColAndCol.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.ColOrCol.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.ConstantVectorExpression.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColAddDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColAddDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColAddLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColAddLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColDivideDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColDivideDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColDivideLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColDivideLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColGreaterDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColGreaterEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColLessDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColLessEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColModuloDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColModuloDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColModuloLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColModuloLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColMultiplyDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColMultiplyDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColMultiplyLongColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColMultiplyLongScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColNotEqualDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColSubtractDoubleColumn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColSubtractDoubleScalar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColSubtractLongColumn.java</file>
    </fixedFiles>
  </bug>
  <bug id="4596" opendate="2013-5-23 00:00:00" fixdate="2013-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix serialization exceptions in VectorGroupByOperator</summary>
      <description>Going down the vectorization pathjava.lang.InstantiationException: org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspectorContinuing ...java.lang.RuntimeException: failed to evaluate: &lt;unbound&gt;=Class.new();Continuing ...java.lang.InstantiationException: org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperatorContinuing ...java.lang.Exception: XMLEncoder: discarding statement ArrayList.add(VectorGroupByOperator);Continuing ...</description>
      <version>vectorization-branch</version>
      <fixedVersion>0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.util.FakeVectorRowBatchFromIterables.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorGroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.VectorHashKeyWrapperBatch.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.VectorHashKeyWrapper.java</file>
    </fixedFiles>
  </bug>
  <bug id="4602" opendate="2013-5-23 00:00:00" fixdate="2013-5-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable running all hive e2e tests under vectorization</summary>
      <description></description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.QTestUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="4606" opendate="2013-5-24 00:00:00" fixdate="2013-6-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement vector group by hash spill</summary>
      <description>the row mode GBy operator is capable of spilling the hash map (by emitting it into the M/R and deleting the keys emitted) to conform to emmory constraints. The VGBy should be able to do the same.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorGroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.util.JavaDataModel.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorHashKeyWrapperBatch.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorHashKeyWrapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorAggregationBufferBatch.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFVar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFSum.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMaxString.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMax.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFCount.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFAvg.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorUDAFCountStar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorUDAFCount.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorAggregateExpression.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinString.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxString.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgDouble.java</file>
    </fixedFiles>
  </bug>
  <bug id="4612" opendate="2013-5-25 00:00:00" fixdate="2013-6-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorized aggregates do not emit proper rows in presence of GROUP BY</summary>
      <description>I discovered this while testing the fix for HIVE-4451 and HIVE-4452. The VGBy is emitting appropriate number of rows, but the row-mode ReduceSinkOperatoir only logs one row and the final result is incomplete. Investigating. Related to HIVE-4599.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorGroupByOperator.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.FakeVectorRowBatchFromObjectIterables.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorReduceSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizedColumnarSerDe.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizedBatchUtil.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFVar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFAvg.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.VectorHashKeyWrapperBatch.java</file>
    </fixedFiles>
  </bug>
  <bug id="4615" opendate="2013-5-27 00:00:00" fixdate="2013-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Invalid column names allowed when created dynamically by a SerDe</summary>
      <description>When a SerDe creates columns dynamically during table creation, there is no checking done on the validity of the created column names. This means that it's possible to create a table that contains columns that can't be queried, and will lead to issues when trying to query the created table.The same column name validation should be performed for dynamically-created columns as for other column names.This behavior can be easily tested using the TestSerDe, and including a column name that includes an invalid identifier character (e.g. a period) in the list of columns to create.</description>
      <version>None</version>
      <fixedVersion>0.12.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Table.java</file>
    </fixedFiles>
  </bug>
  <bug id="4616" opendate="2013-5-27 00:00:00" fixdate="2013-1-27 01:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Simple reconnection support for jdbc2</summary>
      <description>jdbc:hive2://localhost:10000/db2;autoReconnect=truesimple reconnection on TransportException. If hiveserver2 has not been shutdown, session could be reused.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.UDTFCollector.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.UDTFDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.HiveParser.g</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.FromClauseParser.g</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.UDTFOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="4624" opendate="2013-5-29 00:00:00" fixdate="2013-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Integrate Vectorized Substr into Vectorized QE</summary>
      <description>Need to hook up the Vectorized Substr directly into Hive Vectorized QE so it can be leveraged.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorStringExpressions.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringSubstrColStartLen.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringSubstrColStart.java</file>
    </fixedFiles>
  </bug>
  <bug id="4655" opendate="2013-6-4 00:00:00" fixdate="2013-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorization not working with negative constants, hive doesn&amp;#39;t fold constants.</summary>
      <description>Hive optimizer doesn't fold the constants, however vectorized code path assumes that constants have been folded. This should be fixed in hive optimizer. In this jira we just fix vectorization path to handle folding for negative constants. This is needed because hive plan treats negative constants as unary-minus expression on constants, therefore these expressions also need constant folding.This fix will become redundant once constant folding is appropriately implemented in hive optimizer. (HIVE-746)</description>
      <version>None</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.VectorizedRCFileRecordReader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorSelectOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="4665" opendate="2013-6-5 00:00:00" fixdate="2013-6-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>error at VectorExecMapper.close in group-by-agg query over ORC, vectorized</summary>
      <description>CREATE EXTERNAL TABLE FactSqlEngineAM4712( dAppVersionBuild int, dAppVersionBuildUNMAPPED32449 int, dAppVersionMajor int, dAppVersionMinor32447 int, dAverageCols23083 int, dDatabaseSize23090 int, dDate string, dIsInternalMSFT16431 int, dLockEscalationDisabled23323 int, dLockEscalationEnabled23324 int, dMachineID int, dNumberTables23008 int, dNumCompressionPagePartitions23088 int, dNumCompressionRowPartitions23089 int, dNumIndexFragmentation23084 int, dNumPartitionedTables23098 int, dNumPartitions23099 int, dNumTablesClusterIndex23010 int, dNumTablesHeap23100 int, dSessionType5618 int, dSqlEdition8213 int, dTempDbSize23103 int, mNumColumnStoreIndexesVar48171 bigint, mOccurrences int, mRowFlag int) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' LOCATION '/user/ehans/SQM'; create table FactSqlEngineAM_vec_ORC ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.orc.OrcSerde' stored as INPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.CommonOrcInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat' AS select * from FactSqlEngineAM4712;hive&gt; select ddate, max(dnumbertables23008) from factsqlengineam_vec_orc group by ddate;Total MapReduce jobs = 1Launching Job 1 out of 1Number of reduce tasks not specified. Estimated from input data size: 3In order to change the average load for a reducer (in bytes): set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;In order to limit the maximum number of reducers: set hive.exec.reducers.max=&lt;number&gt;In order to set a constant number of reducers: set mapred.reduce.tasks=&lt;number&gt;Validating if vectorized execution is applicableGoing down the vectorization pathjava.lang.InstantiationException: org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspectorContinuing ...java.lang.RuntimeException: failed to evaluate: &lt;unbound&gt;=Class.new();Continuing ...java.lang.InstantiationException: org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperatorContinuing ...java.lang.Exception: XMLEncoder: discarding statement ArrayList.add(VectorGroupByOperator);Continuing ...Starting Job = job_201306041757_0016, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201306041757_0016Kill Command = c:\Hadoop\hadoop-1.1.0-SNAPSHOT\bin\hadoop.cmd job -kill job_201306041757_0016Hadoop job information for Stage-1: number of mappers: 8; number of reducers: 32013-06-05 10:03:06,022 Stage-1 map = 0%, reduce = 0%2013-06-05 10:03:51,142 Stage-1 map = 100%, reduce = 100%Ended Job = job_201306041757_0016 with errorsError during job, obtaining debugging information...Job Tracking URL: http://localhost:50030/jobdetails.jsp?jobid=job_201306041757_0016Examining task ID: task_201306041757_0016_m_000009 (and more) from job job_201306041757_0016Task with the most failures(4):Task ID: task_201306041757_0016_m_000000URL: http://localhost:50030/taskdetails.jsp?jobid=job_201306041757_0016&amp;tipid=task_201306041757_0016_m_000000Diagnostic Messages for this Task:java.lang.RuntimeException: Hive Runtime Error while closing operators at org.apache.hadoop.hive.ql.exec.vector.VectorExecMapper.close(VectorExecMapper.java:229) at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:57) at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372) at org.apache.hadoop.mapred.Child$4.run(Child.java:271) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135) at org.apache.hadoop.mapred.Child.main(Child.java:265)Caused by: java.lang.ClassCastException: org.apache.hadoop.io.BytesWritable cannot be cast to org.apache.hadoop.io.Text at org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableStringObjectInspector.getPrimitiveWritableObject(WritableStringObjectInspector.java:40) at org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.hashCode(ObjectInspectorUtils.java:481) at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.processOp(ReduceSinkOperator.java:235) at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:502) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:832) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.closeOp(VectorGroupByOperator.java:253) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:588) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.vector.VectorExecMapper.close(VectorExecMapper.java:196) ... 8 moreFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTaskMapReduce Jobs Launched:Job 0: Map: 8 Reduce: 3 HDFS Read: 0 HDFS Write: 0 FAILTotal MapReduce CPU Time Spent: 0 msechive&gt;</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpressionWriterFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFVar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFSum.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMaxString.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMax.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFAvg.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinString.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxString.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgDouble.java</file>
    </fixedFiles>
  </bug>
  <bug id="4667" opendate="2013-6-5 00:00:00" fixdate="2013-6-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>tpch query 1 fails with java.lang.ClassCastException</summary>
      <description>Caused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.LongColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector at org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColSubtractLongScalar.evaluate(DoubleColSubtractLongScalar.java:46) at org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression.evaluateChildren(VectorExpression.java:69) at org.apache.hadoop.hive.ql.exec.vector.expressions.gen.DoubleColMultiplyDoubleColumn.evaluate(DoubleColMultiplyDoubleColumn.java:41) at org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumDouble.aggregateInputSelection(VectorUDAFSumDouble.java:98) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.processAggregators(VectorGroupByOperator.java:174) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.processOp(VectorGroupByOperator.java:151) at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:502) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:832) at org.apache.hadoop.hive.ql.exec.vector.VectorSelectOperator.processOp(VectorSelectOperator.java:104) at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:502) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:832) at org.apache.hadoop.hive.ql.exec.vector.VectorFilterOperator.processOp(VectorFilterOperator.java:91) at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:502) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:832) at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:90) at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:502) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:832) at org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.process(VectorMapOperator.java:717) ... 9 more</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.FilterExprOrExpr.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.FilterExprAndExpr.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExecDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="4681" opendate="2013-6-7 00:00:00" fixdate="2013-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix ORC TimestampTreeReader.nextVector() to handle milli-nano math corectly</summary>
      <description>The current TimestampTreeReader implementation is broken when fed only milliseconds.If TS = 222ms. result.vector[i] = ... // == 0; nanoVector.vector[i] = ... // == 222000000 if (result.vector[i] &gt;= 0) { result.vector[i] += nanoVector.vector[i] / 1000000; // 222 }... result.vector[i] = (result.vector[i] * 1000000) + nanoVector.vector[i]; // result.vector[i] == 444000000which is broken.This is not a problem in the Timestamp case, because ts.setTime(222); // {time=0; nanos=222000000}ts.setNanos(222000000); // {time=0; nanos=222000000}Since that is not additive, the error does not occur in the regular ORC reader.</description>
      <version>None</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="4685" opendate="2013-6-7 00:00:00" fixdate="2013-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>query using LIKE does not vectorize</summary>
      <description>The query select count(ddate) from factsqlengineam_vec_orc where ddate like "2013%";Starts up but does not run in vectorization mode. Then during non-vectorized execution it crashes.Expected result:Query runs vectorized and runs successfully.Actual result:hive&gt; select count(ddate) from factsqlengineam_vec_orc where ddate like "2013%";Total MapReduce jobs = 1Launching Job 1 out of 1Number of reduce tasks determined at compile time: 1In order to change the average load for a reducer (in bytes): set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;In order to limit the maximum number of reducers: set hive.exec.reducers.max=&lt;number&gt;In order to set a constant number of reducers: set mapred.reduce.tasks=&lt;number&gt;Validating if vectorized execution is applicableCannot vectorize the plan: org.apache.hadoop.hive.ql.metadata.HiveException: Udf: GenericUDFBridge, is not supportedjava.lang.InstantiationException: org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperatorContinuing ...java.lang.Exception: XMLEncoder: discarding statement ArrayList.add(VectorGroupByOperator);Continuing ...Starting Job = job_201306061504_0041, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201306061504_0041Kill Command = c:\Hadoop\hadoop-1.1.0-SNAPSHOT\bin\hadoop.cmd job -kill job_201306061504_0041Hadoop job information for Stage-1: number of mappers: 8; number of reducers: 12013-06-07 10:41:31,544 Stage-1 map = 0%, reduce = 0%2013-06-07 10:42:01,677 Stage-1 map = 100%, reduce = 100%Ended Job = job_201306061504_0041 with errorsError during job, obtaining debugging information...Job Tracking URL: http://localhost:50030/jobdetails.jsp?jobid=job_201306061504_0041Examining task ID: task_201306061504_0041_m_000009 (and more) from job job_201306061504_0041Examining task ID: task_201306061504_0041_m_000002 (and more) from job job_201306061504_0041Examining task ID: task_201306061504_0041_m_000000 (and more) from job job_201306061504_0041Examining task ID: task_201306061504_0041_m_000004 (and more) from job job_201306061504_0041Task with the most failures(4):Task ID: task_201306061504_0041_m_000006URL: http://localhost:50030/taskdetails.jsp?jobid=job_201306061504_0041&amp;tipid=task_201306061504_0041_m_000006Diagnostic Messages for this Task:java.lang.RuntimeException: Error in configuring object at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117) at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:432) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372) at org.apache.hadoop.mapred.Child$4.run(Child.java:271) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135) at org.apache.hadoop.mapred.Child.main(Child.java:265)Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88) ... 9 moreCaused by: java.lang.RuntimeException: Error in configuring object at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117) at org.apache.hadoop.mapred.MapRunner.configure(MapRunner.java:34) ... 14 moreCaused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88) ... 17 moreCaused by: java.lang.RuntimeException: Map operator initialization failed at org.apache.hadoop.hive.ql.exec.ExecMapper.configure(ExecMapper.java:121) ... 22 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive internal error: cannot find parent in the child operator! at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:360) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:451) at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:407) at org.apache.hadoop.hive.ql.exec.SelectOperator.initializeOp(SelectOperator.java:66) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:375) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:451) at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:407) at org.apache.hadoop.hive.ql.exec.FilterOperator.initializeOp(FilterOperator.java:82) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:375) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:451) at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:407) at org.apache.hadoop.hive.ql.exec.TableScanOperator.initializeOp(TableScanOperator.java:187) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:375) at org.apache.hadoop.hive.ql.exec.MapOperator.initializeOp(MapOperator.java:543) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:375) at org.apache.hadoop.hive.ql.exec.ExecMapper.configure(ExecMapper.java:100) ... 22 moreFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTaskMapReduce Jobs Launched:Job 0: Map: 8 Reduce: 1 HDFS Read: 0 HDFS Write: 0 FAILTotal MapReduce CPU Time Spent: 0 msechive&gt;</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="4686" opendate="2013-6-7 00:00:00" fixdate="2013-6-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Max on float returning wrong results</summary>
      <description>Text and Orc returning: 1.4499999 Vectorized Orc Returning: 0.1drop table LINEITEM_ORC;create external table LINEITEM_ORC(L_DISCOUNT float ) ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.orc.OrcSerde' STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.CommonOrcInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat';SELECT max(l_discount)FROM LINEITEM_ORC</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorGroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFVar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFSum.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMaxString.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMax.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFAvg.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorUDAFCountStar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorUDAFCount.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorAggregateExpression.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinString.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxString.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgDouble.java</file>
    </fixedFiles>
  </bug>
  <bug id="4688" opendate="2013-6-8 00:00:00" fixdate="2013-6-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE in writing null values.</summary>
      <description>VectorExpressionWriter throws NPE when writing null values.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpressionWriterFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="4699" opendate="2013-6-10 00:00:00" fixdate="2013-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Integrate basic UDFs for Timesamp</summary>
      <description>Integrated the timestamp UDFs from HIVE-4608, to be able to use the following TO_UNIX_TIMESTAMP(ts), year(ts),month(ts),weekofyear(ts),dayofmonth(ts),hour(ts),minute(ts),second(ts)in queries.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFYearLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFWeekOfYearLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFUnixTimeStampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFSecondLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFMonthLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFMinuteLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFHourLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorUDFDayOfMonthLong.java</file>
    </fixedFiles>
  </bug>
  <bug id="4745" opendate="2013-6-17 00:00:00" fixdate="2013-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>java.lang.RuntimeException: Hive Runtime Error while closing operators: java.lang.ClassCastException: org.apache.hadoop.io.NullWritable cannot be cast to org.apache.hadoop.hive.serde2.io.DoubleWritable</summary>
      <description>SELECT SUM(L_QUANTITY), (SUM(L_QUANTITY) + -1.30000000000000000000E+000), (-2.20000000000000020000E+000 % (SUM(L_QUANTITY) + -1.30000000000000000000E+000)), MIN(L_EXTENDEDPRICE)FROM lineitem_orcWHERE ((L_EXTENDEDPRICE &lt;= L_LINENUMBER) OR (L_TAX &gt; L_EXTENDEDPRICE));executed over tpch line item with scale factor 1gb13/06/15 11:19:17 WARN conf.HiveConf: DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.Logging initialized using configuration in file:/C:/Hadoop/hive-0.9.0/conf/hive-log4j.propertiesHive history file=c:\hadoop\hive-0.9.0\logs\history/hive_job_log_jenkinsuser_5292@SLAVE23-WIN_201306151119_1652846565.txtTotal MapReduce jobs = 1Launching Job 1 out of 1Number of reduce tasks determined at compile time: 1In order to change the average load for a reducer (in bytes): set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;In order to limit the maximum number of reducers: set hive.exec.reducers.max=&lt;number&gt;In order to set a constant number of reducers: set mapred.reduce.tasks=&lt;number&gt;Starting Job = job_201306142329_0098, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201306142329_0098Kill Command = c:\Hadoop\hadoop-1.1.0-SNAPSHOT\bin\hadoop.cmd job -kill job_201306142329_0098Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 12013-06-15 11:19:47,490 Stage-1 map = 0%, reduce = 0%2013-06-15 11:20:29,801 Stage-1 map = 76%, reduce = 0%2013-06-15 11:20:32,849 Stage-1 map = 0%, reduce = 0%2013-06-15 11:20:35,880 Stage-1 map = 100%, reduce = 100%Ended Job = job_201306142329_0098 with errorsError during job, obtaining debugging information...Job Tracking URL: http://localhost:50030/jobdetails.jsp?jobid=job_201306142329_0098Examining task ID: task_201306142329_0098_m_000002 (and more) from job job_201306142329_0098Task with the most failures(4): -----Task ID: task_201306142329_0098_m_000000URL: http://localhost:50030/taskdetails.jsp?jobid=job_201306142329_0098&amp;tipid=task_201306142329_0098_m_000000-----Diagnostic Messages for this Task:java.lang.RuntimeException: Hive Runtime Error while closing operators at org.apache.hadoop.hive.ql.exec.vector.VectorExecMapper.close(VectorExecMapper.java:229) at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:57) at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372) at org.apache.hadoop.mapred.Child$4.run(Child.java:271) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135) at org.apache.hadoop.mapred.Child.main(Child.java:265)Caused by: java.lang.ClassCastException: org.apache.hadoop.io.NullWritable cannot be cast to org.apache.hadoop.hive.serde2.io.DoubleWritable at org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableDoubleObjectInspector.get(WritableDoubleObjectInspector.java:35) at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serialize(LazyBinarySerDe.java:340) at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serializeStruct(LazyBinarySerDe.java:257) at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serialize(LazyBinarySerDe.java:204) at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.processOp(ReduceSinkOperator.java:245) at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:502) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:832) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.flush(VectorGroupByOperator.java:281) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.closeOp(VectorGroupByOperator.java:423) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:588) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.vector.VectorExecMapper.close(VectorExecMapper.java:196) ... 8 moreFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTaskMapReduce Jobs Launched: Job 0: Map: 1 Reduce: 1 HDFS Read: 0 HDFS Write: 0 FAILTotal MapReduce CPU Time Spent: 0 msecSimilar issues seen with other queries:SELECT VAR_SAMP(L_SUPPKEY), (VAR_SAMP(L_SUPPKEY) - -2.20000000000000020000E+000), (-(VAR_SAMP(L_SUPPKEY)))FROM lineitem_orcWHERE ((L_SUPPKEY = -1));13/06/15 11:41:08 WARN conf.HiveConf: DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.Logging initialized using configuration in file:/C:/Hadoop/hive-0.9.0/conf/hive-log4j.propertiesHive history file=c:\hadoop\hive-0.9.0\logs\history/hive_job_log_jenkinsuser_6976@SLAVE23-WIN_201306151141_1255577417.txtTotal MapReduce jobs = 1Launching Job 1 out of 1Number of reduce tasks determined at compile time: 1In order to change the average load for a reducer (in bytes): set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;In order to limit the maximum number of reducers: set hive.exec.reducers.max=&lt;number&gt;In order to set a constant number of reducers: set mapred.reduce.tasks=&lt;number&gt;Starting Job = job_201306142329_0109, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201306142329_0109Kill Command = c:\Hadoop\hadoop-1.1.0-SNAPSHOT\bin\hadoop.cmd job -kill job_201306142329_0109Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 12013-06-15 11:41:38,753 Stage-1 map = 0%, reduce = 0%2013-06-15 11:42:17,959 Stage-1 map = 100%, reduce = 100%Ended Job = job_201306142329_0109 with errorsError during job, obtaining debugging information...Job Tracking URL: http://localhost:50030/jobdetails.jsp?jobid=job_201306142329_0109Examining task ID: task_201306142329_0109_m_000002 (and more) from job job_201306142329_0109Task with the most failures(4): -----Task ID: task_201306142329_0109_m_000000URL: http://localhost:50030/taskdetails.jsp?jobid=job_201306142329_0109&amp;tipid=task_201306142329_0109_m_000000-----Diagnostic Messages for this Task:java.lang.RuntimeException: Hive Runtime Error while closing operators at org.apache.hadoop.hive.ql.exec.vector.VectorExecMapper.close(VectorExecMapper.java:229) at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:57) at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372) at org.apache.hadoop.mapred.Child$4.run(Child.java:271) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135) at org.apache.hadoop.mapred.Child.main(Child.java:265)Caused by: java.lang.ClassCastException: org.apache.hadoop.io.NullWritable cannot be cast to [Ljava.lang.Object; at org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector.getStructFieldData(StandardStructObjectInspector.java:166) at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serializeStruct(LazyBinarySerDe.java:248) at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serialize(LazyBinarySerDe.java:534) at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serializeStruct(LazyBinarySerDe.java:257) at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serialize(LazyBinarySerDe.java:204) at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.processOp(ReduceSinkOperator.java:245) at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:502) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:832) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.flush(VectorGroupByOperator.java:281) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.closeOp(VectorGroupByOperator.java:423) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:588) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.vector.VectorExecMapper.close(VectorExecMapper.java:196) ... 8 moreFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTaskMapReduce Jobs Launched: Job 0: Map: 1 Reduce: 1 HDFS Read: 0 HDFS Write: 0 FAILTotal MapReduce CPU Time Spent: 0 msecSELECT MAX(L_ORDERKEY), (MAX(L_ORDERKEY) + 2)FROM lineitem_orcWHERE ((L_ORDERKEY &lt;= L_DISCOUNT));13/06/15 11:55:02 WARN conf.HiveConf: DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.Logging initialized using configuration in file:/C:/Hadoop/hive-0.9.0/conf/hive-log4j.propertiesHive history file=c:\hadoop\hive-0.9.0\logs\history/hive_job_log_jenkinsuser_3208@SLAVE23-WIN_201306151155_919702960.txtTotal MapReduce jobs = 1Launching Job 1 out of 1Number of reduce tasks determined at compile time: 1In order to change the average load for a reducer (in bytes): set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;In order to limit the maximum number of reducers: set hive.exec.reducers.max=&lt;number&gt;In order to set a constant number of reducers: set mapred.reduce.tasks=&lt;number&gt;Starting Job = job_201306142329_0114, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201306142329_0114Kill Command = c:\Hadoop\hadoop-1.1.0-SNAPSHOT\bin\hadoop.cmd job -kill job_201306142329_0114Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 12013-06-15 11:55:34,191 Stage-1 map = 0%, reduce = 0%2013-06-15 11:56:14,464 Stage-1 map = 100%, reduce = 100%Ended Job = job_201306142329_0114 with errorsError during job, obtaining debugging information...Job Tracking URL: http://localhost:50030/jobdetails.jsp?jobid=job_201306142329_0114Examining task ID: task_201306142329_0114_m_000002 (and more) from job job_201306142329_0114Task with the most failures(4): -----Task ID: task_201306142329_0114_m_000000URL: http://localhost:50030/taskdetails.jsp?jobid=job_201306142329_0114&amp;tipid=task_201306142329_0114_m_000000-----Diagnostic Messages for this Task:java.lang.RuntimeException: Hive Runtime Error while closing operators at org.apache.hadoop.hive.ql.exec.vector.VectorExecMapper.close(VectorExecMapper.java:229) at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:57) at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372) at org.apache.hadoop.mapred.Child$4.run(Child.java:271) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135) at org.apache.hadoop.mapred.Child.main(Child.java:265)Caused by: java.lang.ClassCastException: org.apache.hadoop.io.NullWritable cannot be cast to org.apache.hadoop.io.LongWritable at org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableLongObjectInspector.get(WritableLongObjectInspector.java:35) at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serialize(LazyBinarySerDe.java:325) at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serializeStruct(LazyBinarySerDe.java:257) at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serialize(LazyBinarySerDe.java:204) at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.processOp(ReduceSinkOperator.java:245) at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:502) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:832) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.flush(VectorGroupByOperator.java:281) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.closeOp(VectorGroupByOperator.java:423) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:588) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.vector.VectorExecMapper.close(VectorExecMapper.java:196) ... 8 moreFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTaskMapReduce Jobs Launched: Job 0: Map: 1 Reduce: 1 HDFS Read: 0 HDFS Write: 0 FAILTotal MapReduce CPU Time Spent: 0 msec</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorGroupByOperator.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorExpressionWriters.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpressionWriterFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFVar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFSum.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMaxString.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMax.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFAvg.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorUDAFCountStar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorUDAFCount.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinString.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxString.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgDouble.java</file>
    </fixedFiles>
  </bug>
  <bug id="4758" opendate="2013-6-19 00:00:00" fixdate="2013-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NULLs and record separators broken with vectorization branch intermediate outputs</summary>
      <description>Queries of type timestamp on partitioned tables return NULL for all rows of timestamp columns, if the first row in the column is NULL.This was tracked down to the failure of timestamp columns to parse the map output properly, which was due to differing format from the unvectorized code's output.The output file for vectorized code says (null)^A2013-02-12 21:05:29^AWhere the unvectorized code outputs\N2013-02-12 21:05:29The vectorized code passes on the "(null)" string to the LazyTimestamp parser, which fails to parse it &amp; returns "NULL", but slowed down massively by the IllegalArgumentException.And the extraneous ^A prevents the actual Timestamp from being parsed into valid timestamps.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch.java</file>
    </fixedFiles>
  </bug>
  <bug id="4774" opendate="2013-6-20 00:00:00" fixdate="2013-7-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive Runtime Error while closing operators: java.lang.NullPointerException</summary>
      <description>table and data attachedSELECT cdouble, cint, (cdouble - -1), (-((cdouble - -1))), MIN((-((cdouble - -1)))), STDDEV_SAMP(cdouble), (0.00000000000000000000E+000 / (cdouble - -1))FROM alltypes_orcWHERE ((cdouble &lt; cint) OR (cdouble &lt;= cint))GROUP BY cdouble, cintORDER BY cint;java.lang.RuntimeException: Hive Runtime Error while closing operators at org.apache.hadoop.hive.ql.exec.vector.VectorExecMapper.close(VectorExecMapper.java:229) at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:57) at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372) at org.apache.hadoop.mapred.Child$4.run(Child.java:271) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135) at org.apache.hadoop.mapred.Child.main(Child.java:265)Caused by: java.lang.NullPointerException at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serialize(LazyBinarySerDe.java:292) at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serializeStruct(LazyBinarySerDe.java:257) at org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.serialize(LazyBinarySerDe.java:204) at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.processOp(ReduceSinkOperator.java:245) at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:502) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:832) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.flush(VectorGroupByOperator.java:302) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.closeOp(VectorGroupByOperator.java:423) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:588) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:597) at org.apache.hadoop.hive.ql.exec.vector.VectorExecMapper.close(VectorExecMapper.java:196) ... 8 more</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpressionWriterFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="4786" opendate="2013-6-25 00:00:00" fixdate="2013-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrect aggregate results</summary>
      <description>ORC + Vectorization Result: 1.94379947764182E37ORC &amp; Text Result: 7.522728032127304E36query:SELECT VAR_SAMP(cbigint) FROM alltypes_orc WHERE cbigint &gt;= ctinyint;</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFVar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFAvg.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgLong.java</file>
    </fixedFiles>
  </bug>
  <bug id="4822" opendate="2013-7-8 00:00:00" fixdate="2013-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>implement vectorized math functions</summary>
      <description>Implement vectorized support for the all the built-in math functions. This includes implementing the vectorized operation, and tying it all together in VectorizationContext so it runs end-to-end. These functions include:round(Col)Round(Col, N)Floor(Col)Ceil(Col)Rand(), Rand(seed)Exp(Col)Ln(Col)Log10(Col)Log2(Col)Log(base, Col)Pow(col, p), Power(col, p)Sqrt(Col)Bin(Col)Hex(Col)Unhex(Col)Conv(Col, from_base, to_base)Abs(Col)Pmod(arg1, arg2)Sin(Col)Asin(Col)Cos(Col)ACos(Col)Atan(Col)Degrees(Col)Radians(Col)Positive(Col)Negative(Col)Sign(Col)E()Pi()To reduce the total code volume, do an implicit type cast from non-double input types to double. Also, POSITITVE and NEGATIVE are syntactic sugar for unary + and unary -, so reuse code for those as appropriate.Try to call the function directly in the inner loop and avoid new() or expensive operations, as appropriate.Templatize the code where appropriate, e.g. all the unary function of form DOUBLE func(DOUBLE)can probably be done with a template.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorStringExpressions.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.UDFHex.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringUnaryUDF.java</file>
      <file type="M">ql.src.gen.vectorization.ExpressionTemplates.ColumnUnaryMinus.txt</file>
      <file type="M">ant.src.org.apache.hadoop.hive.ant.GenVectorCode.java</file>
    </fixedFiles>
  </bug>
  <bug id="4848" opendate="2013-7-13 00:00:00" fixdate="2013-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>std, stddev and stddev_pop aggregates on double/float fail to vectorize</summary>
      <description>the aggregatesDefinition erroneously list std,stddev and stddev for Double as Long. trivial fix.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="4884" opendate="2013-7-18 00:00:00" fixdate="2013-7-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ORC TimestampTreeReader.nextVector() off by a second when time in fractional</summary>
      <description>When using negative timestamps, the ORC vectorized Timestampreader does the followingresult.vector[i] = (result.vector[i] * 1000000) + nanoVector.vector[i];This suffers from inaccuracies because the nanoseconds are always positive and the result.vector&amp;#91;i&amp;#93; is in effect seconds = (getTime() / 1000)nanos = (getNanos())// so -42001 ms is written as// seconds = -42// nanos = 999000000// (-42001 / 1000) * 1000 == -42000// + 999 ms (from nanos)// which is -42999 msThis needs to be adjusted down if nanos has been zero adjusted, to result in -42001 as the vector&amp;#91;i&amp;#93; value.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="4922" opendate="2013-7-23 00:00:00" fixdate="2013-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>create template for string scalar compared with string column</summary>
      <description>Create a template to generate classes to handle comparisons with a scalar on the left and a column on the right.This allows queries similar to the following to run vectorized:select l_orderkey, l_shipmode from lineitem_orc where l_orderkey = 1 and 'M' &gt; l_shipmode;</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorStringExpressions.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.CodeGen.java</file>
    </fixedFiles>
  </bug>
  <bug id="4931" opendate="2013-7-25 00:00:00" fixdate="2013-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MAX/MIN aggregates yield incorrect results</summary>
      <description>With the dataset attached by Tony, running:select max(ctinyint), max(csmallint), max(cint), max(cbigint), max(cfloat), max(cdouble) from alltypes_orc;this is the result in rowmode:OK62 16379 1073737829 2146661184 62.0 16376.0This is the result in vector mode:OK1 16379 1071926788 -106115134 62.0 16361.0</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFVar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFSum.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMax.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFAvg.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFVarPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFSumDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdSampDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFStdPopDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMinDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFMaxDouble.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgLong.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgDouble.java</file>
    </fixedFiles>
  </bug>
  <bug id="4961" opendate="2013-7-30 00:00:00" fixdate="2013-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create bridge for custom UDFs to operate in vectorized mode</summary>
      <description>Suppose you have a custom UDF myUDF() that you've created to extend hive. The goal of this JIRA is to create a facility where if you run a query that uses myUDF() in an expression, the query will run in vectorized mode.This would be a general-purpose bridge for custom UDFs that users add to Hive. It would work with existing UDFs.I'm considering a separate JIRA for a new kind of custom UDF implementation that is vectorized from the beginning, to optimize performance. That is not covered by this JIRA.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">build-common.xml</file>
    </fixedFiles>
  </bug>
  <bug id="4964" opendate="2013-7-31 00:00:00" fixdate="2013-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup PTF code: remove code dealing with non standard sql behavior we had original introduced</summary>
      <description>There are still pieces of code that deal with: supporting select expressions with Windowing supporting a filter with windowingNeed to do this before introducing Perf. improvements.</description>
      <version>None</version>
      <fixedVersion>0.12.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.ptf.WindowingTableFunction.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PTFDeserializer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PTFDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.WindowingSpec.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.PTFTranslator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.PTFOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="4965" opendate="2013-7-31 00:00:00" fixdate="2013-4-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add support so that PTFs can stream their output; Windowing PTF should do this</summary>
      <description>There is no need to create an output PTF Partition for the last PTF in a chain. For the Windowing PTF this should give a perf. boost; we avoid creating temporary results for each UDAF; avoid populating an output Partition.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.ptf.WindowingTableFunction.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.ptf.TableFunctionEvaluator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PTFDeserializer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.PTFTranslator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.PTFOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="4967" opendate="2013-7-31 00:00:00" fixdate="2013-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t serialize unnecessary fields in query plan</summary>
      <description>There are quite a few fields which need not to be serialized since they are initialized anyways in backend. We need not to serialize them in our plan.</description>
      <version>None</version>
      <fixedVersion>0.12.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFStringToMap.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.primitive.AbstractPrimitiveObjectInspector.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.udf.generic.GenericUDFTestTranslate.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.xml.GenericUDFXPath.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDTFStack.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDTFJSONTuple.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDTFInline.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDTFExplode.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFWhen.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFUnion.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFTranslate.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFToUnixTimeStamp.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFToDecimal.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFToDate.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFToBinary.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFTimestamp.java</file>
      <file type="M">contrib.src.java.org.apache.hadoop.hive.contrib.genericudf.example.GenericUDFDBOutput.java</file>
      <file type="M">contrib.src.java.org.apache.hadoop.hive.contrib.udtf.example.GenericUDTFExplode2.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.AbstractGenericUDFEWAHBitmapBop.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.AbstractGenericUDFReflect.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFAverage.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCollectSet.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFComputeStats.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFContextNGrams.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCorrelation.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCovariance.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEWAHBitmap.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFHistogramNumeric.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFLeadLag.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMax.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMin.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFNTile.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentileApprox.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVariance.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFArray.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFArrayContains.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFBaseCompare.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFCase.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFCoalesce.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFConcatWS.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFElt.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFEWAHBitmapEmpty.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFField.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFFormatNumber.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFFromUtcTimestamp.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFHash.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFIf.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFIn.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFInFile.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFInstr.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFLocate.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFMap.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFMapKeys.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFMapValues.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFNvl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPAnd.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNot.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPOr.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFPrintf.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFReflect.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFReflect2.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFSentences.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFSize.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFSortArray.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFSplit.java</file>
    </fixedFiles>
  </bug>
  <bug id="4989" opendate="2013-8-2 00:00:00" fixdate="2013-9-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Consolidate and simplify vectorization code and test generation</summary>
      <description>The current code generation is unwieldy to use and prone to errors. This change consolidates all the code and test generation into a single location, and removes the need to manually place files which can lead to missing or incomplete code or tests.</description>
      <version>vectorization-branch</version>
      <fixedVersion>vectorization-branch,0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.TestColumnScalarFilterVectorExpressionEvaluation.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.gen.TestColumnColumnOperationVectorExpressionEvaluation.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFVar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFSum.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMaxString.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFMinMax.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.VectorUDAFAvg.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.TestColumnScalarOperationVectorExpressionEvaluation.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.TestColumnScalarFilterVectorExpressionEvaluation.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.TestColumnColumnOperationVectorExpressionEvaluation.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.TestColumnColumnFilterVectorExpressionEvaluation.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.TestCodeGen.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.TestClass.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.ScalarArithmeticColumn.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.FilterStringScalarCompareColumn.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.FilterStringColumnCompareScalar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.FilterStringColumnCompareColumn.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.FilterScalarCompareColumn.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.FilterColumnCompareScalar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.FilterColumnCompareColumn.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.ColumnUnaryMinus.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.ColumnCompareScalar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.ColumnArithmeticScalar.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.ColumnArithmeticColumn.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.templates.CodeGen.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.gen.VectorUDAFAvgLong.java</file>
    </fixedFiles>
  </bug>
</bugrepository>
