<?xml version="1.0" encoding="UTF-8"?>

<bugrepository name="HIVE">
  <bug id="10024" opendate="2015-3-19 00:00:00" fixdate="2015-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: q file test is broken again</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.InStream.java</file>
    </fixedFiles>
  </bug>
  <bug id="10025" opendate="2015-3-20 00:00:00" fixdate="2015-4-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: Queued work times out</summary>
      <description>If a daemon holds a task in queue for a long time, it'll eventually time out - but isn't removed from the queue. Ideally, it shouldn't be allowed to time out. Otherwise, handle the timeout so that the task doesn't run - or starts and fails - likely a change in the TaskCommunicator.</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.java.org.apache.tez.dag.app.rm.LlapTaskSchedulerService.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl.java</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.llap.configuration.LlapConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="10099" opendate="2015-3-26 00:00:00" fixdate="2015-3-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable constant folding for Decimal</summary>
      <description></description>
      <version>0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.udf2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.udf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.round.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.expressions.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.udf2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.udf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.expressions.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.literal.decimal.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.decimal.udf2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.decimal.udf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.select.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="101" opendate="2008-12-2 00:00:00" fixdate="2008-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add various files and directories to svn:ignore</summary>
      <description>When creating patches or committing code it's nice to know that certain directories and files will never be included.I suggest we add the following to the svn:ignore variable (for more information see: http://svnbook.red-bean.com/en/1.1/ch07s02.html):build.classpath.project.settings</description>
      <version>None</version>
      <fixedVersion>0.3.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="1010" opendate="2009-12-23 00:00:00" fixdate="2009-5-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement INFORMATION_SCHEMA in Hive</summary>
      <description>INFORMATION_SCHEMA is part of the SQL92 standard and would be useful to implement using our metastore.</description>
      <version>None</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.llap.jdbc.handler.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.jdbc.handler.q</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.InputEstimatorTestClass.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.ppd.OpProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.TableDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PlanUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PartitionDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.UnparseTranslator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.HiveStorageHandler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.DefaultStorageHandler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.parquet.ProjectionPusher.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.HiveInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.index.HiveIndexedInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FileSinkOperator.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cli.LlapServiceDriver.java</file>
      <file type="M">jdbc-handler.src.test.java.org.apache.hive.config.JdbcStorageConfigManagerTest.java</file>
      <file type="M">jdbc-handler.src.main.java.org.apache.hive.storage.jdbc.JdbcStorageHandler.java</file>
      <file type="M">jdbc-handler.src.main.java.org.apache.hive.storage.jdbc.JdbcSerDe.java</file>
      <file type="M">jdbc-handler.src.main.java.org.apache.hive.storage.jdbc.JdbcRecordReader.java</file>
      <file type="M">jdbc-handler.src.main.java.org.apache.hive.storage.jdbc.JdbcInputFormat.java</file>
      <file type="M">jdbc-handler.src.main.java.org.apache.hive.storage.jdbc.dao.MySqlDatabaseAccessor.java</file>
      <file type="M">jdbc-handler.src.main.java.org.apache.hive.storage.jdbc.dao.JdbcRecordIterator.java</file>
      <file type="M">jdbc-handler.src.main.java.org.apache.hive.storage.jdbc.dao.GenericJdbcDatabaseAccessor.java</file>
      <file type="M">jdbc-handler.src.main.java.org.apache.hive.storage.jdbc.conf.JdbcStorageConfigManager.java</file>
      <file type="M">jdbc-handler.src.main.java.org.apache.hive.storage.jdbc.conf.DatabaseType.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.beeline.TestSchemaTool.java</file>
      <file type="M">druid-handler.src.java.org.apache.hadoop.hive.druid.DruidStorageHandler.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">beeline.src.test.org.apache.hive.beeline.TestHiveSchemaTool.java</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.HiveSchemaTool.java</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.HiveSchemaHelper.java</file>
    </fixedFiles>
  </bug>
  <bug id="10110" opendate="2015-3-27 00:00:00" fixdate="2015-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: port updates from HIVE-9555 to llap branch in preparation for trunk merge</summary>
      <description>Some stuff was updated based on CR feedback</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestRecordReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcSplit.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.InStream.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.llap.DebugUtils.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LowLevelCacheImpl.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.DiskRangeList.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.DiskRange.java</file>
    </fixedFiles>
  </bug>
  <bug id="10122" opendate="2015-3-27 00:00:00" fixdate="2015-4-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive metastore filter-by-expression is broken for non-partition expressions</summary>
      <description>See https://issues.apache.org/jira/browse/HIVE-10091?focusedCommentId=14382413&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14382413These two lines of code // Replace virtual columns with nulls. See javadoc for details. prunerExpr = removeNonPartCols(prunerExpr, extractPartColNames(tab), partColsUsedInFilter); // Remove all parts that are not partition columns. See javadoc for details. ExprNodeDesc compactExpr = compactExpr(prunerExpr.clone());are supposed to take care of this; I see there were bunch of changes to this code over some time, and now it appears to be broken.Thanks to thejas for info.</description>
      <version>0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.union.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.truncate.column.list.bucket.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rand.partitionpruner3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.oneskew.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.oneskew.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.oneskew.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.multiskew.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.multiskew.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.multiskew.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.9.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.5.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.4.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.2.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.13.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.12.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.11.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input42.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.stale.partitioned.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.part.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner.java</file>
    </fixedFiles>
  </bug>
  <bug id="10140" opendate="2015-3-30 00:00:00" fixdate="2015-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Window boundary is not compared correctly</summary>
      <description>“ROWS between 10 preceding and 2 preceding” is not handled correctly.Underlying error: Window range invalid, start boundary is greater than end boundary: window(start=range(10 PRECEDING), end=range(2 PRECEDING))If I change it to “2 preceding and 10 preceding”, the syntax works but the results are 0 of course.Reason for the function: during analysis, it is sometimes desired to design the window to filter the most recent events, in the case of the events' responses are not available yet. There is a workaround for this, but it is better/more proper to fix the bug.</description>
      <version>0.13.0,0.14.0,1.0.0,1.1.0,1.2.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.windowing.windowspec.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.windowing.windowspec.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.WindowingSpec.java</file>
    </fixedFiles>
  </bug>
  <bug id="10177" opendate="2015-4-1 00:00:00" fixdate="2015-4-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable constant folding for char &amp; varchar</summary>
      <description></description>
      <version>0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.select.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="10214" opendate="2015-4-4 00:00:00" fixdate="2015-4-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>log metastore call timing information aggregated at query level</summary>
      <description>For troubleshooting issues, it would be useful to log timing information for metastore api calls, aggregated at a query level.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.metadata.TestHive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="10231" opendate="2015-4-6 00:00:00" fixdate="2015-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compute partition column stats fails if partition col type is date</summary>
      <description>Currently the command "analyze table .. partition .. compute statistics for columns" may only work for partition column type of string, numeric types, but not others like date. See following case using date as partition coltype:create table colstatspartdate (key int, value string) partitioned by (ds date, hr int);insert into colstatspartdate partition (ds=date '2015-04-02', hr=2) select key, value from src limit 20;analyze table colstatspartdate partition (ds=date '2015-04-02', hr=2) compute statistics for columns;you will get RuntimeException:FAILED: RuntimeException Cannot convert to Date from: int15/04/06 17:30:01 ERROR ql.Driver: FAILED: RuntimeException Cannot convert to Date from: intjava.lang.RuntimeException: Cannot convert to Date from: int at org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils.getDate(PrimitiveObjectInspectorUtils.java:1048) at org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$DateConverter.convert(PrimitiveObjectInspectorConverter.java:264) at org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.typeCast(ConstantPropagateProcFactory.java:163) at org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.propagate(ConstantPropagateProcFactory.java:333) at org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.foldExpr(ConstantPropagateProcFactory.java:242)....</description>
      <version>0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="10244" opendate="2015-4-7 00:00:00" fixdate="2015-5-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorization : TPC-DS Q80 fails with java.lang.ClassCastException when hive.vectorized.execution.reduce.enabled is enabled</summary>
      <description>Query set hive.vectorized.execution.reduce.enabled=true;with ssr as (select s_store_id as store_id, sum(ss_ext_sales_price) as sales, sum(coalesce(sr_return_amt, 0)) as returns, sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit from store_sales left outer join store_returns on (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number), date_dim, store, item, promotion where ss_sold_date_sk = d_date_sk and d_date between cast('1998-08-04' as date) and (cast('1998-09-04' as date)) and ss_store_sk = s_store_sk and ss_item_sk = i_item_sk and i_current_price &gt; 50 and ss_promo_sk = p_promo_sk and p_channel_tv = 'N' group by s_store_id) , csr as (select cp_catalog_page_id as catalog_page_id, sum(cs_ext_sales_price) as sales, sum(coalesce(cr_return_amount, 0)) as returns, sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit from catalog_sales left outer join catalog_returns on (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number), date_dim, catalog_page, item, promotion where cs_sold_date_sk = d_date_sk and d_date between cast('1998-08-04' as date) and (cast('1998-09-04' as date)) and cs_catalog_page_sk = cp_catalog_page_sk and cs_item_sk = i_item_sk and i_current_price &gt; 50 and cs_promo_sk = p_promo_sk and p_channel_tv = 'N'group by cp_catalog_page_id) , wsr as (select web_site_id, sum(ws_ext_sales_price) as sales, sum(coalesce(wr_return_amt, 0)) as returns, sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit from web_sales left outer join web_returns on (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number), date_dim, web_site, item, promotion where ws_sold_date_sk = d_date_sk and d_date between cast('1998-08-04' as date) and (cast('1998-09-04' as date)) and ws_web_site_sk = web_site_sk and ws_item_sk = i_item_sk and i_current_price &gt; 50 and ws_promo_sk = p_promo_sk and p_channel_tv = 'N'group by web_site_id) select channel , id , sum(sales) as sales , sum(returns) as returns , sum(profit) as profit from (select 'store channel' as channel , concat('store', store_id) as id , sales , returns , profit from ssr union all select 'catalog channel' as channel , concat('catalog_page', catalog_page_id) as id , sales , returns , profit from csr union all select 'web channel' as channel , concat('web_site', web_site_id) as id , sales , returns , profit from wsr ) x group by channel, id with rollup order by channel ,id limit 100Exception Vertex failed, vertexName=Reducer 5, vertexId=vertex_1426707664723_1377_1_22, diagnostics=[Task failed, taskId=task_1426707664723_1377_1_22_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more], TaskAttempt 2 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more], TaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1426707664723_1377_1_22 [Reducer 5] killed/failed due to:null]15/04/07 05:14:52 [main]: ERROR SessionState: Vertex failed, vertexName=Reducer 5, vertexId=vertex_1426707664723_1377_1_22, diagnostics=[Task failed, taskId=task_1426707664723_1377_1_22_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more], TaskAttempt 2 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more], TaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1426707664723_1377_1_22 [Reducer 5] killed/failed due to:null]Vertex killed, vertexName=Reducer 6, vertexId=vertex_1426707664723_1377_1_23, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1426707664723_1377_1_23 [Reducer 6] killed/failed due to:null]15/04/07 05:14:52 [main]: ERROR SessionState: Vertex killed, vertexName=Reducer 6, vertexId=vertex_1426707664723_1377_1_23, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1426707664723_1377_1_23 [Reducer 6] killed/failed due to:null]DAG failed due to vertex failure. failedVertices:1 killedVertices:115/04/07 05:14:52 [main]: ERROR SessionState: DAG failed due to vertex failure. failedVertices:1 killedVertices:1FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Reducer 5, vertexId=vertex_1426707664723_1377_1_22, diagnostics=[Task failed, taskId=task_1426707664723_1377_1_22_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0☃00011.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more], TaskAttempt 2 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more], TaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1426707664723_1377_1_22 [Reducer 5] killed/failed due to:null]Vertex killed, vertexName=Reducer 6, vertexId=vertex_1426707664723_1377_1_23, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1426707664723_1377_1_23 [Reducer 6] killed/failed due to:null]DAG failed due to vertex failure. failedVertices:1 killedVertices:115/04/07 05:14:52 [main]: ERROR ql.Driver: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Reducer 5, vertexId=vertex_1426707664723_1377_1_22, diagnostics=[Task failed, taskId=task_1426707664723_1377_1_22_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more], TaskAttempt 1 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more], TaskAttempt 2 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8☃00012.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more], TaskAttempt 3 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:330) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:179) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:171) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:171) at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.callInternal(TezTaskRunner.java:167) at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:267) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:248) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:148) ... 14 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) \N \N 0 9.285817653506076E8 4.639990363237801E7 -1.1814318134887291E8\N \N 0 4.682909323885761E8 2.2415242712669864E7 -5.966176123188091E7\N \N 0 1.2847032699693155E9 6.300096113768728E7 -5.94963316209578E8 at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:394) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.pushRecord(ReduceRecordSource.java:252) ... 16 moreCaused by: java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector at org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.copyGroupKey(VectorGroupKeyHelper.java:94) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator$ProcessingModeGroupBatches.processBatch(VectorGroupByOperator.java:729) at org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.process(VectorGroupByOperator.java:878) at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.processVectors(ReduceRecordSource.java:378) ... 17 more]], Vertex failed as one or more tasks failed. failedTasks:1, Vertex vertex_1426707664723_1377_1_22 [Reducer 5] killed/failed due to:null]Vertex killed, vertexName=Reducer 6, vertexId=vertex_1426707664723_1377_1_23, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0, Vertex vertex_1426707664723_1377_1_23 [Reducer 6] killed/failed due to:null]DAG failed due to vertex failure. failedVertices:1 killedVertices:1Plan STAGE DEPENDENCIES: Stage-1 is a root stage Stage-0 depends on stages: Stage-1STAGE PLANS: Stage: Stage-1 Tez Edges: Map 12 &lt;- Map 14 (BROADCAST_EDGE), Map 15 (BROADCAST_EDGE), Map 16 (BROADCAST_EDGE), Map 17 (BROADCAST_EDGE), Map 18 (BROADCAST_EDGE) Map 19 &lt;- Map 21 (BROADCAST_EDGE), Map 22 (BROADCAST_EDGE), Map 23 (BROADCAST_EDGE), Map 24 (BROADCAST_EDGE), Map 25 (BROADCAST_EDGE) Reducer 13 &lt;- Map 12 (SIMPLE_EDGE), Union 4 (CONTAINS) Reducer 2 &lt;- Map 1 (SIMPLE_EDGE), Map 10 (BROADCAST_EDGE), Map 11 (BROADCAST_EDGE), Map 7 (SIMPLE_EDGE), Map 8 (BROADCAST_EDGE), Map 9 (BROADCAST_EDGE) Reducer 20 &lt;- Map 19 (SIMPLE_EDGE), Union 4 (CONTAINS) Reducer 3 &lt;- Reducer 2 (SIMPLE_EDGE), Union 4 (CONTAINS) Reducer 5 &lt;- Union 4 (SIMPLE_EDGE) Reducer 6 &lt;- Reducer 5 (SIMPLE_EDGE) DagName: mmokhtar_20150407051226_eb6d232e-cb00-4174-8b2f-d70aa2b3fb15:1 Vertices: Map 1 Map Operator Tree: TableScan alias: store_sales filterExpr: ((ss_item_sk is not null and ss_promo_sk is not null) and ss_store_sk is not null) (type: boolean) Statistics: Num rows: 550076554 Data size: 47370018896 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: ((ss_item_sk is not null and ss_promo_sk is not null) and ss_store_sk is not null) (type: boolean) Statistics: Num rows: 524469260 Data size: 14487496336 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: ss_item_sk (type: int), ss_store_sk (type: int), ss_promo_sk (type: int), ss_ticket_number (type: int), ss_ext_sales_price (type: float), ss_net_profit (type: float), ss_sold_date_sk (type: int) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6 Statistics: Num rows: 524469260 Data size: 14487496336 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int), _col3 (type: int) sort order: ++ Map-reduce partition columns: _col0 (type: int), _col3 (type: int) Statistics: Num rows: 524469260 Data size: 14487496336 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col1 (type: int), _col2 (type: int), _col4 (type: float), _col5 (type: float), _col6 (type: int) Execution mode: vectorized Map 10 Map Operator Tree: TableScan alias: promotion filterExpr: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean) Statistics: Num rows: 450 Data size: 530848 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean) Statistics: Num rows: 225 Data size: 20025 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: p_promo_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE Execution mode: vectorized Map 11 Map Operator Tree: TableScan alias: store filterExpr: s_store_sk is not null (type: boolean) Statistics: Num rows: 212 Data size: 405680 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: s_store_sk is not null (type: boolean) Statistics: Num rows: 212 Data size: 22048 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: s_store_sk (type: int), s_store_id (type: string) outputColumnNames: _col0, _col1 Statistics: Num rows: 212 Data size: 22048 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 212 Data size: 22048 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col1 (type: string) Execution mode: vectorized Map 12 Map Operator Tree: TableScan alias: catalog_sales filterExpr: ((cs_item_sk is not null and cs_promo_sk is not null) and cs_catalog_page_sk is not null) (type: boolean) Statistics: Num rows: 286549727 Data size: 37743959324 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: ((cs_item_sk is not null and cs_promo_sk is not null) and cs_catalog_page_sk is not null) (type: boolean) Statistics: Num rows: 285112475 Data size: 7974560516 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: cs_catalog_page_sk (type: int), cs_item_sk (type: int), cs_promo_sk (type: int), cs_order_number (type: int), cs_ext_sales_price (type: float), cs_net_profit (type: float), cs_sold_date_sk (type: int) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6 Statistics: Num rows: 285112475 Data size: 7974560516 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Left Outer Join0 to 1 keys: 0 _col1 (type: int), _col3 (type: int) 1 _col0 (type: int), _col1 (type: int) outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6, _col9, _col10 input vertices: 1 Map 14 Statistics: Num rows: 3412616 Data size: 109203712 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col6 (type: int) 1 _col0 (type: int) outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col9, _col10 input vertices: 1 Map 15 Statistics: Num rows: 3815661 Data size: 106838508 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col1 (type: int) 1 _col0 (type: int) outputColumnNames: _col0, _col2, _col4, _col5, _col9, _col10 input vertices: 1 Map 16 Statistics: Num rows: 1271887 Data size: 30525288 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col2 (type: int) 1 _col0 (type: int) outputColumnNames: _col0, _col4, _col5, _col9, _col10 input vertices: 1 Map 17 Statistics: Num rows: 635944 Data size: 12718880 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col0 (type: int) 1 _col0 (type: int) outputColumnNames: _col4, _col5, _col9, _col10, _col18 input vertices: 1 Map 18 Statistics: Num rows: 635944 Data size: 73769504 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: _col18 (type: string), _col4 (type: float), COALESCE(_col9,0) (type: float), (_col5 - COALESCE(_col10,0)) (type: float) outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 635944 Data size: 73769504 Basic stats: COMPLETE Column stats: COMPLETE Group By Operator aggregations: sum(_col1), sum(_col2), sum(_col3) keys: _col0 (type: string) mode: hash outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 10590 Data size: 1313160 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: string) sort order: + Map-reduce partition columns: _col0 (type: string) Statistics: Num rows: 10590 Data size: 1313160 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col1 (type: double), _col2 (type: double), _col3 (type: double) Execution mode: vectorized Map 14 Map Operator Tree: TableScan alias: catalog_returns filterExpr: cr_item_sk is not null (type: boolean) Statistics: Num rows: 28798881 Data size: 2942039156 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: cr_item_sk is not null (type: boolean) Statistics: Num rows: 28798881 Data size: 456171072 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: cr_item_sk (type: int), cr_order_number (type: int), cr_return_amount (type: float), cr_net_loss (type: float) outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 28798881 Data size: 456171072 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int), _col1 (type: int) sort order: ++ Map-reduce partition columns: _col0 (type: int), _col1 (type: int) Statistics: Num rows: 28798881 Data size: 456171072 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col2 (type: float), _col3 (type: float) Execution mode: vectorized Map 15 Map Operator Tree: TableScan alias: date_dim filterExpr: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean) Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean) Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: d_date_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: _col0 (type: int) outputColumnNames: _col0 Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE Group By Operator keys: _col0 (type: int) mode: hash outputColumnNames: _col0 Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE Dynamic Partitioning Event Operator Target Input: catalog_sales Partition key expr: cs_sold_date_sk Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE Target column: cs_sold_date_sk Target Vertex: Map 12 Execution mode: vectorized Map 16 Map Operator Tree: TableScan alias: item filterExpr: ((i_current_price &gt; 50.0) and i_item_sk is not null) (type: boolean) Statistics: Num rows: 48000 Data size: 68732712 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: ((i_current_price &gt; 50.0) and i_item_sk is not null) (type: boolean) Statistics: Num rows: 16000 Data size: 127832 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: i_item_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE Execution mode: vectorized Map 17 Map Operator Tree: TableScan alias: promotion filterExpr: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean) Statistics: Num rows: 450 Data size: 530848 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean) Statistics: Num rows: 225 Data size: 20025 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: p_promo_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE Execution mode: vectorized Map 18 Map Operator Tree: TableScan alias: catalog_page filterExpr: cp_catalog_page_sk is not null (type: boolean) Statistics: Num rows: 11718 Data size: 5400282 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: cp_catalog_page_sk is not null (type: boolean) Statistics: Num rows: 11718 Data size: 1218672 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: cp_catalog_page_sk (type: int), cp_catalog_page_id (type: string) outputColumnNames: _col0, _col1 Statistics: Num rows: 11718 Data size: 1218672 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 11718 Data size: 1218672 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col1 (type: string) Execution mode: vectorized Map 19 Map Operator Tree: TableScan alias: web_sales filterExpr: ((ws_item_sk is not null and ws_promo_sk is not null) and ws_web_site_sk is not null) (type: boolean) Statistics: Num rows: 143966864 Data size: 19001610332 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: ((ws_item_sk is not null and ws_promo_sk is not null) and ws_web_site_sk is not null) (type: boolean) Statistics: Num rows: 143930635 Data size: 4029840544 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: ws_item_sk (type: int), ws_web_site_sk (type: int), ws_promo_sk (type: int), ws_order_number (type: int), ws_ext_sales_price (type: float), ws_net_profit (type: float), ws_sold_date_sk (type: int) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6 Statistics: Num rows: 143930635 Data size: 4029840544 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Left Outer Join0 to 1 keys: 0 _col0 (type: int), _col3 (type: int) 1 _col0 (type: int), _col1 (type: int) outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6, _col9, _col10 input vertices: 1 Map 21 Statistics: Num rows: 2406359 Data size: 77003488 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col6 (type: int) 1 _col0 (type: int) outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col9, _col10 input vertices: 1 Map 22 Statistics: Num rows: 2690560 Data size: 75335680 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col0 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col2, _col4, _col5, _col9, _col10 input vertices: 1 Map 23 Statistics: Num rows: 896854 Data size: 21524496 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col2 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col4, _col5, _col9, _col10 input vertices: 1 Map 24 Statistics: Num rows: 448427 Data size: 8968540 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col1 (type: int) 1 _col0 (type: int) outputColumnNames: _col4, _col5, _col9, _col10, _col18 input vertices: 1 Map 25 Statistics: Num rows: 448427 Data size: 52017532 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: _col18 (type: string), _col4 (type: float), COALESCE(_col9,0) (type: float), (_col5 - COALESCE(_col10,0)) (type: float) outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 448427 Data size: 52017532 Basic stats: COMPLETE Column stats: COMPLETE Group By Operator aggregations: sum(_col1), sum(_col2), sum(_col3) keys: _col0 (type: string) mode: hash outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 17 Data size: 2108 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: string) sort order: + Map-reduce partition columns: _col0 (type: string) Statistics: Num rows: 17 Data size: 2108 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col1 (type: double), _col2 (type: double), _col3 (type: double) Execution mode: vectorized Map 21 Map Operator Tree: TableScan alias: web_returns filterExpr: wr_item_sk is not null (type: boolean) Statistics: Num rows: 13749816 Data size: 1237758344 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: wr_item_sk is not null (type: boolean) Statistics: Num rows: 13749816 Data size: 217404672 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: wr_item_sk (type: int), wr_order_number (type: int), wr_return_amt (type: float), wr_net_loss (type: float) outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 13749816 Data size: 217404672 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int), _col1 (type: int) sort order: ++ Map-reduce partition columns: _col0 (type: int), _col1 (type: int) Statistics: Num rows: 13749816 Data size: 217404672 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col2 (type: float), _col3 (type: float) Execution mode: vectorized Map 22 Map Operator Tree: TableScan alias: date_dim filterExpr: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean) Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean) Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: d_date_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: _col0 (type: int) outputColumnNames: _col0 Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE Group By Operator keys: _col0 (type: int) mode: hash outputColumnNames: _col0 Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE Dynamic Partitioning Event Operator Target Input: web_sales Partition key expr: ws_sold_date_sk Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE Target column: ws_sold_date_sk Target Vertex: Map 19 Execution mode: vectorized Map 23 Map Operator Tree: TableScan alias: item filterExpr: ((i_current_price &gt; 50.0) and i_item_sk is not null) (type: boolean) Statistics: Num rows: 48000 Data size: 68732712 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: ((i_current_price &gt; 50.0) and i_item_sk is not null) (type: boolean) Statistics: Num rows: 16000 Data size: 127832 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: i_item_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE Execution mode: vectorized Map 24 Map Operator Tree: TableScan alias: promotion filterExpr: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean) Statistics: Num rows: 450 Data size: 530848 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: ((p_channel_tv = 'N') and p_promo_sk is not null) (type: boolean) Statistics: Num rows: 225 Data size: 20025 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: p_promo_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 225 Data size: 900 Basic stats: COMPLETE Column stats: COMPLETE Execution mode: vectorized Map 25 Map Operator Tree: TableScan alias: web_site filterExpr: web_site_sk is not null (type: boolean) Statistics: Num rows: 38 Data size: 70614 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: web_site_sk is not null (type: boolean) Statistics: Num rows: 38 Data size: 3952 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: web_site_sk (type: int), web_site_id (type: string) outputColumnNames: _col0, _col1 Statistics: Num rows: 38 Data size: 3952 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 38 Data size: 3952 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col1 (type: string) Execution mode: vectorized Map 7 Map Operator Tree: TableScan alias: store_returns filterExpr: sr_item_sk is not null (type: boolean) Statistics: Num rows: 55578005 Data size: 4155315616 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: sr_item_sk is not null (type: boolean) Statistics: Num rows: 55578005 Data size: 881176504 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: sr_item_sk (type: int), sr_ticket_number (type: int), sr_return_amt (type: float), sr_net_loss (type: float) outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 55578005 Data size: 881176504 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int), _col1 (type: int) sort order: ++ Map-reduce partition columns: _col0 (type: int), _col1 (type: int) Statistics: Num rows: 55578005 Data size: 881176504 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col2 (type: float), _col3 (type: float) Execution mode: vectorized Map 8 Map Operator Tree: TableScan alias: date_dim filterExpr: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean) Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: (d_date BETWEEN 1998-08-04 AND 1998-09-04 and d_date_sk is not null) (type: boolean) Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: d_date_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: _col0 (type: int) outputColumnNames: _col0 Statistics: Num rows: 36524 Data size: 146096 Basic stats: COMPLETE Column stats: COMPLETE Group By Operator keys: _col0 (type: int) mode: hash outputColumnNames: _col0 Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE Dynamic Partitioning Event Operator Target Input: store_sales Partition key expr: ss_sold_date_sk Statistics: Num rows: 18262 Data size: 73048 Basic stats: COMPLETE Column stats: COMPLETE Target column: ss_sold_date_sk Target Vertex: Map 1 Execution mode: vectorized Map 9 Map Operator Tree: TableScan alias: item filterExpr: ((i_current_price &gt; 50.0) and i_item_sk is not null) (type: boolean) Statistics: Num rows: 48000 Data size: 68732712 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: ((i_current_price &gt; 50.0) and i_item_sk is not null) (type: boolean) Statistics: Num rows: 16000 Data size: 127832 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: i_item_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 16000 Data size: 64000 Basic stats: COMPLETE Column stats: COMPLETE Execution mode: vectorized Reducer 13 Reduce Operator Tree: Group By Operator aggregations: sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2) keys: KEY._col0 (type: string) mode: mergepartial outputColumnNames: _col0, _col1, _col2, _col3 Select Operator expressions: 'catalog channel' (type: string), concat('catalog_page', _col0) (type: string), _col1 (type: double), _col2 (type: double), _col3 (type: double) outputColumnNames: _col0, _col1, _col2, _col3, _col4 Group By Operator aggregations: sum(_col2), sum(_col3), sum(_col4) keys: _col0 (type: string), _col1 (type: string), '0' (type: string) mode: hash outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5 Reduce Output Operator key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string) sort order: +++ Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string) value expressions: _col3 (type: double), _col4 (type: double), _col5 (type: double) Reducer 2 Reduce Operator Tree: Merge Join Operator condition map: Left Outer Join0 to 1 keys: 0 _col0 (type: int), _col3 (type: int) 1 _col0 (type: int), _col1 (type: int) outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6, _col9, _col10 Statistics: Num rows: 7811006 Data size: 249952192 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col6 (type: int) 1 _col0 (type: int) outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col9, _col10 input vertices: 1 Map 8 Statistics: Num rows: 8733520 Data size: 244538560 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col0 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col2, _col4, _col5, _col9, _col10 input vertices: 1 Map 9 Statistics: Num rows: 2911174 Data size: 69868176 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col2 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col4, _col5, _col9, _col10 input vertices: 1 Map 10 Statistics: Num rows: 1455587 Data size: 29111740 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col1 (type: int) 1 _col0 (type: int) outputColumnNames: _col4, _col5, _col9, _col10, _col18 input vertices: 1 Map 11 Statistics: Num rows: 1455587 Data size: 168848092 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: _col18 (type: string), _col4 (type: float), COALESCE(_col9,0) (type: float), (_col5 - COALESCE(_col10,0)) (type: float) outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 1455587 Data size: 168848092 Basic stats: COMPLETE Column stats: COMPLETE Group By Operator aggregations: sum(_col1), sum(_col2), sum(_col3) keys: _col0 (type: string) mode: hash outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 234 Data size: 29016 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: string) sort order: + Map-reduce partition columns: _col0 (type: string) Statistics: Num rows: 234 Data size: 29016 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col1 (type: double), _col2 (type: double), _col3 (type: double) Reducer 20 Reduce Operator Tree: Group By Operator aggregations: sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2) keys: KEY._col0 (type: string) mode: mergepartial outputColumnNames: _col0, _col1, _col2, _col3 Select Operator expressions: 'web channel' (type: string), concat('web_site', _col0) (type: string), _col1 (type: double), _col2 (type: double), _col3 (type: double) outputColumnNames: _col0, _col1, _col2, _col3, _col4 Group By Operator aggregations: sum(_col2), sum(_col3), sum(_col4) keys: _col0 (type: string), _col1 (type: string), '0' (type: string) mode: hash outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5 Reduce Output Operator key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string) sort order: +++ Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string) value expressions: _col3 (type: double), _col4 (type: double), _col5 (type: double) Reducer 3 Reduce Operator Tree: Group By Operator aggregations: sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2) keys: KEY._col0 (type: string) mode: mergepartial outputColumnNames: _col0, _col1, _col2, _col3 Select Operator expressions: 'store channel' (type: string), concat('store', _col0) (type: string), _col1 (type: double), _col2 (type: double), _col3 (type: double) outputColumnNames: _col0, _col1, _col2, _col3, _col4 Group By Operator aggregations: sum(_col2), sum(_col3), sum(_col4) keys: _col0 (type: string), _col1 (type: string), '0' (type: string) mode: hash outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5 Reduce Output Operator key expressions: _col0 (type: string), _col1 (type: string), _col2 (type: string) sort order: +++ Map-reduce partition columns: _col0 (type: string), _col1 (type: string), _col2 (type: string) value expressions: _col3 (type: double), _col4 (type: double), _col5 (type: double) Reducer 5 Reduce Operator Tree: Group By Operator aggregations: sum(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2) keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: string) mode: mergepartial outputColumnNames: _col0, _col1, _col3, _col4, _col5 Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE pruneGroupingSetId: true Select Operator expressions: _col0 (type: string), _col1 (type: string), _col3 (type: double), _col4 (type: double), _col5 (type: double) outputColumnNames: _col0, _col1, _col2, _col3, _col4 Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: string), _col1 (type: string) sort order: ++ Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE TopN Hash Memory Usage: 0.04 value expressions: _col2 (type: double), _col3 (type: double), _col4 (type: double) Execution mode: vectorized Reducer 6 Reduce Operator Tree: Select Operator expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: double), VALUE._col1 (type: double), VALUE._col2 (type: double) outputColumnNames: _col0, _col1, _col2, _col3, _col4 Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE Limit Number of rows: 100 Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE File Output Operator compressed: false Statistics: Num rows: 1 Data size: 24 Basic stats: COMPLETE Column stats: COMPLETE table: input format: org.apache.hadoop.mapred.TextInputFormat output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe Execution mode: vectorized Union 4 Vertex: Union 4 Stage: Stage-0 Fetch Operator limit: 100 Processor Tree: ListSink</description>
      <version>0.14.0</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="10318" opendate="2015-4-13 00:00:00" fixdate="2015-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The HMS upgrade test does not test patches that affect the upgrade test scripts</summary>
      <description>When doing a change on the HMS upgrade scripts, such as adding a new DB server, then the HMS upgrade test does not test this change. In order to make it work, this patch needs to be committed to trunk.This is not desired, as we need to test the upgrade change first before doing the commit.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.metastore.execute-test-on-lxc.sh</file>
      <file type="M">dev-support.jenkins-execute-hms-test.sh</file>
    </fixedFiles>
  </bug>
  <bug id="1038" opendate="2010-1-8 00:00:00" fixdate="2010-1-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mapjoin dies if the join prunes all the columns</summary>
      <description>The query:select /*+ mapjoin(a) */ count(1) from src a join src b on a.key = b.keydies.It is a blocker for 0.5</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PlanUtils.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="104" opendate="2008-12-3 00:00:00" fixdate="2008-12-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tables with at least 1 non-string columns should use DynamicSerDe instead of MetadataTypedColumnsetSerDe</summary>
      <description>For example, create table TableA (cola int, colb string).The MetadataTypedColumnsetSerDe is not capable of producing int values.</description>
      <version>None</version>
      <fixedVersion>0.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.input.testxpath.q.out</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol.java</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.errors.invalid.index.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subq2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.quote1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.notable.alias2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.notable.alias1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapreduce6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapreduce5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapreduce4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapreduce3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapreduce2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapreduce1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.testxpath2.q.out</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.groupByDesc.java</file>
      <file type="M">ql.src.test.queries.clientpositive.cast1.q</file>
      <file type="M">ql.src.test.queries.clientpositive.groupby3.q</file>
      <file type="M">ql.src.test.queries.clientpositive.groupby3.map.q</file>
      <file type="M">ql.src.test.queries.clientpositive.input1.q</file>
      <file type="M">ql.src.test.queries.clientpositive.input2.q</file>
      <file type="M">ql.src.test.queries.clientpositive.input3.q</file>
      <file type="M">ql.src.test.queries.clientpositive.input5.q</file>
      <file type="M">ql.src.test.queries.clientpositive.inputddl4.q</file>
      <file type="M">ql.src.test.results.clientnegative.invalid.create.tbl1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.case.sensitivity.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cast1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby1.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby1.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby3.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby4.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby5.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input11.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input14.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input1.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.inputddl4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.testsequencefile.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="1042" opendate="2010-1-11 00:00:00" fixdate="2010-1-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>function in a transform with more than 1 argument fails</summary>
      <description>select transform(substr(key, 1, 3)) USING '/bin/cat' FROM srcthrows an error:FAILED: Error in semantic analysis: AS clause has an invalid number of aliases</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10451" opendate="2015-4-23 00:00:00" fixdate="2015-4-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PTF deserializer fails if values are not used in reducer</summary>
      <description>In this particular case no values are needed from reducer to complete processing.</description>
      <version>0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils.java</file>
      <file type="M">ql.src.test.results.clientpositive.windowing.navfn.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.windowing.navfn.q</file>
    </fixedFiles>
  </bug>
  <bug id="10568" opendate="2015-5-1 00:00:00" fixdate="2015-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Select count(distinct()) can have more optimal execution plan</summary>
      <description>select count(distinct ss_ticket_number) from store_sales;can be rewritten asselect count(1) from (select distinct ss_ticket_number from store_sales) a;which may run upto 3x faster</description>
      <version>0.6.0,0.7.0,0.8.0,0.9.0,0.10.0,0.11.0,0.12.0,0.13.0,0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.count.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.distinct.gby.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mrr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.limit.pushdown.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.CalcitePlanner.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="10572" opendate="2015-5-1 00:00:00" fixdate="2015-5-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve Hive service test to check empty string</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.auth.LdapAuthenticationProviderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="10595" opendate="2015-5-4 00:00:00" fixdate="2015-5-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Dropping a table can cause NPEs in the compactor</summary>
      <description>Reproduction: start metastore with compactor off insert enough entries in a table to trigger a compaction drop the table stop metastore restart metastore with compactor onResult: NPE in the compactor threads. I suspect this would also happen if the inserts and drops were done in between a run of the compactor, but I haven't proven it.</description>
      <version>0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.txn.compactor.TestWorker.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.Worker.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.Initiator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.CompactorThread.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.Cleaner.java</file>
    </fixedFiles>
  </bug>
  <bug id="10636" opendate="2015-5-6 00:00:00" fixdate="2015-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CASE comparison operator rotation optimization</summary>
      <description>Step 1 as outlined in description of HIVE-9644</description>
      <version>0.14.0,1.0.0,1.1.0,1.2.0</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableVoidObjectInspector.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.primitive.AbstractPrimitiveObjectInspector.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.io.HiveVarcharWritable.java</file>
      <file type="M">ql.src.test.results.clientpositive.vector.coalesce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.coalesce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.join.nullsafe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.notin.having.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join.nullsafe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.nullsafe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.fold.when.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.filter.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFTranslate.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFPrintf.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFLocate.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFInstr.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFGreatest.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFCoalesce.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.StatsUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ExprNodeNullDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ExprNodeConstantDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.TableAccessAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.SimpleFetchOptimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.PrunerExpressionOperatorFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.lineage.ExprProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GroupByOptimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.translator.RexNodeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExprNodeEvaluatorFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="10639" opendate="2015-5-7 00:00:00" fixdate="2015-5-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>create SHA1 UDF</summary>
      <description>Calculates an SHA-1 160-bit checksum for the string and binary, as described in RFC 3174 (Secure Hash Algorithm). The value is returned as a string of 40 hex digits, or NULL if the argument was NULL.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.show.functions.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
    </fixedFiles>
  </bug>
  <bug id="10678" opendate="2015-5-12 00:00:00" fixdate="2015-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>update sql standard authorization configuration whitelist - more optimization flags</summary>
      <description>hive.exec.parallel and hive.groupby.orderby.position.alias are optimization config parameters that should be settable when sql standard authorization is enabled.</description>
      <version>None</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="10679" opendate="2015-5-12 00:00:00" fixdate="2015-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JsonSerde ignores varchar and char size limit specified during table creation</summary>
      <description>JsonSerde ignores varchar and char size limit specified during table creation and always creates varchar or char column with max length.steps to reproduce the issue:create table jsonserde_1 (v varchar(50), c char(50)) row format serde 'org.apache.hive.hcatalog.data.JsonSerDe';desc jsonserde_1;OKv varchar(65535) from deserializer c char(255) from deserializer Time taken: 0.468 seconds, Fetched: 2 row(s)</description>
      <version>None</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory.java</file>
      <file type="M">hcatalog.core.src.main.java.org.apache.hive.hcatalog.data.HCatRecordObjectInspectorFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="10682" opendate="2015-5-12 00:00:00" fixdate="2015-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: Make use of the task runner which allows killing tasks</summary>
      <description>TEZ-2434 adds a runner which allows tasks to be killed. Jira to integrate with that without the actual kill functionality. That will follow.</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.daemon.impl.TestTaskExecutorService.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.TaskExecutorService.java</file>
    </fixedFiles>
  </bug>
  <bug id="10683" opendate="2015-5-12 00:00:00" fixdate="2015-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: Add a mechanism for daemons to inform the AM about killed tasks</summary>
      <description>Click to add description</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.daemon.impl.TestTaskExecutorService.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorInfo.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.TaskExecutorService.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.QueryTracker.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.AMReporter.java</file>
    </fixedFiles>
  </bug>
  <bug id="10685" opendate="2015-5-12 00:00:00" fixdate="2015-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Alter table concatenate oparetor will cause duplicate data</summary>
      <description>"Orders" table has 1500000000 rows and stored as ORC. hive&gt; select count(*) from orders;OK1500000000Time taken: 37.692 seconds, Fetched: 1 row(s)The table contain 14 files,the size of each file is about 2.1 ~ 3.2 GB.After executing command : ALTER TABLE orders CONCATENATE;The table is already 1530115000 rows.My hive version is 1.1.0.</description>
      <version>0.14.0,1.0.0,1.1.0,1.2.0,1.2.1,1.3.0</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcFileStripeMergeRecordReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="10686" opendate="2015-5-12 00:00:00" fixdate="2015-5-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>java.lang.IndexOutOfBoundsException for query with rank() over(partition ...)</summary>
      <description>CBO throws Index out of bound exception for TPC-DS Q70.Query explainselect sum(ss_net_profit) as total_sum ,s_state ,s_county ,grouping__id as lochierarchy , rank() over(partition by grouping__id, case when grouping__id == 2 then s_state end order by sum(ss_net_profit)) as rank_within_parentfrom store_sales ss join date_dim d1 on d1.d_date_sk = ss.ss_sold_date_sk join store s on s.s_store_sk = ss.ss_store_sk where d1.d_month_seq between 1193 and 1193+11 and s.s_state in ( select s_state from (select s_state as s_state, sum(ss_net_profit), rank() over ( partition by s_state order by sum(ss_net_profit) desc) as ranking from store_sales, store, date_dim where d_month_seq between 1193 and 1193+11 and date_dim.d_date_sk = store_sales.ss_sold_date_sk and store.s_store_sk = store_sales.ss_store_sk group by s_state ) tmp1 where ranking &lt;= 5 ) group by s_state,s_county with rolluporder by lochierarchy desc ,case when lochierarchy = 0 then s_state end ,rank_within_parent limit 100Original plan (correct) HiveSort(fetch=[100]) HiveSort(sort0=[$3], sort1=[$5], sort2=[$4], dir0=[DESC], dir1=[ASC], dir2=[ASC]) HiveProject(total_sum=[$4], s_state=[$0], s_county=[$1], lochierarchy=[$5], rank_within_parent=[rank() OVER (PARTITION BY $5, when(==($5, 2), $0) ORDER BY $4 ROWS BETWEEN 2147483647 FOLLOWING AND 2147483647 PRECEDING)], (tok_function when (= (tok_table_or_col lochierarchy) 0) (tok_table_or_col s_state))=[when(=($5, 0), $0)]) HiveAggregate(group=[{0, 1}], groups=[[{0, 1}, {0}, {}]], indicator=[true], agg#0=[sum($2)], GROUPING__ID=[GROUPING__ID()]) HiveProject($f0=[$7], $f1=[$6], $f2=[$1]) HiveJoin(condition=[=($5, $2)], joinType=[inner], algorithm=[none], cost=[{1177.2086187101072 rows, 0.0 cpu, 0.0 io}]) HiveJoin(condition=[=($3, $0)], joinType=[inner], algorithm=[none], cost=[{2880430.428726483 rows, 0.0 cpu, 0.0 io}]) HiveProject(ss_sold_date_sk=[$0], ss_net_profit=[$21], ss_store_sk=[$22]) HiveTableScan(table=[[tpcds.store_sales]]) HiveProject(d_date_sk=[$0], d_month_seq=[$3]) HiveFilter(condition=[between(false, $3, 1193, +(1193, 11))]) HiveTableScan(table=[[tpcds.date_dim]]) HiveProject(s_store_sk=[$0], s_county=[$1], s_state=[$2]) SemiJoin(condition=[=($2, $3)], joinType=[inner]) HiveProject(s_store_sk=[$0], s_county=[$23], s_state=[$24]) HiveTableScan(table=[[tpcds.store]]) HiveProject(s_state=[$0]) HiveFilter(condition=[&lt;=($1, 5)]) HiveProject((tok_table_or_col s_state)=[$0], rank_window_0=[rank() OVER (PARTITION BY $0 ORDER BY $1 DESC ROWS BETWEEN 2147483647 FOLLOWING AND 2147483647 PRECEDING)]) HiveAggregate(group=[{0}], agg#0=[sum($1)]) HiveProject($f0=[$6], $f1=[$1]) HiveJoin(condition=[=($5, $2)], joinType=[inner], algorithm=[none], cost=[{1177.2086187101072 rows, 0.0 cpu, 0.0 io}]) HiveJoin(condition=[=($3, $0)], joinType=[inner], algorithm=[none], cost=[{2880430.428726483 rows, 0.0 cpu, 0.0 io}]) HiveProject(ss_sold_date_sk=[$0], ss_net_profit=[$21], ss_store_sk=[$22]) HiveTableScan(table=[[tpcds.store_sales]]) HiveProject(d_date_sk=[$0], d_month_seq=[$3]) HiveFilter(condition=[between(false, $3, 1193, +(1193, 11))]) HiveTableScan(table=[[tpcds.date_dim]]) HiveProject(s_store_sk=[$0], s_state=[$24]) HiveTableScan(table=[[tpcds.store]])Plan after fixTopOBSchema (incorrect) HiveSort(fetch=[100]) HiveSort(sort0=[$3], sort1=[$5], sort2=[$4], dir0=[DESC], dir1=[ASC], dir2=[ASC]) HiveProject(total_sum=[$4], s_state=[$0], s_county=[$1], lochierarchy=[$5], rank_within_parent=[rank() OVER (PARTITION BY $5, when(==($5, 2), $0) ORDER BY $4 ROWS BETWEEN 2147483647 FOLLOWING AND 2147483647 PRECEDING)]) HiveAggregate(group=[{0, 1}], groups=[[{0, 1}, {0}, {}]], indicator=[true], agg#0=[sum($2)], GROUPING__ID=[GROUPING__ID()]) HiveProject($f0=[$7], $f1=[$6], $f2=[$1]) HiveJoin(condition=[=($5, $2)], joinType=[inner], algorithm=[none], cost=[{1177.2086187101072 rows, 0.0 cpu, 0.0 io}]) HiveJoin(condition=[=($3, $0)], joinType=[inner], algorithm=[none], cost=[{2880430.428726483 rows, 0.0 cpu, 0.0 io}]) HiveProject(ss_sold_date_sk=[$0], ss_net_profit=[$21], ss_store_sk=[$22]) HiveTableScan(table=[[tpcds.store_sales]]) HiveProject(d_date_sk=[$0], d_month_seq=[$3]) HiveFilter(condition=[between(false, $3, 1193, +(1193, 11))]) HiveTableScan(table=[[tpcds.date_dim]]) HiveProject(s_store_sk=[$0], s_county=[$1], s_state=[$2]) SemiJoin(condition=[=($2, $3)], joinType=[inner]) HiveProject(s_store_sk=[$0], s_county=[$23], s_state=[$24]) HiveTableScan(table=[[tpcds.store]]) HiveProject(s_state=[$0]) HiveFilter(condition=[&lt;=($1, 5)]) HiveProject((tok_table_or_col s_state)=[$0], rank_window_0=[rank() OVER (PARTITION BY $0 ORDER BY $1 DESC ROWS BETWEEN 2147483647 FOLLOWING AND 2147483647 PRECEDING)]) HiveAggregate(group=[{0}], agg#0=[sum($1)]) HiveProject($f0=[$6], $f1=[$1]) HiveJoin(condition=[=($5, $2)], joinType=[inner], algorithm=[none], cost=[{1177.2086187101072 rows, 0.0 cpu, 0.0 io}]) HiveJoin(condition=[=($3, $0)], joinType=[inner], algorithm=[none], cost=[{2880430.428726483 rows, 0.0 cpu, 0.0 io}]) HiveProject(ss_sold_date_sk=[$0], ss_net_profit=[$21], ss_store_sk=[$22]) HiveTableScan(table=[[tpcds.store_sales]]) HiveProject(d_date_sk=[$0], d_month_seq=[$3]) HiveFilter(condition=[between(false, $3, 1193, +(1193, 11))]) HiveTableScan(table=[[tpcds.date_dim]]) HiveProject(s_store_sk=[$0], s_state=[$24]) HiveTableScan(table=[[tpcds.store]])Exception 15/04/14 02:42:52 [main]: ERROR parse.CalcitePlanner: CBO failed, skipping CBO.java.lang.IndexOutOfBoundsException: Index: 5, Size: 5 at java.util.ArrayList.rangeCheck(ArrayList.java:635) at java.util.ArrayList.get(ArrayList.java:411) at org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTConverter$RexVisitor.visitInputRef(ASTConverter.java:395) at org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTConverter$RexVisitor.visitInputRef(ASTConverter.java:372) at org.apache.calcite.rex.RexInputRef.accept(RexInputRef.java:112) at org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTConverter$RexVisitor.visitCall(ASTConverter.java:543) at org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTConverter$RexVisitor.visitCall(ASTConverter.java:372) at org.apache.calcite.rex.RexCall.accept(RexCall.java:107) at org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTConverter$RexVisitor.visitCall(ASTConverter.java:543) at org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTConverter$RexVisitor.visitCall(ASTConverter.java:372) at org.apache.calcite.rex.RexCall.accept(RexCall.java:107) at org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTConverter.convertOBToASTNode(ASTConverter.java:252) at org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTConverter.convert(ASTConverter.java:208) at org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTConverter.convert(ASTConverter.java:98) at org.apache.hadoop.hive.ql.parse.CalcitePlanner.getOptimizedAST(CalcitePlanner.java:607) at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:239) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10003) at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:202) at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:224) at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:74) at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:224) at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:424) at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:308) at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1122) at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170) at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059) at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049) at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:213) at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:165) at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376) at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:311) at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:409) at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:425) at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:714) at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:681) at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:621) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.RunJar.run(RunJar.java:221) at org.apache.hadoop.util.RunJar.main(RunJar.java:136)</description>
      <version>None</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.translator.PlanModifierUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="10698" opendate="2015-5-13 00:00:00" fixdate="2015-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>query on view results fails with table not found error if view is created with subquery alias (CTE).</summary>
      <description>To reproduce it, use bugtest;create table basetb(id int, name string);create view testv1 aswith subtb as (select id, name from bugtest.basetb)select id from subtb;use castest;explain select * from bugtest.testv1;hive&gt; explain select * from bugtest.testv1;FAILED: SemanticException Line 2:15 Table not found 'subtb' in definition of VIEW testv1 [with subtb as (select id, name from bugtest.basetb)select id from `bugtest`.`subtb`] used as testv1 at Line 1:22Note that there is a database prefix `bugtest`.`subtb`</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.HiveParser.g</file>
    </fixedFiles>
  </bug>
  <bug id="10705" opendate="2015-5-14 00:00:00" fixdate="2015-6-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update tests for HIVE-9302 after removing binaries</summary>
      <description>Click to add description</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.session.TestSessionState.java</file>
      <file type="M">common.src.java.org.apache.hive.common.util.HiveTestUtils.java</file>
      <file type="M">beeline.src.test.resources.postgresql-9.3.jdbc3.jar</file>
      <file type="M">beeline.src.test.resources.DummyDriver-1.0-SNAPSHOT.jar</file>
      <file type="M">beeline.src.test.org.apache.hive.beeline.TestBeelineArgParsing.java</file>
      <file type="M">beeline.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="10746" opendate="2015-5-19 00:00:00" fixdate="2015-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive 1.2.0+Tez produces 1-byte FileSplits from mapred.TextInputFormat</summary>
      <description>The following query: SELECT appl_user_id, arsn_cd, COUNT(*) as RecordCount FROM adw.crc_arsn GROUP BY appl_user_id,arsn_cd ORDER BY appl_user_id; runs consistently fast in Spark and Mapreduce on Hive 1.2.0. When attempting to run this same query against Tez as the execution engine it consistently runs for over 300-500 seconds this seems extremely long. This is a basic external table delimited by tabs and is a single file in a folder. In Hive 0.13 this query with Tez runs fast and I tested with Hive 0.14, 0.14.1/1.0.0 and now Hive 1.2.0 and there clearly is something going awry with Hive w/Tez as an execution engine with Single or small file tables. I can attach further logs if someone needs them for deeper analysis.HDFS Output:hadoop fs -ls /example_dw/crc/arsnFound 2 items-rwxr-x--- 6 loaduser hadoopusers 0 2015-05-17 20:03 /example_dw/crc/arsn/_SUCCESS-rwxr-x--- 6 loaduser hadoopusers 3883880 2015-05-17 20:03 /example_dw/crc/arsn/part-m-00000Hive Table Describe:hive&gt; describe formatted crc_arsn;OK# col_name data_type comment arsn_cd string clmlvl_cd string arclss_cd string arclssg_cd string arsn_prcsr_rmk_ind string arsn_mbr_rspns_ind string savtyp_cd string arsn_eff_dt string arsn_exp_dt string arsn_pstd_dts string arsn_lstupd_dts string arsn_updrsn_txt string appl_user_id string arsntyp_cd string pre_d_indicator string arsn_display_txt string arstat_cd string arsn_tracking_no string arsn_cstspcfc_ind string arsn_mstr_rcrd_ind string state_specific_ind string region_specific_in string arsn_dpndnt_cd string unit_adjustment_in string arsn_mbr_only_ind string arsn_qrmb_ind string # Detailed Table Information Database: adw Owner: LOADUSER@EXA.EXAMPLE.COM CreateTime: Mon Apr 28 13:28:05 EDT 2014 LastAccessTime: UNKNOWN Protect Mode: None Retention: 0 Location: hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn Table Type: EXTERNAL_TABLE Table Parameters: EXTERNAL TRUE transient_lastDdlTime 1398706085 # Storage Information SerDe Library: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe InputFormat: org.apache.hadoop.mapred.TextInputFormat OutputFormat: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat Compressed: No Num Buckets: -1 Bucket Columns: [] Sort Columns: [] Storage Desc Params: field.delim \t line.delim \n serialization.format \t Time taken: 1.245 seconds, Fetched: 54 row(s)Explain Hive 1.2.0 w/Tez:STAGE DEPENDENCIES: Stage-1 is a root stage Stage-0 depends on stages: Stage-1STAGE PLANS: Stage: Stage-1 Tez Edges: Reducer 2 &lt;- Map 1 (SIMPLE_EDGE) Reducer 3 &lt;- Reducer 2 (SIMPLE_EDGE)Explain Hive 0.13 w/Tez:STAGE DEPENDENCIES: Stage-1 is a root stage Stage-0 is a root stageSTAGE PLANS: Stage: Stage-1 Tez Edges: Reducer 2 &lt;- Map 1 (SIMPLE_EDGE) Reducer 3 &lt;- Reducer 2 (SIMPLE_EDGE) Results: Hive 1.2.0 w/Spark 1.3.1: Finished successfully in 7.09 seconds Hive 1.2.0 w/Mapreduce: Stage 1: 32 Seconds Stage 2: 35 Seconds Hive 1.2.0 w/Tez 0.5.3: Time taken: 565.025 seconds, Fetched: 11516 row(s) Hive 0.13 w/Tez 0.4.0: Time taken: 13.552 seconds, Fetched: 11516 row(s)And finally looking at the Dag Attempt that is stuck for 500 seconds or so in Tez it looks to be stuck running the same method over and over again:8 duration=2561 from=org.apache.hadoop.hive.ql.exec.tez.RecordProcessor&gt;2015-05-18 19:58:41,719 INFO [TezChild] exec.Utilities: PLAN PATH = hdfs://xhadnnm1p.example.com:8020/tmp/hive/gss2002/dbc4b0b5-7859-4487-a56d-969440bc5e90/hive_2015-05-18_19-58-25_951_5497535752804149087-1/gss2002/_tez_scratch_dir/4e635121-c4cd-4e3f-b96b-9f08a6a7bf5d/map.xml2015-05-18 19:58:41,822 INFO [TezChild] exec.MapOperator: MAP[4]: records read - 12015-05-18 19:58:41,835 INFO [TezChild] io.HiveContextAwareRecordReader: Processing file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-000002015-05-18 19:58:41,848 INFO [TezChild] io.HiveContextAwareRecordReader: Processing file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-00000......2015-05-18 20:07:46,560 INFO [TezChild] io.HiveContextAwareRecordReader: Processing file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-000002015-05-18 20:07:46,574 INFO [TezChild] io.HiveContextAwareRecordReader: Processing file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-000002015-05-18 20:07:46,587 INFO [TezChild] io.HiveContextAwareRecordReader: Processing file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-000002015-05-18 20:07:46,603 INFO [TezChild] io.HiveContextAwareRecordReader: Processing file hdfs://xhadnnm1p.example.com:8020/example_dw/crc/arsn/part-m-000002015-05-18 20:07:46,603 INFO [TezChild] log.PerfLogger: &lt;/PERFLOG method=TezRunProcessor start=1431993518764 end=1431994066603 duration=547839 from=org.apache.hadoop.hive.ql.exec.tez.TezProcessor&gt;2015-05-18 20:07:46,603 INFO [TezChild] exec.MapOperator: 4 finished. closing... 2015-05-18 20:07:46,603 INFO [TezChild] exec.MapOperator: RECORDS_IN_Map_1:13440</description>
      <version>0.14.0,0.14.1,1.1.0,1.1.1,1.2.0</version>
      <fixedVersion>1.2.1,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.java</file>
    </fixedFiles>
  </bug>
  <bug id="10747" opendate="2015-5-19 00:00:00" fixdate="2015-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable the cleanup of side effect for the Encryption related qfile test</summary>
      <description>The hive conf is not reset in the clearTestSideEffects method which is involved from HIVE-8900. This will have pollute other qfile's settings running by TestEncryptedHDFSCliDriver</description>
      <version>None</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.QTestUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="10748" opendate="2015-5-19 00:00:00" fixdate="2015-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace StringBuffer with StringBuilder where possible</summary>
      <description>I found 40 places in Hive where "new StringBuffer(" is used."Where possible, it is recommended that StringBuilder be used in preference to StringBuffer as it will be faster under most implementations"https://docs.oracle.com/javase/7/docs/api/java/lang/StringBuilder.html</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.auth.HttpAuthUtils.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.lazy.TestLazySimpleSerDe.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.Worker.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.Initiator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.TableScanDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PlanUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.FilterDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.SparkProcessAnalyzeTable.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ProcessAnalyzeTable.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.spark.SparkReduceSinkMapJoinProc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ReduceSinkMapJoinProc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMRTableScan1.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.RelOptHiveTable.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizedBatchUtil.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezJobMonitor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.SparkJobMonitor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExplainTask.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HivePreparedStatement.java</file>
      <file type="M">hcatalog.streaming.src.test.org.apache.hive.hcatalog.streaming.TestStreaming.java</file>
      <file type="M">hcatalog.streaming.src.java.org.apache.hive.hcatalog.streaming.HiveEndPoint.java</file>
      <file type="M">hcatalog.streaming.src.java.org.apache.hive.hcatalog.streaming.DelimitedInputWriter.java</file>
      <file type="M">hcatalog.core.src.test.java.org.apache.hive.hcatalog.data.TestJsonSerDe.java</file>
      <file type="M">hcatalog.core.src.main.java.org.apache.hive.hcatalog.common.HCatException.java</file>
      <file type="M">common.src.test.org.apache.hadoop.hive.common.type.TestHiveVarchar.java</file>
      <file type="M">common.src.test.org.apache.hadoop.hive.common.type.TestHiveBaseChar.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.jsonexplain.tez.TezJsonParser.java</file>
    </fixedFiles>
  </bug>
  <bug id="1075" opendate="2010-1-20 00:00:00" fixdate="2010-1-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make it possible for users to recover data when moveTask fails</summary>
      <description>If a "INSERT OVERWRITE" query fails after deleting the output table content but before moving the new content into that output table, we should allow user to recover the data manually.In order to do that, we should expose the temp location of the data and we should not remove the temp data.</description>
      <version>None</version>
      <fixedVersion>0.6.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="10821" opendate="2015-5-26 00:00:00" fixdate="2015-6-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Beeline-CLI: Implement CLI source command using Beeline functionality</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">beeline.src.test.org.apache.hive.beeline.cli.TestHiveCli.java</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.Commands.java</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.BeeLine.java</file>
    </fixedFiles>
  </bug>
  <bug id="10835" opendate="2015-5-27 00:00:00" fixdate="2015-5-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Concurrency issues in JDBC driver</summary>
      <description>Though JDBC specification specifies that "Each Connection object can create multiple Statement objects that may be used concurrently by the program", but that does not work in current Hive JDBC driver. In addition, there also exist race conditions between DatabaseMetaData, Statement and ResultSet as long as they make RPC calls to HS2 using same Thrift transport, which happens within a connection.So we need a connection level lock to serialize all these RPC calls in a connection.</description>
      <version>0.13.0,0.13.1,0.14.0,0.14.1,0.15.0,1.0.0,1.0.1,1.1.0,1.1.1,1.2.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveStatement.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveQueryResultSet.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveConnection.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniHS2.java</file>
    </fixedFiles>
  </bug>
  <bug id="10841" opendate="2015-5-27 00:00:00" fixdate="2015-6-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[WHERE col is not null] does not work sometimes for queries with many JOIN statements</summary>
      <description>The result from the following SELECT query is 3 rows but it should be 1 row.I checked it in MySQL - it returned 1 row.To reproduce the issue in Hive1. prepare tablesdrop table if exists L;drop table if exists LA;drop table if exists FR;drop table if exists A;drop table if exists PI;drop table if exists acct;create table L as select 4436 id;create table LA as select 4436 loan_id, 4748 aid, 4415 pi_id;create table FR as select 4436 loan_id;create table A as select 4748 id;create table PI as select 4415 id;create table acct as select 4748 aid, 10 acc_n, 122 brn;insert into table acct values(4748, null, null);insert into table acct values(4748, null, null);2. run SELECT queryselect acct.ACC_N, acct.brnFROM LJOIN LA ON L.id = LA.loan_idJOIN FR ON L.id = FR.loan_idJOIN A ON LA.aid = A.idJOIN PI ON PI.id = LA.pi_idJOIN acct ON A.id = acct.aidWHERE L.id = 4436 and acct.brn is not null;the result is 3 rows10 122NULL NULLNULL NULLbut it should be 1 row10 1222.1 "explain select ..." output for hive-1.3.0 MRSTAGE DEPENDENCIES: Stage-12 is a root stage Stage-9 depends on stages: Stage-12 Stage-0 depends on stages: Stage-9STAGE PLANS: Stage: Stage-12 Map Reduce Local Work Alias -&gt; Map Local Tables: a Fetch Operator limit: -1 acct Fetch Operator limit: -1 fr Fetch Operator limit: -1 l Fetch Operator limit: -1 pi Fetch Operator limit: -1 Alias -&gt; Map Local Operator Tree: a TableScan alias: a Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: id is not null (type: boolean) Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE HashTable Sink Operator keys: 0 _col5 (type: int) 1 id (type: int) 2 aid (type: int) acct TableScan alias: acct Statistics: Num rows: 3 Data size: 31 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: aid is not null (type: boolean) Statistics: Num rows: 2 Data size: 20 Basic stats: COMPLETE Column stats: NONE HashTable Sink Operator keys: 0 _col5 (type: int) 1 id (type: int) 2 aid (type: int) fr TableScan alias: fr Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (loan_id = 4436) (type: boolean) Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE HashTable Sink Operator keys: 0 4436 (type: int) 1 4436 (type: int) 2 4436 (type: int) l TableScan alias: l Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (id = 4436) (type: boolean) Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE HashTable Sink Operator keys: 0 4436 (type: int) 1 4436 (type: int) 2 4436 (type: int) pi TableScan alias: pi Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: id is not null (type: boolean) Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE HashTable Sink Operator keys: 0 _col6 (type: int) 1 id (type: int) Stage: Stage-9 Map Reduce Map Operator Tree: TableScan alias: la Statistics: Num rows: 1 Data size: 14 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (((loan_id is not null and aid is not null) and pi_id is not null) and (loan_id = 4436)) (type: boolean) Statistics: Num rows: 1 Data size: 14 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 Inner Join 0 to 2 keys: 0 4436 (type: int) 1 4436 (type: int) 2 4436 (type: int) outputColumnNames: _col5, _col6 Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 Inner Join 1 to 2 keys: 0 _col5 (type: int) 1 id (type: int) 2 aid (type: int) outputColumnNames: _col6, _col19, _col20 Statistics: Num rows: 4 Data size: 17 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 keys: 0 _col6 (type: int) 1 id (type: int) outputColumnNames: _col19, _col20 Statistics: Num rows: 4 Data size: 18 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col19 (type: int), _col20 (type: int) outputColumnNames: _col0, _col1 Statistics: Num rows: 4 Data size: 18 Basic stats: COMPLETE Column stats: NONE File Output Operator compressed: false Statistics: Num rows: 4 Data size: 18 Basic stats: COMPLETE Column stats: NONE table: input format: org.apache.hadoop.mapred.TextInputFormat output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe Local Work: Map Reduce Local Work Stage: Stage-0 Fetch Operator limit: -1 Processor Tree: ListSinkTime taken: 0.57 seconds, Fetched: 142 row(s)2.2. "explain select..." output for hive-0.13.1 TezSTAGE DEPENDENCIES: Stage-1 is a root stage Stage-0 is a root stageSTAGE PLANS: Stage: Stage-1 Tez Edges: Reducer 2 &lt;- Map 1 (SIMPLE_EDGE), Map 4 (SIMPLE_EDGE), Reducer 6 (SIMPLE_EDGE) Reducer 3 &lt;- Reducer 2 (SIMPLE_EDGE), Map 9 (SIMPLE_EDGE) Reducer 6 &lt;- Map 5 (SIMPLE_EDGE), Map 7 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE) DagName: lcapp_20150528111717_06c57a5b-8dc6-4ce9-bce7-b9e0a7818fe4:1 Vertices: Map 1 Map Operator Tree: TableScan alias: acct Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: aid (type: int) sort order: + Map-reduce partition columns: aid (type: int) Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: NONE value expressions: acc_n (type: int), brn (type: int) Map 4 Map Operator Tree: TableScan alias: a Statistics: Num rows: 46 Data size: 187 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: id (type: int) sort order: + Map-reduce partition columns: id (type: int) Statistics: Num rows: 46 Data size: 187 Basic stats: COMPLETE Column stats: NONE Map 5 Map Operator Tree: TableScan alias: la Statistics: Num rows: 28 Data size: 347 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (loan_id = 4436) (type: boolean) Statistics: Num rows: 14 Data size: 173 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: loan_id (type: int) sort order: + Map-reduce partition columns: loan_id (type: int) Statistics: Num rows: 14 Data size: 173 Basic stats: COMPLETE Column stats: NONE value expressions: aid (type: int), pi_id (type: int) Map 7 Map Operator Tree: TableScan alias: fr Statistics: Num rows: 46 Data size: 187 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (loan_id = 4436) (type: boolean) Statistics: Num rows: 23 Data size: 93 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: loan_id (type: int) sort order: + Map-reduce partition columns: loan_id (type: int) Statistics: Num rows: 23 Data size: 93 Basic stats: COMPLETE Column stats: NONE Map 8 Map Operator Tree: TableScan alias: l Statistics: Num rows: 46 Data size: 187 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (id = 4436) (type: boolean) Statistics: Num rows: 23 Data size: 93 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: id (type: int) sort order: + Map-reduce partition columns: id (type: int) Statistics: Num rows: 23 Data size: 93 Basic stats: COMPLETE Column stats: NONE Map 9 Map Operator Tree: TableScan alias: pi Statistics: Num rows: 46 Data size: 187 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: id (type: int) sort order: + Map-reduce partition columns: id (type: int) Statistics: Num rows: 46 Data size: 187 Basic stats: COMPLETE Column stats: NONE Reducer 2 Reduce Operator Tree: Join Operator condition map: Inner Join 0 to 1 Inner Join 1 to 2 condition expressions: 0 {VALUE._col2} 1 2 {VALUE._col1} {VALUE._col2} outputColumnNames: _col2, _col15, _col16 Statistics: Num rows: 110 Data size: 448 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col2 (type: int) sort order: + Map-reduce partition columns: _col2 (type: int) Statistics: Num rows: 110 Data size: 448 Basic stats: COMPLETE Column stats: NONE value expressions: _col15 (type: int), _col16 (type: int) Reducer 3 Reduce Operator Tree: Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {VALUE._col1} {VALUE._col2} 1 outputColumnNames: _col1, _col2 Statistics: Num rows: 121 Data size: 492 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: int), _col2 (type: int) outputColumnNames: _col0, _col1 Statistics: Num rows: 121 Data size: 492 Basic stats: COMPLETE Column stats: NONE File Output Operator compressed: false Statistics: Num rows: 121 Data size: 492 Basic stats: COMPLETE Column stats: NONE table: input format: org.apache.hadoop.mapred.TextInputFormat output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe Reducer 6 Reduce Operator Tree: Join Operator condition map: Inner Join 0 to 1 Inner Join 0 to 2 condition expressions: 0 1 {VALUE._col1} {VALUE._col2} 2 outputColumnNames: _col4, _col5 Statistics: Num rows: 50 Data size: 204 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col4 (type: int) sort order: + Map-reduce partition columns: _col4 (type: int) Statistics: Num rows: 50 Data size: 204 Basic stats: COMPLETE Column stats: NONE value expressions: _col5 (type: int) Stage: Stage-0 Fetch Operator limit: -1Time taken: 1.377 seconds, Fetched: 146 row(s)3. The workaround is to put "acct.brn is not null" to join conditionselect acct.ACC_N, acct.brnFROM LJOIN LA ON L.id = LA.loan_idJOIN FR ON L.id = FR.loan_idJOIN A ON LA.aid = A.idJOIN PI ON PI.id = LA.pi_idJOIN acct ON A.id = acct.aid and acct.brn is not nullWHERE L.id = 4436;OK10 122Time taken: 23.479 seconds, Fetched: 1 row(s)I tried it on hive-1.3.0 (MR) and hive-0.13.1 (MR and Tez) - all combinations have the issue</description>
      <version>0.13.0,0.13.1,0.14.0,1.2.0,1.3.0</version>
      <fixedVersion>1.0.2,1.2.1,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="10842" opendate="2015-5-28 00:00:00" fixdate="2015-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: DAGs get stuck in yet another way</summary>
      <description>Looks exactly like HIVE-10744. Last comment there has internal app IDs. Logs upon request.6 (number of slots) tasks from a machine are stuck.jstack for target daemon sayeth: 7 Found one Java-level deadlock: 8 ============================= 9 10 "IPC Server handler 4 on 15001": 11 waiting to lock Monitor@0x00007f3cb0005cb8 (Object@0x000000008cc3ce98, a java/lang/Object), 12 which is held by "Wait-Queue-Scheduler-0" 13 "Wait-Queue-Scheduler-0": 14 waiting to lock Monitor@0x00007f3cb0004d98 (Object@0x000000009234cf58, a org/apache/hadoop/hive/llap/daemon/impl/Q ueryInfo$FinishableStateTracker), 15 which is held by "IPC Server handler 4 on 15001"Oh, this time it is not q1; I was running bunch of TPCDS queries in sequence for some cache test. No parallel queries. There may have been task failures before.The query that got stuck had lots and lots of reducersMap 1: 1/1 Map 10: 1/1 Map 11: 85/85 Map 13: 1/1 Map 14: 1/1 Map 15: 1/1 Map 16: 1/1 Map 17: 94/94 Map 19: 1/1 Map 2: 1/1 Map 20: 1/1 Map 3: 91/91 Map 7: 1/1 Map 8: 1/1 Map 9: 1/1 Reducer 12: 391/391 Reducer 18: 197/197 Reducer 4: 1009/1009 Reducer 5: 1003(+6)/1009 Reducer 6: 0(+1)/1I think it's query 58</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.TaskExecutorService.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.QueryInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="10843" opendate="2015-5-28 00:00:00" fixdate="2015-5-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>desc database and show tables commands don&amp;#39;t pass db to HiveAuthorizer check</summary>
      <description>'show tables' and 'describe database' command should pass the database information for the command to HiveAuthorizer . This is needed for any auditing the hive authorizer might implement, or any authorization check it might decide to do based on the given database name.</description>
      <version>None</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.temp.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.temp.table.names.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.temp.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.temp.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.show.tables.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rename.column.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.creation.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.encrypted.encryption.move.tbl.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.encrypted.encryption.drop.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.describe.table.json.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.describe.database.json.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.describe.database.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.dbtxnmgr.query5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.database.properties.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.database.location.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.database.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.create.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.authorization.owner.actions.db.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter.rename.partition.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter.index.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter.db.owner.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter.change.db.location.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.add.part.exist.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.ctas2.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizationValidator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerCheckInvocation.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.hooks.TestHs2Hooks.java</file>
      <file type="M">itests.hive-minikdc.src.test.java.org.apache.hive.minikdc.TestHs2HooksWithMiniKdc.java</file>
      <file type="M">contrib.src.test.results.clientpositive.url.hook.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="10896" opendate="2015-6-2 00:00:00" fixdate="2015-6-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: the return of the stuck DAG</summary>
      <description>Mapjoin issue again - preempted task that is loading the hashtable</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.util.FakeVectorDataSourceOperator.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.util.FakeCaptureOutputOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorSMBMapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorSelectOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorReduceSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorMapJoinOuterFilteredOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorMapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorMapJoinBaseOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorFilterOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorFileSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorAppMasterEventOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.mapjoin.VectorMapJoinCommonOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.UnionOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.UDTFOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.TableScanOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.SparkHashTableSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.SMBMapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.SelectOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ScriptOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.PTFOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Operator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MuxOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ListSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.LimitOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.LateralViewJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.LateralViewForwardOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.JoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.HashTableSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.HashTableDummyOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.GroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ForwardOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FilterOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FileSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DummyStoreOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DemuxOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.CommonJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.CollectOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.AppMasterEventOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.AbstractFileMergeOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="10925" opendate="2015-6-4 00:00:00" fixdate="2015-6-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Non-static threadlocals in metastore code can potentially cause memory leak</summary>
      <description>There are many places where non-static threadlocals are used. I can't seem to find a good logic for using them. However, they can potentially result in leaking objects if for example they are created in a long running thread every time the thread handles a new session.</description>
      <version>0.13.0,0.14.0,1.0.0,1.1.0,1.2.0</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="10927" opendate="2015-6-4 00:00:00" fixdate="2015-7-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add number of HMS/HS2 connection metrics</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.thrift.ThriftCLIService.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.ObjectStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.metastore.TestMetaStoreMetrics.java</file>
      <file type="M">common.src.test.org.apache.hadoop.hive.common.metrics.metrics2.TestCodahaleMetrics.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.metrics.LegacyMetrics.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.metrics.common.Metrics.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.JvmPauseMonitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="11027" opendate="2015-6-16 00:00:00" fixdate="2015-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive on tez: Bucket map joins fail when hashcode goes negative</summary>
      <description>Seeing an issue when dynamic sort optimization is enabled while doing an insert into bucketed table. We seem to be flipping the negative sign on the hashcode instead of taking the complement of it for routing the data correctly. This results in correctness issues in bucket map joins in hive on tez when the hash code goes negative.</description>
      <version>0.13.0,0.14.0,1.0.0</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="11029" opendate="2015-6-16 00:00:00" fixdate="2015-6-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hadoop.proxyuser.mapr.groups does not work to restrict the groups that can be impersonated</summary>
      <description>In the core-site.xml, the hadoop.proxyuser.&lt;user&gt;.groups specifies the user groups which can be impersonated by the HS2 &lt;user&gt;. However, this does not work properly in Hive. In my core-site.xml, I have the following configs:&lt;property&gt; &lt;name&gt;hadoop.proxyuser.mapr.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.mapr.groups&lt;/name&gt; &lt;value&gt;root&lt;/value&gt;&lt;/property&gt;I would expect with this configuration that 'mapr' can impersonate only members of the Unix group 'root'. However if I submit a query as user 'jon' the query is running as user 'jon' even though 'mapr' should not be able to impersonate this user.</description>
      <version>0.13.0,0.14.0,1.0.0,1.2.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.HiveSessionImplwithUGI.java</file>
    </fixedFiles>
  </bug>
  <bug id="1103" opendate="2010-1-26 00:00:00" fixdate="2010-2-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add .gitignore file</summary>
      <description>Add a .gitignore file (equivalent to svn:ignore) for those using git-svn.</description>
      <version>None</version>
      <fixedVersion>0.6.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11031" opendate="2015-6-17 00:00:00" fixdate="2015-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ORC concatenation of old files can fail while merging column statistics</summary>
      <description>Column statistics in ORC are optional protobuf fields. Old ORC files might not have statistics for newly added types like decimal, date, timestamp etc. But column statistics merging assumes column statistics exists for these types and invokes merge. For example, merging of TimestampColumnStatistics directly casts the received ColumnStatistics object without doing instanceof check. If the ORC file contains time stamp column statistics then this will work else it will throw ClassCastException.Also, the file merge operator swallows the exception.</description>
      <version>0.13.0,0.14.0,1.0.0,1.1.0,1.2.0,2.0.0</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcFileStripeMergeRecordReader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcFileKeyWrapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.ColumnStatisticsImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.OrcFileMergeOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="11035" opendate="2015-6-17 00:00:00" fixdate="2015-6-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PPD: Orc Split elimination fails because filterColumns=[-1]</summary>
      <description>create temporary table xx (x int) stored as orc ;insert into xx values (20),(200);set hive.fetch.task.conversion=none;select * from xx where x is null;This should generate zero tasks after optional split elimination in the app master, instead of generating the 1 task which for sure hits the row-index filters and removes all rows anyway.Right now, this runs 1 task for the stripe containing (min=20, max=200, has_null=false), which is broken.Instead, it returns YES_NO_NULL from the following default casehttps://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java#L976</description>
      <version>0.14.0,1.0.0,1.1.0,1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.ColumnProjectionUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="11055" opendate="2015-6-19 00:00:00" fixdate="2015-7-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HPL/SQL - Implementing Procedural SQL in Hive (PL/HQL Contribution)</summary>
      <description>There is PL/HQL tool (www.plhql.org) that implements procedural SQL for Hive (actually any SQL-on-Hadoop implementation and any JDBC source).Alan Gates offered to contribute it to Hive under HPL/SQL name (org.apache.hive.hplsql package). This JIRA is to create a patch to contribute the PL/HQL code.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11104" opendate="2015-6-25 00:00:00" fixdate="2015-6-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Select operator doesn&amp;#39;t propagate constants appearing in expressions</summary>
      <description></description>
      <version>0.14.0,1.0.0,1.1.0,1.2.0,1.2.1</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.vector.interval.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.round.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.coalesce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.top.level.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.interval.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.round.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.coalesce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.union.dynamic.partition.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.top.level.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join.cond.pushdown.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join.cond.pushdown.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.union.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.udf.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.load.dyn.part14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.13.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.12.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.insert.into5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.dynpart.sort.optimization.acid.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cluster.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.select.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.BucketingSortingReduceSinkOptimizer.java</file>
    </fixedFiles>
  </bug>
  <bug id="11107" opendate="2015-6-25 00:00:00" fixdate="2015-12-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support for Performance regression test suite with TPCDS</summary>
      <description>Support to add TPCDS queries to the performance regression test suite with Hive CBO turned on.This benchmark is intended to make sure that subsequent changes to the optimizer or any hive code do not yield any unexpected plan changes. i.e. the intention is to not run the entire TPCDS query set, but just "explain plan" for the TPCDS queries.As part of this jira, we will manually verify that expected hive optimizations kick in for the queries (for given stats/dataset). If there is a difference in plan within this test suite due to a future commit, it needs to be analyzed and we need to make sure that it is not a regression.The test suite can be run in master branch from itests by mvn test -Dtest=TestPerfCliDriver</description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.scripts.upgrade.derby.hive-schema-2.1.0.derby.sql</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.QTestUtil.java</file>
      <file type="M">itests.qtest.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11108" opendate="2015-6-25 00:00:00" fixdate="2015-6-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HashTableSinkOperator doesn&amp;#39;t support vectorization [Spark Branch]</summary>
      <description>This prevents any BaseWork containing HTS from being vectorized. It's basically specific to spark, because Tez doesn't use HTS and MR runs HTS in local tasks.We should verify if it makes sense to make HTS support vectorization.</description>
      <version>None</version>
      <fixedVersion>spark-branch,1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.mapjoin.reduce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.left.outer.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.decimal.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.nested.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.mapjoin.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.SparkHashTableSinkDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.spark.SparkReduceSinkMapJoinProc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.GenSparkSkewJoinProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.OperatorComparatorFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.SparkHashTableSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.OperatorFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="11132" opendate="2015-6-26 00:00:00" fixdate="2015-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Queries using join and group by produce incorrect output when hive.auto.convert.join=false and hive.optimize.reducededuplication=true</summary>
      <description>Queries using join and group by produce multiple output rows with the same key when hive.auto.convert.join=false and hive.optimize.reducededuplication=true. This interaction between configuration parameters is unexpected and should be well documented at the very least and should likely be considered a bug.e.g. hive&gt; set hive.auto.convert.join = false;hive&gt; set hive.optimize.reducededuplication = true;hive&gt; SELECT foo.id, count as factor &gt; FROM foo &gt; JOIN bar ON (foo.id = bar.id and foo.line_id = bar.line_id) &gt; JOIN split ON (foo.id = split.id and foo.line_id = split.line_id) &gt; JOIN forecast ON (foo.id = forecast.id AND foo.line_id = forecast.line_id) &gt; WHERE foo.order != ‘blah’ AND foo.id = ‘XYZ' &gt; GROUP BY foo.id;XYZ 79XYZ 74XYZ 297XYZ 66hive&gt; set hive.auto.convert.join = true;hive&gt; set hive.optimize.reducededuplication = true;hive&gt; SELECT foo.id, count as factor &gt; FROM foo &gt; JOIN bar ON (foo.id = bar.id and foo.line_id = bar.line_id) &gt; JOIN split ON (foo.id = split.id and foo.line_id = split.line_id) &gt; JOIN forecast ON (foo.id = forecast.id AND foo.line_id = forecast.line_id) &gt; WHERE foo.order != ‘blah’ AND foo.id = ‘XYZ' &gt; GROUP BY foo.id;XYZ 516</description>
      <version>0.14.0,1.0.0,1.1.0,1.2.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.correlation.ReduceSinkDeDuplication.java</file>
    </fixedFiles>
  </bug>
  <bug id="11134" opendate="2015-6-27 00:00:00" fixdate="2015-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HS2 should log open session failure</summary>
      <description>HiveServer2 should log OpenSession failure. If beeline is not running with "--verbose=true" all stack trace information is not available for later debugging, as it is not currently logged in server side.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.SessionManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="11150" opendate="2015-6-30 00:00:00" fixdate="2015-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove wrong warning message related to chgrp</summary>
      <description>When using other file system other than hdfs, users see warning message regarding hdfs chgrp. The warning is very annoying and confusing. We'd better remove it. The warning example:hive&gt; insert overwrite table s3_test select total_emp, salary, description from sample_07 limit 5;-chgrp: '' does not match expected pattern for groupUsage: hadoop fs [generic options] -chgrp [-R] GROUP PATH...Total jobs = 1Launching Job 1 out of 1Number of reduce tasks determined at compile time: 1In order to change the average load for a reducer (in bytes): set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</description>
      <version>0.13.0,0.14.0,1.0.0,1.2.0</version>
      <fixedVersion>1.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
    </fixedFiles>
  </bug>
  <bug id="11172" opendate="2015-7-2 00:00:00" fixdate="2015-7-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorization wrong results for aggregate query with where clause without group by</summary>
      <description>create table testvec(id int, dt int, greg_dt string) stored as orc;insert into table testvecvalues (1,20150330, '2015-03-30'),(2,20150301, '2015-03-01'),(3,20150502, '2015-05-02'),(4,20150401, '2015-04-01'),(5,20150313, '2015-03-13'),(6,20150314, '2015-03-14'),(7,20150404, '2015-04-04');hive&gt; select dt, greg_dt from testvec where id=5;OK20150313 2015-03-13Time taken: 4.435 seconds, Fetched: 1 row(s)hive&gt; set hive.vectorized.execution.enabled=true;hive&gt; set hive.map.aggr;hive.map.aggr=truehive&gt; select max(dt), max(greg_dt) from testvec where id=5;OK20150313 2015-03-30hive&gt; set hive.vectorized.execution.enabled=false;hive&gt; select max(dt), max(greg_dt) from testvec where id=5;OK20150313 2015-03-13</description>
      <version>0.14.0</version>
      <fixedVersion>1.2.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.gen.vectorization.UDAFTemplates.VectorUDAFMinMaxString.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11271" opendate="2015-7-15 00:00:00" fixdate="2015-7-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>java.lang.IndexOutOfBoundsException when union all with if function</summary>
      <description>Some queries with Union all as subquery fail in MapReduce task with stacktrace:15/07/15 14:19:30 [pool-13-thread-1]: INFO exec.UnionOperator: Initializing operator UNION[104]15/07/15 14:19:30 [Thread-72]: INFO mapred.LocalJobRunner: Map task executor complete.15/07/15 14:19:30 [Thread-72]: WARN mapred.LocalJobRunner: job_local826862759_0005java.lang.Exception: java.lang.RuntimeException: Error in configuring object at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:354)Caused by: java.lang.RuntimeException: Error in configuring object at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117) at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:426) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:366) at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:223) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88) ... 10 moreCaused by: java.lang.RuntimeException: Error in configuring object at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117) at org.apache.hadoop.mapred.MapRunner.configure(MapRunner.java:34) ... 14 moreCaused by: java.lang.reflect.InvocationTargetException at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88) ... 17 moreCaused by: java.lang.RuntimeException: Map operator initialization failed at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.configure(ExecMapper.java:140) ... 21 moreCaused by: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1 at java.util.ArrayList.rangeCheck(ArrayList.java:635) at java.util.ArrayList.get(ArrayList.java:411) at org.apache.hadoop.hive.ql.exec.UnionOperator.initializeOp(UnionOperator.java:86) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:362) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:481) at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:438) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:375) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:481) at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:438) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:375) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:481) at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:438) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:375) at org.apache.hadoop.hive.ql.exec.MapOperator.initializeMapOperator(MapOperator.java:442) at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.configure(ExecMapper.java:119) ... 21 moreReproduce:create table if not exists union_all_bug_test_1 ( f1 int,f2 int); create table if not exists union_all_bug_test_2 ( f1 int ); SELECT f1 FROM ( SELECT f1 , if('helloworld' like '%hello%' ,f1,f2) as filter FROM union_all_bug_test_1 union all select f1 , 0 as filter from union_all_bug_test_2 ) A WHERE (filter = 1);</description>
      <version>0.14.0,1.0.0,1.2.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcCtx.java</file>
    </fixedFiles>
  </bug>
  <bug id="11272" opendate="2015-7-15 00:00:00" fixdate="2015-8-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: Execution order within LLAP daemons should consider query-specific priority assigned to fragments</summary>
      <description>It's currently looking at finishable state, start time and vertex parallelism. Vertex parallelism can be replaced by upstream parallelism as well.</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.daemon.impl.TestTaskExecutorService2.java</file>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.daemon.impl.TestTaskExecutorService.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.TaskExecutorService.java</file>
    </fixedFiles>
  </bug>
  <bug id="11273" opendate="2015-7-16 00:00:00" fixdate="2015-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: Register for finishable state change notifications when adding a task instead of when scheduling it</summary>
      <description>Registering when trying to execute is far too late. The task won't be considered for execution (queue may not be re-oredered) without the notification coming in.</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.daemon.impl.TestTaskExecutorService.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.TaskExecutorService.java</file>
    </fixedFiles>
  </bug>
  <bug id="113" opendate="2008-12-4 00:00:00" fixdate="2008-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>support of distribute by and sort by</summary>
      <description>Currently Hive supports "cluster by" which puts the columns into map-reduce key. Hadoop map-reduce actually allows different partitioning (we call distribute) keys and sorting keys.In Hive language, we will add "distribute by" for specifying the partition key, and "sort by" for specifying the sort key. "cluster by" will be a short-cut for "distribute by" and "sort by" with the same keys.</description>
      <version>None</version>
      <fixedVersion>0.3.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11319" opendate="2015-7-20 00:00:00" fixdate="2015-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CTAS with location qualifier overwrites directories</summary>
      <description>CTAS with location clause acts as an insert overwrite. This can cause problems when there sub directories with in a directory.This cause some users accidentally wipe out directories with very important data. We should ban CTAS with location to a non-empty directory. Reproduce:create table ctas1 location '/Users/ychen/tmp' as select * from jsmall limit 10;create table ctas2 location '/Users/ychen/tmp' as select * from jsmall limit 5;Both creates will succeed. But value in table ctas1 will be replaced by ctas2 accidentally.</description>
      <version>0.14.0,1.0.0,1.2.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.ErrorMsg.java</file>
    </fixedFiles>
  </bug>
  <bug id="1134" opendate="2010-2-5 00:00:00" fixdate="2010-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>bucketing mapjoin where the big table contains more than 1 big partition</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.6.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin1.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.bucketmapjoin4.q</file>
      <file type="M">ql.src.test.queries.clientpositive.bucketmapjoin3.q</file>
      <file type="M">ql.src.test.queries.clientpositive.bucketmapjoin2.q</file>
      <file type="M">ql.src.test.queries.clientpositive.bucketmapjoin1.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.MapredWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.MapredLocalWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.BucketMapJoinOptimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExecMapper.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11385" opendate="2015-7-27 00:00:00" fixdate="2015-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: clean up ORC dependencies - move encoded reader path into a separate package and reader</summary>
      <description>Before there's storage handler module, we can clean some things upNO PRECOMMIT TESTS</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestRecordReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.StreamUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.StreamName.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.SettableUncompressedStream.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.ReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.Reader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OutStream.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcFile.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.MetadataReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.llap.OrcCacheKey.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.llap.OrcBatchKey.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.llap.Consumer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.InStream.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.EncodedTreeReaderFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.EncodedReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.EncodedReader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.llap.DebugUtils.java</file>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.cache.TestLowLevelCacheImpl.java</file>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.cache.TestIncrementalObjectSizeEstimator.java</file>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.cache.TestBuddyAllocator.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.metadata.OrcStripeMetadata.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.decode.OrcColumnVectorProducer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.decode.EncodedDataConsumer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.decode.ColumnVectorProducer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.NoopCache.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LowLevelCacheImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LowLevelCache.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LlapDataBuffer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.EvictionAwareAllocator.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.Cache.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.BuddyAllocator.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.io.storage.api.MemoryBuffer.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.io.storage.api.EncodedColumnBatch.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.io.storage.api.DataReader.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.io.storage.api.DataCache.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.io.storage.api.Allocator.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.DiskRangeList.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.DiskRangeInfo.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.DiskRange.java</file>
    </fixedFiles>
  </bug>
  <bug id="11387" opendate="2015-7-28 00:00:00" fixdate="2015-8-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Calcite Operator To Hive Operator (Calcite Return Path) : fix reduce_deduplicate optimization</summary>
      <description>The main problem is that, due to return path, now we may have (RS1-GBY2)&amp;#45;(RS3-GBY4) when map.aggr=false, i.e., no map aggr. However, in the non-return path, it will be treated as (RS1)-(GBY2-RS3-GBY4). The main problem is that it does not take into account of the setting.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.6.subq.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.explainuser.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.6.subq.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.move.tasks.share.dependencies.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.multi.insert.move.tasks.share.dependencies.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.correlation.ReduceSinkDeDuplication.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.correlation.CorrelationUtilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.correlation.AbstractCorrelationProcCtx.java</file>
    </fixedFiles>
  </bug>
  <bug id="11409" opendate="2015-7-30 00:00:00" fixdate="2015-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Calcite Operator To Hive Operator (Calcite Return Path): add SEL before UNION</summary>
      <description>Two purpose: (1) to ensure that the data type of non-primary branch (the 1st branch is the primary branch) of union can be casted to that of the primary branch; (2) to make UnionProcessor optimizer work; (3) if the SEL is redundant, it will be removed by IdentidyProjectRemover optimizer.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.translator.HiveOpConverter.java</file>
    </fixedFiles>
  </bug>
  <bug id="11417" opendate="2015-7-30 00:00:00" fixdate="2015-5-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create shims for the row by row read path that is backed by VectorizedRowBatch</summary>
      <description>I'd like to make the default path for reading and writing ORC files to be vectorized. To ensure that Hive can still read row by row, we'll need shims to support the old API.</description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestStringDictionary.java</file>
      <file type="M">storage-api.src.java.org.apache.hadoop.hive.ql.io.sarg.SearchArgumentImpl.java</file>
      <file type="M">storage-api.src.java.org.apache.hadoop.hive.ql.exec.vector.TimestampColumnVector.java</file>
      <file type="M">shims.common.src.main.java.org.apache.hadoop.hive.shims.HadoopShimsSecure.java</file>
      <file type="M">shims.common.src.main.java.org.apache.hadoop.hive.shims.HadoopShims.java</file>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.ZeroCopyShims.java</file>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.io.TestTimestampWritable.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.io.TimestampWritable.java</file>
      <file type="M">ql.src.test.results.clientpositive.vector.complex.all.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.schema.evol.orc.vec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schema.evol.orc.vec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.int.type.promotion.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.create.q.out</file>
      <file type="M">ql.src.test.resources.orc-file-has-null.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump.json</file>
      <file type="M">ql.src.test.resources.orc-file-dump-dictionary-threshold.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump-bloomfilter2.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump-bloomfilter.out</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.TestTxnCommands.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestVectorOrcFile.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestTypeDescription.java</file>
      <file type="M">bin.ext.orcfiledump.cmd</file>
      <file type="M">bin.ext.orcfiledump.sh</file>
      <file type="M">hcatalog.streaming.src.test.org.apache.hive.hcatalog.streaming.TestStreaming.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata.java</file>
      <file type="M">orc.pom.xml</file>
      <file type="M">orc.src.java.org.apache.orc.impl.HadoopShims.java</file>
      <file type="M">orc.src.java.org.apache.orc.impl.HadoopShimsCurrent.java</file>
      <file type="M">orc.src.java.org.apache.orc.impl.HadoopShims.2.2.java</file>
      <file type="M">orc.src.java.org.apache.orc.impl.IntegerReader.java</file>
      <file type="M">orc.src.java.org.apache.orc.OrcFile.java</file>
      <file type="M">orc.src.java.org.apache.orc.Reader.java</file>
      <file type="M">orc.src.java.org.apache.orc.TypeDescription.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.CastDecimalToTimestamp.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.CastDoubleToTimestamp.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.CastLongToTimestamp.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.CastMillisecondsLongToTimestamp.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.StringExpr.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.hooks.PostExecOrcFileDump.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.FileFormatException.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.ConvertTreeReaderFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.encoded.EncodedTreeReaderFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.FileDump.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.JsonFileDump.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcRecordUpdater.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.ReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.SchemaEvolution.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.TreeReaderFactory.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorTypeCasts.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestTimestampWritableAndColumnVector.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.udf.TestVectorUDFAdaptor.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestColumnStatistics.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestFileDump.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestJsonFileDump.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcFile.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcNullOptimization.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcRecordUpdater.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone1.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcTimezone2.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcWideTable.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestReaderImpl.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestRecordReaderImpl.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestRLEv2.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestStreamName.java</file>
    </fixedFiles>
  </bug>
  <bug id="11429" opendate="2015-7-31 00:00:00" fixdate="2015-8-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase default JDBC result set fetch size (# rows it fetches in one RPC call) to 1000 from 50</summary>
      <description>This is in addition to HIVE-10982 which plans to make the fetch size customizable. This just bumps the default to 1000.</description>
      <version>0.14.0,1.0.0,1.2.0,1.2.1</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveStatement.java</file>
    </fixedFiles>
  </bug>
  <bug id="11461" opendate="2015-8-5 00:00:00" fixdate="2015-8-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Transform flat AND/OR into IN struct clause</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.vectorized.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.explainuser.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ppd.transform.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.pcr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.transform.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.pcr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.flatten.and.or.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.filter.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter.partition.coltype.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.annotate.stats.deep.filters.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.FilterDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ppr.OpProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.Optimizer.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="11482" opendate="2015-8-6 00:00:00" fixdate="2015-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add retrying thrift client for HiveServer2</summary>
      <description>Similar to https://github.com/apache/hive/blob/master/metastore/src/java/org/apache/hadoop/hive/metastore/RetryingMetaStoreClient.java, this improvement request is to add a retrying thrift client for HiveServer2 to do retries upon thrift exceptions.Here are few commits done on a forked branch that can be picked - https://github.com/InMobi/hive/commit/7fb957fb9c2b6000d37c53294e256460010cb6b7https://github.com/InMobi/hive/commit/11e4b330f051c3f58927a276d562446761c9cd6dhttps://github.com/InMobi/hive/commit/241386fd870373a9253dca0bcbdd4ea7e665406c</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="11483" opendate="2015-8-6 00:00:00" fixdate="2015-3-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add encoding and decoding for query string config</summary>
      <description>We have seen some queries in production where some of the literals passed in the query have control characters, which result in exception when query string is set in the job xml.Proposing a solution to encode the query string in configuration and provide getters decoded string.Here is a commit in a forked repo : https://github.com/InMobi/hive/commit/2faf5761191fa3103a0d779fde584d494ed75bf5Suggestions are welcome on the solution.</description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.hooks.TestHooks.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.errors.TestTaskLogProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.ExecDriver.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.errors.TaskLogProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">common.src.test.org.apache.hadoop.hive.conf.TestHiveConf.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="11484" opendate="2015-8-6 00:00:00" fixdate="2015-4-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix ObjectInspector for Char and VarChar</summary>
      <description>The creation of HiveChar and Varchar is not happening through ObjectInspector.Here is fix we pushed internally : https://github.com/InMobi/hive/commit/fe95c7850e7130448209141155f28b25d3504216</description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.objectinspector.TestStandardObjectInspectors.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.objectinspector.TestObjectInspectorConverters.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaHiveVarcharObjectInspector.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaHiveCharObjectInspector.java</file>
      <file type="M">common.src.test.org.apache.hadoop.hive.common.type.TestHiveBaseChar.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.type.HiveVarchar.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.type.HiveBaseChar.java</file>
    </fixedFiles>
  </bug>
  <bug id="11499" opendate="2015-8-7 00:00:00" fixdate="2015-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Datanucleus leaks classloaders when used using embedded metastore with HiveServer2 with UDFs</summary>
      <description>When UDFs are used, we create a new classloader to add the UDF jar. Similar to what hadoop's reflection utils does(HIVE-11408), datanucleus caches the classloaders (https://github.com/datanucleus/datanucleus-core/blob/3.2/src/java/org/datanucleus/NucleusContext.java#L161). JDOPersistanceManager factory (1 per JVM) holds on to a NucleusContext reference (https://github.com/datanucleus/datanucleus-api-jdo/blob/3.2/src/java/org/datanucleus/api/jdo/JDOPersistenceManagerFactory.java#L115). Until we call NucleusContext#close, the classloader cache is not cleared. In case of UDFs this can lead to permgen leak, as shown in the attached screenshot, where NucleusContext holds on to several URLClassloader objects.</description>
      <version>0.14.0,1.0.0,1.1.0,1.1.1,1.2.0,1.2.1</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.ObjectStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.IMetaStoreClient.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStoreClient.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniHS2.java</file>
    </fixedFiles>
  </bug>
  <bug id="1150" opendate="2010-2-10 00:00:00" fixdate="2010-2-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add comment to explain why we check for dir first in add_partitions().</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.6.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="11510" opendate="2015-8-10 00:00:00" fixdate="2015-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Metatool updateLocation warning on views</summary>
      <description>If views are present in a hive database, issuing a 'hive metatool -updateLocation' command will result in an error like this:...Warning: Found records with bad LOCATION in SDS table.. bad location URI: nullbad location URI: nullbad location URI: null....Based on the source code for Metatool, it looks like there would then be a "bad location URI: null" message for every view and it also appears this is happening simply because the 'sds' table in the hive schema has a column called location that is NULL only for views.</description>
      <version>0.14.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.tools.HiveMetaTool.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.ObjectStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="11525" opendate="2015-8-11 00:00:00" fixdate="2015-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bucket pruning</summary>
      <description>Logically and functionally bucketing and partitioning are quite similar - both provide mechanism to segregate and separate the table's data based on its content. Thanks to that significant further optimisations like &amp;#91;partition&amp;#93; PRUNING or &amp;#91;bucket&amp;#93; MAP JOIN are possible.The difference seems to be imposed by design where the PARTITIONing is open/explicit while BUCKETing is discrete/implicit.Partitioning seems to be very common if not a standard feature in all current RDBMS while BUCKETING seems to be HIVE specific only.In a way BUCKETING could be also called by "hashing" or simply "IMPLICIT PARTITIONING".Regardless of the fact that these two are recognised as two separate features available in Hive there should be nothing to prevent leveraging same existing query/join optimisations across the two.BUCKET pruningEnable partition PRUNING equivalent optimisation for queries on BUCKETED tablesSimplest example is for queries like:"SELECT … FROM x WHERE colA=123123"to read only the relevant bucket file rather than all file-buckets that belong to a table.</description>
      <version>0.13.0,0.13.1,0.14.0,1.0.0,1.1.0,1.2.0,1.3.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.TableScanDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.MapWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.GenTezUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.Optimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="11526" opendate="2015-8-11 00:00:00" fixdate="2015-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: implement LLAP UI as a separate service - part 1</summary>
      <description>The specifics are vague at this point. Hadoop metrics can be output, as well as metrics we collect and output in jmx, as well as those we collect per fragment and log right now. This service can do LLAP-specific views, and per-query aggregation.gopalv may have some information on how to reuse existing solutions for part of the work.</description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">LICENSE</file>
      <file type="M">llap-server.src.main.resources.webapps.llap.js.jquery.min.js</file>
      <file type="M">llap-server.src.main.resources.webapps.llap.fonts.glyphicons-halflings-regular.woff</file>
      <file type="M">llap-server.src.main.resources.webapps.llap.fonts.glyphicons-halflings-regular.ttf</file>
      <file type="M">llap-server.src.main.resources.webapps.llap.fonts.glyphicons-halflings-regular.svg</file>
      <file type="M">llap-server.src.main.resources.webapps.llap.fonts.glyphicons-halflings-regular.eot</file>
      <file type="M">llap-server.src.main.resources.webapps.llap.css.hive.css</file>
      <file type="M">llap-server.src.main.resources.webapps.llap.css.bootstrap.min.css</file>
      <file type="M">llap-server.src.main.resources.webapps.llap.css.bootstrap-theme.min.css</file>
    </fixedFiles>
  </bug>
  <bug id="11583" opendate="2015-8-17 00:00:00" fixdate="2015-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>When PTF is used over a large partitions result could be corrupted</summary>
      <description>Dataset: Window has 50001 record (2 blocks on disk and 1 block in memory) Size of the second block is &gt;32Mb (2 splits)Result:When the last block is read from the disk only first split is actually loaded. The second split gets missed. The total count of the result dataset is correct, but some records are missing and another are duplicated.Example:CREATE TABLE ptf_big_src ( id INT, key STRING, grp STRING, value STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';LOAD DATA LOCAL INPATH '../../data/files/ptf_3blocks.txt.gz' OVERWRITE INTO TABLE ptf_big_src;SELECT grp, COUNT(1) cnt FROM ptf_big_trg GROUP BY grp ORDER BY cnt desc;----- A 25000-- B 20000-- C 5001---CREATE TABLE ptf_big_trg AS SELECT *, row_number() OVER (PARTITION BY key ORDER BY grp) grp_num FROM ptf_big_src;SELECT grp, COUNT(1) cnt FROM ptf_big_trg GROUP BY grp ORDER BY cnt desc;-- -- A 34296-- B 15704-- C 1---Counts by 'grp' are incorrect!</description>
      <version>0.13.1,0.14.0,0.14.1,1.0.0,1.2.0,1.2.1</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.persistence.TestPTFRowContainer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.RowContainer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.PTFRowContainer.java</file>
    </fixedFiles>
  </bug>
  <bug id="11654" opendate="2015-8-26 00:00:00" fixdate="2015-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>After HIVE-10289, HBase metastore tests failing</summary>
      <description>After the latest merge from trunk a number of the HBase unit tests are failing.</description>
      <version>None</version>
      <fixedVersion>hbase-metastore-branch,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.hbase.TestHBaseStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.hbase.HBaseUtils.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.hbase.HBaseStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.hbase.HBaseReadWrite.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.metastore.hbase.TestHBaseAggrStatsCacheIntegration.java</file>
    </fixedFiles>
  </bug>
  <bug id="11655" opendate="2015-8-26 00:00:00" fixdate="2015-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>clean build on the branch appears to be broken</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">storage-api.src.java.org.apache.hadoop.hive.common.io.DiskRangeList.java</file>
    </fixedFiles>
  </bug>
  <bug id="11664" opendate="2015-8-27 00:00:00" fixdate="2015-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make tez container logs work with new log4j2 changes</summary>
      <description>MiniTezCliDriver should log container logs to syslog file. With new log4j2 changes this file is not created anymore.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">data.conf.tez.hive-site.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11695" opendate="2015-8-31 00:00:00" fixdate="2015-9-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>If user have no permission to create LOCAL DIRECTORY ，the Hql does not throw any exception and fail silently.</summary>
      <description>If user have no permission to create LOCAL DIRECTORY such as "/data/wangmeng/hiveserver2" ,the query does not throw any exception and fail silently.</description>
      <version>0.13.0,0.14.0,1.0.0,1.1.0,1.2.0,1.2.1</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MoveTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="11724" opendate="2015-9-3 00:00:00" fixdate="2015-9-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebHcat get jobs to order jobs on time order with latest at top</summary>
      <description>HIVE-5519 added pagination feature support to WebHcat. This implementation returns the jobs lexicographically resulting in older jobs showing at the top. Improvement is to order them on time with latest at top. Typically latest jobs (or running) ones are more relevant to the user. Time based ordering with pagination makes more sense.</description>
      <version>0.14.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.Server.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.AppConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="11729" opendate="2015-9-4 00:00:00" fixdate="2015-9-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: update to use Tez 0.8</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="11783" opendate="2015-9-10 00:00:00" fixdate="2015-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extending HPL/SQL parser</summary>
      <description>Need to extend procedural SQL parser and synchronize code base by adding PART_COUNT, PART_COUNT_BY functions as well as CMP ROW_COUNT, CMP SUM and COPY TO HDFS statements.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hplsql.src.test.results.db.select.into.out.txt</file>
      <file type="M">hplsql.src.test.queries.db.select.into.sql</file>
      <file type="M">hplsql.src.test.java.org.apache.hive.hplsql.TestHplsqlOffline.java</file>
      <file type="M">hplsql.src.test.java.org.apache.hive.hplsql.TestHplsqlLocal.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.Var.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.Stmt.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.Select.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.Query.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.Meta.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.functions.FunctionMisc.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.functions.Function.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.File.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.Expression.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.Exec.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.Copy.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.Conn.java</file>
      <file type="M">hplsql.src.main.java.org.apache.hive.hplsql.Column.java</file>
      <file type="M">hplsql.src.main.antlr4.org.apache.hive.hplsql.Hplsql.g4</file>
    </fixedFiles>
  </bug>
  <bug id="11825" opendate="2015-9-15 00:00:00" fixdate="2015-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>get_json_object(col,&amp;#39;$.a&amp;#39;) is null in where clause didn`t work</summary>
      <description>example:select attr from raw_kafka_item_dt0 where l_date='2015-09-06' and customer='Czgc_news' and get_json_object(attr,'$.title') is NULL limit 10;but in results,title is still not null!{"title":"思科Q4收入估$79.2亿 前景阴云笼罩","ItemType":"NewsBase","keywords":"思科Q4收入估\$79.2亿 前景阴云笼罩","random":"1420253511075","callback":"BCore.instances[2].callbacks[1]","user_agent":"Mozilla/5.0 (iPhone; U; CPU iPhone OS 4_2_1 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML; like Gecko) Version/5.0.2 Mobile/8C148 Safari/6533.18.5","is_newgid":"false","uuid":"DS.Input:b56c782bcb75035d:00002116:003dcd40:54a75947","ptime":"1.1549997E9"} attr is a dict</description>
      <version>0.14.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.UDFJson.java</file>
    </fixedFiles>
  </bug>
  <bug id="11978" opendate="2015-9-28 00:00:00" fixdate="2015-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: NPE in Expr toString</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.java</file>
    </fixedFiles>
  </bug>
  <bug id="11988" opendate="2015-9-29 00:00:00" fixdate="2015-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[hive] security issue with hive &amp; ranger for import table command</summary>
      <description>if a user does not have permission to create table in hive , then if the same user import data for a table using following command then , it will have to create table also and that is working successfully , ideally it should not workSTR:====1. put some raw data in hdfs path /user/user1/tempdata2. in ranger check policy , user1 should not have any permission on any table3. login through user1 into beeline ( obviously it will fail since user doesnt have permission to create table)create table tt1(id INT,ff String);FAILED: HiveAccessControlException Permission denied: user user1 does not have CREATE privilege on default/tt1 (state=42000,code=40000)4. now try following command to import data into a table ( table should not exist already)import table tt1 from '/user/user1/tempdata';ER:since user1 doesnt have permission to create table so this operation should failAR:table is created successfully and data is also imported !!</description>
      <version>0.14.0,1.2.1</version>
      <fixedVersion>1.2.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.spark.import.exported.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.repl.2.exim.basic.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.import.exported.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.hidden.files.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.24.import.nonexist.authsuccess.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.20.part.managed.location.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.19.part.external.location.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.19.00.part.external.location.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.18.part.external.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.13.managed.location.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.12.external.location.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.11.managed.external.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.10.external.managed.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.08.nonpart.rename.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.06.one.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.05.some.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.04.evolved.parts.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.04.all.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.02.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.02.00.part.empty.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.01.nonpart.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.00.nonpart.empty.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.uri.import.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.Operation2Privilege.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ImportSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizationValidatorForTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="11990" opendate="2015-9-29 00:00:00" fixdate="2015-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Loading data inpath from a temporary table dir fails on Windows</summary>
      <description>The query runs:load data inpath 'wasb:///tmp/testtemptable/temptablemisc_5/data' overwrite into table temp2;It fails with:FAILED: SemanticException [Error 10028]: Line 2:37 Path is not legal ''wasb:///tmp/testtemptable/temptablemisc_5/data'': Move from: wasb://humb23-hive1@humboldttesting3.blob.core.windows.net/tmp/testtemptable/temptablemisc_5/data to: hdfs://headnode0.humb23-hive1-ssh.h2.internal.cloudapp.net:8020/tmp/hive/hrt_qa/0d5f8b31-5908-44bf-ae4c-9eee956da066/_tmp_space.db/75b44252-42a7-4d28-baf8-4977daa5d49c is not valid. Please check that values for params "default.fs.name" and "hive.metastore.warehouse.dir" do not conflict.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="12058" opendate="2015-10-7 00:00:00" fixdate="2015-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change hive script to record errors when calling hbase fails</summary>
      <description>By default hive will try to find out which jars need to be added to the classpath in order to run MR jobs against an HBase cluster, however if hbase can't be found or if hbase mapredcp fails, the hive script will fail silently and ignore some of the jars to be included into the. That makes very difficult to analyze the real problem.Hive script should record the error not just simply redirect two hbase failures:HBASE_BIN=${HBASE_BIN:-"$(which hbase 2&gt;/dev/null)"}$HBASE_BIN mapredcp 2&gt;/dev/null</description>
      <version>0.14.0,1.1.0,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hive</file>
    </fixedFiles>
  </bug>
  <bug id="12059" opendate="2015-10-7 00:00:00" fixdate="2015-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Clean up reference to deprecated constants in AvroSerdeUtils</summary>
      <description>AvroSerdeUtils contains several deprecated String constants that are used by other Hive modules. Those should be cleaned up.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestAvroSerdeUtils.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestAvroSerde.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.avro.AvroGenericRecordReader.java</file>
      <file type="M">hbase-handler.src.test.org.apache.hadoop.hive.hbase.TestHBaseSerDe.java</file>
      <file type="M">hbase-handler.src.java.org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory.java</file>
      <file type="M">hbase-handler.src.java.org.apache.hadoop.hive.hbase.HBaseSerDeParameters.java</file>
      <file type="M">hbase-handler.src.java.org.apache.hadoop.hive.hbase.HBaseSerDeHelper.java</file>
    </fixedFiles>
  </bug>
  <bug id="12060" opendate="2015-10-7 00:00:00" fixdate="2015-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: create separate variable for llap tests</summary>
      <description>No real reason to just reuse tez one; also needed to parallelize the tests</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
      <file type="M">itests.qtest.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12062" opendate="2015-10-7 00:00:00" fixdate="2015-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>enable HBase metastore file metadata cache for tez tests</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.CommandProcessorFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezSessionState.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.QTestUtil.java</file>
      <file type="M">data.conf.tez.hive-site.xml</file>
    </fixedFiles>
  </bug>
  <bug id="12076" opendate="2015-10-9 00:00:00" fixdate="2015-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebHCat listing jobs after the given JobId even when templeton.jobs.listorder is set to lexicographicaldesc</summary>
      <description>HIVE-11724 introduced new setting to change the order of jobs listed. In-cases where "templeton.jobs.listorder" is set to lexicographicaldesc, filtering based on jobid still returning values greater then given job if, where as less than are expected. Its a code bug.</description>
      <version>0.14.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.Server.java</file>
    </fixedFiles>
  </bug>
  <bug id="12077" opendate="2015-10-9 00:00:00" fixdate="2015-8-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MSCK Repair table should fix partitions in batches</summary>
      <description>If a user attempts to run MSCK REPAIR TABLE on a directory with a large number of untracked partitions HMS will OOME. I suspect this is because it attempts to do one large bulk load in an effort to save time. Ultimately this can lead to a collection so large in size that HMS eventually hits an Out of Memory Exception. Instead I suggest that Hive include a configurable batch size that HMS can use to break up the load.</description>
      <version>None</version>
      <fixedVersion>2.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="12078" opendate="2015-10-9 00:00:00" fixdate="2015-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: document config settings</summary>
      <description>From HIVE-12060:There's a typo in the description of hive.tez.input.generate.consistent.splits: "Whether to generate consisten split" – need "t" for consistent.Several of the new hive.llap.* configs don't have descriptions. Are they for internal use only?Please add newlines (\n) in the description of hive.llap.queue.metrics.percentiles.intervals and keep the indentation identical for all three lines of the description. (And to pick a nit, a few config description indentations are off by one character, including that one.)</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="12244" opendate="2015-10-23 00:00:00" fixdate="2015-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactoring code for avoiding of comparison of Strings and do comparison on Path</summary>
      <description>In Hive often String is used for representation path and it causes new issues.We need to compare it with equals() but comparing Strings often is not right in terms comparing paths .I think if we use Path from org.apache.hadoop.fs we will avoid new problems in future.</description>
      <version>0.13.0,0.14.0,1.0.0,1.2.1</version>
      <fixedVersion>2.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.TestSymlinkTextInputFormat.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.plan.TestConditionalResolverCommonJoin.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.FileUtils.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.AbstractMapOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.ExecDriver.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkDynamicPartitionPruner.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DynamicPartitionPruner.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.SplitGrouper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatchCtx.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.index.HiveIndexedInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.avro.AvroGenericRecordReader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.HiveInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.IOPrepareCache.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.merge.MergeFileWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.parquet.ProjectionPusher.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.rcfile.stats.PartialScanWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.rcfile.truncate.ColumnTruncateWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.SymbolicInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.AbstractJoinTaskDispatcher.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.CommonJoinTaskDispatcher.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.GenMRSkewJoinProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.GenSparkSkewJoinProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.LlapDecider.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.NullScanTaskDispatcher.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.SortMergeJoinTaskDispatcher.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.spark.SparkSkewJoinProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ConditionalResolverCommonJoin.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.MapWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PartitionDesc.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestExecDriver.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestOperators.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestPlan.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestUtilities.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.tez.TestTezTask.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.TestCombineHiveInputFormat.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.TestHiveBinarySearchRecordReader.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.TestHiveFileFormatUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="12245" opendate="2015-10-23 00:00:00" fixdate="2015-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support column comments for an HBase backed table</summary>
      <description>Currently the column comments of an HBase backed table are always returned as "from deserializer". For example,CREATE TABLE hbasetbl (key string comment 'It is key', state string comment 'It is state', country string comment 'It is country', country_id int comment 'It is country_id')STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'WITH SERDEPROPERTIES ("hbase.columns.mapping" = "info:state,info:country,info:country_id");hive&gt; describe hbasetbl;key string from deserializer state string from deserializer country string from deserializer country_id int from deserializer</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-handler.src.test.results.positive.hbase.timestamp.format.q.out</file>
      <file type="M">hbase-handler.src.test.results.positive.hbase.timestamp.q.out</file>
      <file type="M">hbase-handler.src.test.results.positive.hbase.queries.q.out</file>
      <file type="M">hbase-handler.src.test.results.positive.hbase.binary.storage.queries.q.out</file>
      <file type="M">hbase-handler.src.test.results.positive.external.table.ppd.q.out</file>
      <file type="M">hbase-handler.src.test.queries.positive.hbase.queries.q</file>
      <file type="M">hbase-handler.src.java.org.apache.hadoop.hive.hbase.HBaseSerDe.java</file>
      <file type="M">hbase-handler.src.java.org.apache.hadoop.hive.hbase.HBaseLazyObjectFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="12253" opendate="2015-10-23 00:00:00" fixdate="2015-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>revert HIVE-12061</summary>
      <description>Breaks the build on HiveQA. I cannot repro these build errors.</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.DummyRawStoreForJdoConnection.java</file>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.DummyRawStoreControlledCommit.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.RawStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.ObjectStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.hbase.HBaseStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.hbase.HBaseReadWrite.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.filemeta.OrcFileMetadataHandler.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.FileMetadataHandler.java</file>
      <file type="M">metastore.src.gen.thrift.gen-rb.hive.metastore.types.rb</file>
      <file type="M">metastore.src.gen.thrift.gen-py.hive.metastore.ttypes.py</file>
      <file type="M">metastore.src.gen.thrift.gen-php.metastore.Types.php</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetFileMetadataByExprRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.FileMetadataExprType.java</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.ThriftHiveMetastore.cpp</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.hive.metastore.types.h</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.hive.metastore.types.cpp</file>
      <file type="M">metastore.if.hive.metastore.thrift</file>
    </fixedFiles>
  </bug>
  <bug id="12315" opendate="2015-11-2 00:00:00" fixdate="2015-11-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>vectorization_short_regress.q has a wrong result issue for a double calculation</summary>
      <description>I suspect it is related to the fancy optimizations in vectorized double divide that try to quickly process the batch without checking each row for null. public static void setNullAndDivBy0DataEntriesDouble( DoubleColumnVector v, boolean selectedInUse, int[] sel, int n, DoubleColumnVector denoms) { assert v.isRepeating || !denoms.isRepeating; v.noNulls = false; double[] vector = denoms.vector; if (v.isRepeating &amp;&amp; (v.isNull[0] = (v.isNull[0] || vector[0] == 0))) { v.vector[0] = DoubleColumnVector.NULL_VALUE;</description>
      <version>0.14.0,1.0.1,1.1.1,1.2.1,2.0.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.NullUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="12345" opendate="2015-11-5 00:00:00" fixdate="2015-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Followup for HIVE-9013 : Hidden conf vars still visible through beeline</summary>
      <description>HIVE-9013 introduced the ability to hide certain conf variables when output through the "set" command. However, there still exists one further bug in it that causes these variables to still be visible through beeline connecting to HS2, wherein HS2 exposes hidden variables such as the HS2's metastore password when "set" is run.</description>
      <version>None</version>
      <fixedVersion>1.2.2,1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcDriver2.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="12408" opendate="2015-11-13 00:00:00" fixdate="2015-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SQLStdAuthorizer should not require external table creator to be owner of directory, in addition to rw permissions</summary>
      <description>When trying to create an external table via beeline in Hive using the SQLStdAuthorizer it expects the table creator to be the owner of the directory path and ignores the group rwx permission that is granted to the user.Error: Error while compiling statement: FAILED: HiveAccessControlException Permission denied: Principal [name=hari, type=USER] does not have following privileges for operation CREATETABLE [[INSERT, DELETE, OBJECT OWNERSHIP] on Object [type=DFS_URI, name=/etl/path/to/hdfs/dir]] (state=42000,code=40000)All it should be checking is read access to that directory.The directory owner requirement breaks the ability of more than one user to create external table definitions to a given location. For example this is a flume landing directory with json data, and the /etl tree is owned by the flume user. Even chowning the tree to another user would still break access to other users who are able to read the directory in hdfs but would still unable to create external tables on top of it.This looks like a remnant of the owner only access model in SQLStdAuth and is a separate issue to HIVE-11864 / HIVE-12324.</description>
      <version>0.14.0</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.Operation2Privilege.java</file>
    </fixedFiles>
  </bug>
  <bug id="12422" opendate="2015-11-16 00:00:00" fixdate="2015-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: add security to Web UI endpoint</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="12485" opendate="2015-11-20 00:00:00" fixdate="2015-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Secure HS2 web UI with kerberos</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.server.HiveServer2.java</file>
      <file type="M">common.src.java.org.apache.hive.http.HttpServer.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="12537" opendate="2015-11-28 00:00:00" fixdate="2015-12-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>RLEv2 doesn&amp;#39;t seem to work</summary>
      <description>Perhaps I'm doing something wrong or is actually working as expected.Putting 1 million constant int32 values produces an ORC file of 1MB. Surprisingly, 1 million consecutive ints produces a much smaller file.Code and FileDump attached.ObjectInspector inspector = ObjectInspectorFactory.getReflectionObjectInspector( Integer.class, ObjectInspectorFactory.ObjectInspectorOptions.JAVA);Writer w = OrcFile.createWriter(new Path("/tmp/my.orc"), OrcFile.writerOptions(new Configuration()) .compress(CompressionKind.NONE) .inspector(inspector) .encodingStrategy(OrcFile.EncodingStrategy.COMPRESSION) .version(OrcFile.Version.V_0_12) );for (int i = 0; i &lt; 1000000; ++i) { w.addRow(123);}w.close();</description>
      <version>0.14.0,1.0.1,1.1.1,1.2.1,1.3.0,2.0.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.outer.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.llap.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.file.dump.q.out</file>
      <file type="M">ql.src.test.resources.orc-file-has-null.out</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestVectorOrcFile.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.java.orig</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcFile.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RunLengthIntegerWriterV2.java</file>
    </fixedFiles>
  </bug>
  <bug id="12666" opendate="2015-12-14 00:00:00" fixdate="2015-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>PCRExprProcFactory.GenericFuncExprProcessor.process() aggressively removes dynamic partition pruner generated synthetic join predicates.</summary>
      <description>Introduced by HIVE-11634. The original idea in HIVE-11634 was to remove the IN partition conditions from the predicate list since the static dynamic partitioning would kick in and push these predicates down to metastore. However, the check is too aggressive and removes events such as below :- Select Operator- expressions: UDFToDouble(UDFToInteger((hr / 2))) (type: double)- outputColumnNames: _col0- Statistics: Num rows: 1 Data size: 7 Basic stats: COMPLETE Column stats: NONE- Group By Operator- keys: _col0 (type: double)- mode: hash- outputColumnNames: _col0- Statistics: Num rows: 1 Data size: 7 Basic stats: COMPLETE Column stats: NONE- Dynamic Partitioning Event Operator- Target Input: srcpart- Partition key expr: UDFToDouble(hr)- Statistics: Num rows: 1 Data size: 7 Basic stats: COMPLETE Column stats: NONE- Target column: hr- Target Vertex: Map 1</description>
      <version>None</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mergejoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.vectorized.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.DynamicPartitionPruningOptimization.java</file>
    </fixedFiles>
  </bug>
  <bug id="12717" opendate="2015-12-21 00:00:00" fixdate="2015-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enabled to accept quoting of all character backslash qooting mechanism to json_tuple UDTF</summary>
      <description>Similar to HIVE-11825, we need to enable ALLOW_BACKSLASH_ESCAPING_ANY_CHARACTER property in json_tuple UDTFFor example in HIVE-11825, there are null return in below statement(https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-json_tuple)SELECT a.timestamp, b.* FROM log a LATERAL VIEW json_tuple(a.appevent, 'eventid', 'eventname') b as f1, f2;</description>
      <version>0.14.0</version>
      <fixedVersion>2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDTFJSONTuple.java</file>
    </fixedFiles>
  </bug>
  <bug id="12897" opendate="2016-1-21 00:00:00" fixdate="2016-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve dynamic partition loading</summary>
      <description>There are many redundant calls to metastore which is not needed.</description>
      <version>0.11.0,0.12.0,0.13.0,0.14.0,1.0.0,1.1.0,1.2.0</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientnegative.dynamic.partitions.with.whitelist.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ExplainSQRewriteSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.index.RewriteParseContextGenerator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FileSinkOperator.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.ObjectStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.MetaStoreUtils.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="12907" opendate="2016-1-22 00:00:00" fixdate="2016-1-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve dynamic partition loading - II</summary>
      <description>Remove unnecessary calls to metastore.</description>
      <version>0.14.0,1.1.0,1.2.0,2.0.0</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Partition.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">itests.hcatalog-unit.src.test.java.org.apache.hive.hcatalog.listener.TestDbNotificationListener.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.StatsSetupConst.java</file>
    </fixedFiles>
  </bug>
  <bug id="12908" opendate="2016-1-22 00:00:00" fixdate="2016-2-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve dynamic partition loading III</summary>
      <description>Remove unnecessary Namenode calls.</description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.FileUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="12954" opendate="2016-1-28 00:00:00" fixdate="2016-8-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE with str_to_map on null strings</summary>
      <description>Running str_to_map on a null string will return a NullPointerException.Workaround is to use coalesce.</description>
      <version>0.14.0,1.0.0</version>
      <fixedVersion>2.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFStringToMap.java</file>
    </fixedFiles>
  </bug>
  <bug id="13285" opendate="2016-3-15 00:00:00" fixdate="2016-3-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Orc concatenation may drop old files from moving to final path</summary>
      <description>ORC concatenation uses combine hive input format for merging files. Under specific case where all files within a combine split are incompatible for merge (old files without stripe statistics) then these files are added to incompatible file set. But this file set is not processed as closeOp() will not be called (no output file writer will exist which will skip super.closeOp()). As a result, these incompatible files are not moved to final path.</description>
      <version>0.14.0,1.0.0,1.1.0,1.2.0,1.3.0,2.0.0,2.1.0</version>
      <fixedVersion>1.3.0,2.0.1,2.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.OrcFileMergeOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.AbstractFileMergeOperator.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="13413" opendate="2016-4-2 00:00:00" fixdate="2016-4-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add a llapstatus command line tool</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">llap-server.src.main.resources.llap-cli-log4j2.properties</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cli.LlapOptionsProcessor.java</file>
      <file type="M">llap-server.pom.xml</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.llap.registry.ServiceInstance.java</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.llap.registry.impl.LlapZookeeperRegistryImpl.java</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.llap.registry.impl.LlapFixedRegistryImpl.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="13648" opendate="2016-4-29 00:00:00" fixdate="2016-6-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ORC Schema Evolution doesn&amp;#39;t support same type conversion for VARCHAR, CHAR, or DECIMAL when maxLength or precision/scale is different</summary>
      <description>E.g. when a data file is copied in has a VARCHAR maxLength that doesn't match the DDL's maxLength. This error is produced:java.io.IOException: ORC does not support type conversion from file type varchar(145) (36) to reader type varchar(114) (36)</description>
      <version>None</version>
      <fixedVersion>2.1.1,2.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.schema.evol.text.vec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.schema.evol.text.vecrow.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.schema.evol.text.nonvec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.schema.evol.orc.vec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.schema.evol.orc.nonvec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schema.evol.text.vec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schema.evol.text.vecrow.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schema.evol.text.nonvec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schema.evol.orc.vec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schema.evol.orc.nonvec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.schema.evol.text.vec.mapwork.part.all.primitive.q</file>
      <file type="M">ql.src.test.queries.clientpositive.schema.evol.text.vecrow.mapwork.part.all.primitive.q</file>
      <file type="M">ql.src.test.queries.clientpositive.schema.evol.text.nonvec.mapwork.part.all.primitive.q</file>
      <file type="M">ql.src.test.queries.clientpositive.schema.evol.orc.vec.mapwork.part.all.primitive.q</file>
      <file type="M">ql.src.test.queries.clientpositive.schema.evol.orc.nonvec.mapwork.part.all.primitive.q</file>
      <file type="M">orc.src.java.org.apache.orc.impl.TreeReaderFactory.java</file>
      <file type="M">orc.src.java.org.apache.orc.impl.SchemaEvolution.java</file>
      <file type="M">orc.src.java.org.apache.orc.impl.ConvertTreeReaderFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="1365" opendate="2010-5-24 00:00:00" fixdate="2010-5-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bug in SMBJoinOperator which may causes a final part of the results in some cases.</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.6.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.SMBMapJoinOperator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="13710" opendate="2016-5-6 00:00:00" fixdate="2016-5-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP registry ACL check causes error due to namespacing</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.llap.registry.impl.LlapZookeeperRegistryImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="13782" opendate="2016-5-18 00:00:00" fixdate="2016-5-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compile async query asynchronously</summary>
      <description>Currently, when an async query is submitted to HS2, HS2 does the preparation synchronously. One of the preparation step is to compile the query, which may take some time. It will be helpful to provide an option to do the compilation asynchronously.</description>
      <version>None</version>
      <fixedVersion>2.0.1</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.operation.SQLOperation.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="140" opendate="2008-12-9 00:00:00" fixdate="2008-12-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Event Based Infrastructure for Syntax Trees in the compiler</summary>
      <description>In order to refactor SemanticAnalyzer into a bunch of different components, we need to move more modular mechanisms of doing semantic analysis. One of the missing pieces here is the event based infrastructure for analyzing ASTs in the Semantic Analyzer. We will first use this infrastructure for lineage tools and then migrate the rest of the Semantic Analyzer to this infrastructure over time.</description>
      <version>None</version>
      <fixedVersion>0.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="14000" opendate="2016-6-12 00:00:00" fixdate="2016-6-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>(ORC) Changing a numeric type column of a partitioned table to lower type set values to something other than &amp;#39;NULL&amp;#39;</summary>
      <description>When an integer column is changed to a type that is smaller (e.g. bigint to int) and set hive.metastore.disallow.incompatible.col.type.changes=false, the data is clipped instead of being NULL.</description>
      <version>None</version>
      <fixedVersion>2.1.1,2.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">storage-api.src.java.org.apache.hadoop.hive.ql.util.TimestampUtils.java</file>
      <file type="M">ql.src.test.results.clientpositive.tez.schema.evol.text.vec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.schema.evol.text.vecrow.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.schema.evol.text.nonvec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.schema.evol.orc.vec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.schema.evol.orc.nonvec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schema.evol.text.vec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schema.evol.text.vecrow.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schema.evol.text.nonvec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schema.evol.orc.vec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schema.evol.orc.nonvec.mapwork.part.all.primitive.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.schema.evol.text.vec.mapwork.part.all.primitive.q</file>
      <file type="M">ql.src.test.queries.clientpositive.schema.evol.text.vecrow.mapwork.part.all.primitive.q</file>
      <file type="M">ql.src.test.queries.clientpositive.schema.evol.text.nonvec.mapwork.part.all.primitive.q</file>
      <file type="M">ql.src.test.queries.clientpositive.schema.evol.orc.vec.mapwork.part.all.primitive.q</file>
      <file type="M">ql.src.test.queries.clientpositive.schema.evol.orc.nonvec.mapwork.part.all.primitive.q</file>
      <file type="M">orc.src.java.org.apache.orc.impl.ConvertTreeReaderFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="14896" opendate="2016-10-5 00:00:00" fixdate="2016-10-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Stabilize golden files for currently failing tests</summary>
      <description>3 tests currently fail because of stats mismatch in golden files.</description>
      <version>None</version>
      <fixedVersion>2.3.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.vector.join.part.col.char.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ctas.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.llap.ctas.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ctas.hadoop20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ctas.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.acid.mapjoin.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.ctas.hadoop20.q</file>
      <file type="M">ql.src.test.queries.clientpositive.ctas.q</file>
      <file type="M">ql.src.test.queries.clientpositive.acid.mapjoin.q</file>
    </fixedFiles>
  </bug>
  <bug id="3405" opendate="2012-8-23 00:00:00" fixdate="2012-1-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>UDF initcap to obtain a string with the first letter of each word in uppercase other letters in lowercase</summary>
      <description>Hive current releases lacks a INITCAP function which returns String with first letter of the word in uppercase.INITCAP returns String, with the first letter of each word in uppercase, all other letters in same case. Words are delimited by white space.This will be useful report generation.</description>
      <version>0.8.1,0.9.0,0.9.1,0.10.0,0.11.0,0.13.0,0.14.0,0.14.1,0.15.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.show.functions.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
    </fixedFiles>
  </bug>
  <bug id="4810" opendate="2013-7-3 00:00:00" fixdate="2013-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refactor exec package</summary>
      <description>The exec package contains both operators and classes used to execute the job. Moving the latter into a sub package makes the package slightly more manageable and will make it easier to provide a tez-based implementation.</description>
      <version>None</version>
      <fixedVersion>0.12.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientnegative.dyn.part3.q.out</file>
      <file type="M">ql.src.test.results.compiler.plan.union.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf.when.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf.case.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.subq.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample7.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join8.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join7.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input.testxpath2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input.testxpath.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input.testsequencefile.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input.part1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input9.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input8.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input7.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input20.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.cast1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.case.sensitivity.q.xml</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.hook.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.loadpart.err.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.convert.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join25.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.udf.test.error.reduce.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.udf.test.error.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.udf.reflect.neg.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.udf.assert.true2.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.udf.assert.true.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.udfnull.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.stats.publisher.error.2.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.stats.publisher.error.1.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.stats.aggregator.error.2.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.serde.regex2.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.script.error.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.script.broken.pipe3.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.script.broken.pipe2.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.script.broken.pipe1.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.minimr.broken.pipe.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.mapreduce.stack.trace.turnoff.hadoop20.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.mapreduce.stack.trace.turnoff.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.mapreduce.stack.trace.hadoop20.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.mapreduce.stack.trace.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.local.mapred.error.cache.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.index.compact.size.limit.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.index.compact.entry.limit.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.fatal.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.dyn.part.max.per.node.q.out</file>
      <file type="M">cli.src.java.org.apache.hadoop.hive.cli.CliDriver.java</file>
      <file type="M">contrib.src.test.results.clientnegative.case.with.row.sequence.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ColumnStatsTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExecDriver.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExecMapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExecMapperContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExecReducer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FetchOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FetchTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FileSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.HadoopJobExecHelper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.HadoopJobExecHook.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.JobDebugger.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.JobTrackerURLResolver.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapredContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapredLocalTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapRedTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MoveTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Operator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.TableScanOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Task.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.TaskFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Throttle.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.BucketizedHiveInputSplit.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.HiveRecordReader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.rcfile.merge.BlockMergeTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.rcfile.stats.PartialScanTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.rcfile.truncate.ColumnTruncateTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.AbstractJoinTaskDispatcher.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.BucketingSortingInferenceOptimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.CommonJoinTaskDispatcher.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.index.IndexWhereProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.MapJoinResolver.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.SamplingOptimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.SortMergeJoinTaskDispatcher.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.IndexUpdater.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.MapReduceCompiler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.QueryPlan.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestExecDriver.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.TestSymlinkTextInputFormat.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.udf.generic.DummyContextUDF.java</file>
      <file type="M">ql.src.test.results.clientnegative.autolocal1.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.cachingprintstream.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.cluster.tasklog.retrieval.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="4812" opendate="2013-7-3 00:00:00" fixdate="2013-7-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Logical explain plan</summary>
      <description>In various situations it would have been useful to me to glance at the operator plan before we break it into tasks and apply join, total order sort, etc optimizations.I've added this as an options to explain. "Explain logical &lt;QUERY&gt;" will output the full operator tree (not the stage plans, tasks, AST etc).Again, I don't think this has to even be documented for users, but might be useful to developers.</description>
      <version>None</version>
      <fixedVersion>0.12.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ExplainWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.IdentifiersParser.g</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.HiveParser.g</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.HiveLexer.g</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExplainTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Context.java</file>
    </fixedFiles>
  </bug>
  <bug id="567" opendate="2009-6-19 00:00:00" fixdate="2009-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>jdbc: integrate hive with pentaho report designer</summary>
      <description>Instead of trying to get a complete implementation of jdbc, its probably more useful to pick reporting/analytics software out there and implement the jdbc methods necessary to get them working. This jira is a first attempt at this.</description>
      <version>None</version>
      <fixedVersion>0.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hadoop.hive.service.HiveServer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.MetaStoreUtils.java</file>
      <file type="M">jdbc.src.java.org.apache.hadoop.hive.jdbc.HiveResultSetMetaData.java</file>
      <file type="M">jdbc.src.java.org.apache.hadoop.hive.jdbc.HiveResultSet.java</file>
      <file type="M">jdbc.src.java.org.apache.hadoop.hive.jdbc.HivePreparedStatement.java</file>
      <file type="M">jdbc.src.java.org.apache.hadoop.hive.jdbc.HiveDatabaseMetaData.java</file>
      <file type="M">jdbc.src.java.org.apache.hadoop.hive.jdbc.HiveConnection.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="5670" opendate="2013-10-28 00:00:00" fixdate="2013-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>annoying ZK exceptions are annoying</summary>
      <description>when I run tests locally (or on cluster IIRC) there are bunch of ZK-related exceptions in Hive log, such as2013-10-28 09:50:50,851 ERROR zookeeper.ClientCnxn (ClientCnxn.java:processEvent(523)) - Error while calling watcher java.lang.NullPointerException at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:521) at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:497) 2013-10-28 09:51:05,747 DEBUG server.NIOServerCnxn (NIOServerCnxn.java:closeSock(1024)) - ignoring exception during input shutdownjava.net.SocketException: Socket is not connected at sun.nio.ch.SocketChannelImpl.shutdown(Native Method) at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:633) at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:360) at org.apache.zookeeper.server.NIOServerCnxn.closeSock(NIOServerCnxn.java:1020) at org.apache.zookeeper.server.NIOServerCnxn.close(NIOServerCnxn.java:977) at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:347) at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:224) at java.lang.Thread.run(Thread.java:680)They are annoying when you look for actual problems in logs.Those on DEBUG level should be silenced via log levels for ZK classes by default. Not sure what to do with ERROR level one(s?), I'd need to look if they can be silenced/logged as DEBUG on hive side, or maybe file a bug for ZK...</description>
      <version>None</version>
      <fixedVersion>0.13.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.src.main.resources.log4j.properties</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.QTestUtil.java</file>
      <file type="M">ql.src.java.conf.hive-exec-log4j.properties</file>
      <file type="M">data.conf.hive-log4j.properties</file>
      <file type="M">common.src.test.resources.hive-log4j-test.properties</file>
      <file type="M">common.src.test.resources.hive-exec-log4j-test.properties</file>
      <file type="M">common.src.java.conf.hive-log4j.properties</file>
    </fixedFiles>
  </bug>
  <bug id="61" opendate="2008-11-13 00:00:00" fixdate="2008-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implment ORDER BY</summary>
      <description>ORDER BY is in the query language reference but currently is a no-op. We should make it an op.</description>
      <version>None</version>
      <fixedVersion>0.4.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.QBParseInfo.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ErrorMsg.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6362" opendate="2014-2-4 00:00:00" fixdate="2014-2-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support union all on tez</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>tez-branch</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.dml.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.sample1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.merge2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.merge1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mapreduce2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mapreduce1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.load.dyn.part1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.insert.into2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.insert.into1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.insert1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.groupby3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.groupby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.groupby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.ctas.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.join1.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.TezWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ReduceWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.MapWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.BaseWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.TezCompiler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.GenTezWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.GenTezUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.GenTezProcContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.FileSinkProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.tools.InputMerger.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">itests.qtest.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6433" opendate="2014-2-15 00:00:00" fixdate="2014-2-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SQL std auth - allow grant/revoke roles if user has ADMIN OPTION</summary>
      <description>Follow up jira for HIVE-5952.If a user/role has admin option on a role, then user should be able to grant /revoke other users to/from the role.</description>
      <version>None</version>
      <fixedVersion>0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientnegative.authorization.set.role.neg2.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessController.java</file>
    </fixedFiles>
  </bug>
  <bug id="6535" opendate="2014-3-3 00:00:00" fixdate="2014-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JDBC: provide an async API to execute query and fetch results</summary>
      <description>The hive jdbc client waits query completion during execute() call. It would be better to block in the jdbc for completion when the results are being fetched.This way the application using hive jdbc driver can do other tasks while asynchronous query execution is happening, until it needs to fetch the result set.</description>
      <version>0.14.0,1.2.1,2.0.0</version>
      <fixedVersion>2.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.operation.SQLOperation.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.operation.Operation.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.operation.GetTypeInfoOperation.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.operation.GetTableTypesOperation.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.operation.GetTablesOperation.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.operation.GetSchemasOperation.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.operation.GetFunctionsOperation.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.operation.GetColumnsOperation.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.operation.GetCatalogsOperation.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveStatement.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveQueryResultSet.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcDriver2.java</file>
    </fixedFiles>
  </bug>
  <bug id="6546" opendate="2014-3-4 00:00:00" fixdate="2014-3-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebHCat job submission for pig with -useHCatalog argument fails on Windows</summary>
      <description>On a one-box windows setup, do the following from a powershell prompt:cmd /c curl.exe -s ` -d user.name=hadoop ` -d arg=-useHCatalog ` -d execute="emp = load '/data/emp/emp_0.dat'; dump emp;" ` -d statusdir="/tmp/webhcat.output01" ` 'http://localhost:50111/templeton/v1/pig' -vThe job fails with error code 7, but it should run. I traced this down to the following. In the job configuration for the TempletonJobController, we have templeton.args set tocmd,/c,call,C:\\hadoop\\\\pig-0.11.0.1.3.0.0-0846/bin/pig.cmd,-D_WEBHCAT_TOKEN_FILE_LOCATION_="-useHCatalog",-execute,"emp = load '/data/emp/emp_0.dat'; dump emp;"Notice the = sign before "-useHCatalog". I think this should be a comma.The bad string D_WEBHCAT_TOKEN_FILE_LOCATION_="-useHCatalog" gets created in org.apache.hadoop.util.GenericOptionsParser.preProcessForWindows().It happens at line 434: } else { if (i &lt; args.length - 1) { prop += "=" + args[++i]; // RIGHT HERE! at iterations i = 37, 38 } }Bug is here: if (prop != null) { if (prop.contains("=")) { // -D__WEBHCAT_TOKEN_FILE_LOCATION__ does not contain equal, so else branch is run and appends ="-useHCatalog", // everything good } else { if (i &lt; args.length - 1) { prop += "=" + args[++i]; } } newArgs.add(prop); }One possible fix is to change the string constant org.apache.hcatalog.templeton.tool.TempletonControllerJob.TOKEN_FILE_ARG_PLACEHOLDER to have an "=" sign in it. Or, preProcessForWindows() itself could be changed.</description>
      <version>0.11.0,0.12.0,0.13.0,0.14.0</version>
      <fixedVersion>0.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.tool.JobSubmissionConstants.java</file>
    </fixedFiles>
  </bug>
  <bug id="6563" opendate="2014-3-6 00:00:00" fixdate="2014-3-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hdfs jar being pulled in when creating a hadoop-2 based hive tar ball</summary>
      <description>Looks like some dependency issue is causing hadoop-hdfs jar to be packaged in the hive tar ball.</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>0.13.0,0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6584" opendate="2014-3-7 00:00:00" fixdate="2014-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add HiveHBaseTableSnapshotInputFormat</summary>
      <description>HBASE-8369 provided mapreduce support for reading from HBase table snapsopts. This allows a MR job to consume a stable, read-only view of an HBase table directly off of HDFS. Bypassing the online region server API provides a nice performance boost for the full scan. HBASE-10642 is backporting that feature to 0.94/0.96 and also adding a mapred implementation. Once that's available, we should add an input format. A follow-on patch could work out how to integrate this functionality into the StorageHandler, similar to how HIVE-6473 integrates the HFileOutputFormat into existing table definitions.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
      <file type="M">pom.xml</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.QTestUtil.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.hbase.HBaseTestSetup.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.hbase.HBaseQTestUtil.java</file>
      <file type="M">hbase-handler.src.test.templates.TestHBaseCliDriver.vm</file>
      <file type="M">hbase-handler.src.test.results.positive.hbase.binary.storage.queries.q.out</file>
      <file type="M">hbase-handler.src.test.results.positive.external.table.ppd.q.out</file>
      <file type="M">hbase-handler.src.java.org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat.java</file>
      <file type="M">hbase-handler.src.java.org.apache.hadoop.hive.hbase.HBaseStorageHandler.java</file>
      <file type="M">hbase-handler.src.java.org.apache.hadoop.hive.hbase.HBaseSplit.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="6587" opendate="2014-3-7 00:00:00" fixdate="2014-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>allow specifying additional Hive classpath for Hadoop</summary>
      <description>Allow users to add jars to hive's Hadoop classpath without explicitly modifying their Hadoop classpath</description>
      <version>None</version>
      <fixedVersion>0.13.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hive</file>
    </fixedFiles>
  </bug>
  <bug id="6633" opendate="2014-3-12 00:00:00" fixdate="2014-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>pig -useHCatalog with embedded metastore fails to pass command line args to metastore</summary>
      <description>This fails because the embedded metastore can't connect to the database because the command line -D arguments passed to pig are not getting passed to the metastore when the embedded metastore is created. Using hive.metastore.uris set to the empty string causes creation of an embedded metastore.pig -useHCatalog "-Dhive.metastore.uris=" "-Djavax.jdo.option.ConnectionPassword=AzureSQLDBXYZ"The goal is to allow a pig job submitted via WebHCat to specify a metastore to use via job arguments. That is not working because it is not possible to pass Djavax.jdo.option.ConnectionPassword and other necessary arguments to the embedded metastore.</description>
      <version>0.11.0,0.12.0,0.13.0,0.14.0</version>
      <fixedVersion>0.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.main.java.org.apache.hcatalog.pig.PigHCatUtil.java</file>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.main.java.org.apache.hcatalog.pig.HCatLoader.java</file>
    </fixedFiles>
  </bug>
  <bug id="6656" opendate="2014-3-13 00:00:00" fixdate="2014-3-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bug in ORC Timestamp reader returns wrong nanoseconds</summary>
      <description>ORC timestamp writer stores the number of trailing zeros in 3 LSB bits. There is a bug in parsing nanosecond logic that returns incorrect value.Input:1999-01-01 00:00:00.999999999Output: 1999-01-01 00:00:00.463129087The fix for this is parseNanos() should first right shift by 3 and then typecast to int.</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>0.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcFile.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="667" opendate="2009-7-21 00:00:00" fixdate="2009-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement SHOW TABLE EXTENDED</summary>
      <description>Provide hive ql to check table/partition status, including size, creation and access timestamp. This information will be helpful both for data management tasks, and users who send ad-hoc queries against big data set in the cluster.</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.src.common.java.org.apache.hadoop.hive.shims.HadoopShims.java</file>
      <file type="M">shims.src.0.20.java.org.apache.hadoop.hive.shims.Hadoop20Shims.java</file>
      <file type="M">shims.src.0.19.java.org.apache.hadoop.hive.shims.Hadoop19Shims.java</file>
      <file type="M">shims.src.0.18.java.org.apache.hadoop.hive.shims.Hadoop18Shims.java</file>
      <file type="M">shims.src.0.17.java.org.apache.hadoop.hive.shims.Hadoop17Shims.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.QTestUtil.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.DDLWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzerFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.Hive.g</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6732" opendate="2014-3-24 00:00:00" fixdate="2014-4-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update Release Notes for Hive 0.13</summary>
      <description>NO PRECOMMIT TESTS</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>0.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">RELEASE.NOTES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6735" opendate="2014-3-24 00:00:00" fixdate="2014-3-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make scalable dynamic partitioning work in vectorized mode</summary>
      <description>HIVE-6455 added support for scalable dynamic partitioning. This is subtask to make HIVE-6455 work with vectorized operators.</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>0.13.0,0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorReduceSinkOperator.java</file>
      <file type="M">itests.qtest.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6742" opendate="2014-3-25 00:00:00" fixdate="2014-3-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tez Outputs need to be started before accessing the writer</summary>
      <description>Accessing the writer on a Tez Output may not be safe until the Output has been started.</description>
      <version>None</version>
      <fixedVersion>0.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="6743" opendate="2014-3-25 00:00:00" fixdate="2014-4-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow specifying the log level for Tez tasks</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.13.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">conf.hive-default.xml.template</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="6758" opendate="2014-3-26 00:00:00" fixdate="2014-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Beeline doesn&amp;#39;t work with -e option when started in background</summary>
      <description>In hive CLI you could easily integrate its use into a script and back ground the process like this: hive -e "some query" &amp;Beeline does not run when you do the same even with the -f switch.</description>
      <version>0.11.0,0.14.0</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.beeline</file>
    </fixedFiles>
  </bug>
  <bug id="6759" opendate="2014-3-26 00:00:00" fixdate="2014-4-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix reading partial ORC files while they are being written</summary>
      <description>HDFS with the hflush ensures the bytes are visible, but doesn't update the file length on the NameNode. Currently the Orc reader will only read up to the length on the NameNode. If the user specified a length from a flush_length file, the Orc reader should trust it to be right.</description>
      <version>None</version>
      <fixedVersion>0.13.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestRecordReaderImpl.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.ReaderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="6760" opendate="2014-3-26 00:00:00" fixdate="2014-3-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Scalable dynamic partitioning should bail out properly for list bucketing</summary>
      <description>In case of list bucketing HIVE-6455 looks only at this config "hive.optimize.listbucketing" to bail out. There are cases when this config ("hive.optimize.listbucketing") is not set but list bucketing is enabled using SKEWED BY in CREATE TABLE statement.</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>0.13.0,0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.SortedDynPartitionOptimizer.java</file>
    </fixedFiles>
  </bug>
  <bug id="6761" opendate="2014-3-26 00:00:00" fixdate="2014-3-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hashcode computation does not use maximum parallelism for scalable dynamic partitioning</summary>
      <description>Hashcode computation for HIVE-6455 should consider all the partitioning columns and bucket number to distribute the rows. The following code for (int i = 0; i &lt; partitionEval.length - 1; i++) {ignores the last partition column thereby generating lesser hashcodes.</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>0.13.0,0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="6791" opendate="2014-3-30 00:00:00" fixdate="2014-6-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support variable substition for Beeline shell command</summary>
      <description>A follow-up task from HIVE-6694. Similar to HIVE-6570.</description>
      <version>0.14.0</version>
      <fixedVersion>beeline-cli-branch</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.operation.SQLOperation.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.SetProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.DfsProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.DeleteResourceProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.CompileProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.AddResourceProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.VariableSubstitution.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">cli.src.java.org.apache.hadoop.hive.cli.CliDriver.java</file>
      <file type="M">beeline.src.test.org.apache.hive.beeline.cli.TestHiveCli.java</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.Commands.java</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.BeeLine.java</file>
    </fixedFiles>
  </bug>
  <bug id="6792" opendate="2014-3-31 00:00:00" fixdate="2014-4-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hive.warehouse.subdir.inherit.perms doesn&amp;#39;t work correctly in CTAS</summary>
      <description>hive.warehouse.subdir.inherit.perms doesn't work correctly in CTAS. When it is set to true, the table created using create table .. as select.. does not inherit its parent directory's group and permission mode. It can be easily reproduced:==hive&gt; dfs -ls -R /user/hive/warehouse;drwxrwx--T - hive hive 0 2014-03-30 17:44 /user/hive/warehouse/ctas.dbdrwxr-xr-x - hive hive 0 2014-03-30 17:20 /user/hive/warehouse/ctas_src_tblrw-rr- 3 hive hive 46059 2014-03-30 17:20 /user/hive/warehouse/ctas_src_tbl/000000_0hive&gt; create table ctas.test_perm as select * from ctas_src_tbl;hive&gt; dfs -ls -R /user/hive/warehouse; drwxrwx--T - hive hive 0 2014-03-30 17:46 /user/hive/warehouse/ctas.dbdrwxr-xr-x - hive supergroup 0 2014-03-30 17:46 /user/hive/warehouse/ctas.db/test_permrw-rr- 3 hive supergroup 46059 2014-03-30 17:46 /user/hive/warehouse/ctas.db/test_perm/000000_0drwxr-xr-x - hive hive 0 2014-03-30 17:20 /user/hive/warehouse/ctas_src_tblrw-rr- 3 hive hive 46059 2014-03-30 17:20 /user/hive/warehouse/ctas_src_tbl/000000_0==The created table does not inherit its database ctas's group hive and permission mode 770, instead it takes the default group (supergroup) and permission mode (755) in hdfs</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MoveTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="6826" opendate="2014-4-3 00:00:00" fixdate="2014-5-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive-tez has issues when different partitions work off of different input types</summary>
      <description>create table test (key int, value string) partitioned by (p int) stored as textfile;insert into table test partition (p=1) select * from src limit 10;alter table test set fileformat orc;insert into table test partition (p=2) select * from src limit 10;describe test;select * from test where p=1 and key &gt; 0;select * from test where p=2 and key &gt; 0;select * from test where key &gt; 0;throws a classcast exception</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>0.13.1,0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.CustomPartitionVertex.java</file>
      <file type="M">itests.qtest.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6828" opendate="2014-4-3 00:00:00" fixdate="2014-5-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive tez bucket map join conversion interferes with map join conversion</summary>
      <description>The issue is that bucket count is used for checking the scaled down size of the hash tables but is used later on to convert to the map join as well which may be incorrect in cases where the entire hash table does not fit in the specified size.</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>0.13.1,0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.java</file>
    </fixedFiles>
  </bug>
  <bug id="6847" opendate="2014-4-4 00:00:00" fixdate="2014-9-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve / fix bugs in Hive scratch dir setup</summary>
      <description>Currently, the hive server creates scratch directory and changes permission to 777 however, this is not great with respect to security. We need to create user specific scratch directories instead. Also refer to HIVE-6782 1st iteration of the patch for approach.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.test.org.apache.hive.service.cli.TestScratchDir.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.SessionManager.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.HiveSessionImpl.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.HiveSessionBase.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.CLIService.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestUtilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezSessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Context.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniMr.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniHS2.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.TestUtilitiesDfs.java</file>
      <file type="M">itests.hive-unit.src.main.java.org.apache.hive.jdbc.miniHS2.MiniHS2.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.ServerUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="6873" opendate="2014-4-9 00:00:00" fixdate="2014-4-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DISTINCT clause in aggregates is handled incorrectly by vectorized execution</summary>
      <description>The vectorized aggregates ignore the DISTINCT clause. This cause incorrect results. Due to how GroupByOperatorDesc adds the DISTINCT keys to the overall aggregate keys the vectorized aggregates do account for the extra key, but they do not process the data correctly for the key. the reduce side the aggregates the input from the vectorized map side to results that are only sometimes correct but mostly incorrect. HIVE-4607 tracks the proper fix, but meantime I'm filing a bug to disable vectorized execution if DISTINCT is present. Fix is trivial.</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>0.13.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GroupByOptimizer.java</file>
    </fixedFiles>
  </bug>
  <bug id="6898" opendate="2014-4-11 00:00:00" fixdate="2014-4-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Functions in hive are failing with java.lang.ClassNotFoundException on Tez</summary>
      <description>CREATE TABLE T1(key int, val STRING) STORED AS TEXTFILE;LOAD DATA LOCAL INPATH '../../data/files/T1.txt' INTO TABLE T1;add jar /tmp/testudf.jar;create temporary function square as 'org.apache.hive.udf.UDFSquare';select square(key) from T1 limit 3;Fails with Vertex failed, vertexName=Map 1, vertexId=vertex_1397230190905_0590_1_00, diagnostics=[Task failed, taskId=task_1397230190905_0590_1_00_000000, diagnostics=[AttemptID:attempt_1397230190905_0590_1_00_000000_0 Info:Error: java.lang.RuntimeException: Map operator initialization failed at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:145) at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:163) at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:307) at org.apache.hadoop.mapred.YarnTezDagChild$5.run(YarnTezDagChild.java:564) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1557) at org.apache.hadoop.mapred.YarnTezDagChild.main(YarnTezDagChild.java:553)Caused by: java.lang.RuntimeException: java.lang.ClassNotFoundException: org.apache.hive.udf.UDFSquare at org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.getUdfClass(GenericUDFBridge.java:133) at org.apache.hadoop.hive.ql.exec.FunctionRegistry.isStateful(FunctionRegistry.java:1636) at org.apache.hadoop.hive.ql.exec.FunctionRegistry.isDeterministic(FunctionRegistry.java:1599) at org.apache.hadoop.hive.ql.exec.ExprNodeGenericFuncEvaluator.isDeterministic(ExprNodeGenericFuncEvaluator.java:132) at org.apache.hadoop.hive.ql.exec.ExprNodeEvaluatorFactory.iterate(ExprNodeEvaluatorFactory.java:83) at org.apache.hadoop.hive.ql.exec.ExprNodeEvaluatorFactory.toCachedEval(ExprNodeEvaluatorFactory.java:73) at org.apache.hadoop.hive.ql.exec.SelectOperator.initializeOp(SelectOperator.java:59) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:376) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:460) at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:416) at org.apache.hadoop.hive.ql.exec.TableScanOperator.initializeOp(TableScanOperator.java:189) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:376) at org.apache.hadoop.hive.ql.exec.MapOperator.initializeOp(MapOperator.java:425) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:376) at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:121) ... 7 more</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>0.13.1,0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="6944" opendate="2014-4-21 00:00:00" fixdate="2014-4-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>WebHCat e2e tests broken by HIVE-6432</summary>
      <description>HIVE-6432 removed templeton/v/queue REST endpoint and broke webhcat e2e testsNO PRECOMMIT TESTS</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.src.test.e2e.templeton.drivers.TestDriverCurl.pm</file>
    </fixedFiles>
  </bug>
  <bug id="6947" opendate="2014-4-22 00:00:00" fixdate="2014-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>More fixes for tests on hadoop-2</summary>
      <description>Few more fixes for test cases on hadoop-2</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.truncate.column.list.bucket.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stats.partscan.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stats.list.bucket.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.list.bucket.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.16.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="6961" opendate="2014-4-22 00:00:00" fixdate="2014-4-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Drop partitions treats partition columns as strings</summary>
      <description>Discovered just now while testing HIVE-6945</description>
      <version>None</version>
      <fixedVersion>0.13.1,0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.drop.partitions.filter2.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.drop.partitions.filter2.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="698" opendate="2009-7-28 00:00:00" fixdate="2009-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create temporary function for GenericUDAF</summary>
      <description>We don't have that capability for GenericUDAF yet. We should add it.</description>
      <version>None</version>
      <fixedVersion>0.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionTask.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="6988" opendate="2014-4-29 00:00:00" fixdate="2014-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive changes for tez-0.5.x compatibility</summary>
      <description>Umbrella JIRA to track all hive changes needed for tez-0.5.x compatibility.tez-0.4.x -&gt; tez.0.5.x is going to break backwards compat.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.tez.TestTezTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezSessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.CustomPartitionVertex.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.CustomPartitionEdge.java</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="6991" opendate="2014-4-30 00:00:00" fixdate="2014-6-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>History not able to disable/enable after session started</summary>
      <description>By default history is disabled, after session started if enable history through this command set hive.session.history.enabled=true. It is not working.I think it will help to this user queryhttp://mail-archives.apache.org/mod_mbox/hive-user/201404.mbox/%3CCAJqy7aFAPa_pjS6bUon0o8zYT2qwfN2WT-mtZnwfmuRav_8ZjA@mail.gmail.com%3E</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.SetProcessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="7015" opendate="2014-5-5 00:00:00" fixdate="2014-5-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failing to inherit group/permission should not fail the operation</summary>
      <description>In the previous changes, chgrp and chmod were put on the critical path of directory creation and file copy/mvThese should not be, for instance existing users may not have hive-users in the same group as hive group, so chgrp would fail if they turn on the flag ""hive.warehouse.subdir.inherit.perms".</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.CopyTask.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.Warehouse.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.FileUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="7031" opendate="2014-5-7 00:00:00" fixdate="2014-5-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Utiltites.createEmptyFile uses File.Separator instead of Path.Separator to create an empty file in HDFS</summary>
      <description>This leads to inconsitent HDFS naming for empty partition/tables where a file might be named as hdfs://headnode0:9000/hive/scratch/hive_2014-04-07_22-39-52_649_4046112898053848089-1/-mr-10010\0 in windows operating system</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
    </fixedFiles>
  </bug>
  <bug id="7032" opendate="2014-5-7 00:00:00" fixdate="2014-12-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove Triple Negative in Error 10129</summary>
      <description>Error message 10129 currently reads:"Drop partitions for a non string partition columns is not allowed using non-equality"That has three negations and a singular/plural agreement error. Can it be changed to something like:"Drop partitions for a non-string partition column is only allowed using equality"</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.ErrorMsg.java</file>
    </fixedFiles>
  </bug>
  <bug id="7054" opendate="2014-5-13 00:00:00" fixdate="2014-7-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support ELT UDF in vectorized mode</summary>
      <description>Implement support for ELT udf in vectorized execution mode.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="7084" opendate="2014-5-19 00:00:00" fixdate="2014-5-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestWebHCatE2e is failing on trunk</summary>
      <description>I am able to repro it consistently on fresh checkout.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7085" opendate="2014-5-19 00:00:00" fixdate="2014-6-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestOrcHCatPigStorer.testWriteDecimal tests are failing on trunk</summary>
      <description>TestOrcHCatPigStorer.testWriteDecimal, TestOrcHCatPigStorer.testWriteDecimalX, TestOrcHCatPigStorer.testWriteDecimalXYare failing.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.core.src.main.java.org.apache.hive.hcatalog.data.HCatRecordSerDe.java</file>
    </fixedFiles>
  </bug>
  <bug id="7107" opendate="2014-5-21 00:00:00" fixdate="2014-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix HiveServer1 JDBC Driver spec compliancy issue</summary>
      <description>The HiveServer1 driver does not adhere to the JDBC standard of returning null when it can't handle a connection URL. It instead throws an exception which leads to subsequent exceptions (from other drivers, i.e. the HiveServer2 one) being swallowed.This is what you'd see:Error: Invalid URL: jdbc:hive2://localhost:10000/default;principal=hive/_HOST@EXAMPLE.COM (state=08S01,code=0)java.sql.SQLException: Invalid URL: jdbc:hive2://localhost:10000/default;principal=hive/_HOST@EXAMPLE.COM at org.apache.hadoop.hive.jdbc.HiveConnection.&lt;init&gt;(HiveConnection.java:86)In addition this patch cleans up the drivers a bit.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.src.java.org.apache.hadoop.hive.jdbc.HiveDriver.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.jdbc.TestJdbcDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="7118" opendate="2014-5-23 00:00:00" fixdate="2014-6-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Oracle upgrade schema scripts do not map Java long datatype columns correctly for transaction related tables</summary>
      <description>In Transaction related tables, Java long column fields are mapped to NUMBER(10) which results in failure to persist the transaction ids which are incompatible. Following error is seen:ORA-01438: value larger than specified precision allowed for this columnNO PRECOMMIT TESTS</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.scripts.upgrade.oracle.hive-txn-schema-0.13.0.oracle.sql</file>
      <file type="M">metastore.scripts.upgrade.oracle.hive-schema-0.13.0.oracle.sql</file>
    </fixedFiles>
  </bug>
  <bug id="7145" opendate="2014-5-29 00:00:00" fixdate="2014-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove dependence on apache commons-lang</summary>
      <description>We currently depend on both Apache commons-lang and commons-lang3. They are the same project, just at version 2.x vs 3.x. I propose that we move all of the references in Hive to commons-lang3 and remove the v2 usage.</description>
      <version>None</version>
      <fixedVersion>4.0.0-alpha-1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">vector-code-gen.pom.xml</file>
      <file type="M">storage-api.pom.xml</file>
      <file type="M">shims.common.pom.xml</file>
      <file type="M">shims.0.23.pom.xml</file>
      <file type="M">service.pom.xml</file>
      <file type="M">serde.pom.xml</file>
      <file type="M">ql.pom.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">metastore.pom.xml</file>
      <file type="M">llap-server.pom.xml</file>
      <file type="M">hplsql.pom.xml</file>
      <file type="M">hbase-handler.pom.xml</file>
      <file type="M">druid-handler.pom.xml</file>
      <file type="M">common.pom.xml</file>
      <file type="M">cli.pom.xml</file>
      <file type="M">beeline.pom.xml</file>
      <file type="M">accumulo-handler.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7156" opendate="2014-5-31 00:00:00" fixdate="2014-9-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Group-By operator stat-annotation only uses distinct approx to generate rollups</summary>
      <description>The stats annotation for a group-by only annotates the reduce-side row-count with the distinct values.The map-side gets the row-count as the rows output instead of distinct * parallelism, while the reducer side gets the correct parallelism.hive&gt; explain select distinct L_SHIPDATE from lineitem; Vertices: Map 1 Map Operator Tree: TableScan alias: lineitem Statistics: Num rows: 5999989709 Data size: 4745677733354 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: l_shipdate (type: string) outputColumnNames: l_shipdate Statistics: Num rows: 5999989709 Data size: 4745677733354 Basic stats: COMPLETE Column stats: COMPLETE Group By Operator keys: l_shipdate (type: string) mode: hash outputColumnNames: _col0 Statistics: Num rows: 5999989709 Data size: 563999032646 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: string) sort order: + Map-reduce partition columns: _col0 (type: string) Statistics: Num rows: 5999989709 Data size: 563999032646 Basic stats: COMPLETE Column stats: COMPLETE Execution mode: vectorized Reducer 2 Reduce Operator Tree: Group By Operator keys: KEY._col0 (type: string) mode: mergepartial outputColumnNames: _col0 Statistics: Num rows: 1955 Data size: 183770 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: _col0 (type: string) outputColumnNames: _col0 Statistics: Num rows: 1955 Data size: 183770 Basic stats: COMPLETE Column stats: COMPLETE</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.union.remove.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.24.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udtf.explode.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.explode.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.union7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit.partition.metadataonly.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.rollup1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.grouping.sets5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.grouping.sets3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.grouping.sets2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.cube1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.combine2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.binarysortable.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.groupby.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.annotate.stats.groupby.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.StatsUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.stats.annotation.StatsRulesProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.GroupByOperator.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="7158" opendate="2014-5-31 00:00:00" fixdate="2014-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Tez auto-parallelism in Hive</summary>
      <description>Tez can optionally sample data from a fraction of the tasks of a vertex and use that information to choose the number of downstream tasks for any given scatter gather edge.Hive estimates the count of reducers by looking at stats and estimates for each operator in the operator pipeline leading up to the reducer. However, if this estimate turns out to be too large, Tez can reign in the resources used to compute the reducer.It does so by combining partitions of the upstream vertex. It cannot, however, add reducers at this stage.I'm proposing to let users specify whether they want to use auto-parallelism or not. If they do there will be scaling factors to determine max and min reducers Tez can choose from. We will then partition by max reducers, letting Tez sample and reign in the count up until the specified min.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.TezEdgeProperty.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ReduceWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.GenTezWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.GenTezUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">conf.hive-default.xml.template</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="7159" opendate="2014-5-31 00:00:00" fixdate="2014-6-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>For inner joins push a &amp;#39;is not null predicate&amp;#39; to the join sources for every non nullSafe join condition</summary>
      <description>A join B on A.x = B.ycan be transformed to(A where x is not null) join (B where y is not null) on A.x = B.yApart from avoiding shuffling null keyed rows it also avoids issues with reduce-side skew when there are a lot of null values in the data.Thanks to gopalv for the analysis and coming up with the solution.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.6.q.out</file>
      <file type="M">ql.src.test.results.compiler.plan.join3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join1.q.xml</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.shufflejoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.nested.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.context.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.bucketmapjoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.top.level.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union34.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union32.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union24.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.case.column.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.subquery.in.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.subquery.exists.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mrr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mapjoin.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mapjoin.decimal.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.limit.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.filter.join.breaktask.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.product.check.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.product.check.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.bucket.map.join.tez2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.bucket.map.join.tez1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.table.access.keys.stats.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subq.where.serialization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.unqualcolumnrefs.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.multiinsert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.in.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.in.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.exists.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.exists.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stats11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.union.remove.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.union.remove.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.semijoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.select.transform.hint.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.regex.col.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.reduce.deduplicate.extended.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.reduce.deduplicate.exclude.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.quotedid.skew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.vc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.union.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.udf.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.repeated.alias.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.random.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.multi.insert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join.filter.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.gby.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.clusterby.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.pcr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nonmr.fetch.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.multi.join.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.multiMapJoin2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.multiMapJoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.metadataonly1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mergejoins.mixed.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mergejoins.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.subquery2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.subquery.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.memcheck.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit.pushdown.negative.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.lateral.view.noalias.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.lateral.view.cp.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.vc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.thrift.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.star.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.reorder4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.reorder3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.reorder2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.reorder.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.rc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.nullsafe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.map.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.hive.626.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.unqual4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.unqual3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.unqual2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.unqual1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.alt.syntax.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join40.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join38.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join37.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join36.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join35.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join34.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join33.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join32.lessSize.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join32.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join31.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join30.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join29.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join28.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join27.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input39.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.innerjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.map.operators.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.bitmap.auto.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.bitmap3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.self.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.mult.tables.compact.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.mult.tables.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.skew.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.position.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.grouping.sets4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.filter.join.breaktask.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.explain.rearrange.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.explain.logical.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cross.product.check.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cross.product.check.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cross.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.column.access.stats.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cluster.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucket.map.join.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucket.map.join.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketsortoptimize.insert.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketsortoptimize.insert.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketsortoptimize.insert.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketsortoptimize.insert.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketsortoptimize.insert.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketsortoptimize.insert.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin.negative3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin.negative2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin.negative.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.7.q.out</file>
      <file type="M">hbase-handler.src.test.results.positive.hbase.queries.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ColumnPruner.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.test.results.clientnegative.bucket.mapjoin.mismatch1.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.sortmerge.mapjoin.mismatch.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.allcolref.in.udf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ambiguous.col.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join24.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join27.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join29.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join30.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join32.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join.reordering.values.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join.without.localtask.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.smb.mapjoin.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.5.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="7162" opendate="2014-6-1 00:00:00" fixdate="2014-6-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hadoop-1 build broken by HIVE-7071</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.common.src.main.java.org.apache.hadoop.hive.shims.HadoopShims.java</file>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
      <file type="M">shims.0.20.src.main.java.org.apache.hadoop.hive.shims.Hadoop20Shims.java</file>
      <file type="M">shims.0.20S.src.main.java.org.apache.hadoop.hive.shims.Hadoop20SShims.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.java</file>
    </fixedFiles>
  </bug>
  <bug id="7173" opendate="2014-6-3 00:00:00" fixdate="2014-6-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support HIVE-4867 on mapjoin of MR Tasks</summary>
      <description>HIVE-4867 dedups columns in RS for reducer join and RS for order-by. But small aliases of mapjoin of MR tasks still contains key columns in value exprs.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.join28.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.nested.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union34.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.multiinsert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stats11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.select.transform.hint.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.reduce.deduplicate.exclude.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.multi.join.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.multiMapJoin2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.multiMapJoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.test.outer.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.subquery2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.subquery.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.memcheck.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.filter.on.outerjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.reorder4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.map.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join40.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join39.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join37.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join36.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join35.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join34.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join33.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join32.lessSize.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join32.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join31.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join30.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join29.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.MapJoinBytesTableContainer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.UnwrapRowContainer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.LocalMapJoinProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.test.results.clientnegative.sortmerge.mapjoin.mismatch.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join28.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join29.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join30.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join31.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join32.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join.without.localtask.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin.negative3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cross.product.check.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.explain.rearrange.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join27.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="7196" opendate="2014-6-9 00:00:00" fixdate="2014-6-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Configure session by single open session call</summary>
      <description>Currently, jdbc2 connection executes set command for each conf/vars, which can be embedded in TOpenSessionReq.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.HiveSessionImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.SetProcessor.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.Utils.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveConnection.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcDriver2.java</file>
    </fixedFiles>
  </bug>
  <bug id="72" opendate="2008-11-18 00:00:00" fixdate="2008-11-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>wrong results if partition pruning not strict and no mep-reduce job needed</summary>
      <description>Suppose T is a partitioned table on ds, where ds is a string column, the following queries: SELECT a.* FROM T a WHERE a.ds=2008-09-08 LIMIT 1; SELECT a.* FROM T a WHERE a.ds=2008-11-10 LIMIT 1;return the first row from the first partition.This is because of the typecast to double.for a.ds=2008-01-01 or anything (a.ds=1), evaluate (Double, Double) is invoked at partition pruning.Since '2008-11-01' is not a valid double, it is converted to a null, and therefore the result of pruning returns null (unknown) - not FALSE.All unknowns are also accepted, therefore all partitions are accepted which explains this behavior.filter is not invoked since it is a select * query, so map-reduce job is started.We just turn off this optimization if pruning indicates that there can be unknown partitions.</description>
      <version>None</version>
      <fixedVersion>0.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.PartitionPruner.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7204" opendate="2014-6-10 00:00:00" fixdate="2014-6-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use NULL vertex location hint for Prewarm DAG vertices</summary>
      <description>The current 0.5.x branch of Tez added extra preconditions which check for parallelism settings to match between the number of containers and the vertex location hints.Caused by: org.apache.hadoop.ipc.RemoteException(java.lang.IllegalArgumentException): Locations array length must match the parallelism set for the vertex at com.google.common.base.Preconditions.checkArgument(Preconditions.java:88) at org.apache.tez.dag.api.Vertex.setTaskLocationsHint(Vertex.java:105) at org.apache.tez.dag.app.DAGAppMaster.startPreWarmContainers(DAGAppMaster.java:1004)</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="7209" opendate="2014-6-10 00:00:00" fixdate="2014-7-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>allow metastore authorization api calls to be restricted to certain invokers</summary>
      <description>Any user who has direct access to metastore can make metastore api calls that modify the authorization policy. The users who can make direct metastore api calls in a secure cluster configuration are usually the 'cluster insiders' such as Pig and MR users, who are not (securely) covered by the metastore based authorization policy. But it makes sense to disallow access from such users as well.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.HiveMetastoreAuthorizationProvider.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.DefaultHiveMetastoreAuthorizationProvider.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.HiveUtils.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.events.PreEventContext.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.security.DummyHiveMetastoreAuthorizationProvider.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.security.TestAuthorizationPreEventListener.java</file>
      <file type="M">conf.hive-default.xml.template</file>
    </fixedFiles>
  </bug>
  <bug id="7212" opendate="2014-6-11 00:00:00" fixdate="2014-6-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use resource re-localization instead of restarting sessions in Tez</summary>
      <description>scriptfile1.q is failing on Tez because of a recent breakage in localization. On top of that we're currently restarting sessions if the resources have changed. (add file/add jar/etc). Instead of doing this we should just have tez relocalize these new resources. This way no session/AM restart is required.</description>
      <version>0.14.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.tez.TestTezTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezSessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="7220" opendate="2014-6-11 00:00:00" fixdate="2014-7-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Empty dir in external table causes issue (root_dir_external_table.q failure)</summary>
      <description>While looking at root_dir_external_table.q failure, which is doing a query on an external table located at root ('/'), I noticed that latest Hadoop2 CombineFileInputFormat returns split representing empty directories (like '/Users'), which leads to failure in Hive's CombineFileRecordReader as it tries to open the directory for processing.Tried with an external table in a normal HDFS directory, and it also returns the same error. Looks like a real bug.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.common-secure.src.main.java.org.apache.hadoop.hive.shims.HadoopShimsSecure.java</file>
      <file type="M">itests.qtest.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7222" opendate="2014-6-12 00:00:00" fixdate="2014-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support timestamp column statistics in ORC and extend PPD for timestamp</summary>
      <description>Add column statistics for timestamp columns in ORC. Also extend predicate pushdown to support timestamp column evaluation.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.analyze.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge.incompat2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge.incompat1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.analyze.q.out</file>
      <file type="M">ql.src.protobuf.org.apache.hadoop.hive.ql.io.orc.orc.proto.proto</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.sarg.SearchArgumentImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.WriterImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.ColumnStatisticsImpl.java</file>
      <file type="M">ql.src.gen.protobuf.gen-java.org.apache.hadoop.hive.ql.io.orc.OrcProto.java</file>
    </fixedFiles>
  </bug>
  <bug id="7231" opendate="2014-6-14 00:00:00" fixdate="2014-7-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve ORC padding</summary>
      <description>Current ORC padding is not optimal because of fixed stripe sizes within block. The padding overhead will be significant in some cases. Also padding percentage relative to stripe size is not configurable.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.resources.orc-file-dump.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump-dictionary-threshold.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.WriterImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcFile.java</file>
      <file type="M">conf.hive-default.xml.template</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="7243" opendate="2014-6-16 00:00:00" fixdate="2014-7-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Print padding information in ORC file dump</summary>
      <description>It will be useful to print the padding information in orc file dump utility.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.resources.orc-file-dump.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump-dictionary-threshold.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.FileDump.java</file>
    </fixedFiles>
  </bug>
  <bug id="7250" opendate="2014-6-18 00:00:00" fixdate="2014-6-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Adaptive compression buffer size for wide tables in ORC</summary>
      <description>If the input table is wide (in the order of 1000s), ORC compression buffer size overhead becomes significant causing OOM issues. To overcome this issue, buffer size should be adaptively chosen based on the available memory and the number of columns.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestUnrolledBitPack.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.WriterImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="7265" opendate="2014-6-20 00:00:00" fixdate="2014-6-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BINARY columns use BytesWritable::getBytes() without ::getLength()</summary>
      <description>The Text conversion for BINARY columns does case BINARY: t.set(((BinaryObjectInspector) inputOI).getPrimitiveWritableObject(input).getBytes()); return t;This omission was noticed while investigating a different String related bug, in a list of functions which call getBytes() without calling getSize/getLength().</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter.java</file>
    </fixedFiles>
  </bug>
  <bug id="7266" opendate="2014-6-20 00:00:00" fixdate="2014-7-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimized HashTable with vectorized map-joins results in String columns extending</summary>
      <description>The following query returns different results when both vectorized mapjoin and the new optimized hashtable are enabled.hive&gt; set hive.vectorized.execution.enabled=false;hive&gt; select s_suppkey, n_name from supplier, nation where s_nationkey = n_nationkey limit 25;...316869 JAPAN1636869 RUSSIA1096869 IRAN7236869 RUSSIA2276869 INDIA8516869 ARGENTINA2636869 MOZAMBIQUE3836869 ROMANIA2616869 FRANCEBut when vectorization is enabled, the results are 316869 JAPAN1636869 RUSSIA1096869 IRANIA7236869 RUSSIA2276869 INDIAA8516869 ARGENTINA2636869 MOZAMBIQUE3836869 ROMANIAQUE2616869 FRANCEAQUEit works correctly with vectorization when the new optimized map-join hashtable is disabled hive&gt; set hive.vectorized.execution.enabled=true; hive&gt; set hive.mapjoin.optimized.hashtable=false; hive&gt; select s_suppkey, n_name from supplier, nation where s_nationkey = n_nationkey limit 25;316869 JAPAN1636869 RUSSIA1096869 IRAN7236869 RUSSIA2276869 INDIA8516869 ARGENTINA2636869 MOZAMBIQUE3836869 ROMANIA2616869 FRANCE</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorColumnAssignFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="7289" opendate="2014-6-25 00:00:00" fixdate="2014-7-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>revert HIVE-6469</summary>
      <description>this task is to revert HIVE-6469 (see discussion on HIVE-7100)</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl.java</file>
      <file type="M">conf.hive-default.xml.template</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.FileUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="729" opendate="2009-8-6 00:00:00" fixdate="2009-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>select expression with optional "as"</summary>
      <description>"as" should be optional in select expression. Query like the following should work:SELECT a, b FROM ( SELECT key a, value b FROM src) src1ORDER BY a LIMIT 1;</description>
      <version>None</version>
      <fixedVersion>0.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.compiler.errors.invalid.select.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.Hive.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7313" opendate="2014-6-28 00:00:00" fixdate="2014-1-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow in-memory/ssd session-level temp-tables</summary>
      <description>With HDFS storage policies implementation, temporary tables can be written with different storage/reliability policies. In-session temporary tables can be targetted at both SSD and memory storage policies, with fallbacks onto the disk and the associated reliability trade-offs.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.common.src.main.java.org.apache.hadoop.hive.shims.HadoopShims.java</file>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
      <file type="M">shims.0.20S.src.main.java.org.apache.hadoop.hive.shims.Hadoop20SShims.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.FileSinkDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FileSinkOperator.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="7356" opendate="2014-7-7 00:00:00" fixdate="2014-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Table level stats collection fail for partitioned tables</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.columnstats.partlvl.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.columnstats.partlvl.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ColumnStatsTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="736" opendate="2009-8-7 00:00:00" fixdate="2009-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MetaStoreUtils get_fields() does not return partition column</summary>
      <description>MetaStoreUtil's get_fields(), which is offered through the Hive Server interface, does not include the partition field in its returned list of fields. This may be related to JIRA-671. At the moment, there is no way for a Hive client to discover a partition column in a table, creating a big issue for anyone who wishes to query a partitioned table.</description>
      <version>None</version>
      <fixedVersion>0.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.TestHiveMetaStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.IMetaStoreClient.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStoreClient.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">metastore.src.gen-py.hive.metastore.ttypes.py</file>
      <file type="M">metastore.src.gen-py.hive.metastore.ThriftHiveMetastore.py</file>
      <file type="M">metastore.src.gen-py.hive.metastore.ThriftHiveMetastore-remote</file>
      <file type="M">metastore.src.gen-php.ThriftHiveMetastore.php</file>
      <file type="M">metastore.src.gen-javabean.org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore.java</file>
      <file type="M">metastore.src.gen-javabean.org.apache.hadoop.hive.metastore.api.Index.java</file>
      <file type="M">metastore.if.hive.metastore.thrift</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7361" opendate="2014-7-7 00:00:00" fixdate="2014-7-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>using authorization api for RESET, DFS, ADD, DELETE, COMPILE commands</summary>
      <description>The only way to disable the commands SET, RESET, DFS, ADD, DELETE and COMPILE that is available currently is to use the hive.security.command.whitelist parameter.Some of these commands are disabled using this configuration parameter for security reasons when SQL standard authorization is enabled. However, it gets disabled in all cases.If authorization api is used authorize the use of these commands, it will give authorization implementations the flexibility to allow/disallow these commands based on user privileges.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientnegative.authorize.create.tbl.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.temp.table.authorize.create.tbl.q.out</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.authorization.TestJdbcWithSQLAuthorization.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessControllerForTest.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.AddResourceProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.CommandProcessorResponse.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.CompileProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.DeleteResourceProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.DfsProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.ResetProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.HiveOperationType.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.HivePrivilegeObject.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.GrantPrivAuthUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.Operation2Privilege.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLAuthorizationUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessController.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizationValidator.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.TestSQLStdHiveAccessController.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveOperationType.java</file>
      <file type="M">ql.src.test.queries.clientnegative.authorization.addjar.q</file>
      <file type="M">ql.src.test.queries.clientnegative.authorization.dfs.q</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.addjar.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.addpartition.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.alter.db.owner.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.alter.db.owner.default.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.createview.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.create.func1.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.create.func2.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.create.macro1.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.ctas.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.desc.table.nosel.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.dfs.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.droppartition.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.drop.db.cascade.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.drop.db.empty.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.grant.table.allpriv.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.grant.table.fail1.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.grant.table.fail.nogrant.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.insertoverwrite.nodel.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.insert.noinspriv.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.insert.noselectpriv.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.not.owner.alter.tab.rename.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.not.owner.alter.tab.serdeprop.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.not.owner.drop.tab.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.not.owner.drop.view.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.priv.current.role.neg.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.rolehierarchy.privs.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.select.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.select.view.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.show.parts.nosel.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.truncate.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="7364" opendate="2014-7-8 00:00:00" fixdate="2014-7-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Trunk cannot be built on -Phadoop1 after HIVE-7144</summary>
      <description>Text.copyBytes() is introduced in hadoop-2</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.ColumnStatisticsImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="7365" opendate="2014-7-8 00:00:00" fixdate="2014-7-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Explain authorize for auth2 throws exception</summary>
      <description>throws NPE in auth v2.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.authorization.view.sqlstd.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.authorization.view.sqlstd.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.AuthorizationFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExplainTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="7366" opendate="2014-7-8 00:00:00" fixdate="2014-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>getDatabase using direct sql</summary>
      <description>Given that get_database is easily one of the most frequent calls made on the metastore, we should have the ability to bypass datanucleus for that, and use direct SQL instead.This was something that I did initially as part of debugging HIVE-7368, but I think that given the frequency of this call, it's useful to have it in mainline direct sql.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.ObjectStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.MetaStoreDirectSql.java</file>
    </fixedFiles>
  </bug>
  <bug id="7374" opendate="2014-7-9 00:00:00" fixdate="2014-7-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SHOW COMPACTIONS fail with remote metastore when there are no compations</summary>
      <description>Prerequistes :1. Remote metastore2. No compactionsIn CLI after doing this :show compactions;Return error :FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.thrift.transport.TTransportExceptionIn metatore logs :2014-07-09 17:54:10,537 ERROR [pool-3-thread-20]: server.TThreadPoolServer (TThreadPoolServer.java:run(213)) - Thrift error occurred during processing of message.org.apache.thrift.protocol.TProtocolException: Required field 'compacts' is unset! Struct:ShowCompactResponse(compacts:null) at org.apache.hadoop.hive.metastore.api.ShowCompactResponse.validate(ShowCompactResponse.java:310) at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$show_compact_result.validate(ThriftHiveMetastore.java) at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$show_compact_result$show_compact_resultStandardScheme.write(ThriftHiveMetastore.java) at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$show_compact_result$show_compact_resultStandardScheme.write(ThriftHiveMetastore.java) at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$show_compact_result.write(ThriftHiveMetastore.java) at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:53) at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:103) at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:744)</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.txn.compactor.TestCleaner.java</file>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.txn.TestCompactionTxnHandler.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.txn.TxnHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="7375" opendate="2014-7-9 00:00:00" fixdate="2014-5-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add option in test infra to compile in other profiles (like hadoop-1)</summary>
      <description>As we are seeing some commits breaking hadoop-1 compilation due to lack of pre-commit converage, it might be nice to add an option in the test infra to compile on optional profiles as a pre-step before testing on the main profile.NO PRECOMMIT TESTS</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.src.test.java.org.apache.hive.ptest.execution.TestScripts.testPrepSvn.approved.txt</file>
      <file type="M">testutils.ptest2.src.test.java.org.apache.hive.ptest.execution.TestScripts.testPrepNone.approved.txt</file>
      <file type="M">testutils.ptest2.src.test.java.org.apache.hive.ptest.execution.TestScripts.testPrepGit.approved.txt</file>
      <file type="M">testutils.ptest2.src.test.java.org.apache.hive.ptest.execution.TestScripts.java</file>
      <file type="M">testutils.ptest2.src.main.resources.source-prep.vm</file>
    </fixedFiles>
  </bug>
  <bug id="7394" opendate="2014-7-12 00:00:00" fixdate="2014-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ORC writer logging fails when the padding is &lt; 0.01</summary>
      <description>Currently ORC inserts logs the padding fraction.The log line throws a format exception when padding is too small.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.WriterImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="7395" opendate="2014-7-12 00:00:00" fixdate="2014-7-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Work around non availability of stats for partition columns</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.RelNodeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.RelOptHiveTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="7420" opendate="2014-7-15 00:00:00" fixdate="2014-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parameterize tests for HCatalog Pig interfaces for testing against all storage formats</summary>
      <description>Currently, HCatalog tests only test against RCFile with a few testing against ORC. The tests should be covering other Hive storage formats as well.HIVE-7286 turns HCatMapReduceTest into a test fixture that can be run with all Hive storage formats and with that patch, all test suites built on HCatMapReduceTest are running and passing against Sequence File, Text, and ORC in addition to RCFile.Similar changes should be made to make the tests for HCatLoader and HCatStorer generic so that they can be run against all Hive storage formats.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.StorageFormats.java</file>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.test.java.org.apache.hive.hcatalog.pig.TestOrcHCatStorerMulti.java</file>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.test.java.org.apache.hive.hcatalog.pig.TestOrcHCatStorer.java</file>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.test.java.org.apache.hive.hcatalog.pig.TestOrcHCatLoaderComplexSchema.java</file>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.test.java.org.apache.hive.hcatalog.pig.TestOrcHCatLoader.java</file>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.test.java.org.apache.hive.hcatalog.pig.TestHCatStorerMulti.java</file>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.test.java.org.apache.hive.hcatalog.pig.TestHCatStorer.java</file>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.test.java.org.apache.hive.hcatalog.pig.TestHCatLoaderComplexSchema.java</file>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.test.java.org.apache.hive.hcatalog.pig.TestHCatLoader.java</file>
      <file type="M">hcatalog.hcatalog-pig-adapter.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7432" opendate="2014-7-17 00:00:00" fixdate="2014-8-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove deprecated Avro&amp;#39;s Schema.parse usages</summary>
      <description>Schema.parse has been deprecated by Avro, however it is being used at multiple places in Hive.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestThatEvolvedSchemasActAsWeWant.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestSchemaReEncoder.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestGenericAvroRecordWritable.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestAvroSerializer.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestAvroSerdeUtils.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestAvroSerde.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestAvroObjectInspectorGenerator.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestAvroDeserializer.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.TypeInfoToSchema.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.SchemaResolutionProblem.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.AvroSerdeUtils.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.AvroGenericRecordWritable.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.avro.AvroGenericRecordReader.java</file>
    </fixedFiles>
  </bug>
  <bug id="7472" opendate="2014-7-22 00:00:00" fixdate="2014-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CLONE - Import fails for tables created with default text, sequence and orc file formats using HCatalog API</summary>
      <description>Cloning HIVE-5550 because HIVE-5550 fixed org.apache.hcatalog., and not org.apache.hive.hcatalog. . And that other package needs this change too. And with 0.14 pruning of org.apache.hcatalog.*, we miss this patch altogether.====A table was created using HCatalog API with out specifying the file format, it defaults to:fileFormat=TextFile, inputformat=org.apache.hadoop.mapred.TextInputFormat, outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormatBut, when hive fetches the table from the metastore, it strangely replaces the output format with org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormatand the comparison between source and target table fails.The code in org.apache.hadoop.hive.ql.parse.ImportSemanticAnalyzer#checkTable does a string comparison of classes and fails. // check IF/OF/Serde String existingifc = table.getInputFormatClass().getName(); String importedifc = tableDesc.getInputFormat(); String existingofc = table.getOutputFormatClass().getName(); String importedofc = tableDesc.getOutputFormat(); if ((!existingifc.equals(importedifc)) || (!existingofc.equals(importedofc))) { throw new SemanticException( ErrorMsg.INCOMPATIBLE_SCHEMA .getMsg(" Table inputformat/outputformats do not match")); }This only affects tables with text and sequence file formats but not rc or orc.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.webhcat.java-client.src.test.java.org.apache.hive.hcatalog.api.TestHCatClient.java</file>
      <file type="M">hcatalog.webhcat.java-client.src.main.java.org.apache.hive.hcatalog.api.HCatCreateTableDesc.java</file>
    </fixedFiles>
  </bug>
  <bug id="7477" opendate="2014-7-22 00:00:00" fixdate="2014-8-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade hive to use tez 0.4.1</summary>
      <description>Tez has released 0.4.1 that has bug fixes we need.</description>
      <version>0.14.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7478" opendate="2014-7-22 00:00:00" fixdate="2014-7-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: PPD push conditions to Join Operators</summary>
      <description>This was turned off in HivePushFilterPastJoin because non equality conditions were being pushed. Fix this so that equality predicates are pushed as join conditions.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.rules.HivePushFilterPastJoinRule.java</file>
    </fixedFiles>
  </bug>
  <bug id="748" opendate="2009-8-12 00:00:00" fixdate="2009-8-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>test for extracting urls</summary>
      <description>This test is useful because it will help in progress of https://issues.apache.org/jira/browse/HIVE-396</description>
      <version>None</version>
      <fixedVersion>0.4.0,0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7490" opendate="2014-7-23 00:00:00" fixdate="2014-7-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Revert ORC stripe size</summary>
      <description>HIVE-6037 reverted the changes to ORC stripe size introduced by HIVE-7231.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hive-default.xml.template</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="7495" opendate="2014-7-24 00:00:00" fixdate="2014-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Print dictionary size in orc file dump</summary>
      <description>DICTIONARY_V2 fails to print dictionary size in file dump.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.resources.orc-file-dump.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.FileDump.java</file>
    </fixedFiles>
  </bug>
  <bug id="7509" opendate="2014-7-24 00:00:00" fixdate="2014-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fast stripe level merging for ORC</summary>
      <description>Similar to HIVE-1950, add support for fast stripe level merging of ORC files through CONCATENATE command and conditional merge task. This fast merging is ideal for merging many small ORC files to a larger file without decompressing and decoding the data of small orc files.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.union.remove.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rcfile.merge3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rcfile.merge2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rcfile.merge1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rcfile.createas1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.createas1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge.dynamic.partition5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge.dynamic.partition4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.dyn.part.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.GenTezUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.AlterTablePartMergeFilesDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMRFileSink1.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileMergeMapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileBlockMergeInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.WriterImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.ReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.TaskFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MoveTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
      <file type="M">itests.qtest.testconfiguration.properties</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileBlockMergeOutputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.rcfile.merge.MergeWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.rcfile.merge.BlockMergeTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="7510" opendate="2014-7-24 00:00:00" fixdate="2014-7-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO:Add Greedy Algorithm(LucidDB) For Join Order</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.RexNodeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.RelNodeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.rules.HiveRelFieldTrimmer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.reloperators.HiveJoinRel.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.cost.HiveVolcanoPlanner.java</file>
      <file type="M">ql.pom.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">conf.hive-default.xml.template</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="7523" opendate="2014-7-27 00:00:00" fixdate="2014-7-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix spark build after merge merging trunk</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkClient.java</file>
      <file type="M">conf.hive-default.xml.template</file>
    </fixedFiles>
  </bug>
  <bug id="7524" opendate="2014-7-27 00:00:00" fixdate="2014-7-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable auto conversion of SMBjoin in presence of constant propagate optimization</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.nullsafe.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ExprNodeConstantDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.SortedMergeJoinProc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConstantPropagate.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.AbstractBucketJoinProc.java</file>
    </fixedFiles>
  </bug>
  <bug id="7528" opendate="2014-7-27 00:00:00" fixdate="2014-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support cluster by and distributed by [Spark Branch]</summary>
      <description>clustered by = distributed by + sort by, so this is related to HIVE-7527. If sort by is in place, the assumption is that we don't need to do anything about distributed by or clustered by. Still, we need to confirm and verify.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.SparkEdgeProperty.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.GenSparkWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.GenSparkUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkPlanGenerator.java</file>
    </fixedFiles>
  </bug>
  <bug id="7535" opendate="2014-7-28 00:00:00" fixdate="2014-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make use of number of nulls column statistics in filter rule</summary>
      <description>The filter rule does not make use of number of nulls column statistics for "IS NULL" and "IS NOT NULL" expression evaluation.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.metadataonly1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.metadataonly1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.filter.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.stats.annotation.StatsRulesProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="7536" opendate="2014-7-28 00:00:00" fixdate="2014-7-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make use of decimal column statistics in statistics annotation</summary>
      <description>HIVE-6701 added decimal column statistics. The statistics annotation optimizer should make use of decimal column statistics as well.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.StatsUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="7538" opendate="2014-7-29 00:00:00" fixdate="2014-7-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix eclipse:eclipse after HIVE-7496</summary>
      <description>HIVE-7496 removes "hive-default.xml.template" from the source control. However, hive-common still refers to this file in the build-resources. Thus trying to build eclipse projects on fresh checkout of branch will get "hive-common missing required source-folder: ../conf/"NO PRECOMMIT TESTS</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">common.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7540" opendate="2014-7-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NotSerializableException encountered when using sortByKey transformation</summary>
      <description>This exception is thrown when sortByKey is used as the shuffle transformation between MapWork and ReduceWork:org.apache.spark.SparkException: Job aborted due to stage failure: Task not serializable: java.io.NotSerializableException: org.apache.hadoop.io.BytesWritable at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1049) at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1033) at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1031) at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47) at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1031) at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitMissingTasks(DAGScheduler.scala:772) at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:715) at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:719) at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:718) at scala.collection.immutable.List.foreach(List.scala:318) at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:718) at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:699)… The root cause is that the RangePartitioner used by sortByKey contains rangeBounds: Array&amp;#91;BytesWritable&amp;#93;, which is considered not serializable in spark.A workaround to this issue is to set the number of partitions to 1 when calling sortByKey, in which case the rangeBounds will be just an empty array.NO PRECOMMIT TESTS. This is for spark branch only.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.SparkEdgeProperty.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SortByShuffler.java</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7544" opendate="2014-7-29 00:00:00" fixdate="2014-9-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Changes related to TEZ-1288 (FastTezSerialization)</summary>
      <description>Add ability to make use of TezBytesWritableSerialization.NO PRECOMMIT TESTS</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="7546" opendate="2014-7-30 00:00:00" fixdate="2014-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Pull partition and column stats regardless of hive conf settings</summary>
      <description>Because of performance reasons we have flags to avoid loading certain stats when requested. That's fine for the join selection algo, but CBO needs these stats.This patch separates the two so that CBO can fetch the stats it needs and the regular stats annotation can be controlled via flags.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.StatsUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.RelOptHiveTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="7547" opendate="2014-7-30 00:00:00" fixdate="2014-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add ipAddress and userName to ExecHook</summary>
      <description>Auditing tools should be able to know about the ipAddress and userName of the user executing operations. These could be made available through the Hive execution-hooks.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.thrift.ThriftCLIService.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.SessionManager.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.CLIService.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.hooks.HookContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
    </fixedFiles>
  </bug>
  <bug id="7548" opendate="2014-7-30 00:00:00" fixdate="2014-8-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Precondition checks should not fail the merge task in case of automatic trigger</summary>
      <description>ORC fast merge (HIVE-7509) will fail the merge task in case if any of the precondition checks fail. Precondition check fail is good for "ALTER TABLE .. CONCATENATE" but not for automatic trigger of merge task from conditional resolver. In case if a partition has non-compatible ORC files for merging then the merge task should ignore it and not fail the task.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.queries.clientnegative.orc.merge5.q</file>
      <file type="M">ql.src.test.queries.clientnegative.orc.merge4.q</file>
      <file type="M">ql.src.test.queries.clientnegative.orc.merge3.q</file>
      <file type="M">ql.src.test.queries.clientnegative.orc.merge2.q</file>
      <file type="M">ql.src.test.queries.clientnegative.orc.merge1.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcFileMergeMapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.merge.MergeMapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
    </fixedFiles>
  </bug>
  <bug id="755" opendate="2009-8-14 00:00:00" fixdate="2009-9-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Driver NullPointerException when calling getResults without first compiling</summary>
      <description>The Hive Driver will throw a NullPointerException when getResults() is called but the context has not yet been set by a call to compile().</description>
      <version>None</version>
      <fixedVersion>0.4.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.test.org.apache.hadoop.hive.service.TestHiveServer.java</file>
      <file type="M">service.src.java.org.apache.hadoop.hive.service.HiveServer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7550" opendate="2014-7-30 00:00:00" fixdate="2014-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extend cached evaluation to multiple expressions</summary>
      <description>Currently, hive.cache.expr.evaluation caches per expression. But cache context might be shared for multiple expressions.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.SelectOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExprNodeEvaluatorFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="7553" opendate="2014-7-30 00:00:00" fixdate="2014-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>avoid the scheduling maintenance window for every jar change</summary>
      <description>When user needs to refresh existing or add a new jar to HS2, it needs to restart it. As HS2 is service exposed to clients, this requires scheduling maintenance window for every jar change. It would be great if we could avoid that.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.HiveSessionImpl.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.session.TestSessionState.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestUtilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.StatsFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.HiveCommand.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.CommandProcessorFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.TableDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.CreateTableDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.AggregationDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ParseUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ImportSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Table.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Partition.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.HiveUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.HivePassThroughOutputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.hooks.HookUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.HadoopJobExecHelper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ListSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DefaultFetchFormatter.java</file>
      <file type="M">hcatalog.webhcat.java-client.src.main.java.org.apache.hive.hcatalog.api.HCatClient.java</file>
      <file type="M">hcatalog.core.src.main.java.org.apache.hive.hcatalog.common.HCatUtil.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="7556" opendate="2014-7-30 00:00:00" fixdate="2014-7-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix code style, license header, tabs, etc. [Spark Branch]</summary>
      <description>NO PRECOMMIT TESTS. This is for spark branch only.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkTran.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkPlan.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkCollector.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkClient.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.ShuffleTran.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.ReduceTran.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.MapTran.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.KryoSerializer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HiveVoidFunction.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunction.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HiveMapFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="7592" opendate="2014-8-1 00:00:00" fixdate="2014-8-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>List Jars or Files are not supported by Beeline</summary>
      <description>Through adding jars or files are supported by Beeline, List jars or Files are still not supported.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.HiveCommand.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.CommandProcessorFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.CommandProcessor.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">cli.src.java.org.apache.hadoop.hive.cli.CliDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="7618" opendate="2014-8-5 00:00:00" fixdate="2014-8-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestDDLWithRemoteMetastoreSecondNamenode unit test failure</summary>
      <description>Looks like TestDDLWithRemoteMetastoreSecondNamenode started failing after HIVE-6584 was committed.TestDDLWithRemoteMetastoreSecondNamenode.testCreateTableWithIndexAndPartitionsNonDefaultNameNode:272-&gt;createTableAndCheck:201-&gt;createTableAndCheck:219 Table should be located in the second filesystem expected:&lt;[hdfs]&gt; but was:&lt;[pfile]&gt;</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="7620" opendate="2014-8-5 00:00:00" fixdate="2014-8-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive metastore fails to start in secure mode due to "java.lang.NoSuchFieldError: SASL_PROPS" error</summary>
      <description>When Hive metastore is started in a Hadoop 2.5 cluster, it fails to start with following error14/07/31 17:45:58 [main]: ERROR metastore.HiveMetaStore: Metastore Thrift Server threw an exception...java.lang.NoSuchFieldError: SASL_PROPS at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S.getHadoopSaslProperties(HadoopThriftAuthBridge20S.java:126) at org.apache.hadoop.hive.metastore.MetaStoreUtils.getMetaStoreSaslProperties(MetaStoreUtils.java:1483) at org.apache.hadoop.hive.metastore.HiveMetaStore.startMetaStore(HiveMetaStore.java:5225) at org.apache.hadoop.hive.metastore.HiveMetaStore.main(HiveMetaStore.java:5152)Changes in HADOOP-10451 to remove SaslRpcServer.SASL_PROPS are causing this error.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.common.src.main.java.org.apache.hadoop.hive.shims.ShimLoader.java</file>
    </fixedFiles>
  </bug>
  <bug id="7621" opendate="2014-8-5 00:00:00" fixdate="2014-8-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add tests for cte with cbo</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.cbo.correctness.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.cbo.correctness.q</file>
    </fixedFiles>
  </bug>
  <bug id="7634" opendate="2014-8-6 00:00:00" fixdate="2014-8-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use Configuration.getPassword() if available to eliminate passwords from hive-site.xml</summary>
      <description>HADOOP-10607 provides a Configuration.getPassword() API that allows passwords to be retrieved from a configured credential provider, while also being able to fall back to the HiveConf setting if no provider is set up. Hive should use this API for versions of Hadoop that support this API. This would give users the ability to remove the passwords from their Hive configuration files.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.common.src.main.java.org.apache.hadoop.hive.shims.HadoopShims.java</file>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
      <file type="M">shims.0.20.src.main.java.org.apache.hadoop.hive.shims.Hadoop20Shims.java</file>
      <file type="M">shims.0.20S.src.main.java.org.apache.hadoop.hive.shims.Hadoop20SShims.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.thrift.ThriftHttpCLIService.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.thrift.ThriftBinaryCLIService.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.txn.TxnHandler.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.txn.TxnDbUtil.java</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.HiveSchemaTool.java</file>
      <file type="M">beeline.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7647" opendate="2014-8-7 00:00:00" fixdate="2014-9-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Beeline does not honor --headerInterval and --color when executing with "-e"</summary>
      <description>--showHeader is being honored&amp;#91;root@localhost ~&amp;#93;# beeline --showHeader=false -u 'jdbc:hive2://localhost:10000/default' -n hive -d org.apache.hive.jdbc.HiveDriver -e "select * from sample_07 limit 10;"Connecting to jdbc:hive2://localhost:10000/defaultConnected to: Apache Hive (version 0.12.0-cdh5.0.1)Driver: Hive JDBC (version 0.12.0-cdh5.0.1)Transaction isolation: TRANSACTION_REPEATABLE_READ-hiveconf (No such file or directory)---------------------------------------------------------------+ 00-0000 All Occupations 135185230 42270 11-0000 Management occupations 6152650 100310 11-1011 Chief executives 301930 160440 11-1021 General and operations managers 1697690 107970 11-1031 Legislators 64650 37980 11-2011 Advertising and promotions managers 36100 94720 11-2021 Marketing managers 166790 118160 11-2022 Sales managers 333910 110390 11-2031 Public relations managers 51730 101220 11-3011 Administrative services managers 246930 79500 ---------------------------------------------------------------+10 rows selected (0.838 seconds)Beeline version 0.12.0-cdh5.1.0 by Apache HiveClosing: org.apache.hive.jdbc.HiveConnection--outputFormat is being honored.&amp;#91;root@localhost ~&amp;#93;# beeline --outputFormat=csv -u 'jdbc:hive2://localhost:10000/default' -n hive -d org.apache.hive.jdbc.HiveDriver -e "select * from sample_07 limit 10;"Connecting to jdbc:hive2://localhost:10000/defaultConnected to: Apache Hive (version 0.12.0-cdh5.0.1)Driver: Hive JDBC (version 0.12.0-cdh5.0.1)Transaction isolation: TRANSACTION_REPEATABLE_READ'code','description','total_emp','salary''00-0000','All Occupations','135185230','42270''11-0000','Management occupations','6152650','100310''11-1011','Chief executives','301930','160440''11-1021','General and operations managers','1697690','107970''11-1031','Legislators','64650','37980''11-2011','Advertising and promotions managers','36100','94720''11-2021','Marketing managers','166790','118160''11-2022','Sales managers','333910','110390''11-2031','Public relations managers','51730','101220''11-3011','Administrative services managers','246930','79500'10 rows selected (0.664 seconds)Beeline version 0.12.0-cdh5.1.0 by Apache HiveClosing: org.apache.hive.jdbc.HiveConnectionboth --color &amp; --headerInterval are being honored when executing using "-f" option (reads query from a file rather than the commandline) (cannot really see the color here but use the terminal colors)&amp;#91;root@localhost ~&amp;#93;# beeline --showheader=true --color=true --headerInterval=5 -u 'jdbc:hive2://localhost:10000/default' -n hive -d org.apache.hive.jdbc.HiveDriver -f /tmp/tmp.sql Connecting to jdbc:hive2://localhost:10000/defaultConnected to: Apache Hive (version 0.12.0-cdh5.0.1)Driver: Hive JDBC (version 0.12.0-cdh5.0.1)Transaction isolation: TRANSACTION_REPEATABLE_READBeeline version 0.12.0-cdh5.1.0 by Apache Hive0: jdbc:hive2://localhost&gt; select * from sample_07 limit 8;---------------------------------------------------------------+ code description total_emp salary ---------------------------------------------------------------+ 00-0000 All Occupations 135185230 42270 11-0000 Management occupations 6152650 100310 11-1011 Chief executives 301930 160440 11-1021 General and operations managers 1697690 107970 11-1031 Legislators 64650 37980 ---------------------------------------------------------------+ code description total_emp salary ---------------------------------------------------------------+ 11-2011 Advertising and promotions managers 36100 94720 11-2021 Marketing managers 166790 118160 11-2022 Sales managers 333910 110390 ---------------------------------------------------------------+8 rows selected (0.921 seconds)0: jdbc:hive2://localhost&gt; Closing: org.apache.hive.jdbc.HiveConnectionBut when running beeline --showheader=true --color=true --headerInterval=5 -u 'jdbc:hive2://localhost:10000/default' -n hive -d org.apache.hive.jdbc.HiveDriver -e "select * from sample_07 limit 8;"headerInterval &amp; color are being overridden in the code.From Beeline.javaif (commands.size() &gt; 0) {// for single command execute, disable colorgetOpts().setColor(false);getOpts().setHeaderInterval(-1);This overrides the default behavior. The documentation states that the default headerInterval is 100 for "table" output format. By default "table" output format is used with "-e" option but that headerInterval is being set to "-1" which results in header being printed after every row (since HIVE-7200).</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">beeline.src.java.org.apache.hive.beeline.BeeLine.java</file>
    </fixedFiles>
  </bug>
  <bug id="7652" opendate="2014-8-7 00:00:00" fixdate="2014-8-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Check OutputCollector after closing ExecMapper/ExecReducer</summary>
      <description>Some operators such as Group By are adding output records to OutputCollector after closing the ExecMapper/ExecReducer. Need to check if lastRecordOutput has any records after closing the ExecMapper/ExecReducer.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList.java</file>
    </fixedFiles>
  </bug>
  <bug id="7667" opendate="2014-8-9 00:00:00" fixdate="2014-8-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>handle cast for long in get_aggr_stats() api for metastore for mysql</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.StatObjectConverter.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.MetaStoreDirectSql.java</file>
    </fixedFiles>
  </bug>
  <bug id="7679" opendate="2014-8-11 00:00:00" fixdate="2014-8-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JOIN operator should update the column stats when number of rows changes</summary>
      <description>JOIN operator does not update the column stats when the number of rows changes. All other operators scales up/down the column statistics when the number of rows changes. Same should be done for JOIN operator as well. Because of this dataSize might become negative as numNulls can get bigger than numRows (if scaling down of column stats is not done).</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.union20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.join.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.stats.annotation.StatsRulesProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="768" opendate="2009-8-19 00:00:00" fixdate="2009-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add configuration parameters to disable counters</summary>
      <description>All counters are enabled by default right now, which can have a performance hit - it would be good to enable them selectively.</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.compiler.plan.union.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf.when.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf.case.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.subq.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample7.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join8.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join7.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input.testxpath2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input.testxpath.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input.testsequencefile.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input.part1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input9.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input8.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input7.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input20.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.cast1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.case.sensitivity.q.xml</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Operator.java</file>
      <file type="M">data.conf.hive-site.xml</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7701" opendate="2014-8-13 00:00:00" fixdate="2014-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrading tez to 0.4.1 causes metadata only query to fail.</summary>
      <description>With HIVE-7477 we will be upgrading to tez 0.4.1. However, the metadataonly1.q file fails with the upgrade. The upgrade is required to prevent hanging of test runs. We can track the single failure here.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7702" opendate="2014-8-13 00:00:00" fixdate="2014-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Start running .q file tests on spark [Spark Branch]</summary>
      <description>Spark can currently only support a few queries, however there are some .q file tests which will pass today. The basic idea is that we should get some number of these actually working (10-20) so we can actually start testing the project.A good starting point might be the udf*, varchar*, or alter* tests:https://github.com/apache/hive/tree/spark/ql/src/test/queries/clientpositiveTo generate the output file for test XXX.q, you'd do:mvn clean install -DskipTests -Phadoop-2cd itestsmvn clean install -DskipTests -Phadoop-2cd qtest-sparkmvn test -Dtest= TestSparkCliDriver -Dqfile=XXX.q -Dtest.output.overwrite=true -Phadoop-2which would generate XXX.q.out which we can check-in to source control as a "golden file".Multiple tests can be run at a give time as so:mvn test -Dtest= TestSparkCliDriver -Dqfile=X1.q,X2.q -Dtest.output.overwrite=true -Phadoop-2</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7703" opendate="2014-8-13 00:00:00" fixdate="2014-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Don&amp;#39;t recompute partition list between optiq and hive planning</summary>
      <description>otherwise it will add to latency.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.RelNodeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.RelOptHiveTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="7704" opendate="2014-8-13 00:00:00" fixdate="2014-9-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create tez task for fast file merging</summary>
      <description>Currently tez falls back to MR task for merge file task. It will beneficial to convert the merge file tasks to tez task to make use of the performance gains from tez.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.union.remove.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rcfile.merge3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rcfile.merge2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rcfile.merge1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rcfile.createas1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.createas1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge.dynamic.partition5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge.dynamic.partition4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.dyn.part.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.orc.merge1.q</file>
      <file type="M">ql.src.test.queries.clientpositive.list.bucket.dml.8.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.TezCompiler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileMergeMapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileBlockMergeInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.WriterImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.Writer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcFileStripeMergeInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcFileMergeMapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.merge.MergeWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.merge.MergeTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.merge.MergeOutputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.merge.MergeMapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.merge.MergeInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.RecordProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.TaskFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.OperatorFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MoveTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
      <file type="M">ql.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.ql.plan.api.OperatorType.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="7705" opendate="2014-8-13 00:00:00" fixdate="2014-8-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>there&amp;#39;s a useless threadlocal in LBUtils that shows up in perf profiles</summary>
      <description>It might be cheaper to just create a VInt every time, but it can also be passed in externally.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryStruct.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryMap.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryArray.java</file>
    </fixedFiles>
  </bug>
  <bug id="7709" opendate="2014-8-13 00:00:00" fixdate="2014-10-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create SparkReporter [Spark Branch]</summary>
      <description>Hive operators use Reporter to collect global information, with Hive on Spark mode, we need a new implementation of Reporter to collect hive operator level information based on spark specified Counter. This task should depends on HIVE-7551.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkRecordHandler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkPlanGenerator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkClient.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunction.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HivePairFlatMapFunction.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HiveMapFunction.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.counter.SparkCounters.java</file>
    </fixedFiles>
  </bug>
  <bug id="7734" opendate="2014-8-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Join stats annotation rule is not updating columns statistics correctly</summary>
      <description>HIVE-7679 is not doing the correct thing. The scale down/up factor updating column stats was wrong as ratio = newRowCount/oldRowCount is always infinite (oldRowCount = 0). The old row count should be retrieved from parent corresponding to the current column whose statistics is being updated.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.union20.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.StatsUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.stats.annotation.StatsRulesProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="7736" opendate="2014-8-14 00:00:00" fixdate="2014-8-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>improve the columns stats update speed for all the partitions of a table</summary>
      <description>The current implementation of columns stats update for all the partitions of a table takes a long time when there are thousands of partitions. For example, on a given cluster, it took 600+ seconds to update all the partitions' columns stats for a table with 2 columns but 2000 partitions.ANALYZE TABLE src_stat_part partition (partitionId) COMPUTE STATISTICS for columns;We would like to improve the columns stats update speed for all the partitions of a table</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ColumnStatsTask.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.IMetaStoreClient.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStoreClient.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">metastore.src.gen.thrift.gen-rb.thrift.hive.metastore.rb</file>
      <file type="M">metastore.src.gen.thrift.gen-rb.hive.metastore.types.rb</file>
      <file type="M">metastore.src.gen.thrift.gen-py.hive.metastore.ttypes.py</file>
      <file type="M">metastore.src.gen.thrift.gen-py.hive.metastore.ThriftHiveMetastore.py</file>
      <file type="M">metastore.src.gen.thrift.gen-py.hive.metastore.ThriftHiveMetastore-remote</file>
      <file type="M">metastore.src.gen.thrift.gen-php.metastore.Types.php</file>
      <file type="M">metastore.src.gen.thrift.gen-php.metastore.ThriftHiveMetastore.php</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.TableStatsResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.TableStatsRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ShowLocksResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ShowCompactResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Schema.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.RequestPartsSpec.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PartitionsStatsResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PartitionsStatsRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.PartitionsByExprResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.OpenTxnsResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.LockRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.HeartbeatTxnRangeResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetOpenTxnsResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.GetOpenTxnsInfoResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Function.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.EnvironmentContext.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.DropPartitionsResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.AddPartitionsResult.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.AddPartitionsRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.ThriftHiveMetastore.server.skeleton.cpp</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.ThriftHiveMetastore.h</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.ThriftHiveMetastore.cpp</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.hive.metastore.types.h</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.hive.metastore.types.cpp</file>
      <file type="M">metastore.if.hive.metastore.thrift</file>
    </fixedFiles>
  </bug>
  <bug id="776" opendate="2009-8-20 00:00:00" fixdate="2009-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>make div as infix operator</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.4.0,0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.udf.divider.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.udf.divider.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.Hive.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7764" opendate="2014-8-18 00:00:00" fixdate="2014-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support all JDBC-HiveServer2 authentication modes on a secure cluster</summary>
      <description>Currently, HiveServer2 logs in with its keytab only if hive.server2.authentication is set to KERBEROS. However, hive.server2.authentication is config that determines the auth type an end user will use while authenticating with HiveServer2. There is a valid use case of user authenticating with HiveServer2 using LDAP for example, while HiveServer2 runs the query on a kerberized cluster.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.thrift.ThriftCLIService.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.CLIService.java</file>
    </fixedFiles>
  </bug>
  <bug id="7766" opendate="2014-8-18 00:00:00" fixdate="2014-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup Reduce operator code [Spark Branch]</summary>
      <description>This patch https://issues.apache.org/jira/secure/attachment/12662431/HIVE-7624.7-spark.patch over on HIVE-7624.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunctionResultList.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.ExecReducer.java</file>
    </fixedFiles>
  </bug>
  <bug id="7767" opendate="2014-8-18 00:00:00" fixdate="2014-8-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hive.optimize.union.remove does not work properly [Spark Branch]</summary>
      <description>Turing on the hive.optimize.union.remove property generates wrong union all result. For Example:create table inputTbl1(key string, val string) stored as textfile;load data local inpath '../../data/files/T1.txt' into table inputTbl1;SELECT *FROM ( SELECT key, count(1) as values from inputTbl1 group by key UNION ALL SELECT key, count(1) as values from inputTbl1 group by key) a; when the hive.optimize.union.remove is turned on, the query result is like: 1 12 13 17 18 2when the hive.optimize.union.remove is turned off, the query result is like: 7 12 18 23 11 17 12 18 23 11 1The expected query result is:7 12 18 23 11 17 12 18 23 11 1</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.GraphTran.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="777" opendate="2009-8-20 00:00:00" fixdate="2009-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CREATE TABLE with STRUCT type</summary>
      <description>Currently we only support map/array in type definition.We should support STRUCT as well.CREATE TABLE abc ( pageid INT, ads STRUCT&lt;adid:INT,location:STRING&gt;, userid INT);</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.Hive.g</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7772" opendate="2014-8-19 00:00:00" fixdate="2014-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add tests for order/sort/distribute/cluster by query [Spark Branch]</summary>
      <description>Now that these queries are supported, we should have tests to catch any problems we may have.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7773" opendate="2014-8-19 00:00:00" fixdate="2014-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Union all query finished with errors [Spark Branch]</summary>
      <description>When I run a union all query, I found the following error in spark log (the query finished with correct results though):java.lang.RuntimeException: Map operator initialization failed at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.init(SparkMapRecordHandler.java:127) at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunction.call(HiveMapFunction.java:52) at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunction.call(HiveMapFunction.java:30) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:164) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:164) at org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596) at org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262) at org.apache.spark.rdd.RDD.iterator(RDD.scala:229) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41) at org.apache.spark.scheduler.Task.run(Task.scala:54) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:199) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:744)Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:404) at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.init(SparkMapRecordHandler.java:93) ... 16 moreJudging from the log, I think we don't properly handle the input paths when cloning the job conf, so it may also affect other queries with multiple maps or reduces.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.IOContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkPlanGenerator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="7774" opendate="2014-8-19 00:00:00" fixdate="2014-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Issues with location path for temporary external tables</summary>
      <description>Depending on the location string passed into temp external table, a query requiring a map/reduce job will fail. Example:create temporary external table tmp1 (c1 string) location '/tmp/tmp1';describe extended tmp1;select count(*) from tmp1;Will result in the following error:Diagnostic Messages for this Task:Error: java.lang.RuntimeException: Error in configuring object at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:109) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:75) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:426) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342) at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:106) ... 9 moreCaused by: java.lang.RuntimeException: Error in configuring object at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:109) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:75) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.mapred.MapRunner.configure(MapRunner.java:38) ... 14 moreCaused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:106) ... 17 moreCaused by: java.lang.RuntimeException: Map operator initialization failed at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.configure(ExecMapper.java:154) ... 22 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:404) at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.configure(ExecMapper.java:123) ... 22 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:398) ... 23 moreFAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTaskIf the location is set to 'hdfs:/tmp/tmp1', it gets the following error:java.io.IOException: cannot find dir = hdfs://node-1.example.com:8020/tmp/tmp1/tmp1.txt in pathToPartitionInfo: [hdfs:/tmp/tmp1] at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getPartitionDescFromPathRecursively(HiveFileFormatUtils.java:344) at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getPartitionDescFromPathRecursively(HiveFileFormatUtils.java:306) at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat$CombineHiveInputSplit.&lt;init&gt;(CombineHiveInputFormat.java:108) at org.apache.hadoop.hive.ql.io.CombineHiveInputFormat.getSplits(CombineHiveInputFormat.java:455) at org.apache.hadoop.mapreduce.JobSubmitter.writeOldSplits(JobSubmitter.java:520) at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:512) at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:394) at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1285) at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1282) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614) at org.apache.hadoop.mapreduce.Job.submit(Job.java:1282) at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:562) at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:557) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614) at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:557) at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:548) at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:420) at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:136) at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:161) at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85) at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1555) at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1322) at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1136) at org.apache.hadoop.hive.ql.Driver.run(Driver.java:960) at org.apache.hadoop.hive.ql.Driver.run(Driver.java:950) at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:265) at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:217) at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:427) at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:363) at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:460) at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:476) at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:756) at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:694) at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:633) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.RunJar.main(RunJar.java:212)Job Submission failed with exception 'java.io.IOException(cannot find dir = hdfs://node-1.example.com:8020/tmp/tmp1/tmp1.txt in pathToPartitionInfo: [hdfs:/tmp/tmp1])'FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTaskThe only location string value that works properly here is 'hdfs://hostname/tmp/tmp1'.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="7775" opendate="2014-8-19 00:00:00" fixdate="2014-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>enable sample8.q.[Spark Branch]</summary>
      <description>sample8.q contain join query, should enable this qtest after hive on spark support join operation.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7776" opendate="2014-8-19 00:00:00" fixdate="2014-10-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>enable sample10.q.[Spark Branch]</summary>
      <description>sample10.q contain dynamic partition operation, should enable this qtest after hive on spark support dynamic partition.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HiveReduceFunction.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HiveMapFunction.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7777" opendate="2014-8-19 00:00:00" fixdate="2014-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add CSV Serde based on OpenCSV</summary>
      <description>There is no official support for csvSerde for hive while there is an open source project in github(https://github.com/ogrodnek/csv-serde). CSV is of high frequency in use as a data format.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.pom.xml</file>
      <file type="M">ql.pom.xml</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7784" opendate="2014-8-19 00:00:00" fixdate="2014-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Created the needed indexes on Hive.PART_COL_STATS for CBO</summary>
      <description>With CBO we need the correct set of indexes to provide an efficient Read/Write access.These indexes improve performance of Explain plan and Analyzed table by 60% and 300%.MySQL CREATE INDEX PART_COL_STATS_N50 ON PART_COL_STATS (DB_NAME,TABLE_NAME,COLUMN_NAME) USING BTREE;MsSQLCREATE INDEX PART_COL_STATS_N50 ON PART_COL_STATS (DB_NAME,TABLE_NAME,COLUMN_NAME);Oracle CREATE INDEX PART_COL_STATS_N50 ON PART_COL_STATS (DB_NAME,TABLE_NAME,COLUMN_NAME);PostgresCREATE INDEX "PART_COL_STATS_N50" ON "PART_COL_STATS" USING btree ("DB_NAME","TABLE_NAME","COLUMN_NAME");</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.scripts.upgrade.postgres.upgrade-0.13.0-to-0.14.0.postgres.sql</file>
      <file type="M">metastore.scripts.upgrade.postgres.hive-schema-0.14.0.postgres.sql</file>
      <file type="M">metastore.scripts.upgrade.oracle.upgrade-0.13.0-to-0.14.0.oracle.sql</file>
      <file type="M">metastore.scripts.upgrade.oracle.hive-schema-0.14.0.oracle.sql</file>
      <file type="M">metastore.scripts.upgrade.mysql.upgrade-0.13.0-to-0.14.0.mysql.sql</file>
      <file type="M">metastore.scripts.upgrade.mysql.hive-schema-0.14.0.mysql.sql</file>
      <file type="M">metastore.scripts.upgrade.mssql.upgrade.order.mssql</file>
      <file type="M">metastore.scripts.upgrade.derby.upgrade-0.13.0-to-0.14.0.derby.sql</file>
      <file type="M">metastore.scripts.upgrade.derby.hive-schema-0.14.0.derby.sql</file>
    </fixedFiles>
  </bug>
  <bug id="7785" opendate="2014-8-19 00:00:00" fixdate="2014-8-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Projection Pruning needs to handle cross Joins</summary>
      <description>Projection pruning needs to handle cross joins. Ex: select r1.x from r1 join r2.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.cbo.correctness.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.cbo.correctness.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.rules.HiveRelFieldTrimmer.java</file>
    </fixedFiles>
  </bug>
  <bug id="7788" opendate="2014-8-20 00:00:00" fixdate="2014-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Generate plans for insert, update, and delete</summary>
      <description>Insert plans needs to be generated differently for ACID tables, plus we need to be able to generate plans in the semantic analyzer for update and delete.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientnegative.invalid.cast.from.binary.1.q.out</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestExecDriver.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.UDFToInteger.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ReduceSinkDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PlanUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.LoadTableDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.StorageFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzerFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.QBParseInfo.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.SortedDynPartitionOptimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.BucketingSortingReduceSinkOptimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Table.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.lockmgr.HiveTxnManager.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.lockmgr.DbTxnManager.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.AcidUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.hooks.WriteEntity.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.hooks.ReadEntity.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MoveTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.ErrorMsg.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Context.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.txn.TxnHandler.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.history.TestHiveHistory.java</file>
      <file type="M">data.conf.tez.hive-site.xml</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="7790" opendate="2014-8-20 00:00:00" fixdate="2014-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update privileges to check for update and delete</summary>
      <description>In the new SQLStdAuth scheme, we need to add UPDATE and DELETE as operations and add ability check for them.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.Operation2Privilege.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.HivePrivilegeObject.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.AuthorizationUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ColumnAccessInfo.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.security.authorization.plugin.TestHiveAuthorizerCheckInvocation.java</file>
    </fixedFiles>
  </bug>
  <bug id="7791" opendate="2014-8-20 00:00:00" fixdate="2014-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable tests on Spark branch (1) [Sparch Branch]</summary>
      <description>This jira is to enable most of the tests below. If tests don't pass because of some unsupported feature, ensure that a JIRA exists and move on. alter_merge_orc.q,\ alter_merge_stats_orc.q,\ auto_join0.q,\ auto_join1.q,\ bucket2.q,\ bucket3.q,\ bucket4.q,\ count.q,\ create_merge_compressed.q,\ cross_join.q,\ cross_product_check_1.q,\ cross_product_check_2.q,\ ctas.q,\custom_input_output_format.q,\ disable_merge_for_bucketing.q,\ dynpart_sort_opt_vectorization.q,\ dynpart_sort_optimization.q,\</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkPlanGenerator.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7792" opendate="2014-8-20 00:00:00" fixdate="2014-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable tests on Spark branch (2) [Sparch Branch]</summary>
      <description>This jira is to enable most of the tests below. If tests don't pass because of some unsupported feature, ensure that a JIRA exists and move on.limit_pushdown.q,\ load_dyn_part1.q,\ load_dyn_part2.q,\ load_dyn_part3.q,\ mapjoin_mapjoin.q,\ mapreduce1.q,\ mapreduce2.q,\ merge1.q,\ merge2.q,\ metadata_only_queries.q,\ optimize_nullscan.q,\ orc_analyze.q,\ orc_merge1.q,\ orc_merge2.q,\ orc_merge3.q,\ orc_merge4.q,\</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7793" opendate="2014-8-20 00:00:00" fixdate="2014-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable tests on Spark branch (3) [Sparch Branch]</summary>
      <description>This jira is to enable most of the tests below. If tests don't pass because of some unsupported feature, ensure that a JIRA exists and move on. ptf.q,\ sample1.q,\ script_env_var1.q,\ script_env_var2.q,\ script_pipe.q,\ scriptfile1.q,\ stats_counter.q,\ stats_counter_partitioned.q,\ stats_noscan_1.q,\ subquery_exists.q,\ subquery_in.q,\ temp_table.q,\ transform1.q,\ transform2.q,\ transform_ppr1.q,\ transform_ppr2.q,\</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7794" opendate="2014-8-20 00:00:00" fixdate="2014-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable tests on Spark branch (4) [Sparch Branch]</summary>
      <description>This jira is to enable most of the tests below. If tests don't pass because of some unsupported feature, ensure that a JIRA exists and move on. vector_cast_constant.q,\ vector_data_types.q,\ vector_decimal_aggregate.q,\ vector_left_outer_join.q,\ vector_string_concat.q,\ vectorization_12.q,\ vectorization_13.q,\ vectorization_14.q,\ vectorization_15.q,\ vectorization_9.q,\ vectorization_part_project.q,\ vectorization_short_regress.q,\ vectorized_mapjoin.q,\ vectorized_nested_mapjoin.q,\ vectorized_ptf.q,\ vectorized_shufflejoin.q,\ vectorized_timestamp_funcs.q</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7795" opendate="2014-8-20 00:00:00" fixdate="2014-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable ptf.q and ptf_streaming.q.[Spark Branch]</summary>
      <description>ptf.q and ptf_streaming.q contains join queries, we should enable these qtests in milestone2.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7800" opendate="2014-8-20 00:00:00" fixdate="2014-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parquet Column Index Access Schema Size Checking</summary>
      <description>In the case that a parquet formatted table has partitions where the files have different size schema, using column index access can result in an index out of bounds exception.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.java</file>
    </fixedFiles>
  </bug>
  <bug id="7814" opendate="2014-8-20 00:00:00" fixdate="2014-8-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Predicate Push Down Enhancements</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.DerivedTableInjector.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.ASTConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.rules.HivePushFilterPastJoinRule.java</file>
      <file type="M">ql.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="782" opendate="2009-8-21 00:00:00" fixdate="2009-8-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>reduce progress reported incorrectly</summary>
      <description>its reporting map progress as reduce progress as well.</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExecDriver.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7821" opendate="2014-8-21 00:00:00" fixdate="2014-8-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>StarterProject: enable groupby4.q [Spark Branch]</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7824" opendate="2014-8-21 00:00:00" fixdate="2014-8-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CLIServer.getOperationStatus eats ExceutionException</summary>
      <description>ExceutionException has a "cause" member which could be anything including serious errors and thus it should be logged. The other lines are "escape" exceptions and can be logged at trace.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.CLIService.java</file>
    </fixedFiles>
  </bug>
  <bug id="7832" opendate="2014-8-21 00:00:00" fixdate="2014-9-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Do ORC dictionary check at a finer level and preserve encoding across stripes</summary>
      <description>Currently ORC dictionary check happens while writing the stripe. Just before writing stripe if ratio of dictionary entries to total non-null rows is greater than threshold then the dictionary is discarded. Also, the decision of using dictionary or not is preserved across stripes. This sometimes leads to costly insertion cost of O(logn) for each stripes when there are too many distinct keys.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcFile.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.WriterImpl.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="7836" opendate="2014-8-21 00:00:00" fixdate="2014-8-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ease-out denominator for multi-attribute join case in statistics annotation</summary>
      <description>In cases where number of relations involved in join is less than the number of join attributes the denominator of join rule can get larger resulting in aggressive row count estimation.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.join.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.stats.annotation.StatsRulesProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="7858" opendate="2014-8-22 00:00:00" fixdate="2014-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parquet compression should be configurable via table property</summary>
      <description>ORC supports the orc.compress table property:https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORCcreate table Addresses ( name string, street string, city string, state string, zip int) stored as orc tblproperties ("orc.compress"="NONE");I think it'd be great to support the same for Parquet.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.parquet.TestMapredParquetOutputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.parquet.write.ParquetRecordWriterWrapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="7859" opendate="2014-8-22 00:00:00" fixdate="2014-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tune zlib compression in ORC to account for the encoding strategy</summary>
      <description>Currently ORC Zlib is slow because several compression strategies ZLib uses is already done by ORC in itself (dictionary, RLE, bit-packing).We need to pick between Z_FILTERED, Z_HUFFMAN_ONLY, Z_RLE, Z_FIXED and Z_DEFAULT_STRATEGY according to column stream type.For instance an RLE_V2 stream could a use Z_FILTERED compression without invoking the rest of the strategies.The string streams can use Z_FIXED compression strategies and so on.The core limitation to stick to retain compatibility with the default decompressor, so that these are automatically backward compatible.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.analyze.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.alter.merge.stats.orc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.alter.merge.orc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.analyze.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter.merge.stats.orc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter.merge.orc.q.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump-dictionary-threshold.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.ZlibCodec.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.WriterImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.SnappyCodec.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcFile.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.CompressionCodec.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="7866" opendate="2014-8-23 00:00:00" fixdate="2014-8-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Merge from trunk (1) [Spark Branch]</summary>
      <description>I will be creating JIRA's for the merge going forward to run tests beforehand.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.spark.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join27.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.avro.decimal.native.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="7867" opendate="2014-8-23 00:00:00" fixdate="2014-8-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Re-order spark.query.files in sorted order [Spark Branch]</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7880" opendate="2014-8-26 00:00:00" fixdate="2014-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support subquery [Spark Branch]</summary>
      <description>While try to enable SubQuery qtests, I found that SubQuery cases return null value currently, we should enable subquery for Hive on Spark. We should enable subquery_exists.q and subquery_in.q in this task as Tez does.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7881" opendate="2014-8-26 00:00:00" fixdate="2014-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>enable Qtest scriptfile1.q [Spark Branch]</summary>
      <description>scriptfile1.q failed due to script file not found, should verify whether add script file to SparkContext.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ScriptOperator.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="7887" opendate="2014-8-26 00:00:00" fixdate="2014-8-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>VectorFileSinkOp does not publish the stats correctly</summary>
      <description>VectorFSOp inherits FSOp, but the stats collection code in processOp() is out-of-date. Needs to be updated to be in sync with FSOp.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.timestamp.funcs.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.part.project.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorFileSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FileSinkOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="7895" opendate="2014-8-27 00:00:00" fixdate="2014-8-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Storage based authorization should consider sticky bit for drop actions</summary>
      <description>Storage based authorization provides access control for metadata by giving users permissions on metadata that are equivalent to the permission that user has on corresponding data.However, when checking the permissions to drop a metadata object such as database, table or partition, it does not check if the sticky bit is set on the parent dir of objects corresponding dir in hdfs.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProvider.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.FileUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="7901" opendate="2014-8-28 00:00:00" fixdate="2014-9-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CLONE - pig -useHCatalog with embedded metastore fails to pass command line args to metastore (org.apache.hive.hcatalog version)</summary>
      <description>This fails because the embedded metastore can't connect to the database because the command line -D arguments passed to pig are not getting passed to the metastore when the embedded metastore is created. Using hive.metastore.uris set to the empty string causes creation of an embedded metastore.pig -useHCatalog "-Dhive.metastore.uris=" "-Djavax.jdo.option.ConnectionPassword=AzureSQLDBXYZ"The goal is to allow a pig job submitted via WebHCat to specify a metastore to use via job arguments. That is not working because it is not possible to pass Djavax.jdo.option.ConnectionPassword and other necessary arguments to the embedded metastore.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.main.java.org.apache.hive.hcatalog.pig.PigHCatUtil.java</file>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.main.java.org.apache.hive.hcatalog.pig.HCatLoader.java</file>
    </fixedFiles>
  </bug>
  <bug id="7904" opendate="2014-8-28 00:00:00" fixdate="2014-8-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Missing null check cause NPE when updating join column stats in statistics annotation</summary>
      <description>Column stats updation in join stats rule annotation can cause NPE if column stats is missing from one relation.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.stats.annotation.StatsRulesProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="7912" opendate="2014-8-29 00:00:00" fixdate="2014-8-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Don&amp;#39;t add is not null filter for partitioning column</summary>
      <description>HIVE-7159 introduces optimization which introduces is not null filter on inner join columns which is wasteful for partitioning column.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="7925" opendate="2014-8-31 00:00:00" fixdate="2014-9-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>extend current partition status extrapolation to support all DBs</summary>
      <description>extend current partition status extrapolation only supports Derby.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.MetaStoreDirectSql.java</file>
    </fixedFiles>
  </bug>
  <bug id="7927" opendate="2014-9-1 00:00:00" fixdate="2014-9-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Checking sticky bit needs shim</summary>
      <description>Hive cannot be built on hadoop-1 after HIVE-7895, which checks sticky bit in FsPermission.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.common.src.main.java.org.apache.hadoop.hive.shims.HadoopShims.java</file>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
      <file type="M">shims.0.20.src.main.java.org.apache.hadoop.hive.shims.Hadoop20Shims.java</file>
      <file type="M">shims.0.20S.src.main.java.org.apache.hadoop.hive.shims.Hadoop20SShims.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.FileUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="7944" opendate="2014-9-2 00:00:00" fixdate="2014-9-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>current update stats for columns of a partition of a table is not correct</summary>
      <description>We worked hard towards faster update stats for columns of a partition of a table previously https://issues.apache.org/jira/browse/HIVE-7736andhttps://issues.apache.org/jira/browse/HIVE-7876Although there is some improvement, it is only correct in the first run. There will be duplicate column stats later. Thanks to ekoifman 's comments</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.DummyRawStoreForJdoConnection.java</file>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.DummyRawStoreControlledCommit.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.RawStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.ObjectStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="7947" opendate="2014-9-2 00:00:00" fixdate="2014-9-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add message at the end of each testcase with timestamp in Webhcat system tests</summary>
      <description>Currently, Webhcat e2e testsuite only prints message while starting test run:Beginning test &lt;testcase&gt; at 1406716992It should also print ending message with timestamp similar to this:Ending test &lt;testcase&gt; at 1406717992This change will make log collection easy for failed test cases. NO PRECOMMIT TESTS</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.src.test.e2e.templeton.drivers.TestDriverCurl.pm</file>
    </fixedFiles>
  </bug>
  <bug id="7948" opendate="2014-9-3 00:00:00" fixdate="2014-4-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add an E2E test to verify fix for HIVE-7155</summary>
      <description>E2E Test to verify webhcat property templeton.mapper.memory.mb correctly overrides mapreduce.map.memory.mb. The feature was added as part of HIVE-7155.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.src.test.e2e.templeton.README.txt</file>
      <file type="M">hcatalog.src.test.e2e.templeton.deployers.env.sh</file>
      <file type="M">hcatalog.src.test.e2e.templeton.deployers.deploy.e2e.artifacts.sh</file>
      <file type="M">hcatalog.src.test.e2e.templeton.build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="7971" opendate="2014-9-3 00:00:00" fixdate="2014-9-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support alter table change/replace/add columns for existing partitions</summary>
      <description>ALTER TABLE CHANGE COLUMN is allowed for tables, but not for partitions. Same for add/replace columns.Allowing this for partitions can be useful in some cases. For example, one user has tables with Hive 0.12 Decimal columns, which do not specify precision/scale. To be able to properly read the decimal values from the existing partitions, the column types in the partitions need to be changed to decimal types with precision/scale.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.AlterTableDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.HiveParser.g</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="7977" opendate="2014-9-4 00:00:00" fixdate="2014-1-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid creating serde for partitions if possible in FetchTask</summary>
      <description>Currently, FetchTask creates SerDe instance thrice for each partition, which can be avoided if it's same with table SerDe.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.DelegatedUnionObjectInspector.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.DelegatedStructObjectInspector.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.DelegatedObjectInspectorFactory.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.DelegatedMapObjectInspector.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.DelegatedListObjectInspector.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.TableDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.FetchWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.PartitionKeySampler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.ExecMapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FetchOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">data.files.datatypes.txt</file>
    </fixedFiles>
  </bug>
  <bug id="7985" opendate="2014-9-4 00:00:00" fixdate="2014-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>With CBO enabled cross product is generated when a subquery is present</summary>
      <description>This is a regression introduced in the latest build of the CBO branch.Removing the subquery for item will remove the cross productsQueryselect i_item_id,sum(ss_ext_sales_price) total_sales from store_sales, date_dim, item where item.i_item_id in (select i.i_item_id from item i where i_color in ('purple','burlywood','indian')) and ss_item_sk = i_item_sk and ss_sold_date_sk = d_date_sk and d_year = 2001 and d_moy = 1 group by i_item_id;Warning: Map Join MAPJOIN[38][bigTable=?] in task 'Map 1' is a cross productWarning: Map Join MAPJOIN[39][bigTable=store_sales] in task 'Map 4' is a cross productOKSTAGE DEPENDENCIES: Stage-1 is a root stage Stage-0 depends on stages: Stage-1STAGE PLANS: Stage: Stage-1 Tez Edges: Map 1 &lt;- Map 3 (BROADCAST_EDGE) Map 4 &lt;- Map 1 (BROADCAST_EDGE), Map 2 (BROADCAST_EDGE) Reducer 5 &lt;- Map 4 (SIMPLE_EDGE) DagName: mmokhtar_20140904141313_9c253f7e-aad1-4ca4-9be1-ea45e3d34496:1 Vertices: Map 1 Map Operator Tree: TableScan alias: item filterExpr: (true and i_item_id is not null) (type: boolean) Statistics: Num rows: 462000 Data size: 663862160 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: i_item_id is not null (type: boolean) Statistics: Num rows: 231000 Data size: 331931080 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {i_item_sk} {i_item_id} 1 {d_date_sk} keys: 0 1 outputColumnNames: _col0, _col1, _col25 input vertices: 1 Map 3 Statistics: Num rows: 254100 Data size: 365124192 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col0 (type: int), _col1 (type: string), _col25 (type: int) outputColumnNames: _col0, _col1, _col25 Statistics: Num rows: 254100 Data size: 365124192 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator sort order: Statistics: Num rows: 254100 Data size: 365124192 Basic stats: COMPLETE Column stats: NONE value expressions: _col0 (type: int), _col1 (type: string), _col25 (type: int) Execution mode: vectorized Map 2 Map Operator Tree: TableScan alias: i filterExpr: ((i_color) IN ('purple', 'burlywood', 'indian') and i_item_id is not null) (type: boolean) Statistics: Num rows: 462000 Data size: 663862160 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ((i_color) IN ('purple', 'burlywood', 'indian') and i_item_id is not null) (type: boolean) Statistics: Num rows: 115500 Data size: 165965540 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: i_item_id (type: string) outputColumnNames: _col0 Statistics: Num rows: 115500 Data size: 165965540 Basic stats: COMPLETE Column stats: NONE Group By Operator keys: _col0 (type: string) mode: hash outputColumnNames: _col0 Statistics: Num rows: 115500 Data size: 165965540 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: string) sort order: + Map-reduce partition columns: _col0 (type: string) Statistics: Num rows: 115500 Data size: 165965540 Basic stats: COMPLETE Column stats: NONE Execution mode: vectorized Map 3 Map Operator Tree: TableScan alias: date_dim filterExpr: ((d_year = 2001) and (d_moy = 1)) (type: boolean) Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ((d_year = 2001) and (d_moy = 1)) (type: boolean) Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator sort order: Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE value expressions: d_date_sk (type: int) Execution mode: vectorized Map 4 Map Operator Tree: TableScan alias: store_sales Statistics: Num rows: 82510879939 Data size: 7203833257964 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {ss_sold_date_sk} {ss_item_sk} {ss_ext_sales_price} 1 {_col0} {_col1} {_col25} keys: 0 1 outputColumnNames: _col0, _col2, _col15, _col27, _col28, _col52 input vertices: 1 Map 1 Statistics: Num rows: 90761969664 Data size: 7924217282560 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ((_col2 = _col27) and (_col0 = _col52)) (type: boolean) Statistics: Num rows: 22690492416 Data size: 1981054320640 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col15 (type: float), _col28 (type: string) outputColumnNames: _col15, _col59 Statistics: Num rows: 22690492416 Data size: 1981054320640 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Left Semi Join 0 to 1 condition expressions: 0 {_col15} {_col59} 1 keys: 0 _col59 (type: string) 1 _col0 (type: string) outputColumnNames: _col15, _col59 input vertices: 1 Map 2 Statistics: Num rows: 24959541248 Data size: 2179159818240 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col59 (type: string), _col15 (type: float) outputColumnNames: _col0, _col1 Statistics: Num rows: 24959541248 Data size: 2179159818240 Basic stats: COMPLETE Column stats: NONE Group By Operator aggregations: sum(_col1) keys: _col0 (type: string) mode: hash outputColumnNames: _col0, _col1 Statistics: Num rows: 24959541248 Data size: 2179159818240 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: string) sort order: + Map-reduce partition columns: _col0 (type: string) Statistics: Num rows: 24959541248 Data size: 2179159818240 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: double) Execution mode: vectorized Reducer 5 Reduce Operator Tree: Group By Operator aggregations: sum(VALUE._col0) keys: KEY._col0 (type: string) mode: mergepartial outputColumnNames: _col0, _col1 Statistics: Num rows: 12479770624 Data size: 1089579909120 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col0 (type: string), _col1 (type: double) outputColumnNames: _col0, _col1 Statistics: Num rows: 12479770624 Data size: 1089579909120 Basic stats: COMPLETE Column stats: NONE File Output Operator compressed: false Statistics: Num rows: 12479770624 Data size: 1089579909120 Basic stats: COMPLETE Column stats: NONE table: input format: org.apache.hadoop.mapred.TextInputFormat output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe Stage: Stage-0 Fetch Operator limit: -1 Processor Tree: ListSinkNo cross product generated for this query select i_item_id,sum(ss_ext_sales_price) total_sales from store_sales, date_dim, itemwhere i_color in ('purple','burlywood','indian') and ss_item_sk = i_item_sk and ss_sold_date_sk = d_date_sk and d_year = 2001 and d_moy = 1 group by i_item_id;</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.SqlFunctionConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.RexNodeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.stats.FilterSelectivityEstimator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.rules.HivePushFilterPastJoinRule.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.HiveOptiqUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="7987" opendate="2014-9-4 00:00:00" fixdate="2014-9-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Storage based authorization - NPE for drop view</summary>
      <description>When storage based authorization is enabled, NullPointerException is thrown for 'drop view'.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationDrops.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.FileUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="7988" opendate="2014-9-4 00:00:00" fixdate="2014-9-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO:Test changes</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">data.conf.hive-site.xml</file>
      <file type="M">conf.hive-default.xml.template</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="7994" opendate="2014-9-5 00:00:00" fixdate="2014-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>BMJ test fails on tez</summary>
      <description>Problem is that mapjoin hangs on to the wrong hash table.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.bmj.schema.evolution.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="8003" opendate="2014-9-5 00:00:00" fixdate="2014-9-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Handle Literal casting, Restrict CBO to select queries, Translate Strings, Optiq Log</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFToUtcTimestamp.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFTimestamp.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFFromUtcTimestamp.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.TypeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.RexNodeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.ASTBuilder.java</file>
    </fixedFiles>
  </bug>
  <bug id="8019" opendate="2014-9-8 00:00:00" fixdate="2014-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Missing hive 0.13.1 commit in trunk : export/import statement authorization - CVE-2014-0228</summary>
      <description>Noticed that commit 1882de7810fc55a2466dd4cbe74ed67bb41cb667 exists in 0.13 branch, but not it trunk. https://github.com/apache/hive/commit/1882de7810fc55a2466dd4cbe74ed67bb41cb667(trunk) $ git branch -a --contains 1882de7810fc55a2466dd4cbe74ed67bb41cb667 remotes/origin/branch-0.13I looked through some of the changes in this commit and don't see those in trunk. Nor do I see a commit that reverts these changes in trunk.thejas, should we port this over to trunk ? Thanks.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.import.exported.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.hidden.files.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.24.import.nonexist.authsuccess.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.23.import.part.authsuccess.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.22.import.exist.authsuccess.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.20.part.managed.location.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.19.part.external.location.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.19.00.part.external.location.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.18.part.external.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.17.part.managed.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.16.part.external.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.15.external.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.14.managed.location.over.existing.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.13.managed.location.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.12.external.location.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.11.managed.external.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.10.external.managed.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.09.part.spec.nonoverlap.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.08.nonpart.rename.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.07.all.part.over.nonoverlap.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.06.one.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.05.some.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.04.evolved.parts.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.04.all.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.03.nonpart.over.compat.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.02.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.02.00.part.empty.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.01.nonpart.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.exim.00.nonpart.empty.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.exim.00.nonpart.empty.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.Operation2Privilege.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ImportSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ExportSemanticAnalyzer.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.FileUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="8022" opendate="2014-9-8 00:00:00" fixdate="2014-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Recursive root scratch directory creation is not using hdfs umask properly</summary>
      <description>Changes made in HIVE-6847 removed the helper methods that were added HIVE-7001 to get around this problem. Since the root scratch dir must be writable by all, its creation should use those methods.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniHS2.java</file>
    </fixedFiles>
  </bug>
  <bug id="8023" opendate="2014-9-8 00:00:00" fixdate="2014-9-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Code in HIVE-6380 eats exceptions</summary>
      <description>This code eats the stack trace LOG.error("Unable to load resources for " + dbName + "." + fName + ":" + e);</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
    </fixedFiles>
  </bug>
  <bug id="8025" opendate="2014-9-9 00:00:00" fixdate="2014-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[CBO] Handle null-safe joins</summary>
      <description>We will not optimize query containing NS join expression because our join reordering algo cant optimize such joins.</description>
      <version>None</version>
      <fixedVersion>cbo-branch</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.SqlFunctionConverter.java</file>
    </fixedFiles>
  </bug>
  <bug id="8026" opendate="2014-9-9 00:00:00" fixdate="2014-9-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: check for Grouping Sets, Cube and Rollup and bail to non cbo planning</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8042" opendate="2014-9-10 00:00:00" fixdate="2014-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optionally allow move tasks to run in parallel</summary>
      <description>hive.exec.parallel allows one to run different stages of a query in parallel. However that applies only to map-reduce tasks. When using large multi insert queries there are many MoveTasks that are all executed in sequence on the client. There's no real reason for that - they could be run in parallel as well (i.e.: the stage graph captures the dependencies and knows which tasks can happen in parallel).</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8043" opendate="2014-9-10 00:00:00" fixdate="2014-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support merging small files [Spark Branch]</summary>
      <description>Hive currently supports merging small files with MR as the execution engine. There are options available for this, such as hive.merge.mapfileshive.merge.mapredfilesHive.merge.sparkfiles is already introduced in HIVE-7810. To make it work, we might need a little more research and design on this.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.merge2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.merge1.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.merge2.q</file>
      <file type="M">ql.src.test.queries.clientpositive.merge1.q</file>
      <file type="M">ql.src.test.queries.clientpositive.disable.merge.for.bucketing.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkRecordHandler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkPlanGenerator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.HiveMapFunction.java</file>
    </fixedFiles>
  </bug>
  <bug id="8045" opendate="2014-9-10 00:00:00" fixdate="2014-9-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SQL standard auth with cli - Errors and configuration issues</summary>
      <description>HIVE-7533 enabled sql std authorization to be set in hive cli (without enabling authorization checks). This updates hive configuration so that create-table and create-views set permissions appropriately for the owner of the table.HIVE-7209 added a metastore authorization provider that can be used to restricts calls made to the authorization api, so that only HS2 can make those calls (when HS2 uses embedded metastore).Some issues were found with this. Even if hive.security.authorization.enabled=false, authorization checks were happening for non sql statements as add/detete/dfs/compile, which results in MetaStoreAuthzAPIAuthorizerEmbedOnly throwing an error. Create table from hive-cli ended up calling metastore server api call (getRoles) and resulted in MetaStoreAuthzAPIAuthorizerEmbedOnly throwing an error. Some users prefer to enable authorization using hive-site.xml for hive-server2 (hive.security.authorization.enabled param). If this file is shared by hive-cli and hive-server2, SQL std authorizer throws an error because is use in hive-cli is not allowed.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.queries.clientpositive.authorization.cli.createtab.q</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.TestSQLStdHiveAccessControllerCLI.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizationValidator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessController.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLAuthorizationUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.processors.CommandUtil.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizationValidatorForTest.java</file>
    </fixedFiles>
  </bug>
  <bug id="8046" opendate="2014-9-11 00:00:00" fixdate="2014-9-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: fix issues with Windowing queries</summary>
      <description>handle count handle lead/lag</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.SqlFunctionConverter.java</file>
    </fixedFiles>
  </bug>
  <bug id="8047" opendate="2014-9-11 00:00:00" fixdate="2014-9-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Lazy char/varchar are not using escape char defined in serde params</summary>
      <description>A table with char/varchar columns that specifies an escape character for string data still has the escape characters in the char/varchar columns.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableHiveVarcharObjectInspector.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableHiveCharObjectInspector.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyPrimitiveObjectInspectorFactory.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyHiveVarcharObjectInspector.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyHiveCharObjectInspector.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazy.LazyUtils.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazy.LazyString.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazy.LazyHiveVarchar.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazy.LazyHiveChar.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcDriver2.java</file>
    </fixedFiles>
  </bug>
  <bug id="8048" opendate="2014-9-11 00:00:00" fixdate="2014-9-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[CBO] Handle union type</summary>
      <description>Since optiq cant handle union type, disable cbo on queries involving union type.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.TypeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.RexNodeConverter.java</file>
    </fixedFiles>
  </bug>
  <bug id="8057" opendate="2014-9-11 00:00:00" fixdate="2014-9-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Preserve Record Schema For top level Query, subquery enable cbo, Pull common predicate elements</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.DerivedTableInjector.java</file>
    </fixedFiles>
  </bug>
  <bug id="8058" opendate="2014-9-11 00:00:00" fixdate="2014-9-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable correlation opt for Tez</summary>
      <description>Correlation optimizer needs more thought on Tez. Stuff like nested tags are at odds with Tez (where we can expose more stages in a single DAG).For now: disable.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.Optimizer.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8064" opendate="2014-9-11 00:00:00" fixdate="2014-9-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: decimal support is broken for some corner cases</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>cbo-branch</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.RexNodeConverter.java</file>
    </fixedFiles>
  </bug>
  <bug id="8072" opendate="2014-9-12 00:00:00" fixdate="2014-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TesParse_union is failing on trunk</summary>
      <description>Needs golden file update</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.compiler.plan.sample7.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input9.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input7.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input1.q.xml</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.PartitionDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.MapWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.TaskCompiler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="8078" opendate="2014-9-12 00:00:00" fixdate="2014-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ORC Delta encoding corrupts data when delta overflows long</summary>
      <description>There is an issue with the integer encoding that can cause corruption in certain cases.The following 3 longs cause this failure.45133435386182027112911390882471569739-9181829309989854913I believe that even though the numbers are in decreasing order, the delta between the last two numbers overflows causing a positive delta, in this case the last digit ends up being corrupted (the delta is applied for the wrong sign resulting in -3442132998776557225 instead of -9181829309989854913.</description>
      <version>0.13.1,0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge.incompat2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge.incompat1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.analyze.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynpart.sort.opt.vectorization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge.incompat2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge.incompat1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.analyze.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.extrapolate.part.stats.partial.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.extrapolate.part.stats.full.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.dynpart.sort.opt.vectorization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.part.q.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump-dictionary-threshold.out</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestSerializationUtils.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcFile.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestNewIntegerEncoding.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.SerializationUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RunLengthIntegerWriterV2.java</file>
    </fixedFiles>
  </bug>
  <bug id="8092" opendate="2014-9-13 00:00:00" fixdate="2014-9-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorized Tez count(*) returns NULL instead of 0 when result is empty</summary>
      <description>In tez mode when vectorization is enabled, count returns NULL when result is empty.Expected behavior: It should return 0count works as expected when vectorization is off</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.vectorization.short.regress.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.short.regress.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.vectorization.short.regress.q</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorGroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorUDAFCountStar.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.aggregates.VectorUDAFCount.java</file>
    </fixedFiles>
  </bug>
  <bug id="8094" opendate="2014-9-14 00:00:00" fixdate="2014-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>add LIKE keyword support for SHOW FUNCTIONS</summary>
      <description>It would be nice to add LIKE keyword support for SHOW FUNCTIONS as below, and keep the patterns consistent to the way as SHOW DATABASES, SHOW TABLES.SHOW FUNCTIONS LIKE 'foo*';</description>
      <version>0.13.1,0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.show.functions.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.show.functions.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ShowFunctionsDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.HiveParser.g</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="8097" opendate="2014-9-15 00:00:00" fixdate="2014-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorized Reduce-Side [SMB] MapJoin operator fails</summary>
      <description>Fails attempting to getScratchColumnVectorTypes since mapWork is null on reduce-side.Fix by calling that method using reduceWork object.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorSMBMapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorMapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatchCtx.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8104" opendate="2014-9-15 00:00:00" fixdate="2014-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Insert statements against ACID tables NPE when vectorization is on</summary>
      <description>Doing an insert against a table that is using ACID format with the transaction manager set to DbTxnManager and vectorization turned on results in an NPE.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8106" opendate="2014-9-15 00:00:00" fixdate="2014-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable vectorization for spark [spark branch]</summary>
      <description>Enable the vectorization optimization on spark</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8108" opendate="2014-9-15 00:00:00" fixdate="2014-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[CBO] Handle queries without any source tables</summary>
      <description>Disable CBO on such queries since there is nothing much to optimize for those.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="811" opendate="2009-9-2 00:00:00" fixdate="2009-9-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>javadoc broken</summary>
      <description>javadoc is broken</description>
      <version>None</version>
      <fixedVersion>0.4.0,0.5.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.src.common.java.org.apache.hadoop.hive.shims.HadoopShims.java</file>
      <file type="M">service.src.java.org.apache.hadoop.hive.service.HiveServer.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryListObjectInspector.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryPrimitive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.UDFPosMod.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.mapredWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.DDLWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ConditionalResolver.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.QBJoinTree.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ParseContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMRProcContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.NonSyncDataInputBuffer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinObjectValue.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinObjectKey.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FetchOperator.java</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8110" opendate="2014-9-15 00:00:00" fixdate="2014-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[CBO] Improve casting of constants</summary>
      <description>Make it more type-specific</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.ASTBuilder.java</file>
    </fixedFiles>
  </bug>
  <bug id="8111" opendate="2014-9-15 00:00:00" fixdate="2014-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO trunk merge: duplicated casts for arithmetic expressions in Hive and CBO</summary>
      <description>Original test failure: looks like column type changes to different decimals in most cases. In one case it causes the integer part to be too big to fit, so the result becomes null it seems.What happens is that CBO adds casts to arithmetic expressions to make them type compatible; these casts become part of new AST, and then Hive adds casts on top of these casts. This (the first part) also causes lots of out file changes. It's not clear how to best fix it so far, in addition to incorrect decimal width and sometimes nulls when width is larger than allowed in Hive.Option one - don't add those for numeric ops - cannot be done if numeric op is a part of compare, for which CBO needs correct types.Option two - unwrap casts when determining type in Hive - hard or impossible to tell apart CBO-added casts and user casts. Option three - don't change types in Hive if CBO has run - seems hacky and hard to ensure it's applied everywhere.Option four - map all expressions precisely between two trees and remove casts again after optimization, will be pretty difficult.Option five - somehow mark those casts. Not sure about how yet.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.typeinfo.HiveDecimalUtils.java</file>
      <file type="M">ql.src.test.results.clientpositive.decimal.udf.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.decimal.udf.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFBaseNumeric.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.RexNodeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
    </fixedFiles>
  </bug>
  <bug id="8112" opendate="2014-9-15 00:00:00" fixdate="2014-9-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change reporting string to reflect update in Tez</summary>
      <description>We're now printing:Status: Running (application id: Executing on YARN cluster with App id application_1410822917153_0001)Where Tez just used to print the id it now has the full "Executing on YARN..." string.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezJobMonitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="8126" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Standalone hive-jdbc jar is not packaged in the Hive distribution</summary>
      <description>With HIVE-538 we started creating the hive-jdbc-*-standalone.jar but the packaging/distribution does not contain the standalone jdbc jar. I would have expected it to locate under the lib folder of the distribution.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">packaging.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="813" opendate="2009-9-3 00:00:00" fixdate="2009-9-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Show the actual exception thrown in UDF evaluation</summary>
      <description>As title, we should show the actual exception thrown in UDF evaluation.User should be able to see both the message and the stacktrace.</description>
      <version>None</version>
      <fixedVersion>0.4.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8130" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support Date in Avro</summary>
      <description>Avro represents date as Avro int annotated with "date" logical type, where the int stores the number of days from the unix epoch (AVRO-739)</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.test.resources.avro-struct.avsc</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestTypeInfoToSchema.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.TypeInfoToSchema.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.SchemaToTypeInfo.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.AvroSerializer.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.AvroSerDe.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.AvroDeserializer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8131" opendate="2014-9-16 00:00:00" fixdate="2014-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support timestamp in Avro</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestTypeInfoToSchema.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.TypeInfoToSchema.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.SchemaToTypeInfo.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.AvroSerializer.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.AvroSerDe.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.AvroDeserializer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8139" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade commons-lang from 2.4 to 2.6</summary>
      <description>Upgrade commons-lang version from 2.4 to latest 2.6</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8143" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create root scratch dir with 733 instead of 777 perms</summary>
      <description>hive.exec.scratchdir which is treated as the root scratch directory on hdfs only needs to be writable by all. We can use 733 instead of 777 for doing that.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniHS2.java</file>
      <file type="M">itests.hive-unit.src.main.java.org.apache.hive.jdbc.miniHS2.MiniHS2.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="8145" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: bail from Optiq planning if a Select list contains multiple references to the same name</summary>
      <description>Optiq explicitly disallows this:select x, x from t1This is allowed in Hive (and also in mysql). Will check in Postgres. For now bailing from Optiq planning if we see this. Will file an Optiq issue.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8148" opendate="2014-9-16 00:00:00" fixdate="2014-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HDFS Path named with file:// instead of file:/// results in Unit test failures in Windows</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.QTestUtil.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestSSL.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.security.FolderPermissionBase.java</file>
      <file type="M">itests.hive-unit.src.main.java.org.apache.hive.jdbc.miniHS2.MiniHS2.java</file>
      <file type="M">itests.hive-unit-hadoop2.src.test.java.org.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProviderWithACL.java</file>
      <file type="M">hcatalog.webhcat.java-client.src.test.java.org.apache.hive.hcatalog.api.TestHCatClient.java</file>
      <file type="M">hcatalog.streaming.src.test.org.apache.hive.hcatalog.streaming.TestStreaming.java</file>
      <file type="M">cli.src.test.org.apache.hadoop.hive.cli.TestRCFileCat.java</file>
    </fixedFiles>
  </bug>
  <bug id="8149" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hive.optimize.reducededuplication should be set to false for IUD ops</summary>
      <description>this optimizer causes both old and new rows to show up in a select after update (for tables involving few rows)</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.queries.clientpositive.update.where.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.update.all.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.update.after.multiple.inserts.q</file>
      <file type="M">ql.src.test.queries.clientpositive.insert.values.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.insert.values.dynamic.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.insert.update.delete.q</file>
      <file type="M">ql.src.test.queries.clientpositive.delete.whole.partition.q</file>
      <file type="M">ql.src.test.queries.clientpositive.delete.where.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.delete.all.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.delete.all.non.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.acid.vectorization.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8150" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[CBO] Type coercion in union queries</summary>
      <description>If we can't get common type from Optiq, bail out for now.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8151" opendate="2014-9-16 00:00:00" fixdate="2014-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Dynamic partition sort optimization inserts record wrongly to partition when used with GroupBy</summary>
      <description>HIVE-6455 added dynamic partition sort optimization. It added startGroup() method to FileSink operator to look for changes in reduce key for creating partition directories. This method however is not reliable as the key called with startGroup() is different from the key called with processOp(). startGroup() is called with newly changed key whereas processOp() is called with previously aggregated key. This will result in processOp() writing the last row of previous group as the first row of next group. This happens only when used with group by operator.The fix is to not rely on startGroup() and do the partition directory creation in processOp() itself.</description>
      <version>0.13.1,0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.load.dyn.part3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.update.all.partitioned.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.update.all.partitioned.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.dml.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.analyze.q.out</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FileSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.GroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.ExecReducer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Operator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorReduceSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.SortedDynPartitionOptimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.test.queries.clientpositive.alter.partition.change.col.q</file>
      <file type="M">ql.src.test.results.clientpositive.alter.partition.change.col.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.combine2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.constprog.dp.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.delete.all.partitioned.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.dynpart.sort.optimization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.dynpart.sort.opt.vectorization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.extrapolate.part.stats.partial.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby4.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby4.map.skew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.dyn.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input30.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input32.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.insert.into6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.load.dyn.part1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.load.dyn.part10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.load.dyn.part14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.load.dyn.part3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.load.dyn.part4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.load.dyn.part5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.load.dyn.part8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.load.dyn.part9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge.dynamic.partition3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge.dynamic.partition4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge.dynamic.partition5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.analyze.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stats2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stats4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stats.empty.dyn.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.delete.all.partitioned.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynpart.sort.optimization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynpart.sort.opt.vectorization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.load.dyn.part1.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="8152" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update with expression in set fails</summary>
      <description>Doing: update orctabsmall set age = age + 1; results in FAILED: ParseException line 1:33 missing EOF at '+' near 'age'We should be able to handle simple expressions in set clauses.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.update.all.types.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.update.all.types.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.insert.values.tmp.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.insert.values.tmp.table.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.update.all.types.q</file>
      <file type="M">ql.src.test.queries.clientpositive.insert.values.tmp.table.q</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.parse.TestIUD.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.HiveParser.g</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.FromClauseParser.g</file>
    </fixedFiles>
  </bug>
  <bug id="8153" opendate="2014-9-16 00:00:00" fixdate="2014-9-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Reduce the verbosity of debug logs in ORC record reader</summary>
      <description>Following fields are logged for every row.if (LOG.isDebugEnabled()) { LOG.debug("row from " + reader.path); LOG.debug("orc row = " + result); }This should be moved to trace logging.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="8156" opendate="2014-9-17 00:00:00" fixdate="2014-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorized reducers need to avoid memory build-up during a single key</summary>
      <description>When encountering a skewed key with a large number of values, the vectorized reducer will not release memory within the loop.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="8159" opendate="2014-9-17 00:00:00" fixdate="2014-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: bail from Optiq planning if a Select list contains multiple references to the same name</summary>
      <description>Optiq explicitly disallows this:select x, x from t1This is allowed in Hive (and also in mysql). Will check in Postgres. For now bailing from Optiq planning if we see this. Will file an Optiq issue.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.DerivedTableInjector.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.ASTConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.reloperators.HiveProjectRel.java</file>
    </fixedFiles>
  </bug>
  <bug id="8163" opendate="2014-9-17 00:00:00" fixdate="2014-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>With dynamic partition pruning map operator that generates the partition filters is not vectorized</summary>
      <description>Vertex used to generate the partition pruning filters is not vectorized.Sample from the plan : Vertices: Map 1 Map Operator Tree: TableScan alias: d3 filterExpr: ((d_quarter_name) IN ('2000Q1', '2000Q2', '2000Q3') and d_date_sk is not null) (type: boolean) Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ((d_quarter_name) IN ('2000Q1', '2000Q2', '2000Q3') and d_date_sk is not null) (type: boolean) Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: d_date_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col0 (type: int) outputColumnNames: _col0 Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Group By Operator keys: _col0 (type: int) mode: hash outputColumnNames: _col0 Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Dynamic Partitioning Event Operator Target Input: catalog_sales Partition key expr: cs_sold_date_sk Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Target column: cs_sold_date_sk Target Vertex: Map 3</description>
      <version>0.14.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.OperatorFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.AppMasterEventOperator.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8167" opendate="2014-9-17 00:00:00" fixdate="2014-9-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mvn install command broken by HIVE-8126 commit</summary>
      <description>HIVE-8126 broke the mvn install command by referencing a jar that got removed as part of HIVE-8126 command.[INFO] Installing ~/hive/packaging/target/apache-hive-0.14.0-SNAPSHOT-jdbc.jar to ~/.m2/repository/org/apache/hive/hive-packaging/0.14.0-SNAPSHOT/hive-packaging-0.14.0-SNAPSHOT-standalone.jarThe file ~/hive/packaging/target/apache-hive-0.14.0-SNAPSHOT-jdbc.jar doesn't get created right now.Basically a copy goal for the above jar needs to be revived for this command to succeed.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">packaging.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8169" opendate="2014-9-17 00:00:00" fixdate="2014-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Windows: alter table ..set location from hcatalog failed with NullPointerException</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.core.src.main.java.org.apache.hive.hcatalog.cli.SemanticAnalysis.HCatSemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="817" opendate="2009-9-6 00:00:00" fixdate="2009-9-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hive.hwi.war.file incorrectly tries to use environment variables to locate war file</summary>
      <description>&lt;property&gt; &lt;name&gt;hive.hwi.war.file&lt;/name&gt; &lt;value&gt;${HIVE_HOME}/lib/hive-hwi.war&lt;/value&gt;&lt;/property&gt;Is not interpreted correctly. This should read HIVE_HOME from environment as set by bin/hive and append this value to it.</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hwi.src.java.org.apache.hadoop.hive.hwi.HWIServer.java</file>
      <file type="M">conf.hive-default.xml</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8172" opendate="2014-9-18 00:00:00" fixdate="2014-10-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HiveServer2 dynamic service discovery should let the JDBC client use default ZooKeeper namespace</summary>
      <description>Currently the client provides a url like: jdbc:hive2://vgumashta.local:2181,vgumashta.local:2182,vgumashta.local:2183/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2. The zooKeeperNamespace param when not provided should use the default value.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.ZooKeeperHiveClientHelper.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.Utils.java</file>
    </fixedFiles>
  </bug>
  <bug id="8174" opendate="2014-9-18 00:00:00" fixdate="2014-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Bailout if stats needed for VC from base table</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.RelOptHiveTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="8175" opendate="2014-9-18 00:00:00" fixdate="2014-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive metastore upgrade from v0.13.0 to v0.14.0 script for Oracle is missing an upgrade step</summary>
      <description>Hive metastore upgrade script from 0.13.0 to 0.14.0 for Oracle is missing the required upgrade step from HIVE-7118.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.scripts.upgrade.oracle.upgrade-0.13.0-to-0.14.0.oracle.sql</file>
    </fixedFiles>
  </bug>
  <bug id="8179" opendate="2014-9-18 00:00:00" fixdate="2014-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fetch task conversion: Remove some dependencies on AST</summary>
      <description>fetch task conversion is does some strange things:For instance: select * from (select * from x) t, wont get converted even though it's the exact same operator plan as: select * from x.Or: select * from foo will get converted with minimal, but select &lt;list all columns of foo&gt; from foo won't.We also check the AST for group by etc, but then do the same thing in the operator tree again.I'm also wondering why we ship with "moar" as default, but test with "minimal" in the unit tests.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.test.org.apache.hive.service.cli.thrift.ThriftCLIServiceTest.java</file>
      <file type="M">service.src.test.org.apache.hive.service.cli.CLIServiceTest.java</file>
      <file type="M">ql.src.test.results.compiler.plan.udf6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.parse.udf6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.to.unix.timestamp.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.reflect2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.current.database.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.select.dummy.source.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.alias.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.serde.user.properties.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.select.dummy.source.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schemeAuthority2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.schemeAuthority.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.regex.col.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.quotedid.basic.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.quote1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppr.pushdown3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.partition.wise.fileformat2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.parquet.create.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.create.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nonmr.fetch.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit.partition.metadataonly.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.keyword.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.filter.numeric.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.extrapolate.part.stats.partial.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.extrapolate.part.stats.full.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.explain.logical.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.dynamic.partition.skip.default.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.combine2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.column.access.stats.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.select.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter.partition.coltype.q.out</file>
      <file type="M">ql.src.test.queries.positive.udf6.q</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.TestSymlinkTextInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.SimpleFetchOptimizer.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.history.TestHiveHistory.java</file>
      <file type="M">contrib.src.test.results.clientpositive.udf.example.format.q.out</file>
      <file type="M">contrib.src.test.results.clientpositive.udf.example.add.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="8185" opendate="2014-9-18 00:00:00" fixdate="2014-9-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hive-jdbc-0.14.0-SNAPSHOT-standalone.jar fails verification for signatures in build</summary>
      <description>In the current build, runningjarsigner --verify ./lib/hive-jdbc-0.14.0-SNAPSHOT-standalone.jarJar verification failed.unless that jar is removed from the lib dir, all hive queries throw the following error Exception in thread "main" java.lang.SecurityException: Invalid signature file digest for Manifest main attributes at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:240) at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:193) at java.util.jar.JarVerifier.processEntry(JarVerifier.java:305) at java.util.jar.JarVerifier.update(JarVerifier.java:216) at java.util.jar.JarFile.initializeVerifier(JarFile.java:345) at java.util.jar.JarFile.getInputStream(JarFile.java:412) at sun.misc.URLClassPath$JarLoader$2.getInputStream(URLClassPath.java:775)</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8187" opendate="2014-9-19 00:00:00" fixdate="2014-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Change Optiq Type System Precision/scale to use Hive Type System Precision/Scale</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.ASTConverter.java</file>
    </fixedFiles>
  </bug>
  <bug id="8191" opendate="2014-9-19 00:00:00" fixdate="2014-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update and delete on tables with non Acid output formats gives runtime error</summary>
      <description>create table not_an_acid_table(a int, b varchar(128));insert into table not_an_acid_table select cint, cast(cstring1 as varchar(128)) from alltypesorc where cint is not null order by cint limit 10;delete from not_an_acid_table where b = '0ruyd6Y50JpdGRf6HqD';This generates a runtime error. It should get a compile error instead.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.ErrorMsg.java</file>
    </fixedFiles>
  </bug>
  <bug id="8194" opendate="2014-9-19 00:00:00" fixdate="2014-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: bail for having clause referring select expr aliases</summary>
      <description>This is non standard behavior. Not supporting in cbo mode.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8198" opendate="2014-9-19 00:00:00" fixdate="2014-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[CBO] Handle case where top level schema contains repeated alias</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.DerivedTableInjector.java</file>
    </fixedFiles>
  </bug>
  <bug id="8201" opendate="2014-9-19 00:00:00" fixdate="2014-9-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove hardwiring to HiveInputFormat in acid qfile tests</summary>
      <description>Now that HIVE-7812 is checked in we should remove the hardwiring to HiveInputFormat for the qfile tests.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.queries.clientpositive.update.where.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.update.where.no.match.q</file>
      <file type="M">ql.src.test.queries.clientpositive.update.where.non.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.update.two.cols.q</file>
      <file type="M">ql.src.test.queries.clientpositive.update.tmp.table.q</file>
      <file type="M">ql.src.test.queries.clientpositive.update.orig.table.q</file>
      <file type="M">ql.src.test.queries.clientpositive.update.all.types.q</file>
      <file type="M">ql.src.test.queries.clientpositive.update.all.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.update.all.non.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.update.after.multiple.inserts.q</file>
      <file type="M">ql.src.test.queries.clientpositive.insert.values.tmp.table.q</file>
      <file type="M">ql.src.test.queries.clientpositive.insert.values.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.insert.values.orig.table.q</file>
      <file type="M">ql.src.test.queries.clientpositive.insert.values.non.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.insert.values.dynamic.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.insert.update.delete.q</file>
      <file type="M">ql.src.test.queries.clientpositive.insert.orig.table.q</file>
      <file type="M">ql.src.test.queries.clientpositive.delete.whole.partition.q</file>
      <file type="M">ql.src.test.queries.clientpositive.delete.where.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.delete.where.no.match.q</file>
      <file type="M">ql.src.test.queries.clientpositive.delete.where.non.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.delete.tmp.table.q</file>
      <file type="M">ql.src.test.queries.clientpositive.delete.orig.table.q</file>
      <file type="M">ql.src.test.queries.clientpositive.delete.all.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.delete.all.non.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.authorization.update.own.table.q</file>
      <file type="M">ql.src.test.queries.clientpositive.authorization.update.q</file>
      <file type="M">ql.src.test.queries.clientpositive.authorization.delete.own.table.q</file>
      <file type="M">ql.src.test.queries.clientpositive.authorization.delete.q</file>
      <file type="M">ql.src.test.queries.clientpositive.acid.vectorization.q</file>
      <file type="M">ql.src.test.queries.clientnegative.update.partition.col.q</file>
      <file type="M">ql.src.test.queries.clientnegative.update.no.such.table.q</file>
      <file type="M">ql.src.test.queries.clientnegative.authorization.update.noupdatepriv.q</file>
      <file type="M">ql.src.test.queries.clientnegative.authorization.delete.nodeletepriv.q</file>
      <file type="M">ql.src.test.queries.clientnegative.acid.overwrite.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.AcidUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="8202" opendate="2014-9-20 00:00:00" fixdate="2014-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support SMB Join for Hive on Spark [Spark Branch]</summary>
      <description>SMB joins are used wherever the tables are sorted and bucketed. It's a map-side join. The join boils down to just merging the already sorted tables, allowing this operation to be faster than an ordinary map-join.The task is to research and support the conversion from regular SMB join to SMB map join for Spark execution engine.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.spark.smb.mapjoin.25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.smb.mapjoin.21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.smb.mapjoin.20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.smb.mapjoin.17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.parquet.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.disable.merge.for.bucketing.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.smb.mapjoin.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.join32.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.SparkCompiler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.GenSparkWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.GenSparkUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.GenSparkProcContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.Optimizer.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8207" opendate="2014-9-20 00:00:00" fixdate="2014-9-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add .q tests for multi-table insertion [Spark Branch]</summary>
      <description>Now that multi-table insertion is committed to branch, we should enable those related qtests.Here is a list of qfiles that should be activated (some of them may already be activated).The list may not be comprehensive.add_part_multiple.qauto_smb_mapjoin_14.qbucket5.qcolumn_access_stats.qdate_udf.qgroupby10.qgroupby11.qgroupby3_map_multi_distinct.qgroupby3_map.qgroupby3_map_skew.qgroupby3_noskew_multi_distinct.qgroupby3_noskew.qgroupby7_map_multi_single_reducer.qgroupby7_map.qgroupby7_map_skew.qgroupby7_noskew_multi_single_reducer.qgroupby7_noskew.qgroupby7.qgroupby8_map.qgroupby8_map_skew.qgroupby8_noskew.qgroupby8.qgroupby9.qgroupby_complex_types_multi_single_reducer.qgroupby_complex_types.qgroupby_cube1.qgroupby_map_ppr_multi_distinct.qgroupby_map_ppr.qgroupby_multi_insert_common_distinct.qgroupby_multi_single_reducer2.qgroupby_multi_single_reducer3.qgroupby_multi_single_reducer.qgroupby_position.qgroupby_ppr.qgroupby_rollup1.qgroupby_sort_1_23.qgroupby_sort_1.qgroupby_sort_skew_1_23.qinfer_bucket_sort_multi_insert.qinnerjoin.qinput12_hadoop20.qinput12.qinput13.qinput14.qinput17.qinput18.qinput1_limit.qinput_part2.qinsert_into3.qjoin_nullsafe.qload_dyn_part8.qmetadata_only_queries_with_filters.qmultigroupby_singlemr.qmulti_insert_gby2.qmulti_insert_gby3.qmulti_insert_gby.qmulti_insert_lateral_view.qmulti_insert_move_tasks_share_dependencies.qmulti_insert.qparallel.qpartition_date2.qpcr.qppd_multi_insert.qppd_transform.qsmb_mapjoin_11.qsmb_mapjoin_12.qsmb_mapjoin_13.qsmb_mapjoin_15.qsmb_mapjoin_16.qstats4.qsubquery_multiinsert.qtable_access_keys_stats.qtez_dml.qudaf_percentile_approx_20.qudaf_percentile_approx_23.qunion17.qunion18.qunion19.q There are some tests that cannot be enabled right now, due to various reasons:1. ForwardOperator Issue, includinggroupby7_noskew_multi_single_reducer.qgroupby8_map.qgroupby8_map_skew.qgroupby8_noskew.qgroupby8.qgroupby9.qgroupby10.qgroupby_multi_insert_common_distinct.q union17.qReason: currently, if the node to break in the operator tree is a ForwardOperator, we simple do nothing. However, we may have the following case: ... RS_0 | FOR | / \ GBY_1 GBY_2 | | ... ... | | RS_1 RS_2 | | ... ... | | FS_1 FS_2which may result to: RW / \ RW RWand because of the issue in HIVE-7731 and HIVE-8118, both downstream branches will get duplicated (and same) inputs.2. Stats issue, including:bucket5.qinfer_bucket_sort_multi_insert.qstats4.qsmb_mapjoin_13.qsmb_mapjoin_15.qReason: In these tests, I get diff error because numRows and rawDataSize are -1, but they are expected to be some positive value. I don't think this is related to multi-insertion.3. Join/SMB Join Issue, includingauto_smb_mapjoin_14.qauto_sortmerge_join_13.qsmb_mapjoin_11.qsmb_mapjoin_12.qsmb_mapjoin_13.qsmb_mapjoin_15.qsmb_mapjoin_16.qReason: These tests either failed with exception or failed with diff. I think it's because SMB Join (HIVE-8202) isn't supported right now.4. Result doesn't match, includinggroupby3_map_skew.qgroupby_map_ppr_multi_distinct.qgroupby_complex_types_multi_single_reducer.qgroupby_map_ppr.qpartition_date2.qudaf_percentile_approx_23.qReason: The results from these tests are different from MR's. For instance, test for groupby3_map_skew.q failed because:&lt; 130091.0 260.182 256.10355987055016 98.0 0.0 142.92680950752379 143.06995106518903 20428.07288 20469.0109---&gt; 130091.0 260.182 256.10355987055016 98.0 0.0 142.9268095075238 143.06995106518906 20428.07288 20469.0109I don't know why this will happen. But, I think they may not be related to multi-insertion.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8212" opendate="2014-9-22 00:00:00" fixdate="2014-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Regression for hcat commandline alter view set tblproperties</summary>
      <description>HIVE-7681 introduced a regression where hcat -e 'alter view set tblproperties ...' stopped working, since HiveParser.TOK_ALTERVIEW was introduced and is what's visible at the preAnalyze, and that wasn't explicitly permitted.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.core.src.main.java.org.apache.hive.hcatalog.cli.SemanticAnalysis.HCatSemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8227" opendate="2014-9-22 00:00:00" fixdate="2014-9-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE w/ hive on tez when doing unions on empty tables</summary>
      <description>We're looking at aliasToWork.values() to determine input paths etc. This can contain nulls when we're scanning empty tables.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.OperatorUtils.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8228" opendate="2014-9-23 00:00:00" fixdate="2014-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: fix couple of issues with partition pruning</summary>
      <description>Pruner doesn't handle non-deterministic UDFs correctly Plan genned after CBO has a Project between TScan and Filter; which prevents PartPruning from triggering in hive post CBO.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.cbo.correctness.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.rules.PartitionPruner.java</file>
    </fixedFiles>
  </bug>
  <bug id="8229" opendate="2014-9-23 00:00:00" fixdate="2014-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add multithreaded tests for the Hive Writable data types</summary>
      <description>Just to make sure there aren't other issues similar to HIVE-4516.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.io.TestTimestampWritable.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.io.TestHiveVarcharWritable.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.io.TestHiveDecimalWritable.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.io.TestHiveCharWritable.java</file>
      <file type="M">serde.pom.xml</file>
      <file type="M">common.src.test.org.apache.hadoop.hive.common.type.TestHiveVarchar.java</file>
      <file type="M">common.src.test.org.apache.hadoop.hive.common.type.TestHiveDecimal.java</file>
      <file type="M">common.src.test.org.apache.hadoop.hive.common.type.TestHiveChar.java</file>
      <file type="M">common.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8232" opendate="2014-9-23 00:00:00" fixdate="2014-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO Trunk Merge: Address Review Comments</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.RexNodeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.DerivedTableInjector.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.stats.FilterSelectivityEstimator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.rules.HivePartitionPrunerRule.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.rules.HiveMergeProjectRule.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.reloperators.HiveSortRel.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.reloperators.HiveJoinRel.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.HiveOptiqUtil.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.cost.HiveCostUtil.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.cost.HiveCost.java</file>
    </fixedFiles>
  </bug>
  <bug id="8237" opendate="2014-9-23 00:00:00" fixdate="2014-9-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Use Fully qualified table name (db.tablename in ReloptHiveTable)</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.ASTConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.ASTBuilder.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.RelOptHiveTable.java</file>
    </fixedFiles>
  </bug>
  <bug id="8245" opendate="2014-9-24 00:00:00" fixdate="2014-9-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Collect table read entities at same time as view read entities</summary>
      <description></description>
      <version>0.13.0,0.13.1,0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.vectorization.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge.incompat2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge.incompat1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.analyze.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.metadata.only.queries.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.limit.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.alter.merge.stats.orc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stats.only.null.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.query.properties.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ql.rewrite.gbtoidx.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge.incompat2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge.incompat1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.merge5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.analyze.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.metadata.only.queries.with.filters.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.metadata.only.queries.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.explain.dependency.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.authorization.explain.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter.merge.stats.orc.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.limit.partition.stats.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="8261" opendate="2014-9-25 00:00:00" fixdate="2014-9-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO : Predicate pushdown is removed by Optiq</summary>
      <description>Plan for TPC-DS Q64 wasn't optimal upon looking at the logical plan I realized that predicate pushdown is not applied on date_dim d1.Interestingly before optiq we have the predicate pushed :HiveFilterRel(condition=[&lt;=($5, $1)]) HiveJoinRel(condition=[=($3, $6)], joinType=[inner]) HiveProjectRel(_o__col0=[$0], _o__col1=[$2], _o__col2=[$3], _o__col3=[$1]) HiveFilterRel(condition=[=($0, 2000)]) HiveAggregateRel(group=[{0, 1}], agg#0=[count()], agg#1=[sum($2)]) HiveProjectRel($f0=[$4], $f1=[$5], $f2=[$2]) HiveJoinRel(condition=[=($1, $8)], joinType=[inner]) HiveJoinRel(condition=[=($1, $5)], joinType=[inner]) HiveJoinRel(condition=[=($0, $3)], joinType=[inner]) HiveProjectRel(ss_sold_date_sk=[$0], ss_item_sk=[$2], ss_wholesale_cost=[$11]) HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.store_sales]]) HiveProjectRel(d_date_sk=[$0], d_year=[$6]) HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.date_dim]]) HiveFilterRel(condition=[AND(in($2, 'maroon', 'burnished', 'dim', 'steel', 'navajo', 'chocolate'), between(false, $1, 35, +(35, 10)), between(false, $1, +(35, 1), +(35, 15)))]) HiveProjectRel(i_item_sk=[$0], i_current_price=[$5], i_color=[$17]) HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.item]]) HiveProjectRel(_o__col0=[$0]) HiveAggregateRel(group=[{0}]) HiveProjectRel($f0=[$0]) HiveJoinRel(condition=[AND(=($0, $2), =($1, $3))], joinType=[inner]) HiveProjectRel(cs_item_sk=[$15], cs_order_number=[$17]) HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.catalog_sales]]) HiveProjectRel(cr_item_sk=[$2], cr_order_number=[$16]) HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.catalog_returns]]) HiveProjectRel(_o__col0=[$0], _o__col1=[$2], _o__col3=[$1]) HiveFilterRel(condition=[=($0, +(2000, 1))]) HiveAggregateRel(group=[{0, 1}], agg#0=[count()]) HiveProjectRel($f0=[$4], $f1=[$5], $f2=[$2]) HiveJoinRel(condition=[=($1, $8)], joinType=[inner]) HiveJoinRel(condition=[=($1, $5)], joinType=[inner]) HiveJoinRel(condition=[=($0, $3)], joinType=[inner]) HiveProjectRel(ss_sold_date_sk=[$0], ss_item_sk=[$2], ss_wholesale_cost=[$11]) HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.store_sales]]) HiveProjectRel(d_date_sk=[$0], d_year=[$6]) HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.date_dim]]) HiveFilterRel(condition=[AND(in($2, 'maroon', 'burnished', 'dim', 'steel', 'navajo', 'chocolate'), between(false, $1, 35, +(35, 10)), between(false, $1, +(35, 1), +(35, 15)))]) HiveProjectRel(i_item_sk=[$0], i_current_price=[$5], i_color=[$17]) HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.item]]) HiveProjectRel(_o__col0=[$0]) HiveAggregateRel(group=[{0}]) HiveProjectRel($f0=[$0]) HiveJoinRel(condition=[AND(=($0, $2), =($1, $3))], joinType=[inner]) HiveProjectRel(cs_item_sk=[$15], cs_order_number=[$17]) HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.catalog_sales]]) HiveProjectRel(cr_item_sk=[$2], cr_order_number=[$16]) HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.catalog_returns]])While after Optiq the filter on date_dim gets pulled up the plan HiveFilterRel(condition=[&lt;=($5, $1)]): rowcount = 1.0, cumulative cost = {5.50188454E8 rows, 0.0 cpu, 0.0 io}, id = 6895 HiveProjectRel(_o__col0=[$0], _o__col1=[$1], _o__col2=[$2], _o__col3=[$3], _o__col00=[$4], _o__col10=[$5], _o__col30=[$6]): rowcount = 1.0, cumulative cost = {5.50188454E8 rows, 0.0 cpu, 0.0 io}, id = 7046 HiveJoinRel(condition=[=($3, $6)], joinType=[inner]): rowcount = 1.0, cumulative cost = {5.50188454E8 rows, 0.0 cpu, 0.0 io}, id = 7041 HiveProjectRel(_o__col0=[$0], _o__col1=[$2], _o__col2=[$3], _o__col3=[$1]): rowcount = 1.0, cumulative cost = {5.50188452E8 rows, 0.0 cpu, 0.0 io}, id = 6857 HiveFilterRel(condition=[=($0, 2000)]): rowcount = 1.0, cumulative cost = {5.50188452E8 rows, 0.0 cpu, 0.0 io}, id = 6855 HiveAggregateRel(group=[{0, 1}], agg#0=[count()], agg#1=[sum($2)]): rowcount = 1.0, cumulative cost = {5.50188452E8 rows, 0.0 cpu, 0.0 io}, id = 6853 HiveProjectRel($f0=[$4], $f1=[$5], $f2=[$2]): rowcount = 1.0, cumulative cost = {5.50188452E8 rows, 0.0 cpu, 0.0 io}, id = 6851 HiveProjectRel(ss_sold_date_sk=[$3], ss_item_sk=[$4], ss_wholesale_cost=[$5], d_date_sk=[$0], d_year=[$1], i_item_sk=[$6], i_current_price=[$7], i_color=[$8], _o__col0=[$2]): rowcount = 1.0, cumulative cost = {5.50188452E8 rows, 0.0 cpu, 0.0 io}, id = 7039 HiveJoinRel(condition=[=($3, $0)], joinType=[inner]): rowcount = 1.0, cumulative cost = {5.50188452E8 rows, 0.0 cpu, 0.0 io}, id = 7037 HiveProjectRel(d_date_sk=[$0], d_year=[$6]): rowcount = 73049.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 6861 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.date_dim]]): rowcount = 73049.0, cumulative cost = {0}, id = 6537 HiveJoinRel(condition=[=($2, $0)], joinType=[inner]): rowcount = 1.0, cumulative cost = {5.50115402E8 rows, 0.0 cpu, 0.0 io}, id = 7035 HiveProjectRel(_o__col0=[$0]): rowcount = 38846.0, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 6847 HiveAggregateRel(group=[{0}]): rowcount = 38846.0, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 6845 HiveProjectRel($f0=[$0]): rowcount = 6.692553251460564E8, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 6843 HiveProjectRel(cs_item_sk=[$0], cs_order_number=[$1], cr_item_sk=[$2], cr_order_number=[$3]): rowcount = 6.692553251460564E8, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 6945 HiveJoinRel(condition=[AND(=($0, $2), =($1, $3))], joinType=[inner]): rowcount = 6.692553251460564E8, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 6940 HiveProjectRel(cs_item_sk=[$15], cs_order_number=[$17]): rowcount = 2.86549727E8, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 6871 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.catalog_sales]]): rowcount = 2.86549727E8, cumulative cost = {0}, id = 6531 HiveProjectRel(cr_item_sk=[$2], cr_order_number=[$16]): rowcount = 2.8798881E7, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 6873 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.catalog_returns]]): rowcount = 2.8798881E7, cumulative cost = {0}, id = 6532 HiveJoinRel(condition=[=($1, $3)], joinType=[inner]): rowcount = 1.0, cumulative cost = {5.50076555E8 rows, 0.0 cpu, 0.0 io}, id = 6996 HiveProjectRel(ss_sold_date_sk=[$0], ss_item_sk=[$2], ss_wholesale_cost=[$11]): rowcount = 5.50076554E8, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 6859 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.store_sales]]): rowcount = 5.50076554E8, cumulative cost = {0}, id = 6538 HiveFilterRel(condition=[AND(in($2, 'maroon', 'burnished', 'dim', 'steel', 'navajo', 'chocolate'), between(false, $1, 35, +(35, 10)), between(false, $1, +(35, 1), +(35, 15)))]): rowcount = 1.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 6833 HiveProjectRel(i_item_sk=[$0], i_current_price=[$5], i_color=[$17]): rowcount = 48000.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 6831 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.item]]): rowcount = 48000.0, cumulative cost = {0}, id = 6539 HiveProjectRel(_o__col0=[$0], _o__col1=[$2], _o__col3=[$1]): rowcount = 1.0, cumulative cost = {5.50188452E8 rows, 0.0 cpu, 0.0 io}, id = 6891 HiveFilterRel(condition=[=($0, +(2000, 1))]): rowcount = 1.0, cumulative cost = {5.50188452E8 rows, 0.0 cpu, 0.0 io}, id = 6889 HiveAggregateRel(group=[{0, 1}], agg#0=[count()]): rowcount = 1.0, cumulative cost = {5.50188452E8 rows, 0.0 cpu, 0.0 io}, id = 6887 HiveProjectRel($f0=[$4], $f1=[$5], $f2=[$2]): rowcount = 1.0, cumulative cost = {5.50188452E8 rows, 0.0 cpu, 0.0 io}, id = 6885 HiveProjectRel(ss_sold_date_sk=[$3], ss_item_sk=[$4], ss_wholesale_cost=[$5], d_date_sk=[$0], d_year=[$1], i_item_sk=[$6], i_current_price=[$7], i_color=[$8], _o__col0=[$2]): rowcount = 1.0, cumulative cost = {5.50188452E8 rows, 0.0 cpu, 0.0 io}, id = 6992 HiveJoinRel(condition=[=($3, $0)], joinType=[inner]): rowcount = 1.0, cumulative cost = {5.50188452E8 rows, 0.0 cpu, 0.0 io}, id = 6990 HiveProjectRel(d_date_sk=[$0], d_year=[$6]): rowcount = 73049.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 6861 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.date_dim]]): rowcount = 73049.0, cumulative cost = {0}, id = 6537 HiveJoinRel(condition=[=($2, $0)], joinType=[inner]): rowcount = 1.0, cumulative cost = {5.50115402E8 rows, 0.0 cpu, 0.0 io}, id = 6988 HiveProjectRel(_o__col0=[$0]): rowcount = 38846.0, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 6881 HiveAggregateRel(group=[{0}]): rowcount = 38846.0, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 6879 HiveProjectRel($f0=[$0]): rowcount = 6.692553251460564E8, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 6877 HiveProjectRel(cs_item_sk=[$0], cs_order_number=[$1], cr_item_sk=[$2], cr_order_number=[$3]): rowcount = 6.692553251460564E8, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 6938 HiveJoinRel(condition=[AND(=($0, $2), =($1, $3))], joinType=[inner]): rowcount = 6.692553251460564E8, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 6933 HiveProjectRel(cs_item_sk=[$15], cs_order_number=[$17]): rowcount = 2.86549727E8, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 6871 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.catalog_sales]]): rowcount = 2.86549727E8, cumulative cost = {0}, id = 6531 HiveProjectRel(cr_item_sk=[$2], cr_order_number=[$16]): rowcount = 2.8798881E7, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 6873 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.catalog_returns]]): rowcount = 2.8798881E7, cumulative cost = {0}, id = 6532 HiveJoinRel(condition=[=($1, $3)], joinType=[inner]): rowcount = 1.0, cumulative cost = {5.50076555E8 rows, 0.0 cpu, 0.0 io}, id = 6949 HiveProjectRel(ss_sold_date_sk=[$0], ss_item_sk=[$2], ss_wholesale_cost=[$11]): rowcount = 5.50076554E8, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 6859 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.store_sales]]): rowcount = 5.50076554E8, cumulative cost = {0}, id = 6538 HiveFilterRel(condition=[AND(in($2, 'maroon', 'burnished', 'dim', 'steel', 'navajo', 'chocolate'), between(false, $1, 35, +(35, 10)), between(false, $1, +(35, 1), +(35, 15)))]): rowcount = 1.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 6867 HiveProjectRel(i_item_sk=[$0], i_current_price=[$5], i_color=[$17]): rowcount = 48000.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 6865 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.item]]): rowcount = 48000.0, cumulative cost = {0}, id = 6539I simplified the query a little bit while still maintaining the query structure The query : Note that the final join between cs1 and cs2 has a predicates "cs1.syear = 2000 and cs2.syear = 2000 + 1"select cs1.syear ,cs1.cnt ,cs1.s1 ,cs2.syear ,cs2.cntfrom(select d1.d_year as syear ,count(*) as cnt,sum(ss_wholesale_cost) as s1 ,i_item_sk as item_sk FROM store_sales JOIN date_dim d1 ON store_sales.ss_sold_date_sk = d1.d_date_sk JOIN item ON store_sales.ss_item_sk = item.i_item_sk JOIN (select cs_item_sk from catalog_sales JOIN catalog_returns ON catalog_sales.cs_item_sk = catalog_returns.cr_item_sk and catalog_sales.cs_order_number = catalog_returns.cr_order_number group by cs_item_sk) cs_uiON store_sales.ss_item_sk = cs_ui.cs_item_sk WHERE i_color in ('maroon','burnished','dim','steel','navajo','chocolate') and i_current_price between 35 and 35 + 10 and i_current_price between 35 + 1 and 35 + 15group by d1.d_year,i_item_sk) cs1JOIN(select d1.d_year as syear ,count(*) as cnt,sum(ss_wholesale_cost) as s1 , i_item_sk as item_sk FROM store_sales JOIN date_dim d1 ON store_sales.ss_sold_date_sk = d1.d_date_sk JOIN item ON store_sales.ss_item_sk = item.i_item_sk JOIN (select cs_item_sk from catalog_sales JOIN catalog_returns ON catalog_sales.cs_item_sk = catalog_returns.cr_item_sk and catalog_sales.cs_order_number = catalog_returns.cr_order_number group by cs_item_sk) cs_uiON store_sales.ss_item_sk = cs_ui.cs_item_sk WHERE i_color in ('maroon','burnished','dim','steel','navajo','chocolate') and i_current_price between 35 and 35 + 10 and i_current_price between 35 + 1 and 35 + 15group by d1.d_year,i_item_sk) cs2ON cs1.item_sk=cs2.item_skwhere cs1.syear = 2000 and cs2.syear = 2000 + 1 and cs2.cnt &lt;= cs1.cnt;</description>
      <version>0.13.1,0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8263" opendate="2014-9-25 00:00:00" fixdate="2014-10-25 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO : TPC-DS Q64 is item is joined last with store_sales while it should be first as it is the most selective</summary>
      <description>Plan for TPC-DS Q64 shows that item is joined last with store_sales while store_sales x item is the most selective join in the plan.Interestingly predicate push down is applied on item but item comes so late in the join which most likely means that calculation of the join selectivity gave too high of a number of it was never considered.This is a subset of the logical plan showing that item was joined very lastHiveProjectRel(_o__col0=[$0], _o__col1=[$2], _o__col2=[$3], _o__col3=[$4], _o__col4=[$5], _o__col5=[$6], _o__col6=[$7], _o__col7=[$8], _o__col8=[$9], _o__col9=[$10], _o__col10=[$11], _o__col11=[$12], _o__col12=[$13], _o__col13=[$14], _o__col14=[$15], _o__col15=[$16], _o__col16=[$22], _o__col17=[$23], _o__col18=[$24], _o__col19=[$20], _o__col20=[$21]): rowcount = 1.0, cumulative cost = {1.1593403796322412E9 rows, 0.0 cpu, 0.0 io}, id = 990 HiveFilterRel(condition=[&lt;=($21, $13)]): rowcount = 1.0, cumulative cost = {1.1593403796322412E9 rows, 0.0 cpu, 0.0 io}, id = 988 HiveProjectRel(_o__col0=[$0], _o__col1=[$1], _o__col2=[$2], _o__col3=[$3], _o__col4=[$4], _o__col5=[$5], _o__col6=[$6], _o__col7=[$7], _o__col8=[$8], _o__col9=[$9], _o__col10=[$10], _o__col11=[$11], _o__col12=[$12], _o__col15=[$13], _o__col16=[$14], _o__col17=[$15], _o__col18=[$16], _o__col13=[$17], _o__col20=[$18], _o__col30=[$19], _o__col120=[$20], _o__col150=[$21], _o__col160=[$22], _o__col170=[$23], _o__col180=[$24]): rowcount = 1.0, cumulative cost = {1.1593403796322412E9 rows, 0.0 cpu, 0.0 io}, id = 3571 HiveJoinRel(condition=[AND(AND(=($1, $17), =($2, $18)), =($3, $19))], joinType=[inner]): rowcount = 1.0, cumulative cost = {1.1593403796322412E9 rows, 0.0 cpu, 0.0 io}, id = 3566 HiveProjectRel(_o__col0=[$0], _o__col1=[$1], _o__col2=[$2], _o__col3=[$3], _o__col4=[$4], _o__col5=[$5], _o__col6=[$6], _o__col7=[$7], _o__col8=[$8], _o__col9=[$9], _o__col10=[$10], _o__col11=[$11], _o__col12=[$12], _o__col15=[$15], _o__col16=[$16], _o__col17=[$17], _o__col18=[$18]): rowcount = 1.0, cumulative cost = {1.1593403776322412E9 rows, 0.0 cpu, 0.0 io}, id = 890 HiveFilterRel(condition=[=($12, 2000)]): rowcount = 1.0, cumulative cost = {1.1593403776322412E9 rows, 0.0 cpu, 0.0 io}, id = 888 HiveAggregateRel(group=[{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}], agg#0=[count()], agg#1=[sum($15)], agg#2=[sum($16)], agg#3=[sum($17)]): rowcount = 1.0, cumulative cost = {1.1593403776322412E9 rows, 0.0 cpu, 0.0 io}, id = 886 HiveProjectRel($f0=[$53], $f1=[$50], $f2=[$27], $f3=[$28], $f4=[$39], $f5=[$40], $f6=[$41], $f7=[$42], $f8=[$44], $f9=[$45], $f10=[$46], $f11=[$47], $f12=[$21], $f13=[$23], $f14=[$25], $f15=[$9], $f16=[$10], $f17=[$11]): rowcount = 1.0, cumulative cost = {1.1593403776322412E9 rows, 0.0 cpu, 0.0 io}, id = 884 HiveProjectRel(ss_sold_date_sk=[$17], ss_item_sk=[$18], ss_customer_sk=[$19], ss_cdemo_sk=[$20], ss_hdemo_sk=[$21], ss_addr_sk=[$22], ss_store_sk=[$23], ss_promo_sk=[$24], ss_ticket_number=[$25], ss_wholesale_cost=[$26], ss_list_price=[$27], ss_coupon_amt=[$28], sr_item_sk=[$29], sr_ticket_number=[$30], c_customer_sk=[$31], c_current_cdemo_sk=[$32], c_current_hdemo_sk=[$33], c_current_addr_sk=[$34], c_first_shipto_date_sk=[$35], c_first_sales_date_sk=[$36], d_date_sk=[$37], d_year=[$38], d_date_sk0=[$39], d_year0=[$40], d_date_sk1=[$41], d_year1=[$42], s_store_sk=[$43], s_store_name=[$44], s_zip=[$45], cd_demo_sk=[$46], cd_marital_status=[$47], cd_demo_sk0=[$48], cd_marital_status0=[$49], p_promo_sk=[$0], hd_demo_sk=[$15], hd_income_band_sk=[$16], hd_demo_sk0=[$13], hd_income_band_sk0=[$14], ca_address_sk=[$6], ca_street_number=[$7], ca_street_name=[$8], ca_city=[$9], ca_zip=[$10], ca_address_sk0=[$1], ca_street_number0=[$2], ca_street_name0=[$3], ca_city0=[$4], ca_zip0=[$5], ib_income_band_sk=[$12], ib_income_band_sk0=[$11], i_item_sk=[$51], i_current_price=[$52], i_color=[$53], i_product_name=[$54], _o__col0=[$50]): rowcount = 1.0, cumulative cost = {1.1593403776322412E9 rows, 0.0 cpu, 0.0 io}, id = 3564 HiveJoinRel(condition=[=($24, $0)], joinType=[inner]): rowcount = 1.0, cumulative cost = {1.1593403776322412E9 rows, 0.0 cpu, 0.0 io}, id = 3562 HiveProjectRel(p_promo_sk=[$0]): rowcount = 450.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 928 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.promotion]]): rowcount = 450.0, cumulative cost = {0}, id = 58 HiveJoinRel(condition=[=($33, $0)], joinType=[inner]): rowcount = 1.0, cumulative cost = {1.1593399266322412E9 rows, 0.0 cpu, 0.0 io}, id = 3560 HiveProjectRel(ca_address_sk=[$0], ca_street_number=[$2], ca_street_name=[$3], ca_city=[$6], ca_zip=[$9]): rowcount = 800000.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 940 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.customer_address]]): rowcount = 800000.0, cumulative cost = {0}, id = 61 HiveJoinRel(condition=[=($16, $0)], joinType=[inner]): rowcount = 1.0, cumulative cost = {1.1585399256322412E9 rows, 0.0 cpu, 0.0 io}, id = 3558 HiveProjectRel(ca_address_sk=[$0], ca_street_number=[$2], ca_street_name=[$3], ca_city=[$6], ca_zip=[$9]): rowcount = 800000.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 940 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.customer_address]]): rowcount = 800000.0, cumulative cost = {0}, id = 61 HiveJoinRel(condition=[=($3, $0)], joinType=[inner]): rowcount = 1.0, cumulative cost = {1.1577399246322412E9 rows, 0.0 cpu, 0.0 io}, id = 3556 HiveProjectRel(ib_income_band_sk=[$0]): rowcount = 20.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 948 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.income_band]]): rowcount = 20.0, cumulative cost = {0}, id = 63 HiveJoinRel(condition=[=($4, $0)], joinType=[inner]): rowcount = 1.0, cumulative cost = {1.1577399036322412E9 rows, 0.0 cpu, 0.0 io}, id = 3554 HiveProjectRel(ib_income_band_sk=[$0]): rowcount = 20.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 948 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.income_band]]): rowcount = 20.0, cumulative cost = {0}, id = 63 HiveJoinRel(condition=[=($5, $38)], joinType=[inner]): rowcount = 1.0, cumulative cost = {1.1577398826322412E9 rows, 0.0 cpu, 0.0 io}, id = 3552 HiveJoinRel(condition=[=($20, $0)], joinType=[inner]): rowcount = 1.0, cumulative cost = {1.1577398806322412E9 rows, 0.0 cpu, 0.0 io}, id = 3550 HiveProjectRel(hd_demo_sk=[$0], hd_income_band_sk=[$1]): rowcount = 7200.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 932 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.household_demographics]]): rowcount = 7200.0, cumulative cost = {0}, id = 53 HiveJoinRel(condition=[=($6, $0)], joinType=[inner]): rowcount = 1.0, cumulative cost = {1.1577326796322412E9 rows, 0.0 cpu, 0.0 io}, id = 3548 HiveProjectRel(hd_demo_sk=[$0], hd_income_band_sk=[$1]): rowcount = 7200.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 932 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.household_demographics]]): rowcount = 7200.0, cumulative cost = {0}, id = 53 HiveJoinRel(condition=[=($1, $33)], joinType=[inner]): rowcount = 1.0, cumulative cost = {1.1577254786322412E9 rows, 0.0 cpu, 0.0 io}, id = 2795 HiveFilterRel(condition=[&lt;&gt;($30, $32)]): rowcount = 1.0, cumulative cost = {1.1577254766322412E9 rows, 0.0 cpu, 0.0 io}, id = 832 HiveProjectRel(ss_sold_date_sk=[$0], ss_item_sk=[$1], ss_customer_sk=[$2], ss_cdemo_sk=[$3], ss_hdemo_sk=[$4], ss_addr_sk=[$5], ss_store_sk=[$6], ss_promo_sk=[$7], ss_ticket_number=[$8], ss_wholesale_cost=[$9], ss_list_price=[$10], ss_coupon_amt=[$11], sr_item_sk=[$31], sr_ticket_number=[$32], c_customer_sk=[$21], c_current_cdemo_sk=[$22], c_current_hdemo_sk=[$23], c_current_addr_sk=[$24], c_first_shipto_date_sk=[$25], c_first_sales_date_sk=[$26], d_date_sk=[$14], d_year=[$15], d_date_sk0=[$27], d_year0=[$28], d_date_sk1=[$29], d_year1=[$30], s_store_sk=[$16], s_store_name=[$17], s_zip=[$18], cd_demo_sk=[$12], cd_marital_status=[$13], cd_demo_sk0=[$19], cd_marital_status0=[$20]): rowcount = 3.9579965360452816, cumulative cost = {1.1577254766322412E9 rows, 0.0 cpu, 0.0 io}, id = 1998 HiveJoinRel(condition=[AND(=($1, $31), =($8, $32))], joinType=[inner]): rowcount = 3.9579965360452816, cumulative cost = {1.1577254766322412E9 rows, 0.0 cpu, 0.0 io}, id = 1996 HiveJoinRel(condition=[=($2, $21)], joinType=[inner]): rowcount = 1.0, cumulative cost = {1.1021474706322412E9 rows, 0.0 cpu, 0.0 io}, id = 1994 HiveJoinRel(condition=[=($6, $16)], joinType=[inner]): rowcount = 1.0, cumulative cost = {1.1021474686322412E9 rows, 0.0 cpu, 0.0 io}, id = 1987 HiveJoinRel(condition=[=($0, $14)], joinType=[inner]): rowcount = 299.6322411714753, cumulative cost = {1.102146957E9 rows, 0.0 cpu, 0.0 io}, id = 1985 HiveJoinRel(condition=[=($3, $12)], joinType=[inner]): rowcount = 5.50076554E8, cumulative cost = {5.51997354E8 rows, 0.0 cpu, 0.0 io}, id = 1569 HiveProjectRel(ss_sold_date_sk=[$0], ss_item_sk=[$2], ss_customer_sk=[$3], ss_cdemo_sk=[$4], ss_hdemo_sk=[$5], ss_addr_sk=[$6], ss_store_sk=[$7], ss_promo_sk=[$8], ss_ticket_number=[$9], ss_wholesale_cost=[$11], ss_list_price=[$12], ss_coupon_amt=[$19]): rowcount = 5.50076554E8, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 892 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.store_sales]]): rowcount = 5.50076554E8, cumulative cost = {0}, id = 55 HiveProjectRel(cd_demo_sk=[$0], cd_marital_status=[$2]): rowcount = 1920800.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 918 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.customer_demographics]]): rowcount = 1920800.0, cumulative cost = {0}, id = 56 HiveProjectRel(d_date_sk=[$0], d_year=[$6]): rowcount = 73049.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 902 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.date_dim]]): rowcount = 73049.0, cumulative cost = {0}, id = 65 HiveProjectRel(s_store_sk=[$0], s_store_name=[$5], s_zip=[$25]): rowcount = 212.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 914 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.store]]): rowcount = 212.0, cumulative cost = {0}, id = 54 HiveJoinRel(condition=[=($6, $10)], joinType=[inner]): rowcount = 1.0, cumulative cost = {5266899.0 rows, 0.0 cpu, 0.0 io}, id = 1992 HiveJoinRel(condition=[=($7, $8)], joinType=[inner]): rowcount = 1.0, cumulative cost = {5193849.0 rows, 0.0 cpu, 0.0 io}, id = 1990 HiveJoinRel(condition=[=($3, $0)], joinType=[inner]): rowcount = 1600000.0, cumulative cost = {3520800.0 rows, 0.0 cpu, 0.0 io}, id = 1578 HiveProjectRel(cd_demo_sk=[$0], cd_marital_status=[$2]): rowcount = 1920800.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 918 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.customer_demographics]]): rowcount = 1920800.0, cumulative cost = {0}, id = 56 HiveProjectRel(c_customer_sk=[$0], c_current_cdemo_sk=[$2], c_current_hdemo_sk=[$3], c_current_addr_sk=[$4], c_first_shipto_date_sk=[$5], c_first_sales_date_sk=[$6]): rowcount = 1600000.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 898 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.customer]]): rowcount = 1600000.0, cumulative cost = {0}, id = 59 HiveProjectRel(d_date_sk=[$0], d_year=[$6]): rowcount = 73049.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 902 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.date_dim]]): rowcount = 73049.0, cumulative cost = {0}, id = 65 HiveProjectRel(d_date_sk=[$0], d_year=[$6]): rowcount = 73049.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 902 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.date_dim]]): rowcount = 73049.0, cumulative cost = {0}, id = 65 HiveProjectRel(sr_item_sk=[$2], sr_ticket_number=[$9]): rowcount = 5.5578005E7, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 894 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.store_returns]]): rowcount = 5.5578005E7, cumulative cost = {0}, id = 62 HiveProjectRel(_o__col0=[$0]): rowcount = 1.0, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 880 HiveFilterRel(condition=[&gt;($1, *(CAST(2):DOUBLE NOT NULL, $2))]): rowcount = 1.0, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 878 HiveAggregateRel(group=[{0}], agg#0=[sum($1)], agg#1=[sum($2)]): rowcount = 38846.0, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 876 HiveProjectRel($f0=[$0], $f1=[$2], $f2=[+(+($5, $6), $7)]): rowcount = 6.692553251460564E8, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 874 HiveProjectRel(cs_item_sk=[$0], cs_order_number=[$1], cs_ext_list_price=[$2], cr_item_sk=[$3], cr_order_number=[$4], cr_refunded_cash=[$5], cr_reversed_charge=[$6], cr_store_credit=[$7]): rowcount = 6.692553251460564E8, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 1132 HiveJoinRel(condition=[AND(=($0, $3), =($1, $4))], joinType=[inner]): rowcount = 6.692553251460564E8, cumulative cost = {3.15348608E8 rows, 0.0 cpu, 0.0 io}, id = 1127 HiveProjectRel(cs_item_sk=[$15], cs_order_number=[$17], cs_ext_list_price=[$25]): rowcount = 2.86549727E8, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 962 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.catalog_sales]]): rowcount = 2.86549727E8, cumulative cost = {0}, id = 45 HiveProjectRel(cr_item_sk=[$2], cr_order_number=[$16], cr_refunded_cash=[$23], cr_reversed_charge=[$24], cr_store_credit=[$25]): rowcount = 2.8798881E7, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 964 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.catalog_returns]]): rowcount = 2.8798881E7, cumulative cost = {0}, id = 46 HiveFilterRel(condition=[AND(in($2, 'maroon', 'burnished', 'dim', 'steel', 'navajo', 'chocolate'), between(false, $1, 35, +(35, 10)), between(false, $1, +(35, 1), +(35, 15)))]): rowcount = 1.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 864 HiveProjectRel(i_item_sk=[$0], i_current_price=[$5], i_color=[$17], i_product_name=[$21]): rowcount = 48000.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 862 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200.item]]): rowcount = 48000.0, cumulative cost = {0}, id = 68Physical plan STAGE PLANS: Stage: Stage-1 Tez Edges: Map 10 &lt;- Map 40 (BROADCAST_EDGE) Map 16 &lt;- Map 2 (BROADCAST_EDGE), Map 23 (BROADCAST_EDGE), Map 6 (BROADCAST_EDGE) Map 19 &lt;- Map 42 (BROADCAST_EDGE) Map 33 &lt;- Map 35 (BROADCAST_EDGE) Map 35 &lt;- Map 1 (BROADCAST_EDGE), Map 16 (BROADCAST_EDGE), Map 3 (BROADCAST_EDGE), Map 8 (BROADCAST_EDGE) Map 36 &lt;- Map 18 (BROADCAST_EDGE), Map 25 (BROADCAST_EDGE), Map 41 (BROADCAST_EDGE) Map 38 &lt;- Map 15 (BROADCAST_EDGE), Map 31 (BROADCAST_EDGE), Map 36 (BROADCAST_EDGE), Map 5 (BROADCAST_EDGE) Map 4 &lt;- Map 38 (BROADCAST_EDGE) Reducer 11 &lt;- Map 10 (SIMPLE_EDGE), Map 22 (BROADCAST_EDGE), Map 24 (BROADCAST_EDGE), Map 26 (BROADCAST_EDGE), Map 27 (BROADCAST_EDGE), Map 30 (BROADCAST_EDGE), Map 32 (BROADCAST_EDGE), Map 39 (BROADCAST_EDGE), Map 4 (BROADCAST_EDGE), Map 7 (BROADCAST_EDGE) Reducer 12 &lt;- Reducer 11 (SIMPLE_EDGE) Reducer 13 &lt;- Reducer 12 (SIMPLE_EDGE), Reducer 21 (SIMPLE_EDGE) Reducer 14 &lt;- Reducer 13 (SIMPLE_EDGE) Reducer 20 &lt;- Map 17 (BROADCAST_EDGE), Map 19 (SIMPLE_EDGE), Map 28 (BROADCAST_EDGE), Map 29 (BROADCAST_EDGE), Map 33 (BROADCAST_EDGE), Map 34 (BROADCAST_EDGE), Map 37 (BROADCAST_EDGE), Map 43 (BROADCAST_EDGE), Map 44 (BROADCAST_EDGE), Map 9 (BROADCAST_EDGE) Reducer 21 &lt;- Reducer 20 (SIMPLE_EDGE) DagName: mmokhtar_20140925174747_6fa8c67a-6d24-43cc-8fbb-3be14937b8b1:1 Vertices: Map 1 Map Operator Tree: TableScan alias: d1 filterExpr: d_date_sk is not null (type: boolean) Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: d_date_sk is not null (type: boolean) Statistics: Num rows: 36525 Data size: 40871475 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: d_date_sk (type: int), d_year (type: int) outputColumnNames: _col0, _col1 Statistics: Num rows: 36525 Data size: 40871475 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 36525 Data size: 40871475 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: int) Execution mode: vectorized Map 10 Map Operator Tree: TableScan alias: catalog_sales filterExpr: (cs_item_sk is not null and cs_order_number is not null) (type: boolean) Statistics: Num rows: 286549727 Data size: 38890158232 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (cs_item_sk is not null and cs_order_number is not null) (type: boolean) Statistics: Num rows: 71637432 Data size: 9722539591 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: cs_item_sk (type: int), cs_order_number (type: int), cs_ext_list_price (type: float) outputColumnNames: _col0, _col1, _col2 Statistics: Num rows: 71637432 Data size: 9722539591 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col0} {_col2} 1 {_col2} {_col3} {_col4} keys: 0 _col0 (type: int), _col1 (type: int) 1 _col0 (type: int), _col1 (type: int) outputColumnNames: _col0, _col2, _col5, _col6, _col7 input vertices: 1 Map 40 Statistics: Num rows: 78801176 Data size: 10694794240 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col0 (type: int), _col2 (type: float), ((_col5 + _col6) + _col7) (type: float) outputColumnNames: _col0, _col1, _col2 Statistics: Num rows: 78801176 Data size: 10694794240 Basic stats: COMPLETE Column stats: NONE Group By Operator aggregations: sum(_col1), sum(_col2) keys: _col0 (type: int) mode: hash outputColumnNames: _col0, _col1, _col2 Statistics: Num rows: 78801176 Data size: 10694794240 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 78801176 Data size: 10694794240 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: double), _col2 (type: double) Execution mode: vectorized Map 15 Map Operator Tree: TableScan alias: customer filterExpr: (((((c_current_cdemo_sk is not null and c_first_sales_date_sk is not null) and c_first_shipto_date_sk is not null) and c_customer_sk is not null) and c_current_hdemo_sk is not null) and c_current_addr_sk is not null) (type: boolean) Statistics: Num rows: 1600000 Data size: 1376033128 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (((((c_current_cdemo_sk is not null and c_first_sales_date_sk is not null) and c_first_shipto_date_sk is not null) and c_customer_sk is not null) and c_current_hdemo_sk is not null) and c_current_addr_sk is not null) (type: boolean) Statistics: Num rows: 25000 Data size: 21500517 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: c_customer_sk (type: int), c_current_cdemo_sk (type: int), c_current_hdemo_sk (type: int), c_current_addr_sk (type: int), c_first_shipto_date_sk (type: int), c_first_sales_date_sk (type: int) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5 Statistics: Num rows: 25000 Data size: 21500517 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col1 (type: int) sort order: + Map-reduce partition columns: _col1 (type: int) Statistics: Num rows: 25000 Data size: 21500517 Basic stats: COMPLETE Column stats: NONE value expressions: _col0 (type: int), _col2 (type: int), _col3 (type: int), _col4 (type: int), _col5 (type: int) Execution mode: vectorized Map 16 Map Operator Tree: TableScan alias: cd1 filterExpr: cd_demo_sk is not null (type: boolean) Statistics: Num rows: 1920800 Data size: 718379200 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: cd_demo_sk is not null (type: boolean) Statistics: Num rows: 960400 Data size: 359189600 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: cd_demo_sk (type: int), cd_marital_status (type: string) outputColumnNames: _col0, _col1 Statistics: Num rows: 960400 Data size: 359189600 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col0} {_col1} {_col2} {_col4} {_col5} {_col6} {_col7} {_col8} {_col9} {_col10} {_col11} 1 {_col1} keys: 0 _col3 (type: int) 1 _col0 (type: int) outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col13 input vertices: 0 Map 6 Statistics: Num rows: 1181805 Data size: 51579732 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col4} {_col5} {_col6} {_col7} {_col8} {_col9} {_col10} {_col11} {_col13} 1 keys: 0 _col0 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col2, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col13 input vertices: 1 Map 23 Statistics: Num rows: 1299985 Data size: 56737708 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col4} {_col5} {_col7} {_col8} {_col9} {_col10} {_col11} {_col13} 1 {_col1} {_col2} keys: 0 _col6 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col2, _col4, _col5, _col7, _col8, _col9, _col10, _col11, _col13, _col17, _col18 input vertices: 1 Map 2 Statistics: Num rows: 1429983 Data size: 62411480 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col2 (type: int) sort order: + Map-reduce partition columns: _col2 (type: int) Statistics: Num rows: 1429983 Data size: 62411480 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: int), _col4 (type: int), _col5 (type: int), _col7 (type: int), _col8 (type: int), _col9 (type: float), _col10 (type: float), _col11 (type: float), _col13 (type: string), _col17 (type: string), _col18 (type: string) Execution mode: vectorized Map 17 Map Operator Tree: TableScan alias: ib1 filterExpr: ib_income_band_sk is not null (type: boolean) Statistics: Num rows: 20 Data size: 240 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ib_income_band_sk is not null (type: boolean) Statistics: Num rows: 10 Data size: 120 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: ib_income_band_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 10 Data size: 120 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 10 Data size: 120 Basic stats: COMPLETE Column stats: NONE Execution mode: vectorized Map 18 Map Operator Tree: TableScan alias: store_sales filterExpr: ((((((((ss_cdemo_sk is not null and ss_sold_date_sk is not null) and ss_store_sk is not null) and ss_customer_sk is not null) and ss_item_sk is not null) and ss_ticket_number is not null) and ss_hdemo_sk is not null) and ss_addr_sk is not null) and ss_promo_sk is not null) (type: boolean) Statistics: Num rows: 550076554 Data size: 24008004411 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ((((((((ss_cdemo_sk is not null and ss_sold_date_sk is not null) and ss_store_sk is not null) and ss_customer_sk is not null) and ss_item_sk is not null) and ss_ticket_number is not null) and ss_hdemo_sk is not null) and ss_addr_sk is not null) and ss_promo_sk is not null) (type: boolean) Statistics: Num rows: 1074369 Data size: 46890665 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: ss_sold_date_sk (type: int), ss_item_sk (type: int), ss_customer_sk (type: int), ss_cdemo_sk (type: int), ss_hdemo_sk (type: int), ss_addr_sk (type: int), ss_store_sk (type: int), ss_promo_sk (type: int), ss_ticket_number (type: int), ss_wholesale_cost (type: float), ss_list_price (type: float), ss_coupon_amt (type: float) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11 Statistics: Num rows: 1074369 Data size: 46890665 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col3 (type: int) sort order: + Map-reduce partition columns: _col3 (type: int) Statistics: Num rows: 1074369 Data size: 46890665 Basic stats: COMPLETE Column stats: NONE value expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: int), _col8 (type: int), _col9 (type: float), _col10 (type: float), _col11 (type: float) Execution mode: vectorized Map 19 Map Operator Tree: TableScan alias: catalog_sales filterExpr: (cs_item_sk is not null and cs_order_number is not null) (type: boolean) Statistics: Num rows: 286549727 Data size: 38890158232 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (cs_item_sk is not null and cs_order_number is not null) (type: boolean) Statistics: Num rows: 71637432 Data size: 9722539591 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: cs_item_sk (type: int), cs_order_number (type: int), cs_ext_list_price (type: float) outputColumnNames: _col0, _col1, _col2 Statistics: Num rows: 71637432 Data size: 9722539591 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col0} {_col2} 1 {_col2} {_col3} {_col4} keys: 0 _col0 (type: int), _col1 (type: int) 1 _col0 (type: int), _col1 (type: int) outputColumnNames: _col0, _col2, _col5, _col6, _col7 input vertices: 1 Map 42 Statistics: Num rows: 78801176 Data size: 10694794240 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col0 (type: int), _col2 (type: float), ((_col5 + _col6) + _col7) (type: float) outputColumnNames: _col0, _col1, _col2 Statistics: Num rows: 78801176 Data size: 10694794240 Basic stats: COMPLETE Column stats: NONE Group By Operator aggregations: sum(_col1), sum(_col2) keys: _col0 (type: int) mode: hash outputColumnNames: _col0, _col1, _col2 Statistics: Num rows: 78801176 Data size: 10694794240 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 78801176 Data size: 10694794240 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: double), _col2 (type: double) Execution mode: vectorized Map 2 Map Operator Tree: TableScan alias: store filterExpr: ((s_store_sk is not null and s_store_name is not null) and s_zip is not null) (type: boolean) Statistics: Num rows: 212 Data size: 405680 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ((s_store_sk is not null and s_store_name is not null) and s_zip is not null) (type: boolean) Statistics: Num rows: 27 Data size: 51666 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: s_store_sk (type: int), s_store_name (type: string), s_zip (type: string) outputColumnNames: _col0, _col1, _col2 Statistics: Num rows: 27 Data size: 51666 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 27 Data size: 51666 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: string), _col2 (type: string) Execution mode: vectorized Map 22 Map Operator Tree: TableScan alias: ib1 filterExpr: ib_income_band_sk is not null (type: boolean) Statistics: Num rows: 20 Data size: 240 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ib_income_band_sk is not null (type: boolean) Statistics: Num rows: 10 Data size: 120 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: ib_income_band_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 10 Data size: 120 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 10 Data size: 120 Basic stats: COMPLETE Column stats: NONE Execution mode: vectorized Map 23 Map Operator Tree: TableScan alias: d1 filterExpr: (d_date_sk is not null and (d_year = 2000)) (type: boolean) Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (d_date_sk is not null and (d_year = 2000)) (type: boolean) Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: d_date_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Execution mode: vectorized Map 24 Map Operator Tree: TableScan alias: hd1 filterExpr: (hd_demo_sk is not null and hd_income_band_sk is not null) (type: boolean) Statistics: Num rows: 7200 Data size: 799 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (hd_demo_sk is not null and hd_income_band_sk is not null) (type: boolean) Statistics: Num rows: 1800 Data size: 199 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: hd_demo_sk (type: int), hd_income_band_sk (type: int) outputColumnNames: _col0, _col1 Statistics: Num rows: 1800 Data size: 199 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 1800 Data size: 199 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: int) Execution mode: vectorized Map 25 Map Operator Tree: TableScan alias: d1 filterExpr: (d_date_sk is not null and (d_year = 2001)) (type: boolean) Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (d_date_sk is not null and (d_year = 2001)) (type: boolean) Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: d_date_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 18262 Data size: 20435178 Basic stats: COMPLETE Column stats: NONE Execution mode: vectorized Map 26 Map Operator Tree: TableScan alias: promotion filterExpr: p_promo_sk is not null (type: boolean) Statistics: Num rows: 450 Data size: 530848 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: p_promo_sk is not null (type: boolean) Statistics: Num rows: 225 Data size: 265424 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: p_promo_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 225 Data size: 265424 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 225 Data size: 265424 Basic stats: COMPLETE Column stats: NONE Execution mode: vectorized Map 27 Map Operator Tree: TableScan alias: hd1 filterExpr: (hd_demo_sk is not null and hd_income_band_sk is not null) (type: boolean) Statistics: Num rows: 7200 Data size: 799 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (hd_demo_sk is not null and hd_income_band_sk is not null) (type: boolean) Statistics: Num rows: 1800 Data size: 199 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: hd_demo_sk (type: int), hd_income_band_sk (type: int) outputColumnNames: _col0, _col1 Statistics: Num rows: 1800 Data size: 199 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 1800 Data size: 199 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: int) Execution mode: vectorized Map 28 Map Operator Tree: TableScan alias: ad1 filterExpr: ca_address_sk is not null (type: boolean) Statistics: Num rows: 800000 Data size: 811903688 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ca_address_sk is not null (type: boolean) Statistics: Num rows: 400000 Data size: 405951844 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: ca_address_sk (type: int), ca_street_number (type: string), ca_street_name (type: string), ca_city (type: string), ca_zip (type: string) outputColumnNames: _col0, _col1, _col2, _col3, _col4 Statistics: Num rows: 400000 Data size: 405951844 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 400000 Data size: 405951844 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string) Execution mode: vectorized Map 29 Map Operator Tree: TableScan alias: item filterExpr: ((((i_color) IN ('maroon', 'burnished', 'dim', 'steel', 'navajo', 'chocolate') and i_current_price BETWEEN 35 AND 45) and i_current_price BETWEEN 36 AND 50) and i_item_sk is not null) (type: boolean) Statistics: Num rows: 48000 Data size: 68732712 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ((((i_color) IN ('maroon', 'burnished', 'dim', 'steel', 'navajo', 'chocolate') and i_current_price BETWEEN 35 AND 45) and i_current_price BETWEEN 36 AND 50) and i_item_sk is not null) (type: boolean) Statistics: Num rows: 3000 Data size: 4295794 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: i_item_sk (type: int), i_product_name (type: string) outputColumnNames: _col0, _col3 Statistics: Num rows: 3000 Data size: 4295794 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 3000 Data size: 4295794 Basic stats: COMPLETE Column stats: NONE value expressions: _col3 (type: string) Execution mode: vectorized Map 3 Map Operator Tree: TableScan alias: customer filterExpr: (((((c_current_cdemo_sk is not null and c_first_sales_date_sk is not null) and c_first_shipto_date_sk is not null) and c_customer_sk is not null) and c_current_hdemo_sk is not null) and c_current_addr_sk is not null) (type: boolean) Statistics: Num rows: 1600000 Data size: 1376033128 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (((((c_current_cdemo_sk is not null and c_first_sales_date_sk is not null) and c_first_shipto_date_sk is not null) and c_customer_sk is not null) and c_current_hdemo_sk is not null) and c_current_addr_sk is not null) (type: boolean) Statistics: Num rows: 25000 Data size: 21500517 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: c_customer_sk (type: int), c_current_cdemo_sk (type: int), c_current_hdemo_sk (type: int), c_current_addr_sk (type: int), c_first_shipto_date_sk (type: int), c_first_sales_date_sk (type: int) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5 Statistics: Num rows: 25000 Data size: 21500517 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col1 (type: int) sort order: + Map-reduce partition columns: _col1 (type: int) Statistics: Num rows: 25000 Data size: 21500517 Basic stats: COMPLETE Column stats: NONE value expressions: _col0 (type: int), _col2 (type: int), _col3 (type: int), _col4 (type: int), _col5 (type: int) Execution mode: vectorized Map 30 Map Operator Tree: TableScan alias: ib1 filterExpr: ib_income_band_sk is not null (type: boolean) Statistics: Num rows: 20 Data size: 240 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ib_income_band_sk is not null (type: boolean) Statistics: Num rows: 10 Data size: 120 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: ib_income_band_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 10 Data size: 120 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 10 Data size: 120 Basic stats: COMPLETE Column stats: NONE Execution mode: vectorized Map 31 Map Operator Tree: TableScan alias: d1 filterExpr: d_date_sk is not null (type: boolean) Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: d_date_sk is not null (type: boolean) Statistics: Num rows: 36525 Data size: 40871475 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: d_date_sk (type: int), d_year (type: int) outputColumnNames: _col0, _col1 Statistics: Num rows: 36525 Data size: 40871475 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 36525 Data size: 40871475 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: int) Execution mode: vectorized Map 32 Map Operator Tree: TableScan alias: ad1 filterExpr: ca_address_sk is not null (type: boolean) Statistics: Num rows: 800000 Data size: 811903688 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ca_address_sk is not null (type: boolean) Statistics: Num rows: 400000 Data size: 405951844 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: ca_address_sk (type: int), ca_street_number (type: string), ca_street_name (type: string), ca_city (type: string), ca_zip (type: string) outputColumnNames: _col0, _col1, _col2, _col3, _col4 Statistics: Num rows: 400000 Data size: 405951844 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 400000 Data size: 405951844 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string) Execution mode: vectorized Map 33 Map Operator Tree: TableScan alias: store_returns filterExpr: (sr_item_sk is not null and sr_ticket_number is not null) (type: boolean) Statistics: Num rows: 55578005 Data size: 4377627636 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (sr_item_sk is not null and sr_ticket_number is not null) (type: boolean) Statistics: Num rows: 13894502 Data size: 1094406968 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: sr_item_sk (type: int), sr_ticket_number (type: int) outputColumnNames: _col0, _col1 Statistics: Num rows: 13894502 Data size: 1094406968 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col4} {_col5} {_col7} {_col9} {_col10} {_col11} {_col13} {_col17} {_col18} {_col20} {_col23} {_col24} {_col28} {_col30} 1 keys: 0 _col1 (type: int), _col8 (type: int) 1 _col0 (type: int), _col1 (type: int) outputColumnNames: _col1, _col4, _col5, _col7, _col9, _col10, _col11, _col13, _col17, _col18, _col20, _col23, _col24, _col28, _col30 input vertices: 0 Map 35 Statistics: Num rows: 15283953 Data size: 1203847680 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (_col13 &lt;&gt; _col20) (type: boolean) Statistics: Num rows: 15283953 Data size: 1203847680 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: int), _col10 (type: float), _col11 (type: float), _col23 (type: int), _col24 (type: int), 2000 (type: int), _col28 (type: int), _col30 (type: int), _col17 (type: string), _col18 (type: string), _col4 (type: int), _col5 (type: int), _col7 (type: int), _col9 (type: float) outputColumnNames: _col1, _col10, _col11, _col16, _col17, _col21, _col23, _col25, _col27, _col28, _col4, _col5, _col7, _col9 Statistics: Num rows: 15283953 Data size: 1203847680 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col1 (type: int) sort order: + Map-reduce partition columns: _col1 (type: int) Statistics: Num rows: 15283953 Data size: 1203847680 Basic stats: COMPLETE Column stats: NONE value expressions: _col4 (type: int), _col5 (type: int), _col7 (type: int), _col9 (type: float), _col10 (type: float), _col11 (type: float), _col16 (type: int), _col17 (type: int), _col21 (type: int), _col23 (type: int), _col25 (type: int), _col27 (type: string), _col28 (type: string) Execution mode: vectorized Map 34 Map Operator Tree: TableScan alias: promotion filterExpr: p_promo_sk is not null (type: boolean) Statistics: Num rows: 450 Data size: 530848 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: p_promo_sk is not null (type: boolean) Statistics: Num rows: 225 Data size: 265424 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: p_promo_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 225 Data size: 265424 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 225 Data size: 265424 Basic stats: COMPLETE Column stats: NONE Execution mode: vectorized Map 35 Map Operator Tree: TableScan alias: cd1 filterExpr: cd_demo_sk is not null (type: boolean) Statistics: Num rows: 1920800 Data size: 718379200 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: cd_demo_sk is not null (type: boolean) Statistics: Num rows: 960400 Data size: 359189600 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: cd_demo_sk (type: int), cd_marital_status (type: string) outputColumnNames: _col0, _col1 Statistics: Num rows: 960400 Data size: 359189600 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} 1 {_col0} {_col2} {_col3} {_col4} {_col5} keys: 0 _col0 (type: int) 1 _col1 (type: int) outputColumnNames: _col1, _col2, _col4, _col5, _col6, _col7 input vertices: 1 Map 3 Statistics: Num rows: 1056440 Data size: 395108576 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col4} {_col5} {_col6} 1 {_col1} keys: 0 _col7 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col2, _col4, _col5, _col6, _col9 input vertices: 1 Map 8 Statistics: Num rows: 1162084 Data size: 434619456 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col4} {_col5} {_col9} 1 {_col1} keys: 0 _col6 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col2, _col4, _col5, _col9, _col11 input vertices: 1 Map 1 Statistics: Num rows: 1278292 Data size: 478081408 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: string), _col11 (type: int), _col2 (type: int), _col4 (type: int), _col5 (type: int), _col9 (type: int) outputColumnNames: _col1, _col11, _col2, _col4, _col5, _col9 Statistics: Num rows: 1278292 Data size: 478081408 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col4} {_col5} {_col7} {_col8} {_col9} {_col10} {_col11} {_col13} {_col17} {_col18} 1 {_col1} {_col4} {_col5} {_col9} {_col11} keys: 0 _col2 (type: int) 1 _col2 (type: int) outputColumnNames: _col1, _col4, _col5, _col7, _col8, _col9, _col10, _col11, _col13, _col17, _col18, _col20, _col23, _col24, _col28, _col30 input vertices: 0 Map 16 Statistics: Num rows: 1572981 Data size: 68652632 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col1 (type: int), _col8 (type: int) sort order: ++ Map-reduce partition columns: _col1 (type: int), _col8 (type: int) Statistics: Num rows: 1572981 Data size: 68652632 Basic stats: COMPLETE Column stats: NONE value expressions: _col4 (type: int), _col5 (type: int), _col7 (type: int), _col9 (type: float), _col10 (type: float), _col11 (type: float), _col13 (type: string), _col17 (type: string), _col18 (type: string), _col20 (type: string), _col23 (type: int), _col24 (type: int), _col28 (type: int), _col30 (type: int) Execution mode: vectorized Map 36 Map Operator Tree: TableScan alias: cd1 filterExpr: cd_demo_sk is not null (type: boolean) Statistics: Num rows: 1920800 Data size: 718379200 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: cd_demo_sk is not null (type: boolean) Statistics: Num rows: 960400 Data size: 359189600 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: cd_demo_sk (type: int), cd_marital_status (type: string) outputColumnNames: _col0, _col1 Statistics: Num rows: 960400 Data size: 359189600 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col0} {_col1} {_col2} {_col4} {_col5} {_col6} {_col7} {_col8} {_col9} {_col10} {_col11} 1 {_col1} keys: 0 _col3 (type: int) 1 _col0 (type: int) outputColumnNames: _col0, _col1, _col2, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col13 input vertices: 0 Map 18 Statistics: Num rows: 1181805 Data size: 51579732 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col4} {_col5} {_col6} {_col7} {_col8} {_col9} {_col10} {_col11} {_col13} 1 keys: 0 _col0 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col2, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col13 input vertices: 1 Map 25 Statistics: Num rows: 1299985 Data size: 56737708 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col4} {_col5} {_col7} {_col8} {_col9} {_col10} {_col11} {_col13} 1 {_col1} {_col2} keys: 0 _col6 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col2, _col4, _col5, _col7, _col8, _col9, _col10, _col11, _col13, _col17, _col18 input vertices: 1 Map 41 Statistics: Num rows: 1429983 Data size: 62411480 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col2 (type: int) sort order: + Map-reduce partition columns: _col2 (type: int) Statistics: Num rows: 1429983 Data size: 62411480 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: int), _col4 (type: int), _col5 (type: int), _col7 (type: int), _col8 (type: int), _col9 (type: float), _col10 (type: float), _col11 (type: float), _col13 (type: string), _col17 (type: string), _col18 (type: string) Execution mode: vectorized Map 37 Map Operator Tree: TableScan alias: ib1 filterExpr: ib_income_band_sk is not null (type: boolean) Statistics: Num rows: 20 Data size: 240 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ib_income_band_sk is not null (type: boolean) Statistics: Num rows: 10 Data size: 120 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: ib_income_band_sk (type: int) outputColumnNames: _col0 Statistics: Num rows: 10 Data size: 120 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 10 Data size: 120 Basic stats: COMPLETE Column stats: NONE Execution mode: vectorized Map 38 Map Operator Tree: TableScan alias: cd1 filterExpr: cd_demo_sk is not null (type: boolean) Statistics: Num rows: 1920800 Data size: 718379200 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: cd_demo_sk is not null (type: boolean) Statistics: Num rows: 960400 Data size: 359189600 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: cd_demo_sk (type: int), cd_marital_status (type: string) outputColumnNames: _col0, _col1 Statistics: Num rows: 960400 Data size: 359189600 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} 1 {_col0} {_col2} {_col3} {_col4} {_col5} keys: 0 _col0 (type: int) 1 _col1 (type: int) outputColumnNames: _col1, _col2, _col4, _col5, _col6, _col7 input vertices: 1 Map 15 Statistics: Num rows: 1056440 Data size: 395108576 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col4} {_col5} {_col6} 1 {_col1} keys: 0 _col7 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col2, _col4, _col5, _col6, _col9 input vertices: 1 Map 31 Statistics: Num rows: 1162084 Data size: 434619456 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col4} {_col5} {_col9} 1 {_col1} keys: 0 _col6 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col2, _col4, _col5, _col9, _col11 input vertices: 1 Map 5 Statistics: Num rows: 1278292 Data size: 478081408 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: string), _col11 (type: int), _col2 (type: int), _col4 (type: int), _col5 (type: int), _col9 (type: int) outputColumnNames: _col1, _col11, _col2, _col4, _col5, _col9 Statistics: Num rows: 1278292 Data size: 478081408 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col4} {_col5} {_col7} {_col8} {_col9} {_col10} {_col11} {_col13} {_col17} {_col18} 1 {_col1} {_col4} {_col5} {_col9} {_col11} keys: 0 _col2 (type: int) 1 _col2 (type: int) outputColumnNames: _col1, _col4, _col5, _col7, _col8, _col9, _col10, _col11, _col13, _col17, _col18, _col20, _col23, _col24, _col28, _col30 input vertices: 0 Map 36 Statistics: Num rows: 1572981 Data size: 68652632 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col1 (type: int), _col8 (type: int) sort order: ++ Map-reduce partition columns: _col1 (type: int), _col8 (type: int) Statistics: Num rows: 1572981 Data size: 68652632 Basic stats: COMPLETE Column stats: NONE value expressions: _col4 (type: int), _col5 (type: int), _col7 (type: int), _col9 (type: float), _col10 (type: float), _col11 (type: float), _col13 (type: string), _col17 (type: string), _col18 (type: string), _col20 (type: string), _col23 (type: int), _col24 (type: int), _col28 (type: int), _col30 (type: int) Execution mode: vectorized Map 39 Map Operator Tree: TableScan alias: item filterExpr: ((((i_color) IN ('maroon', 'burnished', 'dim', 'steel', 'navajo', 'chocolate') and i_current_price BETWEEN 35 AND 45) and i_current_price BETWEEN 36 AND 50) and i_item_sk is not null) (type: boolean) Statistics: Num rows: 48000 Data size: 68732712 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ((((i_color) IN ('maroon', 'burnished', 'dim', 'steel', 'navajo', 'chocolate') and i_current_price BETWEEN 35 AND 45) and i_current_price BETWEEN 36 AND 50) and i_item_sk is not null) (type: boolean) Statistics: Num rows: 3000 Data size: 4295794 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: i_item_sk (type: int), i_product_name (type: string) outputColumnNames: _col0, _col3 Statistics: Num rows: 3000 Data size: 4295794 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 3000 Data size: 4295794 Basic stats: COMPLETE Column stats: NONE value expressions: _col3 (type: string) Execution mode: vectorized Map 4 Map Operator Tree: TableScan alias: store_returns filterExpr: (sr_item_sk is not null and sr_ticket_number is not null) (type: boolean) Statistics: Num rows: 55578005 Data size: 4377627636 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (sr_item_sk is not null and sr_ticket_number is not null) (type: boolean) Statistics: Num rows: 13894502 Data size: 1094406968 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: sr_item_sk (type: int), sr_ticket_number (type: int) outputColumnNames: _col0, _col1 Statistics: Num rows: 13894502 Data size: 1094406968 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col4} {_col5} {_col7} {_col9} {_col10} {_col11} {_col13} {_col17} {_col18} {_col20} {_col23} {_col24} {_col28} {_col30} 1 keys: 0 _col1 (type: int), _col8 (type: int) 1 _col0 (type: int), _col1 (type: int) outputColumnNames: _col1, _col4, _col5, _col7, _col9, _col10, _col11, _col13, _col17, _col18, _col20, _col23, _col24, _col28, _col30 input vertices: 0 Map 38 Statistics: Num rows: 15283953 Data size: 1203847680 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (_col13 &lt;&gt; _col20) (type: boolean) Statistics: Num rows: 15283953 Data size: 1203847680 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: int), _col10 (type: float), _col11 (type: float), _col23 (type: int), _col24 (type: int), 2001 (type: int), _col28 (type: int), _col30 (type: int), _col17 (type: string), _col18 (type: string), _col4 (type: int), _col5 (type: int), _col7 (type: int), _col9 (type: float) outputColumnNames: _col1, _col10, _col11, _col16, _col17, _col21, _col23, _col25, _col27, _col28, _col4, _col5, _col7, _col9 Statistics: Num rows: 15283953 Data size: 1203847680 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col1 (type: int) sort order: + Map-reduce partition columns: _col1 (type: int) Statistics: Num rows: 15283953 Data size: 1203847680 Basic stats: COMPLETE Column stats: NONE value expressions: _col4 (type: int), _col5 (type: int), _col7 (type: int), _col9 (type: float), _col10 (type: float), _col11 (type: float), _col16 (type: int), _col17 (type: int), _col21 (type: int), _col23 (type: int), _col25 (type: int), _col27 (type: string), _col28 (type: string) Execution mode: vectorized Map 40 Map Operator Tree: TableScan alias: catalog_returns filterExpr: (cr_item_sk is not null and cr_order_number is not null) (type: boolean) Statistics: Num rows: 28798881 Data size: 3057234680 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (cr_item_sk is not null and cr_order_number is not null) (type: boolean) Statistics: Num rows: 7199721 Data size: 764308749 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: cr_item_sk (type: int), cr_order_number (type: int), cr_refunded_cash (type: float), cr_reversed_charge (type: float), cr_store_credit (type: float) outputColumnNames: _col0, _col1, _col2, _col3, _col4 Statistics: Num rows: 7199721 Data size: 764308749 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int), _col1 (type: int) sort order: ++ Map-reduce partition columns: _col0 (type: int), _col1 (type: int) Statistics: Num rows: 7199721 Data size: 764308749 Basic stats: COMPLETE Column stats: NONE value expressions: _col2 (type: float), _col3 (type: float), _col4 (type: float) Execution mode: vectorized Map 41 Map Operator Tree: TableScan alias: store filterExpr: ((s_store_sk is not null and s_store_name is not null) and s_zip is not null) (type: boolean) Statistics: Num rows: 212 Data size: 405680 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ((s_store_sk is not null and s_store_name is not null) and s_zip is not null) (type: boolean) Statistics: Num rows: 27 Data size: 51666 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: s_store_sk (type: int), s_store_name (type: string), s_zip (type: string) outputColumnNames: _col0, _col1, _col2 Statistics: Num rows: 27 Data size: 51666 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 27 Data size: 51666 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: string), _col2 (type: string) Execution mode: vectorized Map 42 Map Operator Tree: TableScan alias: catalog_returns filterExpr: (cr_item_sk is not null and cr_order_number is not null) (type: boolean) Statistics: Num rows: 28798881 Data size: 3057234680 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (cr_item_sk is not null and cr_order_number is not null) (type: boolean) Statistics: Num rows: 7199721 Data size: 764308749 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: cr_item_sk (type: int), cr_order_number (type: int), cr_refunded_cash (type: float), cr_reversed_charge (type: float), cr_store_credit (type: float) outputColumnNames: _col0, _col1, _col2, _col3, _col4 Statistics: Num rows: 7199721 Data size: 764308749 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int), _col1 (type: int) sort order: ++ Map-reduce partition columns: _col0 (type: int), _col1 (type: int) Statistics: Num rows: 7199721 Data size: 764308749 Basic stats: COMPLETE Column stats: NONE value expressions: _col2 (type: float), _col3 (type: float), _col4 (type: float) Execution mode: vectorized Map 43 Map Operator Tree: TableScan alias: ad1 filterExpr: ca_address_sk is not null (type: boolean) Statistics: Num rows: 800000 Data size: 811903688 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ca_address_sk is not null (type: boolean) Statistics: Num rows: 400000 Data size: 405951844 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: ca_address_sk (type: int), ca_street_number (type: string), ca_street_name (type: string), ca_city (type: string), ca_zip (type: string) outputColumnNames: _col0, _col1, _col2, _col3, _col4 Statistics: Num rows: 400000 Data size: 405951844 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 400000 Data size: 405951844 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string) Execution mode: vectorized Map 44 Map Operator Tree: TableScan alias: hd1 filterExpr: (hd_demo_sk is not null and hd_income_band_sk is not null) (type: boolean) Statistics: Num rows: 7200 Data size: 799 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (hd_demo_sk is not null and hd_income_band_sk is not null) (type: boolean) Statistics: Num rows: 1800 Data size: 199 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: hd_demo_sk (type: int), hd_income_band_sk (type: int) outputColumnNames: _col0, _col1 Statistics: Num rows: 1800 Data size: 199 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 1800 Data size: 199 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: int) Execution mode: vectorized Map 5 Map Operator Tree: TableScan alias: d1 filterExpr: d_date_sk is not null (type: boolean) Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: d_date_sk is not null (type: boolean) Statistics: Num rows: 36525 Data size: 40871475 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: d_date_sk (type: int), d_year (type: int) outputColumnNames: _col0, _col1 Statistics: Num rows: 36525 Data size: 40871475 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 36525 Data size: 40871475 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: int) Execution mode: vectorized Map 6 Map Operator Tree: TableScan alias: store_sales filterExpr: ((((((((ss_cdemo_sk is not null and ss_sold_date_sk is not null) and ss_store_sk is not null) and ss_customer_sk is not null) and ss_item_sk is not null) and ss_ticket_number is not null) and ss_hdemo_sk is not null) and ss_addr_sk is not null) and ss_promo_sk is not null) (type: boolean) Statistics: Num rows: 550076554 Data size: 24008004411 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ((((((((ss_cdemo_sk is not null and ss_sold_date_sk is not null) and ss_store_sk is not null) and ss_customer_sk is not null) and ss_item_sk is not null) and ss_ticket_number is not null) and ss_hdemo_sk is not null) and ss_addr_sk is not null) and ss_promo_sk is not null) (type: boolean) Statistics: Num rows: 1074369 Data size: 46890665 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: ss_sold_date_sk (type: int), ss_item_sk (type: int), ss_customer_sk (type: int), ss_cdemo_sk (type: int), ss_hdemo_sk (type: int), ss_addr_sk (type: int), ss_store_sk (type: int), ss_promo_sk (type: int), ss_ticket_number (type: int), ss_wholesale_cost (type: float), ss_list_price (type: float), ss_coupon_amt (type: float) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11 Statistics: Num rows: 1074369 Data size: 46890665 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col3 (type: int) sort order: + Map-reduce partition columns: _col3 (type: int) Statistics: Num rows: 1074369 Data size: 46890665 Basic stats: COMPLETE Column stats: NONE value expressions: _col0 (type: int), _col1 (type: int), _col2 (type: int), _col4 (type: int), _col5 (type: int), _col6 (type: int), _col7 (type: int), _col8 (type: int), _col9 (type: float), _col10 (type: float), _col11 (type: float) Execution mode: vectorized Map 7 Map Operator Tree: TableScan alias: ad1 filterExpr: ca_address_sk is not null (type: boolean) Statistics: Num rows: 800000 Data size: 811903688 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: ca_address_sk is not null (type: boolean) Statistics: Num rows: 400000 Data size: 405951844 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: ca_address_sk (type: int), ca_street_number (type: string), ca_street_name (type: string), ca_city (type: string), ca_zip (type: string) outputColumnNames: _col0, _col1, _col2, _col3, _col4 Statistics: Num rows: 400000 Data size: 405951844 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 400000 Data size: 405951844 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string) Execution mode: vectorized Map 8 Map Operator Tree: TableScan alias: d1 filterExpr: d_date_sk is not null (type: boolean) Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: d_date_sk is not null (type: boolean) Statistics: Num rows: 36525 Data size: 40871475 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: d_date_sk (type: int), d_year (type: int) outputColumnNames: _col0, _col1 Statistics: Num rows: 36525 Data size: 40871475 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 36525 Data size: 40871475 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: int) Execution mode: vectorized Map 9 Map Operator Tree: TableScan alias: hd1 filterExpr: (hd_demo_sk is not null and hd_income_band_sk is not null) (type: boolean) Statistics: Num rows: 7200 Data size: 799 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (hd_demo_sk is not null and hd_income_band_sk is not null) (type: boolean) Statistics: Num rows: 1800 Data size: 199 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: hd_demo_sk (type: int), hd_income_band_sk (type: int) outputColumnNames: _col0, _col1 Statistics: Num rows: 1800 Data size: 199 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 1800 Data size: 199 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: int) Execution mode: vectorized Reducer 11 Reduce Operator Tree: Group By Operator aggregations: sum(VALUE._col0), sum(VALUE._col1) keys: KEY._col0 (type: int) mode: mergepartial outputColumnNames: _col0, _col1, _col2 Statistics: Num rows: 39400588 Data size: 5347397120 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (_col1 &gt; (UDFToDouble(2) * _col2)) (type: boolean) Statistics: Num rows: 13133529 Data size: 1782465661 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col0 (type: int) outputColumnNames: _col0 Statistics: Num rows: 13133529 Data size: 1782465661 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col4} {_col5} {_col7} {_col9} {_col10} {_col11} {_col16} {_col17} {_col21} {_col23} {_col25} {_col27} {_col28} 1 keys: 0 _col1 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col4, _col5, _col7, _col9, _col10, _col11, _col16, _col17, _col21, _col23, _col25, _col27, _col28 input vertices: 0 Map 4 Statistics: Num rows: 16812348 Data size: 1324232448 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: int), _col10 (type: float), _col11 (type: float), _col16 (type: int), _col17 (type: int), _col21 (type: int), _col23 (type: int), _col25 (type: int), _col27 (type: string), _col28 (type: string), _col4 (type: int), _col5 (type: int), _col7 (type: int), _col9 (type: float) outputColumnNames: _col1, _col10, _col11, _col16, _col17, _col21, _col23, _col25, _col27, _col28, _col4, _col5, _col7, _col9 Statistics: Num rows: 16812348 Data size: 1324232448 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} 1 {_col1} {_col5} {_col7} {_col9} {_col10} {_col11} {_col16} {_col17} {_col21} {_col23} {_col25} {_col27} {_col28} keys: 0 _col0 (type: int) 1 _col4 (type: int) outputColumnNames: _col1, _col3, _col7, _col9, _col11, _col12, _col13, _col18, _col19, _col23, _col25, _col27, _col29, _col30 input vertices: 0 Map 24 Statistics: Num rows: 18493584 Data size: 1456655744 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: int), _col11 (type: float), _col12 (type: float), _col13 (type: float), _col18 (type: int), _col19 (type: int), _col23 (type: int), _col25 (type: int), _col27 (type: int), _col29 (type: string), _col3 (type: int), _col30 (type: string), _col7 (type: int), _col9 (type: int) outputColumnNames: _col1, _col11, _col12, _col13, _col18, _col19, _col23, _col25, _col27, _col29, _col3, _col30, _col7, _col9 Statistics: Num rows: 18493584 Data size: 1456655744 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} 1 {_col1} {_col3} {_col7} {_col9} {_col11} {_col12} {_col13} {_col19} {_col23} {_col25} {_col27} {_col29} {_col30} keys: 0 _col0 (type: int) 1 _col18 (type: int) outputColumnNames: _col1, _col3, _col5, _col9, _col11, _col13, _col14, _col15, _col21, _col25, _col27, _col29, _col31, _col32 input vertices: 0 Map 27 Statistics: Num rows: 20342942 Data size: 1602321408 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col3} {_col9} {_col11} {_col13} {_col14} {_col15} {_col21} {_col25} {_col27} {_col29} {_col31} {_col32} 1 {_col0} {_col3} keys: 0 _col5 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col3, _col9, _col11, _col13, _col14, _col15, _col21, _col25, _col27, _col29, _col31, _col32, _col38, _col41 input vertices: 1 Map 39 Statistics: Num rows: 22377236 Data size: 1762553600 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: int), _col11 (type: int), _col13 (type: float), _col14 (type: float), _col15 (type: float), _col21 (type: int), _col25 (type: int), _col27 (type: int), _col29 (type: int), _col3 (type: int), _col31 (type: string), _col32 (type: string), _col38 (type: int), _col41 (type: string), _col9 (type: int) outputColumnNames: _col1, _col11, _col13, _col14, _col15, _col21, _col25, _col27, _col29, _col3, _col31, _col32, _col38, _col41, _col9 Statistics: Num rows: 22377236 Data size: 1762553600 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 1 {_col1} {_col9} {_col11} {_col13} {_col14} {_col15} {_col21} {_col25} {_col27} {_col29} {_col31} {_col32} {_col38} {_col41} keys: 0 _col0 (type: int) 1 _col3 (type: int) outputColumnNames: _col2, _col10, _col12, _col14, _col15, _col16, _col22, _col26, _col28, _col30, _col32, _col33, _col39, _col42 input vertices: 0 Map 22 Statistics: Num rows: 24614960 Data size: 1938808960 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col10 (type: int), _col12 (type: int), _col14 (type: float), _col15 (type: float), _col16 (type: float), _col2 (type: int), _col22 (type: int), _col26 (type: int), _col28 (type: int), _col30 (type: int), _col32 (type: string), _col33 (type: string), _col39 (type: int), _col42 (type: string) outputColumnNames: _col10, _col12, _col14, _col15, _col16, _col2, _col22, _col26, _col28, _col30, _col32, _col33, _col39, _col42 Statistics: Num rows: 24614960 Data size: 1938808960 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 1 {_col10} {_col12} {_col14} {_col15} {_col16} {_col22} {_col26} {_col28} {_col30} {_col32} {_col33} {_col39} {_col42} keys: 0 _col0 (type: int) 1 _col2 (type: int) outputColumnNames: _col11, _col13, _col15, _col16, _col17, _col23, _col27, _col29, _col31, _col33, _col34, _col40, _col43 input vertices: 0 Map 30 Statistics: Num rows: 27076456 Data size: 2132689920 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col11 (type: int), _col13 (type: int), _col15 (type: float), _col16 (type: float), _col17 (type: float), _col23 (type: int), _col27 (type: int), _col29 (type: int), _col31 (type: int), _col33 (type: string), _col34 (type: string), _col40 (type: int), _col43 (type: string) outputColumnNames: _col11, _col13, _col15, _col16, _col17, _col23, _col27, _col29, _col31, _col33, _col34, _col40, _col43 Statistics: Num rows: 27076456 Data size: 2132689920 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col3} {_col4} 1 {_col13} {_col15} {_col16} {_col17} {_col23} {_col27} {_col29} {_col31} {_col33} {_col34} {_col40} {_col43} keys: 0 _col0 (type: int) 1 _col11 (type: int) outputColumnNames: _col1, _col2, _col3, _col4, _col18, _col20, _col21, _col22, _col28, _col32, _col34, _col36, _col38, _col39, _col45, _col48 input vertices: 0 Map 32 Statistics: Num rows: 29784102 Data size: 2345958912 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: string), _col18 (type: int), _col2 (type: string), _col20 (type: float), _col21 (type: float), _col22 (type: float), _col28 (type: int), _col3 (type: string), _col32 (type: int), _col34 (type: int), _col36 (type: int), _col38 (type: string), _col39 (type: string), _col4 (type: string), _col45 (type: int), _col48 (type: string) outputColumnNames: _col1, _col18, _col2, _col20, _col21, _col22, _col28, _col3, _col32, _col34, _col36, _col38, _col39, _col4, _col45, _col48 Statistics: Num rows: 29784102 Data size: 2345958912 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col3} {_col4} 1 {_col1} {_col2} {_col3} {_col4} {_col18} {_col20} {_col21} {_col22} {_col32} {_col34} {_col36} {_col38} {_col39} {_col45} {_col48} keys: 0 _col0 (type: int) 1 _col28 (type: int) outputColumnNames: _col1, _col2, _col3, _col4, _col6, _col7, _col8, _col9, _col23, _col25, _col26, _col27, _col37, _col39, _col41, _col43, _col44, _col50, _col53 input vertices: 0 Map 7 Statistics: Num rows: 32762512 Data size: 2580554752 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: string), _col2 (type: string), _col23 (type: int), _col25 (type: float), _col26 (type: float), _col27 (type: float), _col3 (type: string), _col37 (type: int), _col39 (type: int), _col4 (type: string), _col41 (type: int), _col43 (type: string), _col44 (type: string), _col50 (type: int), _col53 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string) outputColumnNames: _col1, _col2, _col23, _col25, _col26, _col27, _col3, _col37, _col39, _col4, _col41, _col43, _col44, _col50, _col53, _col6, _col7, _col8, _col9 Statistics: Num rows: 32762512 Data size: 2580554752 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 1 {_col1} {_col2} {_col3} {_col4} {_col6} {_col7} {_col8} {_col9} {_col25} {_col26} {_col27} {_col37} {_col39} {_col41} {_col43} {_col44} {_col50} {_col53} keys: 0 _col0 (type: int) 1 _col23 (type: int) outputColumnNames: _col2, _col3, _col4, _col5, _col7, _col8, _col9, _col10, _col26, _col27, _col28, _col38, _col40, _col42, _col44, _col45, _col51, _col54 input vertices: 0 Map 26 Statistics: Num rows: 36038764 Data size: 2838610176 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col54 (type: string), _col51 (type: int), _col44 (type: string), _col45 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string), _col10 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col38 (type: int), _col40 (type: int), _col42 (type: int), _col26 (type: float), _col27 (type: float), _col28 (type: float) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17 Statistics: Num rows: 36038764 Data size: 2838610176 Basic stats: COMPLETE Column stats: NONE Group By Operator aggregations: count(), sum(_col15), sum(_col16), sum(_col17) keys: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string), _col10 (type: string), _col11 (type: string), _col12 (type: int), _col13 (type: int), _col14 (type: int) mode: hash outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18 Statistics: Num rows: 36038764 Data size: 2838610176 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string), _col10 (type: string), _col11 (type: string), _col12 (type: int), _col13 (type: int), _col14 (type: int) sort order: +++++++++++++++ Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string), _col10 (type: string), _col11 (type: string), _col12 (type: int), _col13 (type: int), _col14 (type: int) Statistics: Num rows: 36038764 Data size: 2838610176 Basic stats: COMPLETE Column stats: NONE value expressions: _col15 (type: bigint), _col16 (type: double), _col17 (type: double), _col18 (type: double) Reducer 12 Reduce Operator Tree: Group By Operator aggregations: count(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2), sum(VALUE._col3) keys: KEY._col0 (type: string), KEY._col1 (type: int), KEY._col2 (type: string), KEY._col3 (type: string), KEY._col4 (type: string), KEY._col5 (type: string), KEY._col6 (type: string), KEY._col7 (type: string), KEY._col8 (type: string), KEY._col9 (type: string), KEY._col10 (type: string), KEY._col11 (type: string), KEY._col12 (type: int), KEY._col13 (type: int), KEY._col14 (type: int) mode: mergepartial outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18 Statistics: Num rows: 18019382 Data size: 1419305088 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: int), _col2 (type: string), _col3 (type: string), _col12 (type: int), _col15 (type: bigint), _col16 (type: double), _col17 (type: double), _col18 (type: double) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7 Statistics: Num rows: 18019382 Data size: 1419305088 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: int), _col1 (type: string), _col2 (type: string) sort order: +++ Map-reduce partition columns: _col0 (type: int), _col1 (type: string), _col2 (type: string) Statistics: Num rows: 18019382 Data size: 1419305088 Basic stats: COMPLETE Column stats: NONE value expressions: _col3 (type: int), _col4 (type: bigint), _col5 (type: double), _col6 (type: double), _col7 (type: double) Execution mode: vectorized Reducer 13 Reduce Operator Tree: Merge Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {VALUE._col0} {KEY.reducesinkkey1} {KEY.reducesinkkey2} {VALUE._col1} {VALUE._col2} {VALUE._col3} {VALUE._col4} {VALUE._col5} {VALUE._col6} {VALUE._col7} {VALUE._col8} {VALUE._col9} {VALUE._col10} {VALUE._col11} {VALUE._col12} {VALUE._col13} 1 {VALUE._col0} {VALUE._col1} {VALUE._col2} {VALUE._col3} {VALUE._col4} outputColumnNames: _col0, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col20, _col21, _col22, _col23, _col24 Statistics: Num rows: 19821320 Data size: 1561235584 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (_col21 &lt;= _col13) (type: boolean) Statistics: Num rows: 6607106 Data size: 520411808 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col0 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string), _col10 (type: string), _col11 (type: string), _col12 (type: int), _col13 (type: bigint), _col14 (type: double), _col15 (type: double), _col16 (type: double), _col22 (type: double), _col23 (type: double), _col24 (type: double), _col20 (type: int), _col21 (type: bigint) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20 Statistics: Num rows: 6607106 Data size: 520411808 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: string), _col1 (type: string), _col20 (type: bigint) sort order: +++ Statistics: Num rows: 6607106 Data size: 520411808 Basic stats: COMPLETE Column stats: NONE value expressions: _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string), _col10 (type: string), _col11 (type: int), _col12 (type: bigint), _col13 (type: double), _col14 (type: double), _col15 (type: double), _col16 (type: double), _col17 (type: double), _col18 (type: double), _col19 (type: int) Reducer 14 Reduce Operator Tree: Select Operator expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: string), VALUE._col1 (type: string), VALUE._col2 (type: string), VALUE._col3 (type: string), VALUE._col4 (type: string), VALUE._col5 (type: string), VALUE._col6 (type: string), VALUE._col7 (type: string), VALUE._col8 (type: string), VALUE._col9 (type: int), VALUE._col10 (type: bigint), VALUE._col11 (type: double), VALUE._col12 (type: double), VALUE._col13 (type: double), VALUE._col14 (type: double), VALUE._col15 (type: double), VALUE._col16 (type: double), VALUE._col17 (type: int), KEY.reducesinkkey2 (type: bigint) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18, _col19, _col20 Statistics: Num rows: 6607106 Data size: 520411808 Basic stats: COMPLETE Column stats: NONE File Output Operator compressed: false Statistics: Num rows: 6607106 Data size: 520411808 Basic stats: COMPLETE Column stats: NONE table: input format: org.apache.hadoop.mapred.TextInputFormat output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe Execution mode: vectorized Reducer 20 Reduce Operator Tree: Group By Operator aggregations: sum(VALUE._col0), sum(VALUE._col1) keys: KEY._col0 (type: int) mode: mergepartial outputColumnNames: _col0, _col1, _col2 Statistics: Num rows: 39400588 Data size: 5347397120 Basic stats: COMPLETE Column stats: NONE Filter Operator predicate: (_col1 &gt; (UDFToDouble(2) * _col2)) (type: boolean) Statistics: Num rows: 13133529 Data size: 1782465661 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col0 (type: int) outputColumnNames: _col0 Statistics: Num rows: 13133529 Data size: 1782465661 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col4} {_col5} {_col7} {_col9} {_col10} {_col11} {_col16} {_col17} {_col21} {_col23} {_col25} {_col27} {_col28} 1 keys: 0 _col1 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col4, _col5, _col7, _col9, _col10, _col11, _col16, _col17, _col21, _col23, _col25, _col27, _col28 input vertices: 0 Map 33 Statistics: Num rows: 16812348 Data size: 1324232448 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: int), _col10 (type: float), _col11 (type: float), _col16 (type: int), _col17 (type: int), _col21 (type: int), _col23 (type: int), _col25 (type: int), _col27 (type: string), _col28 (type: string), _col4 (type: int), _col5 (type: int), _col7 (type: int), _col9 (type: float) outputColumnNames: _col1, _col10, _col11, _col16, _col17, _col21, _col23, _col25, _col27, _col28, _col4, _col5, _col7, _col9 Statistics: Num rows: 16812348 Data size: 1324232448 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} 1 {_col1} {_col5} {_col7} {_col9} {_col10} {_col11} {_col16} {_col17} {_col21} {_col23} {_col25} {_col27} {_col28} keys: 0 _col0 (type: int) 1 _col4 (type: int) outputColumnNames: _col1, _col3, _col7, _col9, _col11, _col12, _col13, _col18, _col19, _col23, _col25, _col27, _col29, _col30 input vertices: 0 Map 9 Statistics: Num rows: 18493584 Data size: 1456655744 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: int), _col11 (type: float), _col12 (type: float), _col13 (type: float), _col18 (type: int), _col19 (type: int), _col23 (type: int), _col25 (type: int), _col27 (type: int), _col29 (type: string), _col3 (type: int), _col30 (type: string), _col7 (type: int), _col9 (type: int) outputColumnNames: _col1, _col11, _col12, _col13, _col18, _col19, _col23, _col25, _col27, _col29, _col3, _col30, _col7, _col9 Statistics: Num rows: 18493584 Data size: 1456655744 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} 1 {_col1} {_col3} {_col7} {_col9} {_col11} {_col12} {_col13} {_col19} {_col23} {_col25} {_col27} {_col29} {_col30} keys: 0 _col0 (type: int) 1 _col18 (type: int) outputColumnNames: _col1, _col3, _col5, _col9, _col11, _col13, _col14, _col15, _col21, _col25, _col27, _col29, _col31, _col32 input vertices: 0 Map 44 Statistics: Num rows: 20342942 Data size: 1602321408 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col3} {_col9} {_col11} {_col13} {_col14} {_col15} {_col21} {_col25} {_col27} {_col29} {_col31} {_col32} 1 {_col0} {_col3} keys: 0 _col5 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col3, _col9, _col11, _col13, _col14, _col15, _col21, _col25, _col27, _col29, _col31, _col32, _col38, _col41 input vertices: 1 Map 29 Statistics: Num rows: 22377236 Data size: 1762553600 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: int), _col11 (type: int), _col13 (type: float), _col14 (type: float), _col15 (type: float), _col21 (type: int), _col25 (type: int), _col27 (type: int), _col29 (type: int), _col3 (type: int), _col31 (type: string), _col32 (type: string), _col38 (type: int), _col41 (type: string), _col9 (type: int) outputColumnNames: _col1, _col11, _col13, _col14, _col15, _col21, _col25, _col27, _col29, _col3, _col31, _col32, _col38, _col41, _col9 Statistics: Num rows: 22377236 Data size: 1762553600 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 1 {_col1} {_col9} {_col11} {_col13} {_col14} {_col15} {_col21} {_col25} {_col27} {_col29} {_col31} {_col32} {_col38} {_col41} keys: 0 _col0 (type: int) 1 _col3 (type: int) outputColumnNames: _col2, _col10, _col12, _col14, _col15, _col16, _col22, _col26, _col28, _col30, _col32, _col33, _col39, _col42 input vertices: 0 Map 37 Statistics: Num rows: 24614960 Data size: 1938808960 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col10 (type: int), _col12 (type: int), _col14 (type: float), _col15 (type: float), _col16 (type: float), _col2 (type: int), _col22 (type: int), _col26 (type: int), _col28 (type: int), _col30 (type: int), _col32 (type: string), _col33 (type: string), _col39 (type: int), _col42 (type: string) outputColumnNames: _col10, _col12, _col14, _col15, _col16, _col2, _col22, _col26, _col28, _col30, _col32, _col33, _col39, _col42 Statistics: Num rows: 24614960 Data size: 1938808960 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 1 {_col10} {_col12} {_col14} {_col15} {_col16} {_col22} {_col26} {_col28} {_col30} {_col32} {_col33} {_col39} {_col42} keys: 0 _col0 (type: int) 1 _col2 (type: int) outputColumnNames: _col11, _col13, _col15, _col16, _col17, _col23, _col27, _col29, _col31, _col33, _col34, _col40, _col43 input vertices: 0 Map 17 Statistics: Num rows: 27076456 Data size: 2132689920 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col11 (type: int), _col13 (type: int), _col15 (type: float), _col16 (type: float), _col17 (type: float), _col23 (type: int), _col27 (type: int), _col29 (type: int), _col31 (type: int), _col33 (type: string), _col34 (type: string), _col40 (type: int), _col43 (type: string) outputColumnNames: _col11, _col13, _col15, _col16, _col17, _col23, _col27, _col29, _col31, _col33, _col34, _col40, _col43 Statistics: Num rows: 27076456 Data size: 2132689920 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col3} {_col4} 1 {_col13} {_col15} {_col16} {_col17} {_col23} {_col27} {_col29} {_col31} {_col33} {_col34} {_col40} {_col43} keys: 0 _col0 (type: int) 1 _col11 (type: int) outputColumnNames: _col1, _col2, _col3, _col4, _col18, _col20, _col21, _col22, _col28, _col32, _col34, _col36, _col38, _col39, _col45, _col48 input vertices: 0 Map 43 Statistics: Num rows: 29784102 Data size: 2345958912 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: string), _col18 (type: int), _col2 (type: string), _col20 (type: float), _col21 (type: float), _col22 (type: float), _col28 (type: int), _col3 (type: string), _col32 (type: int), _col34 (type: int), _col36 (type: int), _col38 (type: string), _col39 (type: string), _col4 (type: string), _col45 (type: int), _col48 (type: string) outputColumnNames: _col1, _col18, _col2, _col20, _col21, _col22, _col28, _col3, _col32, _col34, _col36, _col38, _col39, _col4, _col45, _col48 Statistics: Num rows: 29784102 Data size: 2345958912 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col3} {_col4} 1 {_col1} {_col2} {_col3} {_col4} {_col18} {_col20} {_col21} {_col22} {_col32} {_col34} {_col36} {_col38} {_col39} {_col45} {_col48} keys: 0 _col0 (type: int) 1 _col28 (type: int) outputColumnNames: _col1, _col2, _col3, _col4, _col6, _col7, _col8, _col9, _col23, _col25, _col26, _col27, _col37, _col39, _col41, _col43, _col44, _col50, _col53 input vertices: 0 Map 28 Statistics: Num rows: 32762512 Data size: 2580554752 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col1 (type: string), _col2 (type: string), _col23 (type: int), _col25 (type: float), _col26 (type: float), _col27 (type: float), _col3 (type: string), _col37 (type: int), _col39 (type: int), _col4 (type: string), _col41 (type: int), _col43 (type: string), _col44 (type: string), _col50 (type: int), _col53 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string) outputColumnNames: _col1, _col2, _col23, _col25, _col26, _col27, _col3, _col37, _col39, _col4, _col41, _col43, _col44, _col50, _col53, _col6, _col7, _col8, _col9 Statistics: Num rows: 32762512 Data size: 2580554752 Basic stats: COMPLETE Column stats: NONE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 1 {_col1} {_col2} {_col3} {_col4} {_col6} {_col7} {_col8} {_col9} {_col25} {_col26} {_col27} {_col37} {_col39} {_col41} {_col43} {_col44} {_col50} {_col53} keys: 0 _col0 (type: int) 1 _col23 (type: int) outputColumnNames: _col2, _col3, _col4, _col5, _col7, _col8, _col9, _col10, _col26, _col27, _col28, _col38, _col40, _col42, _col44, _col45, _col51, _col54 input vertices: 0 Map 34 Statistics: Num rows: 36038764 Data size: 2838610176 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col54 (type: string), _col51 (type: int), _col44 (type: string), _col45 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string), _col10 (type: string), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col38 (type: int), _col40 (type: int), _col42 (type: int), _col26 (type: float), _col27 (type: float), _col28 (type: float) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17 Statistics: Num rows: 36038764 Data size: 2838610176 Basic stats: COMPLETE Column stats: NONE Group By Operator aggregations: count(), sum(_col15), sum(_col16), sum(_col17) keys: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string), _col10 (type: string), _col11 (type: string), _col12 (type: int), _col13 (type: int), _col14 (type: int) mode: hash outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18 Statistics: Num rows: 36038764 Data size: 2838610176 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string), _col10 (type: string), _col11 (type: string), _col12 (type: int), _col13 (type: int), _col14 (type: int) sort order: +++++++++++++++ Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string), _col10 (type: string), _col11 (type: string), _col12 (type: int), _col13 (type: int), _col14 (type: int) Statistics: Num rows: 36038764 Data size: 2838610176 Basic stats: COMPLETE Column stats: NONE value expressions: _col15 (type: bigint), _col16 (type: double), _col17 (type: double), _col18 (type: double) Reducer 21 Reduce Operator Tree: Group By Operator aggregations: count(VALUE._col0), sum(VALUE._col1), sum(VALUE._col2), sum(VALUE._col3) keys: KEY._col0 (type: string), KEY._col1 (type: int), KEY._col2 (type: string), KEY._col3 (type: string), KEY._col4 (type: string), KEY._col5 (type: string), KEY._col6 (type: string), KEY._col7 (type: string), KEY._col8 (type: string), KEY._col9 (type: string), KEY._col10 (type: string), KEY._col11 (type: string), KEY._col12 (type: int), KEY._col13 (type: int), KEY._col14 (type: int) mode: mergepartial outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16, _col17, _col18 Statistics: Num rows: 18019382 Data size: 1419305088 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string), _col3 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string), _col10 (type: string), _col11 (type: string), _col12 (type: int), _col15 (type: bigint), _col16 (type: double), _col17 (type: double), _col18 (type: double) outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8, _col9, _col10, _col11, _col12, _col13, _col14, _col15, _col16 Statistics: Num rows: 18019382 Data size: 1419305088 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col1 (type: int), _col2 (type: string), _col3 (type: string) sort order: +++ Map-reduce partition columns: _col1 (type: int), _col2 (type: string), _col3 (type: string) Statistics: Num rows: 18019382 Data size: 1419305088 Basic stats: COMPLETE Column stats: NONE value expressions: _col0 (type: string), _col4 (type: string), _col5 (type: string), _col6 (type: string), _col7 (type: string), _col8 (type: string), _col9 (type: string), _col10 (type: string), _col11 (type: string), _col12 (type: int), _col13 (type: bigint), _col14 (type: double), _col15 (type: double), _col16 (type: double) Execution mode: vectorized Stage: Stage-0 Fetch Operator limit: -1 Processor Tree: ListSinkQuery select cs1.product_name ,cs1.store_name ,cs1.store_zip ,cs1.b_street_number ,cs1.b_streen_name ,cs1.b_city ,cs1.b_zip ,cs1.c_street_number ,cs1.c_street_name ,cs1.c_city ,cs1.c_zip ,cs1.syear ,cs1.cnt ,cs1.s1 ,cs1.s2 ,cs1.s3 ,cs2.s1 ,cs2.s2 ,cs2.s3 ,cs2.syear ,cs2.cntfrom(select i_product_name as product_name ,i_item_sk as item_sk ,s_store_name as store_name ,s_zip as store_zip ,ad1.ca_street_number as b_street_number ,ad1.ca_street_name as b_streen_name ,ad1.ca_city as b_city ,ad1.ca_zip as b_zip ,ad2.ca_street_number as c_street_number ,ad2.ca_street_name as c_street_name ,ad2.ca_city as c_city ,ad2.ca_zip as c_zip ,d1.d_year as syear ,d2.d_year as fsyear ,d3.d_year as s2year ,count(*) as cnt ,sum(ss_wholesale_cost) as s1 ,sum(ss_list_price) as s2 ,sum(ss_coupon_amt) as s3 FROM store_sales JOIN store_returns ON store_sales.ss_item_sk = store_returns.sr_item_sk and store_sales.ss_ticket_number = store_returns.sr_ticket_number JOIN customer ON store_sales.ss_customer_sk = customer.c_customer_sk JOIN date_dim d1 ON store_sales.ss_sold_date_sk = d1.d_date_sk JOIN date_dim d2 ON customer.c_first_sales_date_sk = d2.d_date_sk JOIN date_dim d3 ON customer.c_first_shipto_date_sk = d3.d_date_sk JOIN store ON store_sales.ss_store_sk = store.s_store_sk JOIN customer_demographics cd1 ON store_sales.ss_cdemo_sk= cd1.cd_demo_sk JOIN customer_demographics cd2 ON customer.c_current_cdemo_sk = cd2.cd_demo_sk JOIN promotion ON store_sales.ss_promo_sk = promotion.p_promo_sk JOIN household_demographics hd1 ON store_sales.ss_hdemo_sk = hd1.hd_demo_sk JOIN household_demographics hd2 ON customer.c_current_hdemo_sk = hd2.hd_demo_sk JOIN customer_address ad1 ON store_sales.ss_addr_sk = ad1.ca_address_sk JOIN customer_address ad2 ON customer.c_current_addr_sk = ad2.ca_address_sk JOIN income_band ib1 ON hd1.hd_income_band_sk = ib1.ib_income_band_sk JOIN income_band ib2 ON hd2.hd_income_band_sk = ib2.ib_income_band_sk JOIN item ON store_sales.ss_item_sk = item.i_item_sk JOIN (select cs_item_sk ,sum(cs_ext_list_price) as sale,sum(cr_refunded_cash+cr_reversed_charge+cr_store_credit) as refund from catalog_sales JOIN catalog_returns ON catalog_sales.cs_item_sk = catalog_returns.cr_item_sk and catalog_sales.cs_order_number = catalog_returns.cr_order_number group by cs_item_sk having sum(cs_ext_list_price)&gt;2*sum(cr_refunded_cash+cr_reversed_charge+cr_store_credit)) cs_uiON store_sales.ss_item_sk = cs_ui.cs_item_sk WHERE cd1.cd_marital_status &lt;&gt; cd2.cd_marital_status and i_color in ('maroon','burnished','dim','steel','navajo','chocolate') and i_current_price between 35 and 35 + 10 and i_current_price between 35 + 1 and 35 + 15group by i_product_name ,i_item_sk ,s_store_name ,s_zip ,ad1.ca_street_number ,ad1.ca_street_name ,ad1.ca_city ,ad1.ca_zip ,ad2.ca_street_number ,ad2.ca_street_name ,ad2.ca_city ,ad2.ca_zip ,d1.d_year ,d2.d_year ,d3.d_year) cs1JOIN(select i_product_name as product_name ,i_item_sk as item_sk ,s_store_name as store_name ,s_zip as store_zip ,ad1.ca_street_number as b_street_number ,ad1.ca_street_name as b_streen_name ,ad1.ca_city as b_city ,ad1.ca_zip as b_zip ,ad2.ca_street_number as c_street_number ,ad2.ca_street_name as c_street_name ,ad2.ca_city as c_city ,ad2.ca_zip as c_zip ,d1.d_year as syear ,d2.d_year as fsyear ,d3.d_year as s2year ,count(*) as cnt ,sum(ss_wholesale_cost) as s1 ,sum(ss_list_price) as s2 ,sum(ss_coupon_amt) as s3 FROM store_sales JOIN store_returns ON store_sales.ss_item_sk = store_returns.sr_item_sk and store_sales.ss_ticket_number = store_returns.sr_ticket_number JOIN customer ON store_sales.ss_customer_sk = customer.c_customer_sk JOIN date_dim d1 ON store_sales.ss_sold_date_sk = d1.d_date_sk JOIN date_dim d2 ON customer.c_first_sales_date_sk = d2.d_date_sk JOIN date_dim d3 ON customer.c_first_shipto_date_sk = d3.d_date_sk JOIN store ON store_sales.ss_store_sk = store.s_store_sk JOIN customer_demographics cd1 ON store_sales.ss_cdemo_sk= cd1.cd_demo_sk JOIN customer_demographics cd2 ON customer.c_current_cdemo_sk = cd2.cd_demo_sk JOIN promotion ON store_sales.ss_promo_sk = promotion.p_promo_sk JOIN household_demographics hd1 ON store_sales.ss_hdemo_sk = hd1.hd_demo_sk JOIN household_demographics hd2 ON customer.c_current_hdemo_sk = hd2.hd_demo_sk JOIN customer_address ad1 ON store_sales.ss_addr_sk = ad1.ca_address_sk JOIN customer_address ad2 ON customer.c_current_addr_sk = ad2.ca_address_sk JOIN income_band ib1 ON hd1.hd_income_band_sk = ib1.ib_income_band_sk JOIN income_band ib2 ON hd2.hd_income_band_sk = ib2.ib_income_band_sk JOIN item ON store_sales.ss_item_sk = item.i_item_sk JOIN (select cs_item_sk ,sum(cs_ext_list_price) as sale,sum(cr_refunded_cash+cr_reversed_charge+cr_store_credit) as refund from catalog_sales JOIN catalog_returns ON catalog_sales.cs_item_sk = catalog_returns.cr_item_sk and catalog_sales.cs_order_number = catalog_returns.cr_order_number group by cs_item_sk having sum(cs_ext_list_price)&gt;2*sum(cr_refunded_cash+cr_reversed_charge+cr_store_credit)) cs_uiON store_sales.ss_item_sk = cs_ui.cs_item_sk WHERE cd1.cd_marital_status &lt;&gt; cd2.cd_marital_status and i_color in ('maroon','burnished','dim','steel','navajo','chocolate') and i_current_price between 35 and 35 + 10 and i_current_price between 35 + 1 and 35 + 15group by i_product_name ,i_item_sk ,s_store_name ,s_zip ,ad1.ca_street_number ,ad1.ca_street_name ,ad1.ca_city ,ad1.ca_zip ,ad2.ca_street_number ,ad2.ca_street_name ,ad2.ca_city ,ad2.ca_zip ,d1.d_year ,d2.d_year ,d3.d_year) cs2ON cs1.item_sk=cs2.item_skwhere cs1.syear = 2000 and cs2.syear = 2000 + 1 and cs2.cnt &lt;= cs1.cnt and cs1.store_name = cs2.store_name and cs1.store_zip = cs2.store_ziporder by cs1.product_name ,cs1.store_name ,cs2.cnt</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.stats.HiveRelMdRowCount.java</file>
    </fixedFiles>
  </bug>
  <bug id="827" opendate="2009-9-12 00:00:00" fixdate="2009-9-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>increase hive.mapjoin.cache.numrows default value</summary>
      <description>Currently, it is 10000 and leads to bad performance</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">conf.hive-default.xml</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8270" opendate="2014-9-26 00:00:00" fixdate="2014-9-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JDBC uber jar is missing some classes required in secure setup.</summary>
      <description>JDBC uber jar is missing some required classes for a secure setup.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8271" opendate="2014-9-26 00:00:00" fixdate="2014-10-26 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>Jackson incompatibility between hadoop-2.4 and hive-14</summary>
      <description>jackson-1.8 is not API compatible with jackson-1.9 (abstract classes).threw an Error. Shutting down now...java.lang.AbstractMethodError: org.codehaus.jackson.map.AnnotationIntrospector.findSerializer(Lorg/codehaus/jackson/map/introspect/Annotated;)Ljava/lang/Object;hadoop-common (2.4) depends on jackson-1.8 and hive-14 depends on jackson-1.9.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8272" opendate="2014-9-26 00:00:00" fixdate="2014-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Query with particular decimal expression causes NPE during execution initialization</summary>
      <description>Query:select cast(sum(dc)*100 as decimal(11,3)) as c1 from somedecimaltable order by c1 limit 100;Fails during execution initialization due to null ExprNodeDesc.Noticed while trying to simplify a Vectorization issue and realized it was a more general issue.Caused by: java.lang.RuntimeException: Map operator initialization failed at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.configure(ExecMapper.java:154) ... 22 moreCaused by: java.lang.RuntimeException: java.lang.NullPointerException at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.initializeOp(ReduceSinkOperator.java:215) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:380) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:464) at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:420) at org.apache.hadoop.hive.ql.exec.GroupByOperator.initializeOp(GroupByOperator.java:427) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:380) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:464) at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:420) at org.apache.hadoop.hive.ql.exec.SelectOperator.initializeOp(SelectOperator.java:65) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:380) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:464) at org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:420) at org.apache.hadoop.hive.ql.exec.TableScanOperator.initializeOp(TableScanOperator.java:193) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:380) at org.apache.hadoop.hive.ql.exec.MapOperator.initializeOp(MapOperator.java:425) at org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:380) at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.configure(ExecMapper.java:133) ... 22 moreCaused by: java.lang.NullPointerException at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.getExprString(ExprNodeGenericFuncDesc.java:154) at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.getExprString(ExprNodeGenericFuncDesc.java:154) at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.initializeOp(ReduceSinkOperator.java:148) ... 38 more</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ExprNodeDescUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="8280" opendate="2014-9-26 00:00:00" fixdate="2014-10-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO : When filter is applied on dimension table PK/FK code path is not in effect.</summary>
      <description>When a filter is applied on PK side joins don't qualify as PK/FK join.In getUniqueKeys when a filter is applied on the table the child is no longer a table scan. public Set&lt;BitSet&gt; getUniqueKeys(ProjectRelBase rel, boolean ignoreNulls) { RelNode child = rel.getChild(); if (!(child instanceof HiveTableScanRel)) { Function&lt;RelNode, Metadata&gt; fn = RelMdUniqueKeys.SOURCE.apply( rel.getClass(), BuiltInMetadata.UniqueKeys.class); return ((BuiltInMetadata.UniqueKeys) fn.apply(rel)) .getUniqueKeys(ignoreNulls); } Repro with ss as (select ss_customer_sk, ss_item_sk, ss_ticket_numberfrom store_sales, storewhere s_store_sk = ss_store_sk and s_market_id = 4), sr as(select sr_customer_sk,sr_item_sk ,sr_ticket_number from store_returns, store where s_store_sk = sr_store_sk and s_market_id=4) select count(*)from ss, srwhere ss_customer_sk = sr_customer_sk and ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number;</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.stats.HiveRelMdUniqueKeys.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.stats.HiveRelMdRowCount.java</file>
    </fixedFiles>
  </bug>
  <bug id="8281" opendate="2014-9-27 00:00:00" fixdate="2014-9-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NPE with dynamic partition pruning on Tez</summary>
      <description>Dynamic partition pruning can generate incorrect query plans during join algorithm selection.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.java</file>
    </fixedFiles>
  </bug>
  <bug id="8296" opendate="2014-9-29 00:00:00" fixdate="2014-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tez ReduceShuffle Vectorization needs 2 data buffers (key and value) for adding rows</summary>
      <description>We reuse the keys for the vectorized row batch and need to use a separate buffer (for strings) for reuse the batch for new values.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.ReduceRecordSource.java</file>
    </fixedFiles>
  </bug>
  <bug id="8300" opendate="2014-9-30 00:00:00" fixdate="2014-9-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Missing guava lib causes IllegalStateException when deserializing a task [Spark Branch]</summary>
      <description>In spark-1.2, we have guava shaded in spark-assembly. And we only ship hive-exec to spark cluster. So spark executor won't have (original) guava in its class path.This can cause some problem when TaskRunner deserializes a task, and throws something like this:org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, node13-1): java.lang.IllegalStateException: unread block data java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2421) java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1382) java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990) java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915) java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798) java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) java.io.ObjectInputStream.readObject(ObjectInputStream.java:370) org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62) org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87) org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:164) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) java.lang.Thread.run(Thread.java:744)We may have to verify this issue and ship guava to spark cluster.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8304" opendate="2014-9-30 00:00:00" fixdate="2014-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tez Reduce-Side GROUP BY Vectorization doesn&amp;#39;t copy NULL keys correctly</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.aggregate.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8313" opendate="2014-9-30 00:00:00" fixdate="2014-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Optimize evaluation for ExprNodeConstantEvaluator and ExprNodeNullEvaluator</summary>
      <description>Consider the following query:SELECT foo, bar, goo, idFROM myTableWHERE id IN ( 'A', 'B', 'C', 'D', ... , 'ZZZZZZ' );One finds that when the IN clause has several thousand elements (and the table has several million rows), the query above takes orders-of-magnitude longer to run on Hive 0.12 than say Hive 0.10.I have a possibly incomplete fix.</description>
      <version>0.12.0,0.13.0,0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExprNodeGenericFuncEvaluator.java</file>
    </fixedFiles>
  </bug>
  <bug id="8314" opendate="2014-9-30 00:00:00" fixdate="2014-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Restore thrift string interning of HIVE-7975</summary>
      <description>In HIVE-7975 did string interning in thrift-generated code by having a google-replacer plugin run with -Pthriftif that does the replacements. In commit of HIVE-7482, it was removed as it was done without that plugin. Thrift code should be regenerated.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.StorageDescriptor.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.SerDeInfo.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.Partition.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.FieldSchema.java</file>
    </fixedFiles>
  </bug>
  <bug id="8315" opendate="2014-9-30 00:00:00" fixdate="2014-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO : Negate condition underestimates selectivity which results in an in-efficient plan</summary>
      <description>For TPC-DS Q64 the predicate cd1.cd_marital_status &lt;&gt; cd2.cd_marital_status under estimate the join selectivity by a huge margin and results in in-efficient join order.This is a subset of the logical plan showing that item was joined very last HiveJoinRel(condition=[=($0, $37)], joinType=[inner]): rowcount = 1.0, cumulative cost = {6.386017602518958E8 rows, 0.0 cpu, 0.0 io}, id = 3790 HiveJoinRel(condition=[=($0, $33)], joinType=[inner]): rowcount = 1.0, cumulative cost = {6.386017582518958E8 rows, 0.0 cpu, 0.0 io}, id = 3067 HiveFilterRel(condition=[&lt;&gt;($30, $32)]): rowcount = 1.8252236387887635, cumulative cost = {6.386017554266721E8 rows, 0.0 cpu, 0.0 io}, id = 1153 HiveProjectRel(ss_item_sk=[$2], ss_customer_sk=[$3], ss_cdemo_sk=[$4], ss_hdemo_sk=[$5], ss_addr_sk=[$6], ss_store_sk=[$7], ss_promo_sk=[$8], ss_ticket_number=[$9], ss_wholesale_cost=[$10], ss_list_price=[$11], ss_coupon_amt=[$12], ss_sold_date_sk=[$13], sr_item_sk=[$0], sr_ticket_number=[$1], c_customer_sk=[$23], c_current_cdemo_sk=[$24], c_current_hdemo_sk=[$25], c_current_addr_sk=[$26], c_first_shipto_date_sk=[$27], c_first_sales_date_sk=[$28], d_date_sk=[$14], d_year=[$15], d_date_sk0=[$29], d_year0=[$30], d_date_sk1=[$31], d_year1=[$32], s_store_sk=[$18], s_store_name=[$19], s_zip=[$20], cd_demo_sk=[$16], cd_marital_status=[$17], cd_demo_sk0=[$21], cd_marital_status0=[$22]): rowcount = 3.6246005783468924E7, cumulative cost = {6.386017554266721E8 rows, 0.0 cpu, 0.0 io}, id = 2312 HiveJoinRel(condition=[AND(=($2, $0), =($9, $1))], joinType=[inner]): rowcount = 3.6246005783468924E7, cumulative cost = {6.386017554266721E8 rows, 0.0 cpu, 0.0 io}, id = 2310 HiveProjectRel(sr_item_sk=[$1], sr_ticket_number=[$8]): rowcount = 5.5578005E7, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 912 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200_orig.store_returns]]): rowcount = 5.5578005E7, cumulative cost = {0}, id = 62 HiveJoinRel(condition=[=($1, $21)], joinType=[inner]): rowcount = 1.2950939439433252E7, cumulative cost = {5.700728109872389E8 rows, 0.0 cpu, 0.0 io}, id = 2308 HiveJoinRel(condition=[=($5, $16)], joinType=[inner]): rowcount = 5491530.921341597, cumulative cost = {5.629812800658973E8 rows, 0.0 cpu, 0.0 io}, id = 2301 HiveJoinRel(condition=[=($2, $14)], joinType=[inner]): rowcount = 5491530.921341597, cumulative cost = {5.574895371445558E8 rows, 0.0 cpu, 0.0 io}, id = 2299 HiveJoinRel(condition=[=($11, $12)], joinType=[inner]): rowcount = 5491530.921341597, cumulative cost = {5.500772062232143E8 rows, 0.0 cpu, 0.0 io}, id = 1898 HiveProjectRel(ss_item_sk=[$1], ss_customer_sk=[$2], ss_cdemo_sk=[$3], ss_hdemo_sk=[$4], ss_addr_sk=[$5], ss_store_sk=[$6], ss_promo_sk=[$7], ss_ticket_number=[$8], ss_wholesale_cost=[$10], ss_list_price=[$11], ss_coupon_amt=[$18], ss_sold_date_sk=[$22]): rowcount = 5.50076554E8, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 909 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200_orig.store_sales]]): rowcount = 5.50076554E8, cumulative cost = {0}, id = 55Query select cs1.product_name ,cs1.store_name ,cs1.store_zip ,cs1.b_street_number ,cs1.b_streen_name ,cs1.b_city ,cs1.b_zip ,cs1.c_street_number ,cs1.c_street_name ,cs1.c_city ,cs1.c_zip ,cs1.syear ,cs1.cnt ,cs1.s1 ,cs1.s2 ,cs1.s3 ,cs2.s1 ,cs2.s2 ,cs2.s3 ,cs2.syear ,cs2.cntfrom(select i_product_name as product_name ,i_item_sk as item_sk ,s_store_name as store_name ,s_zip as store_zip ,ad1.ca_street_number as b_street_number ,ad1.ca_street_name as b_streen_name ,ad1.ca_city as b_city ,ad1.ca_zip as b_zip ,ad2.ca_street_number as c_street_number ,ad2.ca_street_name as c_street_name ,ad2.ca_city as c_city ,ad2.ca_zip as c_zip ,d1.d_year as syear ,d2.d_year as fsyear ,d3.d_year as s2year ,count(*) as cnt ,sum(ss_wholesale_cost) as s1 ,sum(ss_list_price) as s2 ,sum(ss_coupon_amt) as s3 FROM store_sales JOIN store_returns ON store_sales.ss_item_sk = store_returns.sr_item_sk and store_sales.ss_ticket_number = store_returns.sr_ticket_number JOIN customer ON store_sales.ss_customer_sk = customer.c_customer_sk JOIN date_dim d1 ON store_sales.ss_sold_date_sk = d1.d_date_sk JOIN date_dim d2 ON customer.c_first_sales_date_sk = d2.d_date_sk JOIN date_dim d3 ON customer.c_first_shipto_date_sk = d3.d_date_sk JOIN store ON store_sales.ss_store_sk = store.s_store_sk JOIN customer_demographics cd1 ON store_sales.ss_cdemo_sk= cd1.cd_demo_sk JOIN customer_demographics cd2 ON customer.c_current_cdemo_sk = cd2.cd_demo_sk JOIN promotion ON store_sales.ss_promo_sk = promotion.p_promo_sk JOIN household_demographics hd1 ON store_sales.ss_hdemo_sk = hd1.hd_demo_sk JOIN household_demographics hd2 ON customer.c_current_hdemo_sk = hd2.hd_demo_sk JOIN customer_address ad1 ON store_sales.ss_addr_sk = ad1.ca_address_sk JOIN customer_address ad2 ON customer.c_current_addr_sk = ad2.ca_address_sk JOIN income_band ib1 ON hd1.hd_income_band_sk = ib1.ib_income_band_sk JOIN income_band ib2 ON hd2.hd_income_band_sk = ib2.ib_income_band_sk JOIN item ON store_sales.ss_item_sk = item.i_item_sk JOIN (select cs_item_sk ,sum(cs_ext_list_price) as sale,sum(cr_refunded_cash+cr_reversed_charge+cr_store_credit) as refund from catalog_sales JOIN catalog_returns ON catalog_sales.cs_item_sk = catalog_returns.cr_item_sk and catalog_sales.cs_order_number = catalog_returns.cr_order_number group by cs_item_sk having sum(cs_ext_list_price)&gt;2*sum(cr_refunded_cash+cr_reversed_charge+cr_store_credit)) cs_uiON store_sales.ss_item_sk = cs_ui.cs_item_sk WHERE cd1.cd_marital_status &lt;&gt; cd2.cd_marital_status and i_color in ('maroon','burnished','dim','steel','navajo','chocolate') and i_current_price between 35 and 35 + 10 and i_current_price between 35 + 1 and 35 + 15group by i_product_name ,i_item_sk ,s_store_name ,s_zip ,ad1.ca_street_number ,ad1.ca_street_name ,ad1.ca_city ,ad1.ca_zip ,ad2.ca_street_number ,ad2.ca_street_name ,ad2.ca_city ,ad2.ca_zip ,d1.d_year ,d2.d_year ,d3.d_year) cs1JOIN(select i_product_name as product_name ,i_item_sk as item_sk ,s_store_name as store_name ,s_zip as store_zip ,ad1.ca_street_number as b_street_number ,ad1.ca_street_name as b_streen_name ,ad1.ca_city as b_city ,ad1.ca_zip as b_zip ,ad2.ca_street_number as c_street_number ,ad2.ca_street_name as c_street_name ,ad2.ca_city as c_city ,ad2.ca_zip as c_zip ,d1.d_year as syear ,d2.d_year as fsyear ,d3.d_year as s2year ,count(*) as cnt ,sum(ss_wholesale_cost) as s1 ,sum(ss_list_price) as s2 ,sum(ss_coupon_amt) as s3 FROM store_sales JOIN store_returns ON store_sales.ss_item_sk = store_returns.sr_item_sk and store_sales.ss_ticket_number = store_returns.sr_ticket_number JOIN customer ON store_sales.ss_customer_sk = customer.c_customer_sk JOIN date_dim d1 ON store_sales.ss_sold_date_sk = d1.d_date_sk JOIN date_dim d2 ON customer.c_first_sales_date_sk = d2.d_date_sk JOIN date_dim d3 ON customer.c_first_shipto_date_sk = d3.d_date_sk JOIN store ON store_sales.ss_store_sk = store.s_store_sk JOIN customer_demographics cd1 ON store_sales.ss_cdemo_sk= cd1.cd_demo_sk JOIN customer_demographics cd2 ON customer.c_current_cdemo_sk = cd2.cd_demo_sk JOIN promotion ON store_sales.ss_promo_sk = promotion.p_promo_sk JOIN household_demographics hd1 ON store_sales.ss_hdemo_sk = hd1.hd_demo_sk JOIN household_demographics hd2 ON customer.c_current_hdemo_sk = hd2.hd_demo_sk JOIN customer_address ad1 ON store_sales.ss_addr_sk = ad1.ca_address_sk JOIN customer_address ad2 ON customer.c_current_addr_sk = ad2.ca_address_sk JOIN income_band ib1 ON hd1.hd_income_band_sk = ib1.ib_income_band_sk JOIN income_band ib2 ON hd2.hd_income_band_sk = ib2.ib_income_band_sk JOIN item ON store_sales.ss_item_sk = item.i_item_sk JOIN (select cs_item_sk ,sum(cs_ext_list_price) as sale,sum(cr_refunded_cash+cr_reversed_charge+cr_store_credit) as refund from catalog_sales JOIN catalog_returns ON catalog_sales.cs_item_sk = catalog_returns.cr_item_sk and catalog_sales.cs_order_number = catalog_returns.cr_order_number group by cs_item_sk having sum(cs_ext_list_price)&gt;2*sum(cr_refunded_cash+cr_reversed_charge+cr_store_credit)) cs_uiON store_sales.ss_item_sk = cs_ui.cs_item_sk WHERE cd1.cd_marital_status &lt;&gt; cd2.cd_marital_status and i_color in ('maroon','burnished','dim','steel','navajo','chocolate') and i_current_price between 35 and 35 + 10 and i_current_price between 35 + 1 and 35 + 15group by i_product_name ,i_item_sk ,s_store_name ,s_zip ,ad1.ca_street_number ,ad1.ca_street_name ,ad1.ca_city ,ad1.ca_zip ,ad2.ca_street_number ,ad2.ca_street_name ,ad2.ca_city ,ad2.ca_zip ,d1.d_year ,d2.d_year ,d3.d_year) cs2ON cs1.item_sk=cs2.item_skwhere cs1.syear = 2000 and cs2.syear = 2000 + 1 and cs2.cnt &lt;= cs1.cnt and cs1.store_name = cs2.store_name and cs1.store_zip = cs2.store_ziporder by cs1.product_name ,cs1.store_name ,cs2.cnt</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.stats.HiveRelMdSelectivity.java</file>
    </fixedFiles>
  </bug>
  <bug id="8327" opendate="2014-10-2 00:00:00" fixdate="2014-1-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mvn site -Pfindbugs</summary>
      <description>HIVE-3099 originally added findbugs into the old ant build.Get basic findbugs working for the maven build.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8328" opendate="2014-10-2 00:00:00" fixdate="2014-10-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MapJoin implementation in Tez should not reload hashtables</summary>
      <description>private void loadHashTable() throws HiveException { if ((this.getExecContext() != null) &amp;&amp; ((this.getExecContext().getLocalWork() == null) || (!this.getExecContext() .getLocalWork().getInputFileChangeSensitive()))) { if (hashTblInitedOnce) { return; } else { hashTblInitedOnce = true; } }This is not exiting in Tez, even if hashTblInitedOnce=true;</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="8337" opendate="2014-10-3 00:00:00" fixdate="2014-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change default of hive.warehouse.subdir.inherit.perms to true</summary>
      <description>In my experience users want hive.warehouse.subdir.inherit.perms set to true since they want permissions to be inherited from the parent directory. Let's set the default value to true.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="8338" opendate="2014-10-3 00:00:00" fixdate="2014-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add ip and command to semantic analyzer hook context</summary>
      <description>This is useful for semantic analysis hooks like Sentrywhen reporting authorization outcomes.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHookContextImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHookContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.hooks.TestHs2Hooks.java</file>
      <file type="M">itests.hive-minikdc.src.test.java.org.apache.hive.minikdc.TestHs2HooksWithMiniKdc.java</file>
      <file type="M">itests.hive-minikdc.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8340" opendate="2014-10-3 00:00:00" fixdate="2014-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Windows: HiveServer2 service doesn&amp;#39;t stop backend jvm process, which prevents follow-up service start.</summary>
      <description>On stopping the HS2 service from the services tab, it only kills the root process and does not kill the child java process. As a result resources are not freed and this throws an error on restarting from command line.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">bin.hive.cmd</file>
      <file type="M">bin.ext.hiveserver2.cmd</file>
    </fixedFiles>
  </bug>
  <bug id="8341" opendate="2014-10-3 00:00:00" fixdate="2014-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Transaction information in config file can grow excessively large</summary>
      <description>In our testing we have seen cases where the transaction list grows very large. We need a more efficient way of communicating the list.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ScriptOperator.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.ValidTxnListImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="8344" opendate="2014-10-3 00:00:00" fixdate="2014-10-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive on Tez sets mapreduce.framework.name to yarn-tez</summary>
      <description>This was done to run MR jobs when in Tez mode (emulate MR on Tez). However, we don't switch back when the user specifies MR as exec engine.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezSessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.ExecDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="8348" opendate="2014-10-4 00:00:00" fixdate="2014-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix Hive to match changes introduced by TEZ-1510</summary>
      <description>TEZ-1510 changes the way configuration objects are handled in tez, by avoiding polluting the new Configuration(); object within HiveServer2.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="8349" opendate="2014-10-4 00:00:00" fixdate="2014-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DISTRIBUTE BY should work with tez auto-parallelism enabled</summary>
      <description>Current implementation of DISTRIBUTE BY does not work when tez auto-parallelism is turned on, because of hashCode distribution issues.In case of distribute by, the key is actually zero bytes, with only partitioning enabled via hashCode - this adversely affects the uniform hashing implementation.In an ideal scenario, the edge should go from the ordered kv input to the unordered partitioned edge, to speed up the processing massively.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.compiler.plan.join8.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join7.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input20.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.groupby1.q.xml</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ReduceSinkDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ExprNodeDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.GenTezUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.SetReducerParallelism.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ReduceSinkMapJoinProc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="8350" opendate="2014-10-4 00:00:00" fixdate="2014-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Constant folding should happen before group-by optimization</summary>
      <description>Constant folding should happen as early as possible, so later optimizations can take advantages of it.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.compiler.plan.udf.when.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf.case.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.udf1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.cast1.q.xml</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.Optimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GroupByOptimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="8351" opendate="2014-10-4 00:00:00" fixdate="2014-10-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow testing of both hadoop-1 and hadoop-2 for precommits</summary>
      <description>Since we keep breaking Hadoop-1, we should make it possible to run both Hadoop-1 and Hadoop-2 as pre-commits. This may cost additional dollars as we'd have to increase the number of hosts we use to build, but would make the Hadoop-1 build stable.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.src.test.java.org.apache.hive.ptest.execution.TestJIRAService.java</file>
      <file type="M">testutils.ptest2.src.main.java.org.apache.hive.ptest.execution.PTest.java</file>
      <file type="M">testutils.ptest2.src.main.java.org.apache.hive.ptest.execution.JIRAService.java</file>
    </fixedFiles>
  </bug>
  <bug id="8353" opendate="2014-10-5 00:00:00" fixdate="2014-10-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Merge trunk into spark 10/4/2015 [Spark Branch]</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.spark.input18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.cast.constant.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.shufflejoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorization.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.24.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union33.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union30.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union28.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.transform.ppr2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.transform.ppr1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.transform1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.temp.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.subquery.multiinsert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sort.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.script.pipe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ppd.transform.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ppd.multi.insert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.parallel.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.parallel.join0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.parallel.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.order2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.order.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.optimize.nullscan.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.move.tasks.share.dependencies.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.lateral.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.gby3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.gby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.gby.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multigroupby.singlemr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.metadata.only.queries.with.filters.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.metadata.only.queries.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.merge2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.merge1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.mapreduce2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.mapreduce1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.limit.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join.nullsafe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join27.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.insert.into3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.insert.into2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.insert.into1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.insert1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input.part2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input1.limit.q.out</file>
      <file type="M">itests.qtest-spark.pom.xml</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FilterOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.ExecMapperContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkReduceRecordHandler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.IOContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.Optimizer.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestOperators.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.TestHiveBinarySearchRecordReader.java</file>
      <file type="M">ql.src.test.results.clientpositive.spark.alter.merge.stats.orc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.column.access.stats.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.count.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ctas.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.disable.merge.for.bucketing.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.escape.clusterby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.escape.distributeby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.escape.orderby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.escape.sortby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.map.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.noskew.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby7.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby7.map.multi.single.reducer.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby7.map.skew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby7.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.cube1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.multi.single.reducer.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.multi.single.reducer2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.multi.single.reducer3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.position.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.rollup1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.sort.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.sort.skew.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.innerjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input17.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="8354" opendate="2014-10-5 00:00:00" fixdate="2014-10-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HIVE-7156 introduced required dependency on tez</summary>
      <description>Should not be much work to fix, but HIVE-7156 introduced a require dep of tez-api.</description>
      <version>0.14.0,0.15.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.StatsUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.stats.annotation.StatsRulesProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="8358" opendate="2014-10-6 00:00:00" fixdate="2014-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Constant folding should happen before PCR</summary>
      <description>So, that partition pruning and transitive predicate propagation may take advantage of constant folding.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.truncate.column.list.bucket.q.out</file>
      <file type="M">ql.src.test.results.compiler.plan.sample1.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.input.part1.q.xml</file>
      <file type="M">ql.src.test.results.clientpositive.union.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.ppr.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.Optimizer.java</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucket3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.columnstats.partlvl.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.columnstats.partlvl.dp.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.constprog.dp.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.unused.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.stale.partitioned.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input42.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit.partition.metadataonly.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.multiskew.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge.dynamic.partition.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nonmr.fetch.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nonmr.fetch.threshold.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.parallel.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.pcr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.udf.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.union.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.quotedid.partition.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rand.partitionpruner2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rand.partitionpruner3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.bucket3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynamic.partition.pruning.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.sample1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.transform.ppr2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.transform.ppr2.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="8366" opendate="2014-10-6 00:00:00" fixdate="2014-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO fails if there is a table sample in subquery</summary>
      <description>Bail out from cbo in such cases.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.HiveOptiqUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="8368" opendate="2014-10-6 00:00:00" fixdate="2014-10-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>compactor is improperly writing delete records in base file</summary>
      <description>When the compactor reads records from the base and deltas, it is not properly dropping delete records. This leads to oversized base files, and possibly to wrong query results.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.txn.compactor.TestWorker.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcRawRecordMerger.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.AcidInputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="8374" opendate="2014-10-7 00:00:00" fixdate="2014-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>schematool fails on Postgres versions &lt; 9.2</summary>
      <description>The upgrade script for HIVE-5700 creates an UDF with language 'plpgsql',which is available by default only for Postgres 9.2+.For older Postgres versions, the language must be explicitly created,otherwise schematool fails with the error:Error: ERROR: language "plpgsql" does not exist Hint: Use CREATE LANGUAGE to load the language into the database. (state=42704,code=0)</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.MetaStoreSchemaInfo.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.beeline.TestSchemaTool.java</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.HiveSchemaTool.java</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.HiveSchemaHelper.java</file>
    </fixedFiles>
  </bug>
  <bug id="8377" opendate="2014-10-7 00:00:00" fixdate="2014-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable Kerberized SSL for HiveServer2 in http mode</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.thrift.ThriftHttpCLIService.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="8389" opendate="2014-10-7 00:00:00" fixdate="2014-10-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix CBO when indexes are used</summary>
      <description>Disable CBO when indexes are used</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientnegative.set.hiveconf.validation2.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.index.bitmap.auto.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientpositive.index.auto.partitioned.q</file>
      <file type="M">ql.src.test.queries.clientnegative.set.hiveconf.validation2.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.Optimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="8391" opendate="2014-10-8 00:00:00" fixdate="2014-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Comparion between TIMESTAMP and Integer types goes to STRING as "common comparison denominator" instead of a numeric type</summary>
      <description>Discovered while investigating why vectorization_7.q has different results for non-vectorized &amp;#91;+CBO&amp;#93; and vectorized &amp;#91;+CBO&amp;#93;.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestFunctionRegistry.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
    </fixedFiles>
  </bug>
  <bug id="8393" opendate="2014-10-8 00:00:00" fixdate="2014-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handle SIGINT on Tez</summary>
      <description>The signal handler in hive currently only interrupts MR jobs. The same logic can be used to interrupt Tez dags as well.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezJobMonitor.java</file>
      <file type="M">cli.src.java.org.apache.hadoop.hive.cli.CliDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="8395" opendate="2014-10-8 00:00:00" fixdate="2014-12-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: enable by default</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.auto.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.windowing.streaming.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.string.concat.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.reduce.groupby.decimal.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.partitioned.date.time.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.orderby.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.mapjoin.reduce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.left.outer.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.groupby.reduce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.groupby.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.elt.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.distinct.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.udf2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.udf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.round.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.precision.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.math.funcs.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.expressions.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.aggregate.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.count.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.coalesce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.char.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.cast.constant.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.aggregate.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.timestamp.funcs.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.shufflejoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.parquet.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.nested.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.distinct.gby.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.date.funcs.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.casts.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.short.regress.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.part.project.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.div0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorization.0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.top.level.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.24.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.date.trim.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union33.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union30.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union28.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union24.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udtf.explode.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.to.unix.timestamp.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.second.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.parse.url.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.minute.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.lower.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.like.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.hour.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.count.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.case.column.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.between.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.10.trims.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udaf.number.format.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.string.concat.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.reduce.groupby.decimal.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.partitioned.date.time.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.orderby.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.mapjoin.reduce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.left.outer.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.groupby.reduce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.groupby.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.elt.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.distinct.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.udf2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.udf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.round.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.precision.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.math.funcs.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.expressions.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.aggregate.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.count.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.coalesce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.cast.constant.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.aggregate.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.timestamp.funcs.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.shufflejoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.parquet.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.nested.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.distinct.gby.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.date.funcs.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.casts.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.short.regress.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.part.project.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.div0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorization.0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.union9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.union8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.union7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.union6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.union5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.union4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.union2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.smb.main.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.join.tests.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.joins.explain.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.dml.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.temp.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.subquery.in.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.subquery.exists.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.skewjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.optimize.nullscan.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mrr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.metadata.only.queries.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.metadataonly1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.merge2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.merge1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mapjoin.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.limit.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.groupby3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.groupby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.groupby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.filter.join.breaktask2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynpart.sort.opt.vectorization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynpart.sort.optimization2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynpart.sort.optimization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.product.check.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.product.check.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.count.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.correlationoptimizer1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.temp.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.table.access.keys.stats.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.symlink.text.input.format.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subq.where.serialization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.views.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.unqualcolumnrefs.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.notin.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.notin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.notexists.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.notexists.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.in.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.in.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.exists.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.exists.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.alias.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subq2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subq.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.str.to.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stats.only.null.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stats1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.set.processor.namespaces.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.semijoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.select.unquote.or.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.select.unquote.not.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.select.unquote.and.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.router.join.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.regex.col.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.reduce.deduplicate.extended.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rcfile.null.value.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rand.partitionpruner3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.quotedid.partition.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.quotedid.basic.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.quote1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.print.header.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppr.pushdown3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppr.allchildsarenull.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.vc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.union.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.udf.col.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.udf.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.random.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.outer.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.outer.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.outer.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.outer.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join.filter.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.gby.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.gby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.gby.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.constant.expr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.plan.json.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.pcr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.partition.wise.fileformat2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.partition.multilevels.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.partition.boolexpr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.parquet.ctas.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.outer.join.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.order2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.predicate.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.optional.outer.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.optimize.nullscan.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.num.op.type.conv.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nullgroup4.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nullgroup4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nullgroup3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nullgroup2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nullgroup.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.notable.alias2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.notable.alias1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nonmr.fetch.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nonblock.op.deduplicate.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.noalias.subq1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.multiMapJoin2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.metadata.only.queries.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.metadataonly1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge.dynamic.partition5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge.dynamic.partition4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mergejoins.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.subquery.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.louter.join.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.load.dyn.part14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.load.dyn.part13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.oneskew.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.oneskew.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.oneskew.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.multiskew.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.multiskew.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.query.multiskew.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.list.bucket.dml.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.lineage1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit.pushdown.negative.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit.partition.metadataonly.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.vc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.nulls.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.merging.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.merge.multi.expressions.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.filters.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.alt.syntax.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join40.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join35.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join34.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join33.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join32.lessSize.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join32.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join31.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join29.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join28.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join18.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input42.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input32.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input31.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input30.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input2.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input24.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input11.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.innerjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.const.type.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.reducers.power.two.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.merge.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.map.operators.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.dyn.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.convert.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.stale.partitioned.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.stale.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.compression.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.bitmap.compression.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.bitmap.auto.partitioned.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.update.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.unused.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.self.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.partitioned.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.mult.tables.compact.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.mult.tables.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.multiple.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.file.format.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.empty.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.having2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.test.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.skew.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.resolution.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.ppr.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.ppd.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.position.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.map.ppr.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.map.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.distinct.samekey.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby6.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby6.map.skew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby6.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby5.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby5.map.skew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby5.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby4.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby4.map.skew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby4.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby3.noskew.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby3.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby3.map.skew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby3.map.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby3.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.noskew.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.map.skew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.map.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby1.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby1.map.skew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby1.map.nomap.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby1.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby1.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.gby.star.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.filter.join.breaktask2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.filter.join.breaktask.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.fetch.aggregation.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.explain.logical.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.explain.dependency.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.dynpart.sort.opt.vectorization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.dynpart.sort.optimization2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.dynpart.sort.optimization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.distinct.stats.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.decimal.udf2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.decimal.udf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.decimal.precision.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.database.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ctas.colname.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cross.product.check.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cross.product.check.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cross.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.create.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.create.genericudaf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.count.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.constprog.partitioner.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.constprog2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.constantPropagateForSubQuery.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.combine2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cast1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucket.groupby.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.binarysortable.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join.without.localtask.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join.reordering.values.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join.nulls.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join.filters.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join33.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join27.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join18.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join16.q.out</file>
      <file type="M">accumulo-handler.src.test.results.positive.accumulo.predicate.pushdown.q.out</file>
      <file type="M">accumulo-handler.src.test.results.positive.accumulo.queries.q.out</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">contrib.src.test.results.clientpositive.dboutput.q.out</file>
      <file type="M">contrib.src.test.results.clientpositive.udaf.example.avg.q.out</file>
      <file type="M">contrib.src.test.results.clientpositive.udaf.example.group.concat.q.out</file>
      <file type="M">contrib.src.test.results.clientpositive.udaf.example.max.q.out</file>
      <file type="M">contrib.src.test.results.clientpositive.udaf.example.max.n.q.out</file>
      <file type="M">contrib.src.test.results.clientpositive.udaf.example.min.q.out</file>
      <file type="M">contrib.src.test.results.clientpositive.udaf.example.min.n.q.out</file>
      <file type="M">hbase-handler.src.test.results.positive.hbase.ppd.key.range.q.out</file>
      <file type="M">hbase-handler.src.test.results.positive.hbase.queries.q.out</file>
      <file type="M">hbase-handler.src.test.results.positive.hbase.timestamp.q.out</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcDriver2.java</file>
      <file type="M">ql.src.test.queries.clientnegative.join.nonexistent.part.q</file>
      <file type="M">ql.src.test.queries.clientpositive.ambiguous.col.q</file>
      <file type="M">ql.src.test.queries.clientpositive.annotate.stats.groupby2.q</file>
      <file type="M">ql.src.test.queries.clientpositive.constantPropagateForSubQuery.q</file>
      <file type="M">ql.src.test.queries.clientpositive.filter.join.breaktask2.q</file>
      <file type="M">ql.src.test.queries.clientpositive.join.vc.q</file>
      <file type="M">ql.src.test.queries.clientpositive.mrr.q</file>
      <file type="M">ql.src.test.queries.clientpositive.optimize.nullscan.q</file>
      <file type="M">ql.src.test.queries.clientpositive.ppd.gby.join.q</file>
      <file type="M">ql.src.test.queries.clientpositive.ql.rewrite.gbtoidx.q</file>
      <file type="M">ql.src.test.queries.clientpositive.query.properties.q</file>
      <file type="M">ql.src.test.queries.clientpositive.subquery.exists.explain.rewrite.q</file>
      <file type="M">ql.src.test.queries.clientpositive.subquery.in.explain.rewrite.q</file>
      <file type="M">ql.src.test.results.clientnegative.join.nonexistent.part.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.ptf.negative.InvalidValueBoundary.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.allcolref.in.udf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter.partition.coltype.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ambiguous.col.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.filter.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.groupby.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.groupby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.join.pkfk.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.select.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ansi.sql.arithmetic.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.authorization.explain.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.autogen.colalias.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join13.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="8402" opendate="2014-10-8 00:00:00" fixdate="2014-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Orc pushing SARGs into delta files causing ArrayOutOfBoundsExceptions</summary>
      <description>ORC is in some instances pushing SARGs into delta files. This is wrong behavior in general as it may result in failing to pull the most recent version of a row. When the SARG is applied to a row that is deleted it causes an ArrayOutOfBoundsException because there is no data in the row.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.java</file>
    </fixedFiles>
  </bug>
  <bug id="8403" opendate="2014-10-8 00:00:00" fixdate="2014-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Build broken by datanucleus.org being offline</summary>
      <description>datanucleus.org is not available, making it impossible to download jars.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8407" opendate="2014-10-8 00:00:00" fixdate="2014-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[CBO] Handle filters with non-boolean return type</summary>
      <description>e.g. select * from src where 'foo';</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8408" opendate="2014-10-8 00:00:00" fixdate="2014-10-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hcat cli throws NPE when authorizer using new api is enabled</summary>
      <description>Hcat cli tries to authorize actions using the authorizer configured for hive-cli. When authorizer based on new authorization interface is used, it throws a NPE as it checks only for the old api based authorization implementation.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.pom.xml</file>
      <file type="M">hcatalog.core.src.main.java.org.apache.hive.hcatalog.cli.SemanticAnalysis.HCatSemanticAnalyzerBase.java</file>
      <file type="M">hcatalog.core.src.main.java.org.apache.hive.hcatalog.cli.SemanticAnalysis.CreateTableHook.java</file>
    </fixedFiles>
  </bug>
  <bug id="8409" opendate="2014-10-9 00:00:00" fixdate="2014-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SMB joins fail intermittently on tez</summary>
      <description>Flakiness with regard to SMB joins in tez. TEZ-1647 is required to complete the fix.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.BaseWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.GenTezWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.MergeJoinProc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.IOContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.tools.KeyValueInputMerger.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.SplitGrouper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.MergeFileRecordProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.CustomVertexConfiguration.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.CustomPartitionVertex.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="8413" opendate="2014-10-9 00:00:00" fixdate="2014-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[CBO] Handle ill-formed queries which have distinct, having in incorrect context</summary>
      <description>e.g., select hash (distinct key) from src;</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8421" opendate="2014-10-9 00:00:00" fixdate="2014-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>[CBO] Use OptiqSemanticException in error conditions</summary>
      <description>TestNegativeCliDriver</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8422" opendate="2014-10-9 00:00:00" fixdate="2014-10-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Turn on all join .q tests [Spark Branch]</summary>
      <description>With HIVE-8412, all join queries should work on Spark, whether they require a particular optimization or not.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8424" opendate="2014-10-9 00:00:00" fixdate="2014-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support fair scheduler user queue mapping in non-impersonation mode</summary>
      <description>Under non-impersonation mode, all MR jobs run as the hive system user. The default scheduler queue mapping is one queue per user. This is problematic for users who use the queues to regulate and track their MR resource usage.Yarn exposes an API to retrieve the fair scheduler queue mapping, which we can use to set the appropriate MR queue for the current user.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.common.src.main.java.org.apache.hadoop.hive.shims.HadoopShims.java</file>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
      <file type="M">shims.0.23.pom.xml</file>
      <file type="M">shims.0.20.src.main.java.org.apache.hadoop.hive.shims.Hadoop20Shims.java</file>
      <file type="M">shims.0.20S.src.main.java.org.apache.hadoop.hive.shims.Hadoop20SShims.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.HiveSessionImpl.java</file>
      <file type="M">itests.hive-unit-hadoop2.pom.xml</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="8427" opendate="2014-10-10 00:00:00" fixdate="2014-10-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive Streaming : secure streaming hangs leading to time outs.</summary>
      <description>Need to enable Thrift Sasl setting for secure mode communcation</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.streaming.src.java.org.apache.hive.hcatalog.streaming.HiveEndPoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="8452" opendate="2014-10-14 00:00:00" fixdate="2014-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cleanup handling of resource configuration for tez</summary>
      <description>Currently there's a way to configure container size for tez as well as java opts to start containers.However, if you only set container size and not java opts, we fall back to MR settings for java opts which will likely fail (killed by yarn).vcores is always taken from the MR settings. Need to have a way to overwrite that too.Tez 0.5 and onwards will automatically generate the right java opts string when the container/cpus are specified. This is preferable to falling back to MR.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="8455" opendate="2014-10-14 00:00:00" fixdate="2014-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Print Spark job progress format info on the console[Spark Branch]</summary>
      <description>We have add support of spark job status monitoring on HIVE-7439, but not print job progress format info on the console, user may confuse about what the progress info means, so I would like to add job progress format info here.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.SparkProgress.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.SparkJobStatus.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.SparkJobMonitor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.impl.SimpleSparkJobStatus.java</file>
    </fixedFiles>
  </bug>
  <bug id="8462" opendate="2014-10-14 00:00:00" fixdate="2014-10-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO duplicates columns</summary>
      <description>select *, rank() over(partition by key order by value) as rr from src1Original plan appears to be incorrect:HiveProjectRel(key=[$0], value=[$1], (tok_function rank (tok_windowspec (tok_partitioningspec (tok_distributeby (tok_table_or_col key)) (tok_orderby (tok_tabsortcolnameasc (tok_table_or_col value))))))=[$5], rr=[$5]) HiveProjectRel(key=[$0], value=[$1], block__offset__inside__file=[$2], input__file__name=[$3], row__id=[$4], (tok_function rank (tok_windowspec (tok_partitioningspec (tok_distributeby (tok_table_or_col key)) (tok_orderby (tok_tabsortcolnameasc (tok_table_or_col value))))))=[rank() OVER (PARTITION BY $0 ORDER BY $1 ROWS BETWEEN 2147483647 FOLLOWING AND 2147483647 PRECEDING)]) HiveTableScanRel(table=[[default.src1]])and final AST has TOK_SELEXPR . TOK_TABLE_OR_COL $hdt$_0 (tok_function rank (tok_windowspec (tok_partitioningspec (tok_distributeby (tok_table_or_col key)) (tok_orderby (tok_tabsortcolnameasc (tok_table_or_col value)))))) (tok_function rank (tok_windowspec (tok_partitioningspec (tok_distributeby (tok_table_or_col key)) (tok_orderby (tok_tabsortcolnameasc (tok_table_or_col value)))))) TOK_SELEXPR . TOK_TABLE_OR_COL $hdt$_0 (tok_function rank (tok_windowspec (tok_partitioningspec (tok_distributeby (tok_table_or_col key)) (tok_orderby (tok_tabsortcolnameasc (tok_table_or_col value)))))) rr</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.cbo.correctness.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.cbo.correctness.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8463" opendate="2014-10-15 00:00:00" fixdate="2014-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add numPartitions info to SparkEdgeProperty [Spark Branch]</summary>
      <description>When we are debugging the Spark branch, it's better if we can add the number of partitions info associated with SparkEdgeProperty in the "explain" result.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.spark.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.left.outer.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.decimal.aggregate.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.data.types.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.cast.constant.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.timestamp.funcs.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.shufflejoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.nested.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorization.part.project.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorization.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorization.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorization.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.24.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union33.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union30.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union29.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union28.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.transform.ppr2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.transform.ppr1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.temp.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.subquery.multiinsert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.subquery.in.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.subquery.exists.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sort.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.skewjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.script.pipe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ppd.transform.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ppd.multi.insert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.parallel.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.parallel.join0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.parallel.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.order2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.order.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.orc.analyze.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.optimize.nullscan.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.move.tasks.share.dependencies.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.lateral.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.gby3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.gby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.gby.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multigroupby.singlemr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.metadata.only.queries.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.merge2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.merge1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.mapreduce2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.mapreduce1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.limit.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join.nullsafe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join27.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join15.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExplainTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.SparkWork.java</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.column.access.stats.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.count.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ctas.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.disable.merge.for.bucketing.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.escape.clusterby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.escape.distributeby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.escape.orderby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.escape.sortby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.map.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.noskew.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby7.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby7.map.multi.single.reducer.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby7.map.skew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby7.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.cube1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.multi.single.reducer.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.multi.single.reducer2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.multi.single.reducer3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.position.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.rollup1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.sort.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.sort.skew.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.innerjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input1.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.insert.into1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.insert.into2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.insert.into3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join13.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="8465" opendate="2014-10-15 00:00:00" fixdate="2014-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix some minor test fails on trunk</summary>
      <description>org.apache.hive.beeline.TestSchemaTool.testSchemaInitorg.apache.hive.beeline.TestSchemaTool.testSchemaUpgradeorg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parallel&amp;#8211; due to HIVE-2828org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_custom_keyorg.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_custom_key2org.apache.hadoop.hive.cli.TestHBaseCliDriver.testCliDriver_hbase_custom_key3</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.AbstractSerDe.java</file>
      <file type="M">metastore.scripts.upgrade.postgres.upgrade.order.postgres</file>
      <file type="M">metastore.scripts.upgrade.oracle.upgrade.order.oracle</file>
      <file type="M">metastore.scripts.upgrade.mysql.upgrade.order.mysql</file>
      <file type="M">metastore.scripts.upgrade.mssql.upgrade.order.mssql</file>
      <file type="M">metastore.scripts.upgrade.derby.upgrade.order.derby</file>
      <file type="M">hbase-handler.src.java.org.apache.hadoop.hive.hbase.HBaseSerDeParameters.java</file>
    </fixedFiles>
  </bug>
  <bug id="8478" opendate="2014-10-15 00:00:00" fixdate="2014-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorized Reduce-Side Group By doesn&amp;#39;t handle Decimal type correctly</summary>
      <description>Note that DecimalColumnVector is different than LongColumnVector because it keeps (an instance) reference to a Decimal128 class whereas the latter stores a long primitive value. So, trouble if you set the reference instead of updating the object.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorGroupKeyHelper.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8479" opendate="2014-10-16 00:00:00" fixdate="2014-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tez sessions cannot change queues once assigned to one within a CLI session</summary>
      <description>Observed during execution. Once associated with a queue, the CLI session cannot change queues.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.tez.TestTezSessionState.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.tez.TestTezSessionPool.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezSessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.java</file>
    </fixedFiles>
  </bug>
  <bug id="8485" opendate="2014-10-16 00:00:00" fixdate="2014-1-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HMS on Oracle incompatibility</summary>
      <description>Oracle does not distinguish between empty strings and NULL,which proves problematic for DataNucleus.In the event a user creates a table with some property stored as an empty string the table will no longer be accessible.i.e. TBLPROPERTIES ('serialization.null.format'='')If they try to select, describe, drop, etc the client prints the following exception.ERROR ql.Driver: FAILED: SemanticException &amp;#91;Error 10001&amp;#93;: Table not found &lt;table name&gt;The work around for this was to go into the hive metastore on the Oracle database and replace NULL with some other string. Users could then drop the tables or alter their data to use the new null format they just set.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.ObjectStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.MetaStoreUtils.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.MetaStoreDirectSql.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="8489" opendate="2014-10-16 00:00:00" fixdate="2014-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add sanity check to dynamic partition pruning</summary>
      <description>For debugging/safety it would help to make sure we received the right number of events from tez tasks. This is always supposed to be the case, but would be really hard to debug if something goes wrong.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DynamicPartitionPruner.java</file>
    </fixedFiles>
  </bug>
  <bug id="8490" opendate="2014-10-16 00:00:00" fixdate="2014-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Constant folding should happen before partition pruning</summary>
      <description>so that partition pruning see simplified expressions and present simpler expressions to metastore</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.Optimizer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8491" opendate="2014-10-16 00:00:00" fixdate="2014-10-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix build name in ptest pre-commit message</summary>
      <description>HIVE-8351 added the build name to the pre-commit message, but included a carriage return in the middle.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.src.main.java.org.apache.hive.ptest.execution.JIRAService.java</file>
    </fixedFiles>
  </bug>
  <bug id="8492" opendate="2014-10-17 00:00:00" fixdate="2014-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enhance Constant Folding to propagate constants for simple expressions</summary>
      <description>currently it propagates only for projects, can be enhanced to propagate for simple expressions like casts, e.g,SELECT src1.key, src1.key + 1, src2.value FROM src src1 join src src2 ON src1.key = src2.key AND cast(src1.key as double) = 86;</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.constprog2.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.constprog2.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
    </fixedFiles>
  </bug>
  <bug id="8495" opendate="2014-10-17 00:00:00" fixdate="2014-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add progress bar for Hive on Tez queries</summary>
      <description>Build a "Progress bar" to provide overall progress on running tasks.Progress is calculated as : (Completed tasks) / (Total number of tasks)</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.log.PerfLogger.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezJobMonitor.java</file>
      <file type="M">ql.pom.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="8496" opendate="2014-10-17 00:00:00" fixdate="2014-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Re-enable statistics [Spark Branch]</summary>
      <description>AnnotatedWithStatistics is not activated due to a recent merge, and hence the SetSparkReducerParallelism is not activated either. This caused Hive to always use one reducer. We should re-enable statistics.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.spark.join11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.left.outer.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.decimal.aggregate.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.data.types.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vector.cast.constant.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.timestamp.funcs.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.shufflejoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.nested.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorization.part.project.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorization.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorization.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorization.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.24.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.remove.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union33.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union30.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union28.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.transform.ppr2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.transform.ppr1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.transform1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.temp.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.subquery.multiinsert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.subquery.in.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.subquery.exists.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sort.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.skewjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.script.pipe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ppd.transform.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ppd.multi.insert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.parallel.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.parallel.join0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.parallel.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.order2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.order.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.optimize.nullscan.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.move.tasks.share.dependencies.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.lateral.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.gby3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.gby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.gby.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multi.insert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.multigroupby.singlemr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.metadata.only.queries.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.merge2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.merge1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.mapreduce2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.mapreduce1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.load.dyn.part1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.limit.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join.nullsafe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join27.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join12.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.Optimizer.java</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.sortmerge.join.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.bucket4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.column.access.stats.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.count.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ctas.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.disable.merge.for.bucketing.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.escape.clusterby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.escape.distributeby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.escape.orderby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.escape.sortby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.map.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby3.noskew.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby7.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby7.map.multi.single.reducer.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby7.map.skew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby7.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.cube1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.multi.single.reducer.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.multi.single.reducer2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.multi.single.reducer3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.position.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.rollup1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.sort.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.sort.skew.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.innerjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input1.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input.part2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.insert1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.insert.into1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.insert.into2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.insert.into3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join10.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="8498" opendate="2014-10-17 00:00:00" fixdate="2014-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Insert into table misses some rows when vectorization is enabled</summary>
      <description>Following is a small reproducible case for the issuecreate table orc1 stored as orc tblproperties("orc.compress"="ZLIB") as select rn from ( select cast(1 as int) as rn from src limit 1 union all select cast(100 as int) as rn from src limit 1 union all select cast(10000 as int) as rn from src limit 1 ) t;create table orc_rn1 (rn int);create table orc_rn2 (rn int);create table orc_rn3 (rn int);// These inserts should produce 3 rows but only 1 row is producedfrom orc1 ainsert overwrite table orc_rn1 select a.* where a.rn &lt; 100insert overwrite table orc_rn2 select a.* where a.rn &gt;= 100 and a.rn &lt; 1000insert overwrite table orc_rn3 select a.* where a.rn &gt;= 1000;select * from orc_rn1union allselect * from orc_rn2union allselect * from orc_rn3;The expected output of the query is110010000But with vectorization enabled we get1</description>
      <version>0.13.1,0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.vector.TestVectorFilterOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorFilterOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="85" opendate="2008-11-27 00:00:00" fixdate="2008-12-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>separate compression options for different output types</summary>
      <description>currently hive uses mapred.output.compress to determine compression for all output files. however not all files are final output. at least three different kinds of output files are generated:1. intermediate output files for next map-reduce job2. files targeted for result hdfs directories or hive tables/partitions (which are just hdfs dirs)3. files written to user local directories (downloading results)the plan is to provide three separate options for controlling 1,2,3 separately. we may want to split (2) in case compression is determined by table metadata (and not session options).</description>
      <version>None</version>
      <fixedVersion>0.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.input.dynamicserde.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subq2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subq.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.quote1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.notable.alias2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.notable.alias1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.noalias.subq1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapreduce6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapreduce5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapreduce4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapreduce3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapreduce2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapreduce1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.testxpath3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.testxpath2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.testxpath.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.testsequencefile.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part1.q.out</file>
      <file type="M">CHANGES.txt</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">conf.hive-default.xml</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExplainTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FileSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.fileSinkDesc.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestExecDriver.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestOperators.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.QTestUtil.java</file>
      <file type="M">ql.src.test.queries.clientpositive.groupby7.q</file>
      <file type="M">ql.src.test.results.clientpositive.case.sensitivity.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cast1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby1.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby1.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby3.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby4.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby5.map.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input11.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input14.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input1.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input2.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input3.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.inputddl1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.inputddl2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.inputddl3.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="8500" opendate="2014-10-17 00:00:00" fixdate="2014-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>beeline does not need to set hive.aux.jars.path</summary>
      <description>Since beeline may be run from a host not running HS2, there is no reason for it to set hive.aux.jars.path property. Beeline doesn't need these jars, HS2 does and should use hive.aux.jars.path property populated with jars on HS2 host (not the ones sent over by beeline connection.)</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">bin.hive</file>
    </fixedFiles>
  </bug>
  <bug id="8501" opendate="2014-10-17 00:00:00" fixdate="2014-10-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix CBO to use indexes when GenericUDFBridge is applied</summary>
      <description>previous https://issues.apache.org/jira/browse/HIVE-8389 assumes thatwe have predicate: ((UDFToDouble(key) &gt; UDFToDouble(80)) and (UDFToDouble(key) &lt; UDFToDouble(100))) for example.This does not work for the case when we have predicate: ((UDFToDouble(key) &gt; 80.0) and (UDFToDouble(key) &lt; 100.0))</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8518" opendate="2014-10-20 00:00:00" fixdate="2014-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compile time skew join optimization returns duplicated results</summary>
      <description>Compile time skew join optimization clones the join operator tree and unions the results.The problem here is that we don't properly insert the predicate for the cloned join (relying on an assert statement).To reproduce the issue, run the simple query:select * from tbl1 join tbl2 on tbl1.key=tbl2.key;And suppose there's some skew in tbl1 (specify skew with CREATE or ALTER statement).Duplicated results will be returned if you set hive.optimize.skewjoin.compiletime=true.</description>
      <version>0.14.0</version>
      <fixedVersion>1.0.2,1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.SkewJoinOptimizer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8543" opendate="2014-10-21 00:00:00" fixdate="2014-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compactions fail on metastore using postgres</summary>
      <description>The worker fails to update the stats when the metastore is using Postgres as the RDBMS. org.postgresql.util.PSQLException: ERROR: relation "tab_col_stats" does not exist</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.txn.TxnHandler.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="8546" opendate="2014-10-21 00:00:00" fixdate="2014-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Handle "add archive scripts.tar.gz" in Tez</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezSessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="8547" opendate="2014-10-21 00:00:00" fixdate="2014-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO and/or constant propagation breaks partition_varchar2 test</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="8550" opendate="2014-10-21 00:00:00" fixdate="2014-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive cannot load data into partitioned table with Unicode key</summary>
      <description>Steps to reproduce:1) Copy the file partitioned.txt to the root folder of your HDFS root dir. Copy the two hql files to your local directory.2) Open Hive CLI.3) Run:hive&gt; source &lt;path to CreatePartitionedTable.hql&gt;;4) Run hive&gt; source &lt;path to LoadIntoPartitionedTable.hql&gt;;The following error will be shown:hive&gt; source C:\Scripts\partition\LoadIntoPartitionedTable.hql;Loading data to table default.mypartitioned partition (tag=ä¶µ)Failed with exception nullFAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MoveTask</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.scripts.upgrade.mssql.upgrade-0.13.0-to-0.14.0.mssql.sql</file>
      <file type="M">metastore.scripts.upgrade.mssql.hive-schema-0.15.0.mssql.sql</file>
      <file type="M">metastore.scripts.upgrade.mssql.hive-schema-0.14.0.mssql.sql</file>
    </fixedFiles>
  </bug>
  <bug id="8552" opendate="2014-10-21 00:00:00" fixdate="2014-10-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove hard code of offline and make addHost api public</summary>
      <description>I've seen a number of issues where offline mode causes issues for slaves. Let's not hardcode offline mode. This can be specified in the properties file if needed.Additionally the addHost method needs to be public if other ContextProviders are to be specified, such as an Azure context.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.src.test.java.org.apache.hive.ptest.execution.TestScripts.testBatch.approved.txt</file>
      <file type="M">testutils.ptest2.src.test.java.org.apache.hive.ptest.execution.TestScripts.testAlternativeTestJVM.approved.txt</file>
      <file type="M">testutils.ptest2.src.main.resources.batch-exec.vm</file>
      <file type="M">testutils.ptest2.src.main.java.org.apache.hive.ptest.execution.context.ExecutionContext.java</file>
    </fixedFiles>
  </bug>
  <bug id="8555" opendate="2014-10-22 00:00:00" fixdate="2014-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Too many casts results in loss of original string representation for constant</summary>
      <description>SELECT key, value FROM src WHERE key = cast(86 as double);86.0 val_86With constant propagate off we get different and correct result.set hive.optimize.constant.propagation=false;SELECT key, value FROM src WHERE key = cast(86 as double);86 val_86</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.constprog.type.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.constprog.type.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ExprNodeConstantDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConstantPropagateProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
    </fixedFiles>
  </bug>
  <bug id="8556" opendate="2014-10-22 00:00:00" fixdate="2014-11-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>introduce overflow control and sanity check to BytesBytesMapJoin</summary>
      <description>When stats are incorrect, negative or very large number can be passed to the map</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.HashTableLoader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.MapJoinBytesTableContainer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.BytesBytesMultiHashMap.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.HashTableLoader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mapjoin.MapJoinMemoryExhaustionHandler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.HashTableLoader.java</file>
    </fixedFiles>
  </bug>
  <bug id="8558" opendate="2014-10-22 00:00:00" fixdate="2014-10-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: enable n-way joins after CBO join reordering</summary>
      <description>With CBO, we disable n-way joins. But for consecutive tables we can safely collapse into n-way joins. For e.g this is safe to collapse:select p1.p_name, p2.p_name, p3.p_name from part p1 join part p2 on p1.p_name = p2.p_name join part p3 on p3.p_name = p1.p_name;whereas, we shouldn't reorder in this case:select p1.p_name, p2.p_name, p3.p_name from part p1 join part p2 on p1.p_name = p2.p_name join part p3 on p3.p_size = p1.p_size and p3.p_size = p2.p_size join part p4 on p1.p_name = p4.p_name;</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8582" opendate="2014-10-23 00:00:00" fixdate="2014-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Outer Join Simplification is broken</summary>
      <description>CLEAR LIBRARY CACHE</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.stats.HiveRelMdRowCount.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.rules.HivePushFilterPastJoinRule.java</file>
    </fixedFiles>
  </bug>
  <bug id="8583" opendate="2014-10-23 00:00:00" fixdate="2014-8-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HIVE-8341 Cleanup &amp; Test for hive.script.operator.env.blacklist</summary>
      <description>alangates added the following in HIVE-8341: String bl = hconf.get(HiveConf.ConfVars.HIVESCRIPT_ENV_BLACKLIST.toString()); if (bl != null &amp;&amp; bl.length() &gt; 0) { String[] bls = bl.split(","); for (String b : bls) { b.replaceAll(".", "_"); blackListedConfEntries.add(b); } }The replaceAll call is confusing as its result is not used at all.This patch contains the following: Adds reading of default value for HIVESCRIPT_ENV_BLACKLIST Lets blackListed take a Configuration job as parameter which allowed me to add a test for this Tabs to Spaces conversion</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestOperators.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ScriptOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="8586" opendate="2014-10-24 00:00:00" fixdate="2014-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Record counters aren&amp;#39;t updated correctly for vectorized queries</summary>
      <description>Counts batches not rows.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorMapOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="8588" opendate="2014-10-24 00:00:00" fixdate="2014-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sqoop REST endpoint fails to send appropriate JDBC driver to the cluster</summary>
      <description>This is originally discovered by deepeshWhen running a Sqoop integration test from WebHCatcurl --show-error -d command="export -libjars hdfs:///tmp/mysql-connector-java.jar --connect jdbc:mysql://deepesh-c6-1.cs1cloud.internal/sqooptest --username sqoop --password passwd --export-dir /tmp/templeton_test_data/sqoop --table person" -d statusdir=sqoop.output -X POST "http://deepesh-c6-1.cs1cloud.internal:50111/templeton/v1/sqoop?user.name=hrt_qa"the job is failing with the following error:$ hadoop fs -cat /user/hrt_qa/sqoop.output/stderr14/10/15 23:52:53 INFO sqoop.Sqoop: Running Sqoop version: 1.4.5.2.2.0.0-89714/10/15 23:52:53 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.14/10/15 23:52:54 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.14/10/15 23:52:54 INFO tool.CodeGenTool: Beginning code generation14/10/15 23:52:54 ERROR sqoop.Sqoop: Got exception running Sqoop: java.lang.RuntimeException: Could not load db driver class: com.mysql.jdbc.Driverjava.lang.RuntimeException: Could not load db driver class: com.mysql.jdbc.Driver at org.apache.sqoop.manager.SqlManager.makeConnection(SqlManager.java:848) at org.apache.sqoop.manager.GenericJdbcManager.getConnection(GenericJdbcManager.java:52) at org.apache.sqoop.manager.SqlManager.execute(SqlManager.java:736) at org.apache.sqoop.manager.SqlManager.execute(SqlManager.java:759) at org.apache.sqoop.manager.SqlManager.getColumnInfoForRawQuery(SqlManager.java:269) at org.apache.sqoop.manager.SqlManager.getColumnTypesForRawQuery(SqlManager.java:240) at org.apache.sqoop.manager.SqlManager.getColumnTypes(SqlManager.java:226) at org.apache.sqoop.manager.ConnManager.getColumnTypes(ConnManager.java:295) at org.apache.sqoop.orm.ClassWriter.getColumnTypes(ClassWriter.java:1773) at org.apache.sqoop.orm.ClassWriter.generate(ClassWriter.java:1578) at org.apache.sqoop.tool.CodeGenTool.generateORM(CodeGenTool.java:96) at org.apache.sqoop.tool.ExportTool.exportTable(ExportTool.java:64) at org.apache.sqoop.tool.ExportTool.run(ExportTool.java:100) at org.apache.sqoop.Sqoop.run(Sqoop.java:143) at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70) at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:179) at org.apache.sqoop.Sqoop.runTool(Sqoop.java:218) at org.apache.sqoop.Sqoop.runTool(Sqoop.java:227) at org.apache.sqoop.Sqoop.main(Sqoop.java:236)Note that the Sqoop tar bundle does not contain the JDBC connector jar. I think the problem here maybe that the mysql connector jar added to libjars isn't available to the Sqoop tool which first connects to the database through JDBC driver to collect some table information before running the MR job. libjars will only add the connector jar for the MR job and not the local one.NO PRECOMMIT TESTS</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.tool.TempletonUtils.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.tool.LaunchMapper.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.tool.JobSubmissionConstants.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.SqoopDelegator.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.Server.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.LauncherDelegator.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.JarDelegator.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.AppConfig.java</file>
      <file type="M">hcatalog.src.test.e2e.templeton.tests.jobsubmission.conf</file>
      <file type="M">hcatalog.src.test.e2e.templeton.deployers.env.sh</file>
      <file type="M">hcatalog.src.test.e2e.templeton.deployers.deploy.e2e.artifacts.sh</file>
      <file type="M">hcatalog.src.test.e2e.templeton.deployers.config.webhcat.webhcat-site.xml</file>
      <file type="M">hcatalog.src.test.e2e.templeton.deployers.clean.file.system.sh</file>
      <file type="M">hcatalog.src.test.e2e.templeton.README.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8589" opendate="2014-10-24 00:00:00" fixdate="2014-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TPCDS query 75 fails with tez</summary>
      <description>WITH all_sales AS ( SELECT d_year ,i_brand_id ,i_class_id ,i_category_id ,i_manufact_id ,SUM(sales_cnt) AS sales_cnt ,SUM(sales_amt) AS sales_amt FROM (SELECT d_year ,i_brand_id ,i_class_id ,i_category_id ,i_manufact_id ,cs_quantity - COALESCE(cr_return_quantity,0) AS sales_cnt ,cs_ext_sales_price - COALESCE(cr_return_amount,0.0) AS sales_amt FROM catalog_sales JOIN item ON i_item_sk=cs_item_sk JOIN date_dim ON d_date_sk=cs_sold_date_sk LEFT JOIN catalog_returns ON (cs_order_number=cr_order_number AND cs_item_sk=cr_item_sk) WHERE i_category='Sports' UNION ALL SELECT d_year ,i_brand_id ,i_class_id ,i_category_id ,i_manufact_id ,ss_quantity - COALESCE(sr_return_quantity,0) AS sales_cnt ,ss_ext_sales_price - COALESCE(sr_return_amt,0.0) AS sales_amt FROM store_sales JOIN item ON i_item_sk=ss_item_sk JOIN date_dim ON d_date_sk=ss_sold_date_sk LEFT JOIN store_returns ON (ss_ticket_number=sr_ticket_number AND ss_item_sk=sr_item_sk) WHERE i_category='Sports' UNION ALL SELECT d_year ,i_brand_id ,i_class_id ,i_category_id ,i_manufact_id ,ws_quantity - COALESCE(wr_return_quantity,0) AS sales_cnt ,ws_ext_sales_price - COALESCE(wr_return_amt,0.0) AS sales_amt FROM web_sales JOIN item ON i_item_sk=ws_item_sk JOIN date_dim ON d_date_sk=ws_sold_date_sk LEFT JOIN web_returns ON (ws_order_number=wr_order_number AND ws_item_sk=wr_item_sk) WHERE i_category='Sports') sales_detail GROUP BY d_year, i_brand_id, i_class_id, i_category_id, i_manufact_id) SELECT prev_yr.d_year AS prev_year ,curr_yr.d_year AS year ,curr_yr.i_brand_id ,curr_yr.i_class_id ,curr_yr.i_category_id ,curr_yr.i_manufact_id ,prev_yr.sales_cnt AS prev_yr_cnt ,curr_yr.sales_cnt AS curr_yr_cnt ,curr_yr.sales_cnt-prev_yr.sales_cnt AS sales_cnt_diff ,curr_yr.sales_amt-prev_yr.sales_amt AS sales_amt_diff FROM all_sales curr_yr, all_sales prev_yr WHERE curr_yr.i_brand_id=prev_yr.i_brand_id AND curr_yr.i_class_id=prev_yr.i_class_id AND curr_yr.i_category_id=prev_yr.i_category_id AND curr_yr.i_manufact_id=prev_yr.i_manufact_id AND curr_yr.d_year=2002 AND prev_yr.d_year=2002-1 AND CAST(curr_yr.sales_cnt AS DECIMAL(17,2))/CAST(prev_yr.sales_cnt AS DECIMAL(17,2))&lt;0.9 ORDER BY sales_cnt_diff limit 100throws a null pointer exception when executed via tez.java.lang.IllegalArgumentException: Output vertex null doesn't exist! at org.apache.tez.dag.api.DAG.addEdge(DAG.java:236) at org.apache.hadoop.hive.ql.exec.tez.TezTask.build(TezTask.java:340) at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:152) at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:161) at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85) at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1604) at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1364) at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1177) at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1004) at org.apache.hadoop.hive.ql.Driver.run(Driver.java:994) at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:247) at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:199) at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:410) at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:783) at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:677) at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:616) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.RunJar.main(RunJar.java:212)</description>
      <version>0.14.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.GenTezWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.java</file>
    </fixedFiles>
  </bug>
  <bug id="8596" opendate="2014-10-24 00:00:00" fixdate="2014-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HiveServer2 dynamic service discovery: ZK throws too many connections error</summary>
      <description>2014-10-23 07:55:44,221 - WARN [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@193] - Too many connections from /172.31.47.11 - max is 60</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.ZooKeeperHiveClientHelper.java</file>
    </fixedFiles>
  </bug>
  <bug id="8597" opendate="2014-10-24 00:00:00" fixdate="2014-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>SMB join small table side should use the same set of serialized payloads across tasks</summary>
      <description>Each task sees all splits belonging to the bucket being processed by the task. At the moment, we end up using different instances of the same serialized split which adds unnecessary memory pressure.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.CustomPartitionVertex.java</file>
    </fixedFiles>
  </bug>
  <bug id="8598" opendate="2014-10-24 00:00:00" fixdate="2014-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Push constant filters through joins</summary>
      <description>Will make NullScanOptimizer more effective.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.optimize.nullscan.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.optimize.nullscan.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.optimize.nullscan.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.ppd.OpProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="8599" opendate="2014-10-24 00:00:00" fixdate="2014-10-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add InterfaceAudience annotations to spark-client [Spark Branch]</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.SparkClientFactory.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.SparkClient.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.RemoteDriver.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.ShuffleWriteMetrics.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.ShuffleReadMetrics.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.Metrics.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.InputMetrics.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.DataReadMethod.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.MetricsCollection.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.JobHandle.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.JobContext.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.Job.java</file>
      <file type="M">spark-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="86" opendate="2008-11-29 00:00:00" fixdate="2008-12-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>drop table should not delete data for external tables</summary>
      <description>We should not delete data for external tables.</description>
      <version>None</version>
      <fixedVersion>0.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.TestHiveMetaStore.java</file>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.TestDrop.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.RWTable.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8614" opendate="2014-10-27 00:00:00" fixdate="2014-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade hive to use tez version 0.5.2-SNAPSHOT</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.5.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.java</file>
      <file type="M">pom.xml</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8615" opendate="2014-10-27 00:00:00" fixdate="2014-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>beeline csv,tsv outputformat needs backward compatibility mode</summary>
      <description>Changes in HIVE-7390 break backward compatibility for beeline csv and tsv formats.This can cause problems for users upgrading to hive 0.14, if they have code for parsing the old output format. Instead of removing the old format in this release, we should consider it deprecated and support it in a few releases before removing it completely.Incompatible Changes in the tsv and csv formats- Old format quoted every field. New format quotes only fields that contain a delimiter or the quoteing char. Old format quoted using single quotes, new format quotes using double quotes Old format didn't escape quotes in a field (a bug). New format does escape the quotes</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.beeline.TestBeeLineWithArgs.java</file>
      <file type="M">beeline.src.main.resources.BeeLine.properties</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.SeparatedValuesOutputFormat.java</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.BeeLineOpts.java</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.BeeLine.java</file>
    </fixedFiles>
  </bug>
  <bug id="8616" opendate="2014-10-27 00:00:00" fixdate="2014-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>convert joinOp to MapJoinOp and generate MapWorks only [Spark Branch]</summary>
      <description>This is a sub-task of map join on spark. The parent jira ishttps://issues.apache.org/jira/browse/HIVE-7613</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.SparkCompiler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.GenSparkWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.GenSparkUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.spark.GenSparkProcContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor.java</file>
    </fixedFiles>
  </bug>
  <bug id="8617" opendate="2014-10-27 00:00:00" fixdate="2014-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Turn on all join .q tests #2 [Spark Branch]</summary>
      <description>There are still a few tests need to turned on (most of them need SORT_QUERY_RESULTS after we resolved HIVE-8422:auto_join26bucketmapjoin7date_join1join40skewjoinopt2vector_decimal_mapjoinvector_mapjoin_reduceauto_join_without_localtaskmapjoin1</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8619" opendate="2014-10-27 00:00:00" fixdate="2014-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO causes some more type problems</summary>
      <description>On recent rerun, tests such as char_cast, decimal_2, literal_double, vector_elt (incl. in Tez), udf4, vector_decimal_math_funcs have changes in results it looks like something is broken with types again; ".0" suffix disappeared in some cases (in char_cast it's probably the simplest to see), number formats changed when casts are involved.Also, windowing_expressions and couple more tests fail due to attempts to cast Double to Int writables, might be the same issue.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.ASTBuilder.java</file>
    </fixedFiles>
  </bug>
  <bug id="8621" opendate="2014-10-27 00:00:00" fixdate="2014-11-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Dump small table join data for map-join [Spark Branch]</summary>
      <description>This jira aims to re-use a slightly modified approach of map-reduce distributed cache in spark to dump map-joined small tables as hash tables onto spark DFS cluster. This is a sub-task of map-join for spark https://issues.apache.org/jira/browse/HIVE-7613This can use the baseline patch for map-joinhttps://issues.apache.org/jira/browse/HIVE-8616The original thought process was to use broadcast variable concept in spark, for the small tables. The number of broadcast variables that must be created is m x n where'm' is the number of small tables in the (m+1) way join and n is the number of buckets of tables. If unbucketed, n=1But it was discovered that objects compressed with kryo serialization on disk, can occupy 20X or more when deserialized in-memory. For bucket join, the spark Driver has to hold all the buckets (for bucketed tables) in-memory (to provide for fault-tolerance against Executor failures) although the executors only need individual buckets in their memory. So the broadcast variable approach may not be the right approach.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.HashTableSinkOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="8622" opendate="2014-10-27 00:00:00" fixdate="2014-11-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Split map-join plan into 2 SparkTasks in 3 stages [Spark Branch]</summary>
      <description>This is a sub-task of map-join for spark https://issues.apache.org/jira/browse/HIVE-7613This can use the baseline patch for map-joinhttps://issues.apache.org/jira/browse/HIVE-8616</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.SparkWork.java</file>
    </fixedFiles>
  </bug>
  <bug id="8623" opendate="2014-10-27 00:00:00" fixdate="2014-11-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement HashTableLoader for Spark map-join [Spark Branch]</summary>
      <description>This is a sub-task of map-join for spark https://issues.apache.org/jira/browse/HIVE-7613This can use the baseline patch for map-joinhttps://issues.apache.org/jira/browse/HIVE-8616</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.HashTableLoaderFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainerSerDe.java</file>
    </fixedFiles>
  </bug>
  <bug id="8624" opendate="2014-10-27 00:00:00" fixdate="2014-10-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Record counters don&amp;#39;t work with Tez container reuse</summary>
      <description>Problem is that the counters aren't re-initialized when containers are re-used.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FileSinkOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="8629" opendate="2014-10-28 00:00:00" fixdate="2014-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Streaming / ACID : hive cli session creation takes too long and times out if execution engine is tez</summary>
      <description>When creating a hive session to run basic "alter table create partition" queries, the session creation takes too long (more than 5 sec) if the hive execution engine is set to tez.Since the streaming clients dont care about Tez , it can explicitly override the setting to mr.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.streaming.src.java.org.apache.hive.hcatalog.streaming.HiveEndPoint.java</file>
    </fixedFiles>
  </bug>
  <bug id="8631" opendate="2014-10-28 00:00:00" fixdate="2014-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compressed transaction list cannot be parsed in job.xml</summary>
      <description>HIVE-8341 added code to compress the transaction list in the JobConf when it reaches a certain size. This breaks when the JobConf is converted to job.xml and sent to MR. The special characters are not correctly escaped. The proposed fix is to back out the compression (not the changes to ScriptOperator) for now and look later at compressing/encoding it in a way that works with job.xml.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">common.src.test.org.apache.hadoop.hive.common.TestValidTxnImpl.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.common.ValidTxnListImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="8634" opendate="2014-10-28 00:00:00" fixdate="2014-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HiveServer2 fair scheduler queue mapping doesn&amp;#39;t handle the secondary groups rules correctly</summary>
      <description>The fair scheduler queue refresh in HiveServer2 (for non-impersonation mode), doesn't handle the primary/secondary queue mappings correctly. It's not reading primary and secondary rules from the scheduler rule file.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
      <file type="M">itests.hive-unit-hadoop2.src.test.java.org.apache.hive.jdbc.TestSchedulerQueue.java</file>
    </fixedFiles>
  </bug>
  <bug id="8635" opendate="2014-10-28 00:00:00" fixdate="2014-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: ambiguous_col negative test no longer fails</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8637" opendate="2014-10-28 00:00:00" fixdate="2014-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>In insert into X select from Y, table properties from X are clobbering those from Y</summary>
      <description>With a query like:insert into table X select * from Y;the table properties from table X are being sent to the input formats for table Y.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.HiveInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
    </fixedFiles>
  </bug>
  <bug id="8641" opendate="2014-10-28 00:00:00" fixdate="2014-10-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Disable skew joins in tez.</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.Optimizer.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8643" opendate="2014-10-29 00:00:00" fixdate="2014-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DDL operations via WebHCat with doAs parameter in secure cluster fail</summary>
      <description>webhcat handles DDL command by forking to 'hcat', i.e. HCatCliThis starts a session.SessionState.start() creates scratch dir based on current user namevia startSs.createSessionDirs(sessionUGI.getShortUserName());This UGI is not aware of doAs param, so the name of the dir always ends up 'hcat', but because a delegation token is generated in WebHCat for HDFS access, the owner of the scratch dir is the calling user. Thus next time a session is started (because of a new DDL call from different user), it ends up trying to use the same scratch dir but cannot as it has 700 permission set.We need to pass in doAs user into SessionState</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.common-secure.src.main.java.org.apache.hadoop.hive.shims.HadoopShimsSecure.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.ProxyUserAuthenticator.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.SecureProxySupport.java</file>
    </fixedFiles>
  </bug>
  <bug id="8647" opendate="2014-10-29 00:00:00" fixdate="2014-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HIVE-8186 causes addition of same child operator multiple times</summary>
      <description>With HIVE-8186, the same child operator ends up getting added multiple times to the map operator when processing multiple files for the same alias in the map task. I believe we should also eliminate having so many mapOpCtx for the same child operator and instead should have only 1 per alias. However, that looks like a big change that may not be needed before 0.14 goes out.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="8649" opendate="2014-10-29 00:00:00" fixdate="2014-11-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Increase level of parallelism in reduce phase [Spark Branch]</summary>
      <description>We calculate the number of reducers based on the same code for MapReduce. However, reducers are vastly cheaper in Spark and it's generally recommended we have many more reducers than in MR.Sandy Ryza who works on Spark has some ideas about a heuristic.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.spark.SetSparkReducerParallelism.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="865" opendate="2009-10-1 00:00:00" fixdate="2009-10-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>mapjoin: memory leak for same key with very large number of values</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinOperator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8653" opendate="2014-10-29 00:00:00" fixdate="2014-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Push Semi Join through, Project/Filter/Join</summary>
      <description>CLEAR LIBRARY CACHE</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8654" opendate="2014-10-29 00:00:00" fixdate="2014-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: parquet_ctas test returns incorrect results</summary>
      <description>I am investigating right now. The issue is specific to Parquet:set hive.cbo.enable=true;drop table staging;drop table parquet_ctas;create table staging (key int, value string) stored as textfile;insert into table staging select * from src order by key limit 10;select * from staging;create table parquet_ctas stored as parquet as select * from staging;select * from parquet_ctas;create table orc_ctas stored as orc as select * from staging;select * from orc_ctas;create table txt_ctas stored as textfile as select * from staging;select * from txt_ctas;The parquet query returns all NULLs with CBO on.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8655" opendate="2014-10-29 00:00:00" fixdate="2014-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: ppr_pushdown, udf_substr produces incorrect results due to broken tablesample handling</summary>
      <description>Bunch of rows were added. Looks like tablesample in subquery is no longer blocking CBO, probably broken by HIVE-8021</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.HiveOptiqUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="8656" opendate="2014-10-29 00:00:00" fixdate="2014-11-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: auto_join_filters fails</summary>
      <description>Haven't looked why yet</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.TypeConverter.java</file>
    </fixedFiles>
  </bug>
  <bug id="8663" opendate="2014-10-29 00:00:00" fixdate="2014-10-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fetching Vectorization scratch column map in Reduce-Side stop working</summary>
      <description>Recent changes (somewhere) caused scratch column types to not be fetched on reduce-side.Switching to use scratch column types from VectorizationContext.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorSMBMapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorMapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatchCtx.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorGroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
    </fixedFiles>
  </bug>
  <bug id="8665" opendate="2014-10-30 00:00:00" fixdate="2014-10-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix misc unit tests on Windows</summary>
      <description>Several junit tests failing on Windows for misc reasons (path issues, resources need to be closed before file can be deleted, etc).</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.avro.TestTypeInfoToSchema.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcDriver2.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.java</file>
      <file type="M">itests.hive-unit-hadoop2.src.test.java.org.apache.hadoop.hive.ql.security.TestPasswordWithCredentialProvider.java</file>
      <file type="M">hcatalog.webhcat.java-client.src.test.java.org.apache.hive.hcatalog.api.TestHCatClient.java</file>
      <file type="M">hcatalog.webhcat.java-client.pom.xml</file>
      <file type="M">hcatalog.hcatalog-pig-adapter.src.test.java.org.apache.hive.hcatalog.pig.TestHCatLoaderStorer.java</file>
      <file type="M">hcatalog.core.src.test.java.org.apache.hive.hcatalog.cli.TestUseDatabase.java</file>
      <file type="M">common.src.test.resources.hive-log4j-test.properties</file>
      <file type="M">common.src.test.resources.hive-exec-log4j-test.properties</file>
      <file type="M">common.src.test.org.apache.hadoop.hive.conf.TestHiveLogging.java</file>
    </fixedFiles>
  </bug>
  <bug id="8666" opendate="2014-10-30 00:00:00" fixdate="2014-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hive.metastore.server.max.threads default is too high</summary>
      <description>hive.metastore.server.max.threads defaults to 100K. Each thread requires a 1024KB stack which is 100GB. We should move the default to something more sensible like 1000.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="8670" opendate="2014-10-30 00:00:00" fixdate="2014-11-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Combine Hive Operator statistic and Spark Metric to an uniformed query statistic.[Spark Branch]</summary>
      <description>For a Hive on Spark query, job statistic include Hive Operator level statistic and spark job metric, we should combine these statistics in an uniformed format and expose to user.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.SparkJobStatus.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.impl.SimpleSparkJobStatus.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="8685" opendate="2014-10-31 00:00:00" fixdate="2014-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>DDL operations in WebHCat set proxy user to "null" in unsecure mode</summary>
      <description>This makes DDL commands failThis was stupidly broken in HIVE-8643</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.common-secure.src.main.java.org.apache.hadoop.hive.shims.HadoopShimsSecure.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.SecureProxySupport.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.ExecServiceImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="8686" opendate="2014-10-31 00:00:00" fixdate="2014-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable vectorization tests with query results sort [Spark Branch]</summary>
      <description>Hive-8573 added query results sort to some vectorization tests. Now since the patch is merged to the spark branch. We can enable these tests in the spark branch now.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8688" opendate="2014-10-31 00:00:00" fixdate="2014-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>serialized plan OutputStream is not being closed</summary>
      <description>The OutputStream to which serialized plan is not being closed in several places.This can result in plan not getting written correctly.I have seen intermittent issues in deserializing the plan, and I think this could be the/a cause.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.MapRedTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.QTestUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="8689" opendate="2014-10-31 00:00:00" fixdate="2014-11-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>handle overflows in statistics better</summary>
      <description>Improve overflow checks in StatsAnnotation optimizer.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.StatsUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.stats.annotation.StatsRulesProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.SetReducerParallelism.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
    </fixedFiles>
  </bug>
  <bug id="8693" opendate="2014-11-1 00:00:00" fixdate="2014-11-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Separate out fair scheduler dependency from hadoop 0.23 shim</summary>
      <description>As part of HIVE-8424 HiveServer2 uses Fair scheduler APIs to determine resource queue allocation for non-impersonation case. This adds a hard dependency of Yarn server jars for Hive.</description>
      <version>0.14.0,0.15.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.pom.xml</file>
      <file type="M">shims.common.src.main.java.org.apache.hadoop.hive.shims.ShimLoader.java</file>
      <file type="M">shims.aggregator.pom.xml</file>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
    </fixedFiles>
  </bug>
  <bug id="8697" opendate="2014-11-2 00:00:00" fixdate="2014-11-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorized round(decimal, negative) produces wrong results</summary>
      <description>Separated a 2nd issue &amp;#8211; wrong result &amp;#8211; found by thiruvel in HIVE-8417 from 1st issue (IndexOutOfBoundsException due to scratch columns in reduce-side).Interesting to note that in HIVE-8461 we converted Vectorization to use HiveDecimal instead of Decimal128, yet the rounding problem still occurs...</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.FuncRoundWithNumDigitsDecimalToDecimal.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.DecimalUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="8698" opendate="2014-11-2 00:00:00" fixdate="2014-11-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>default log4j.properties not included in jar files anymore</summary>
      <description>trunk and hive 0.14 based builds no longer have hive-log4j.properties in the jars. This means that in default tar, unless hive-log4j.properties is created in conf dir (from hive-log4j.properties.template file), hive cli is much more verbose in what is printed to console. Hiveserver2 fails to come up, as it errors out with - org.apache.hadoop.hive.common.LogUtils$LogInitializationException: Unable to initialize logging using hive-log4j.properties, not found on CLASSPATH!</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">common.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="870" opendate="2009-10-5 00:00:00" fixdate="2009-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement LEFT SEMI JOIN</summary>
      <description>Semi-join is an efficient way to unnest an IN/EXISTS subquery. For example,select * from Awhere A.id IN (select id from B where B.date&gt; '2009-10-01');returns from A whose ID is in the set of IDs found in B, whose date is greater than a certain date. This query can be unnested using a INNER join or LEFT OUTER JOIN, but we need to deduplicate the IDs returned by the subquery on table B. The semantics of LEFT SEMI JOIN is that as long as there is ANY row in the right-hand table that matches the join key, the left-hand table row will be emitted as a result w/o necessarily looking further in the right-hand table for further matches. This is exactly the semantics of the IN subquery.</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.joinDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.joinCond.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.QBJoinTree.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.joinType.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.Hive.g</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ASTNode.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Operator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExecMapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.CommonJoinOperator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8700" opendate="2014-11-2 00:00:00" fixdate="2014-11-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace ReduceSink to HashTableSink (or equi.) for small tables [Spark Branch]</summary>
      <description>With HIVE-8616 enabled, the new plan has ReduceSinkOperator for the small tables. For example, the follow represents the operator plan for the small table dec1 derived from query explain select /*+ MAPJOIN(dec)*/ * from dec join dec1 on dec.value=dec1.d; Map 2 Map Operator Tree: TableScan alias: dec1 Statistics: Num rows: 0 Data size: 107 Basic stats: PARTIAL Column stats: NONE Filter Operator predicate: d is not null (type: boolean) Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE Reduce Output Operator key expressions: d (type: decimal(5,2)) sort order: + Map-reduce partition columns: d (type: decimal(5,2)) Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE value expressions: i (type: int)With the new design for broadcasting small tables, we need to convert the ReduceSinkOperator with HashTableSinkOperator or equivalent in the new plan.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.spark.SparkReduceSinkMapJoinProc.java</file>
    </fixedFiles>
  </bug>
  <bug id="8705" opendate="2014-11-3 00:00:00" fixdate="2014-11-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Support using pre-authenticated subject in kerberized HiveServer2 HTTP mode</summary>
      <description>HIVE-6486 provided a patch to utilize pre-authenticated subject (someone who has programmatically done a JAAS login and is not doing kinit before connecting to HiveServer2 using the JDBC driver). However, that feature was only for the binary mode code path. We need to have a similar feature when the driver-server communicate using http transport.</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.thrift.ThriftHttpServlet.java</file>
      <file type="M">service.src.java.org.apache.hive.service.auth.HttpAuthUtils.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HttpKerberosRequestInterceptor.java</file>
      <file type="M">jdbc.src.java.org.apache.hive.jdbc.HiveConnection.java</file>
    </fixedFiles>
  </bug>
  <bug id="8716" opendate="2014-11-3 00:00:00" fixdate="2014-11-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Partition filters are not pushed down with lateral view</summary>
      <description>Changes to HIVE-8454 revealed issues with partition filters not being pushed down in case of lateral view. For more info see discussion in HIVE-5718.</description>
      <version>0.14.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.union26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udtf.stack.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.lateral.view.ppd.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.lateral.view.noalias.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.lateral.view.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.udf.assert.true2.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.udf.assert.true.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.SortedDynPartitionOptimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.GenMRSkewJoinProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.JoinCondTypeCheckProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="8725" opendate="2014-11-4 00:00:00" fixdate="2014-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>spark-client build failed sometimes.[Spark Branch]</summary>
      <description>Sometimes spark-client build failed due to miss spark dependency version, I'm not sure the root cause, but add dependency version definitely fix my problem.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8726" opendate="2014-11-4 00:00:00" fixdate="2014-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Collect Spark TaskMetrics and build job statistic[Spark Branch]</summary>
      <description>Implement SparkListener to collect TaskMetrics, and build SparkStatistic.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.SparkJobStatus.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.impl.SimpleSparkJobStatus.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.impl.JobStateListener.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="8727" opendate="2014-11-4 00:00:00" fixdate="2014-11-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Dag summary has incorrect row counts and duration per vertex</summary>
      <description>During the code review for HIVE-8495 some code was reworked which broke some of INPUT/OUTPUT counters and duration.Patch attached which fixes that.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezJobMonitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="8740" opendate="2014-11-5 00:00:00" fixdate="2014-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sorted dynamic partition does not work correctly with constant folding</summary>
      <description>Sorted dynamic partition optimization looks for partition columns from the operator above FileSinkOperator. As per hive convention it expects partition columns at the last. But with HIVE-8585 equality filters on partition columns gets folded to constant. The column pruner then prunes the constant expression as they don't reference any columns. This in some cases will yield unexpected results (throw ArrayIndexOutOfBounds exception) with sorted dynamic partition insert optimization. In such cases we don't really need sorted dynamic partition optimization.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.SortedDynPartitionOptimizer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8746" opendate="2014-11-5 00:00:00" fixdate="2014-3-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>ORC timestamp columns are sensitive to daylight savings time</summary>
      <description>Hive uses Java's Timestamp class to manipulate timestamp columns. Unfortunately the textual parsing in Timestamp is done in local time and the internal storage is in UTC.ORC mostly side steps this issue by storing the difference between the time and a base time also in local and storing that difference in the file. Reading the file between timezones will mostly work correctly "2014-01-01 12:34:56" will read correctly in every timezone.However, when moving between timezones with different daylight saving it creates trouble. In particular, moving from a computer in PST to UTC will read "2014-06-06 12:34:56" as "2014-06-06 11:34:56".</description>
      <version>0.11.0,0.12.0,0.13.0,0.14.0,1.0.0,1.1.0,1.2.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.analyze.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynpart.sort.opt.vectorization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynpart.sort.optimization2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.alter.merge.stats.orc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.alter.merge.orc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.alter.merge.stats.orc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.alter.merge.orc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.orc.analyze.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.extrapolate.part.stats.partial.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.extrapolate.part.stats.full.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.encrypted.encryption.insert.partition.static.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.encrypted.encryption.insert.partition.dynamic.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.dynpart.sort.opt.vectorization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.dynpart.sort.optimization2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.table.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.part.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter.merge.stats.orc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.alter.merge.orc.q.out</file>
      <file type="M">ql.src.test.resources.orc-file-has-null.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump-dictionary-threshold.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump-bloomfilter2.out</file>
      <file type="M">ql.src.test.resources.orc-file-dump-bloomfilter.out</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.java</file>
      <file type="M">ql.src.protobuf.org.apache.hadoop.hive.ql.io.orc.orc.proto.proto</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.WriterImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.FileDump.java</file>
      <file type="M">ql.src.gen.protobuf.gen-java.org.apache.hadoop.hive.ql.io.orc.OrcProto.java</file>
    </fixedFiles>
  </bug>
  <bug id="8748" opendate="2014-11-5 00:00:00" fixdate="2014-11-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>jdbc uber jar is missing commons-logging</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8754" opendate="2014-11-6 00:00:00" fixdate="2014-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Sqoop job submission via WebHCat doesn&amp;#39;t properly localize required jdbc jars in secure cluster</summary>
      <description>HIVE-8588 added support for this by copying jdbc jars to lib/ of localized/exploded Sqoop tar. Unfortunately, in a secure cluster, Dist Cache intentionally sets permissions on exploded tars such that they are not writable.this needs to be fixed, otherwise the users would have to modify their sqoop tar to include the relevant jdbc jars which is burdensome is different DBs are used and may create headache around licensing issuesNO PRECOMMIT TESTS</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.tool.LaunchMapper.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.SqoopDelegator.java</file>
    </fixedFiles>
  </bug>
  <bug id="8760" opendate="2014-11-6 00:00:00" fixdate="2014-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Pass a copy of HiveConf to hooks</summary>
      <description>because hadoop's Configuration is not thread-safe</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.hooks.ATSHook.java</file>
    </fixedFiles>
  </bug>
  <bug id="8765" opendate="2014-11-6 00:00:00" fixdate="2014-10-6 01:00:00" resolution="Won&amp;#39;t Fix">
    <buginformation>
      <summary>TPC-DS Q21 : Incorrect join order makes query run slower (Not scaling selectivity by NDV)</summary>
      <description>CBO joins with date_dim first instead of item where item is the more selective join.Query select * from(select w_warehouse_name ,i_item_id ,sum(case when (cast(d_date as date) &lt; cast ('1998-04-08' as date)) then inv_quantity_on_hand else 0 end) as inv_before ,sum(case when (cast(d_date as date) &gt;= cast ('1998-04-08' as date)) then inv_quantity_on_hand else 0 end) as inv_after from inventory ,warehouse ,item ,date_dim where i_current_price between 0.99 and 1.49 and item.i_item_sk = inventory.inv_item_sk and inventory.inv_warehouse_sk = warehouse.w_warehouse_sk and inventory.inv_date_sk = date_dim.d_date_sk and d_date between '1998-03-09' and '1998-05-07' group by w_warehouse_name, i_item_id) x where (case when inv_before &gt; 0 then inv_after / inv_before else null end) between 2.0/3.0 and 3.0/2.0 order by w_warehouse_name ,i_item_id limit 100Logical Plan 2014-11-06 16:58:32,041 DEBUG [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:apply(12631)) - Plan After Join Reordering:HiveSortRel(fetch=[100]): rowcount = 1.0, cumulative cost = {1.627879384609158E9 rows, 2.0 cpu, 0.0 io}, id = 12521 HiveSortRel(sort0=[$0], sort1=[$1], dir0=[ASC], dir1=[ASC]): rowcount = 1.0, cumulative cost = {1.627879368609158E9 rows, 1.0 cpu, 0.0 io}, id = 12519 HiveProjectRel(w_warehouse_name=[$0], i_item_id=[$1], inv_before=[$2], inv_after=[$3]): rowcount = 1.0, cumulative cost = {1.627879352609158E9 rows, 0.0 cpu, 0.0 io}, id = 12517 HiveFilterRel(condition=[between(false, when(&gt;($2, 0), /(CAST($3):DOUBLE, CAST($2):DOUBLE), null), /(2E0, 3E0), /(3E0, 2E0))]): rowcount = 1.0, cumulative cost = {1.627879352609158E9 rows, 0.0 cpu, 0.0 io}, id = 12515 HiveAggregateRel(group=[{0, 1}], agg#0=[sum($2)], agg#1=[sum($3)]): rowcount = 1.7688372892644288, cumulative cost = {1.627879352609158E9 rows, 0.0 cpu, 0.0 io}, id = 12513 HiveProjectRel($f0=[$5], $f1=[$7], $f2=[when(&lt;(CAST($10):DATE, CAST('1998-04-08'):DATE), $2, 0)], $f3=[when(&gt;=(CAST($10):DATE, CAST('1998-04-08'):DATE), $2, 0)]): rowcount = 1.8477987480495097, cumulative cost = {1.627879352609158E9 rows, 0.0 cpu, 0.0 io}, id = 12511 HiveProjectRel(inv_item_sk=[$2], inv_warehouse_sk=[$3], inv_quantity_on_hand=[$4], inv_date_sk=[$5], w_warehouse_sk=[$0], w_warehouse_name=[$1], i_item_sk=[$8], i_item_id=[$9], i_current_price=[$10], d_date_sk=[$6], d_date=[$7]): rowcount = 1.8477987480495097, cumulative cost = {1.627879352609158E9 rows, 0.0 cpu, 0.0 io}, id = 12577 HiveJoinRel(condition=[=($3, $0)], joinType=[inner]): rowcount = 1.8477987480495097, cumulative cost = {1.627879352609158E9 rows, 0.0 cpu, 0.0 io}, id = 12575 HiveProjectRel(w_warehouse_sk=[$0], w_warehouse_name=[$2]): rowcount = 27.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 12463 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_30000.warehouse]]): rowcount = 27.0, cumulative cost = {0}, id = 12287 HiveJoinRel(condition=[=($6, $0)], joinType=[inner]): rowcount = 1.8477987480495097, cumulative cost = {1.6278793237613592E9 rows, 0.0 cpu, 0.0 io}, id = 12573 HiveJoinRel(condition=[=($3, $4)], joinType=[inner]): rowcount = 22284.45290147709, cumulative cost = {1.627857001E9 rows, 0.0 cpu, 0.0 io}, id = 12534 HiveProjectRel(inv_item_sk=[$0], inv_warehouse_sk=[$1], inv_quantity_on_hand=[$2], inv_date_sk=[$3]): rowcount = 1.627857E9, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 12460 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_30000.inventory]]): rowcount = 1.627857E9, cumulative cost = {0}, id = 12284 HiveProjectRel(d_date_sk=[$0], d_date=[$2]): rowcount = 1.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 12507 HiveFilterRel(condition=[between(false, $2, '1998-03-09', '1998-05-07')]): rowcount = 1.0, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 12505 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_30000.date_dim]]): rowcount = 73049.0, cumulative cost = {0}, id = 12286 HiveProjectRel(i_item_sk=[$0], i_item_id=[$1], i_current_price=[$5]): rowcount = 38.308457711442784, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 12501 HiveFilterRel(condition=[between(false, $5, 9.8999999999999999111E-1, 1.4899999999999999911E0)]): rowcount = 38.308457711442784, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 12499 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_30000.item]]): rowcount = 462000.0, cumulative cost = {0}, id = 12285Physical planSTAGE DEPENDENCIES: Stage-1 is a root stage Stage-0 depends on stages: Stage-1STAGE PLANS: Stage: Stage-1 Tez Edges: Map 3 &lt;- Map 1 (BROADCAST_EDGE), Map 2 (BROADCAST_EDGE), Map 6 (BROADCAST_EDGE) Reducer 4 &lt;- Map 3 (SIMPLE_EDGE) Reducer 5 &lt;- Reducer 4 (SIMPLE_EDGE) DagName: mmokhtar_20141104001212_4ebd83eb-0b1a-4375-aa32-b6455db0b8f9:1 Vertices: Map 1 Map Operator Tree: TableScan alias: warehouse filterExpr: w_warehouse_sk is not null (type: boolean) Statistics: Num rows: 27 Data size: 27802 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: w_warehouse_sk is not null (type: boolean) Statistics: Num rows: 27 Data size: 2808 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: w_warehouse_sk (type: int), w_warehouse_name (type: string) outputColumnNames: _col0, _col1 Statistics: Num rows: 27 Data size: 2808 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 27 Data size: 2808 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col1 (type: string) Execution mode: vectorized Map 2 Map Operator Tree: TableScan alias: item filterExpr: (i_current_price BETWEEN 0.99 AND 1.49 and i_item_sk is not null) (type: boolean) Statistics: Num rows: 462000 Data size: 663862160 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: (i_current_price BETWEEN 0.99 AND 1.49 and i_item_sk is not null) (type: boolean) Statistics: Num rows: 231000 Data size: 24945664 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: i_item_sk (type: int), i_item_id (type: string) outputColumnNames: _col0, _col1 Statistics: Num rows: 231000 Data size: 24024000 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 231000 Data size: 24024000 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col1 (type: string) Execution mode: vectorized Map 3 Map Operator Tree: TableScan alias: inventory filterExpr: (inv_item_sk is not null and inv_warehouse_sk is not null) (type: boolean) Statistics: Num rows: 1627857000 Data size: 19208695084 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: (inv_item_sk is not null and inv_warehouse_sk is not null) (type: boolean) Statistics: Num rows: 1627857000 Data size: 25720123084 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: inv_item_sk (type: int), inv_warehouse_sk (type: int), inv_quantity_on_hand (type: int), inv_date_sk (type: int) outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 1627857000 Data size: 25720123084 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col0} {_col1} {_col2} 1 {_col1} keys: 0 _col3 (type: int) 1 _col0 (type: int) outputColumnNames: _col0, _col1, _col2, _col5 input vertices: 1 Map 6 Statistics: Num rows: 1820114157 Data size: 185651644014 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} {_col2} {_col5} 1 {_col1} keys: 0 _col0 (type: int) 1 _col0 (type: int) outputColumnNames: _col1, _col2, _col5, _col7 input vertices: 1 Map 2 Statistics: Num rows: 1913285356 Data size: 378830500488 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: _col1 (type: int), _col2 (type: int), _col5 (type: string), _col7 (type: string) outputColumnNames: _col1, _col2, _col5, _col7 Statistics: Num rows: 1913285356 Data size: 378830500488 Basic stats: COMPLETE Column stats: COMPLETE Map Join Operator condition map: Inner Join 0 to 1 condition expressions: 0 {_col1} 1 {_col2} {_col5} {_col7} keys: 0 _col0 (type: int) 1 _col1 (type: int) outputColumnNames: _col1, _col4, _col7, _col9 input vertices: 0 Map 1 Statistics: Num rows: 2348122936 Data size: 699740634928 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: _col1 (type: string), _col9 (type: string), CASE WHEN ((CAST( _col7 AS DATE) &lt; 1998-04-08)) THEN (_col4) ELSE (0) END (type: int), CASE WHEN ((CAST( _col7 AS DATE) &gt;= 1998-04-08)) THEN (_col4) ELSE (0) END (type: int) outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 2348122936 Data size: 699740634928 Basic stats: COMPLETE Column stats: COMPLETE Group By Operator aggregations: sum(_col2), sum(_col3) keys: _col0 (type: string), _col1 (type: string) mode: hash outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 1174061468 Data size: 253597277088 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: string), _col1 (type: string) sort order: ++ Map-reduce partition columns: _col0 (type: string), _col1 (type: string) Statistics: Num rows: 1174061468 Data size: 253597277088 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col2 (type: bigint), _col3 (type: bigint) Map 6 Map Operator Tree: TableScan alias: date_dim filterExpr: (d_date BETWEEN '1998-03-09' AND '1998-05-07' and d_date_sk is not null) (type: boolean) Statistics: Num rows: 73049 Data size: 81741831 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: (d_date BETWEEN '1998-03-09' AND '1998-05-07' and d_date_sk is not null) (type: boolean) Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: d_date_sk (type: int), d_date (type: string) outputColumnNames: _col0, _col1 Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: int) sort order: + Map-reduce partition columns: _col0 (type: int) Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE value expressions: _col1 (type: string) Select Operator expressions: _col0 (type: int) outputColumnNames: _col0 Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE Group By Operator keys: _col0 (type: int) mode: hash outputColumnNames: _col0 Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE Dynamic Partitioning Event Operator Target Input: inventory Partition key expr: inv_date_sk Statistics: Num rows: 36524 Data size: 3579352 Basic stats: COMPLETE Column stats: COMPLETE Target column: inv_date_sk Target Vertex: Map 3 Execution mode: vectorized Reducer 4 Reduce Operator Tree: Group By Operator aggregations: sum(VALUE._col0), sum(VALUE._col1) keys: KEY._col0 (type: string), KEY._col1 (type: string) mode: mergepartial outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 3263127 Data size: 704835432 Basic stats: COMPLETE Column stats: COMPLETE Filter Operator predicate: CASE WHEN ((_col2 &gt; 0)) THEN ((UDFToDouble(_col3) / UDFToDouble(_col2))) ELSE (null) END BETWEEN 0.6666666666666666 AND 1.5 (type: boolean) Statistics: Num rows: 1631563 Data size: 352417608 Basic stats: COMPLETE Column stats: COMPLETE Select Operator expressions: _col0 (type: string), _col1 (type: string), _col2 (type: bigint), _col3 (type: bigint) outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 1631563 Data size: 352417608 Basic stats: COMPLETE Column stats: COMPLETE Reduce Output Operator key expressions: _col0 (type: string), _col1 (type: string) sort order: ++ Statistics: Num rows: 1631563 Data size: 352417608 Basic stats: COMPLETE Column stats: COMPLETE TopN Hash Memory Usage: 0.04 value expressions: _col2 (type: bigint), _col3 (type: bigint) Reducer 5 Reduce Operator Tree: Select Operator expressions: KEY.reducesinkkey0 (type: string), KEY.reducesinkkey1 (type: string), VALUE._col0 (type: bigint), VALUE._col1 (type: bigint) outputColumnNames: _col0, _col1, _col2, _col3 Statistics: Num rows: 1631563 Data size: 352417608 Basic stats: COMPLETE Column stats: COMPLETE Limit Number of rows: 100 Statistics: Num rows: 100 Data size: 21600 Basic stats: COMPLETE Column stats: COMPLETE File Output Operator compressed: false Statistics: Num rows: 100 Data size: 21600 Basic stats: COMPLETE Column stats: COMPLETE table: input format: org.apache.hadoop.mapred.TextInputFormat output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe Execution mode: vectorized Stage: Stage-0 Fetch Operator limit: 100 Processor Tree: ListSinkTime taken: 6.142 seconds, Fetched: 205 row(s)</description>
      <version>0.14.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.thrift.ThriftHttpCLIService.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.thrift.ThriftBinaryCLIService.java</file>
      <file type="M">service.src.java.org.apache.hive.service.auth.HiveAuthFactory.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestSSL.java</file>
      <file type="M">itests.hive-unit.src.main.java.org.apache.hive.jdbc.miniHS2.AbstractHiveService.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="8768" opendate="2014-11-6 00:00:00" fixdate="2014-11-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Fix filter selectivity for "in clause" &amp; "&lt;&gt;"</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.SqlFunctionConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.stats.FilterSelectivityEstimator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.rules.HivePushFilterPastJoinRule.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezSessionState.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezJobMonitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="877" opendate="2009-10-15 00:00:00" fixdate="2009-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>error with cast(null as short)</summary>
      <description>also cast(null as long)</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.udf.negative.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.udf.negative.q</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8774" opendate="2014-11-7 00:00:00" fixdate="2014-12-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Fix groupBy index optimization</summary>
      <description>Right now, even when groupby index is build, CBO is not able to use it. In this patch, we are trying to make it use groupby index that we build.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex.java</file>
      <file type="M">ql.src.test.results.clientpositive.ql.rewrite.gbtoidx.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndexCtx.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.index.RewriteGBUsingIndex.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyCtx.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8779" opendate="2014-11-7 00:00:00" fixdate="2014-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tez in-place progress UI can show wrong estimated time for sub-second queries</summary>
      <description>The in-place progress update UI added as part of HIVE-8495 can show wrong estimated time for AM only job which goes from INITED to SUCCEEDED DAG state directly without going to RUNNING state.</description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezJobMonitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="8781" opendate="2014-11-7 00:00:00" fixdate="2014-11-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Nullsafe joins are busted on Tez</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.union.group.by.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.CommonMergeJoinOperator.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8783" opendate="2014-11-7 00:00:00" fixdate="2014-12-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create some tests that use Spark counter for stats collection [Spark Branch]</summary>
      <description>Currently when .q tests are run with Spark, the default stats collection is "fs". We need to have some tests that use Spark counter for stats collection to enhance coverage.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkTask.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="8797" opendate="2014-11-8 00:00:00" fixdate="2014-12-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Simultaneous dynamic inserts can result in "partition already exists" error</summary>
      <description>If two users attempt a dynamic insert into the same new partition at the same time, a possible race condition exists where both will attempt to create the partition and one will fail.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
    </fixedFiles>
  </bug>
  <bug id="8799" opendate="2014-11-9 00:00:00" fixdate="2014-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>boatload of missing apache headers</summary>
      <description>Adding missing apache headers to a number of files.</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestFileSinkOperator.java</file>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.io.TestDateWritable.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.avro.AvroObjectInspectorException.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.udf.generic.TestGenericUDFOPNumeric.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.parquet.serde.primitive.TestParquetShortInspector.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.parquet.serde.primitive.TestParquetByteInspector.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.AccumuloHiveRow.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.AccumuloStorageHandler.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.LazyAccumuloRow.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.AccumuloPredicateHandler.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.CompareOp.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.DoubleCompare.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.Equal.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.GreaterThan.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.GreaterThanOrEqual.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.IntCompare.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.LessThan.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.LessThanOrEqual.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.Like.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.LongCompare.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.NotEqual.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.PrimitiveComparison.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.compare.StringCompare.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.predicate.PrimitiveComparisonFilter.java</file>
      <file type="M">accumulo-handler.src.java.org.apache.hadoop.hive.accumulo.serde.AccumuloSerDe.java</file>
      <file type="M">accumulo-handler.src.test.org.apache.hadoop.hive.accumulo.mr.TestHiveAccumuloTableInputFormat.java</file>
      <file type="M">accumulo-handler.src.test.org.apache.hadoop.hive.accumulo.predicate.compare.TestDoubleCompare.java</file>
      <file type="M">accumulo-handler.src.test.org.apache.hadoop.hive.accumulo.predicate.compare.TestIntCompare.java</file>
      <file type="M">accumulo-handler.src.test.org.apache.hadoop.hive.accumulo.predicate.compare.TestLongComparison.java</file>
      <file type="M">accumulo-handler.src.test.org.apache.hadoop.hive.accumulo.predicate.compare.TestStringCompare.java</file>
      <file type="M">accumulo-handler.src.test.org.apache.hadoop.hive.accumulo.predicate.TestAccumuloPredicateHandler.java</file>
      <file type="M">accumulo-handler.src.test.org.apache.hadoop.hive.accumulo.serde.TestAccumuloSerDe.java</file>
      <file type="M">common.src.java.org.apache.hive.common.util.Decimal128FastBuffer.java</file>
      <file type="M">hbase-handler.src.test.org.apache.hadoop.hive.hbase.TestHBaseKeyFactory3.java</file>
      <file type="M">hcatalog.webhcat.java-client.src.main.java.org.apache.hive.hcatalog.api.MetadataJSONSerializer.java</file>
      <file type="M">hcatalog.webhcat.java-client.src.main.java.org.apache.hive.hcatalog.api.MetadataSerializer.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.partition.spec.CompositePartitionSpecProxy.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.partition.spec.PartitionListComposingSpecProxy.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecWithSharedSDProxy.java</file>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.MockPartitionExpressionForMetastore.java</file>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.java</file>
      <file type="M">pom.xml</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.MapJoinBytesTableContainer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.PTFTopNHash.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.TimestampColumnStatistics.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.sarg.SearchArgumentFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.lib.ForwardWalker.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.MergeJoinProc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.metainfo.annotation.AnnotateWithOpTraits.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.cost.HiveVolcanoPlanner.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.TraitsUtil.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.MergeJoinWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.stats.StatsSetupConst.java</file>
    </fixedFiles>
  </bug>
  <bug id="880" opendate="2009-10-15 00:00:00" fixdate="2009-10-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>user group information not populated for pre and post hook</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.repair.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8800" opendate="2014-11-9 00:00:00" fixdate="2014-11-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Update release notes and notice for hive .14</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">RELEASE.NOTES.txt</file>
      <file type="M">NOTICE</file>
    </fixedFiles>
  </bug>
  <bug id="8805" opendate="2014-11-10 00:00:00" fixdate="2014-11-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO skipped due to SemanticException: Line 0:-1 Both left and right aliases encountered in JOIN &amp;#39;avg_cs_ext_discount_amt&amp;#39;</summary>
      <description>Queryset hive.cbo.enable=trueset hive.stats.fetch.column.stats=trueset hive.exec.dynamic.partition.mode=nonstrictset hive.tez.auto.reducer.parallelism=trueset hive.auto.convert.join.noconditionaltask.size=320000000set hive.exec.reducers.bytes.per.reducer=100000000set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DummyTxnManagerset hive.support.concurrency=falseset hive.tez.exec.print.summary=trueexplain SELECT sum(cs1.cs_ext_discount_amt) as excess_discount_amountFROM (SELECT cs.cs_item_sk as cs_item_sk, cs.cs_ext_discount_amt as cs_ext_discount_amt FROM catalog_sales cs JOIN date_dim d ON (d.d_date_sk = cs.cs_sold_date_sk) WHERE d.d_date between '2000-01-27' and '2000-04-27') cs1JOIN item i ON (i.i_item_sk = cs1.cs_item_sk)JOIN (SELECT cs2.cs_item_sk as cs_item_sk, 1.3 * avg(cs_ext_discount_amt) as avg_cs_ext_discount_amt FROM (SELECT cs.cs_item_sk as cs_item_sk, cs.cs_ext_discount_amt as cs_ext_discount_amt FROM catalog_sales cs JOIN date_dim d ON (d.d_date_sk = cs.cs_sold_date_sk) WHERE d.d_date between '2000-01-27' and '2000-04-27') cs2 GROUP BY cs2.cs_item_sk) tmp1ON (i.i_item_sk = tmp1.cs_item_sk)WHERE i.i_manufact_id = 436 and cs1.cs_ext_discount_amt &gt; tmp1.avg_cs_ext_discount_amtException14/11/07 19:15:38 [main]: ERROR parse.SemanticAnalyzer: CBO failed, skipping CBO. org.apache.hadoop.hive.ql.parse.SemanticException: Line 0:-1 Both left and right aliases encountered in JOIN 'avg_cs_ext_discount_amt' at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.parseJoinCondition(SemanticAnalyzer.java:2369) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.parseJoinCondition(SemanticAnalyzer.java:2293) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.parseJoinCondition(SemanticAnalyzer.java:2249) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genJoinTree(SemanticAnalyzer.java:8010) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9678) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9593) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9619) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9593) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9619) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9606) at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10053) at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221) at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:74) at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221) at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:415) at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:303) at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1067) at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1129) at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1004) at org.apache.hadoop.hive.ql.Driver.run(Driver.java:994) at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:247) at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:199) at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:410) at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:345) at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:443) at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:459) at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:739) at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:677) at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:616) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.RunJar.main(RunJar.java:212)</description>
      <version>0.14.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.rules.HivePushFilterPastJoinRule.java</file>
    </fixedFiles>
  </bug>
  <bug id="8812" opendate="2014-11-11 00:00:00" fixdate="2014-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestMinimrCliDriver failure if run in the same command as TestHBaseNegativeCliDriver</summary>
      <description>TestHBaseNegativeCliDriver does not drop all of the tables created during the test. The next CliDriver test in line (TestMinimrCliDriver) tries to clean up the tables created by the test HBase instance and fails:{format}junit.framework.AssertionFailedError: Unexpected exception in setup at junit.framework.Assert.fail(Assert.java:57) at junit.framework.TestCase.fail(TestCase.java:227) at org.apache.hadoop.hive.cli.TestMinimrCliDriver.setUp(TestMinimrCliDriver.java:71)This only happens if you run these tests in the same maven command.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.QTestUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="8813" opendate="2014-11-11 00:00:00" fixdate="2014-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow tests to be excluded based on pattern/regex</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8827" opendate="2014-11-11 00:00:00" fixdate="2014-11-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove SSLv2Hello from list of disabled protocols</summary>
      <description>Turns out SSLv2Hello is not the same as SSLv2.</description>
      <version>0.14.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="8831" opendate="2014-11-12 00:00:00" fixdate="2014-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>show roles appends dummy new line</summary>
      <description>hive&gt; show roles; OKADMINPUBLICadminnavispublicr1role1role2s1src_role2Time taken: 0.092 seconds, Fetched: 11 row(s)</description>
      <version>None</version>
      <fixedVersion>0.14.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.show.roles.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.authorization.view.sqlstd.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.authorization.set.show.current.role.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.authorization.role.grant1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.authorization.grant.public.role.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.authorization.admin.almighty1.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.role.case.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.rolehierarchy.privs.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.priv.current.role.neg.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.drop.role.no.admin.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.drop.db.empty.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.drop.db.cascade.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.authorization.caseinsensitivity.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="8833" opendate="2014-11-12 00:00:00" fixdate="2014-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Unify spark client API and implement remote spark client.[Spark Branch]</summary>
      <description>Hive would support submitting spark job through both local spark client and remote spark client. we should unify the spark client API, and implement remote spark client through Remote Spark Context.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.SparkClientImpl.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.SparkClient.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.spark.SetSparkReducerParallelism.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.SparkJobRef.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkUtilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkClient.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.session.SparkSessionImpl.java</file>
      <file type="M">ql.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8834" opendate="2014-11-12 00:00:00" fixdate="2014-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>enable job progress monitoring of Remote Spark Context [Spark Branch]</summary>
      <description>We should enable job progress monitor in Remote Spark Context, the spark job progress info should fit into SparkJobStatus. SPARK-2321 supply new spark progress API, which should make this task easier.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.SparkClientImpl.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.RemoteDriver.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.Protocol.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.JobHandleImpl.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.JobHandle.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.JobContextImpl.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.JobContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.SparkJobMonitor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.impl.SimpleSparkJobStatus.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.RemoteHiveSparkClient.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.LocalHiveSparkClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="8835" opendate="2014-11-12 00:00:00" fixdate="2014-11-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>identify dependency scope for Remote Spark Context.[Spark Branch]</summary>
      <description>While submit job through Remote Spark Context, spark RDD graph generation and job submit is executed in remote side, so we have to add hive related dependency into its classpath with spark.driver.extraClassPath. instead of add all hive/hadoop dependency, we should narrow the scope and identify what dependency remote spark context required.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8870" opendate="2014-11-14 00:00:00" fixdate="2014-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>errors when selecting a struct field within an array from ORC based tables</summary>
      <description>When using ORC as storage for a table, we get errors on selecting a struct field within an array. These errors do not appear with default format.CREATE TABLE `foobar_orc`( `uid` bigint, `elements` array&lt;struct&lt;elementid:bigint,foo:struct&lt;bar:string&gt;&gt;&gt;)STORED AS ORC;When selecting from this empty table, we get a direct NPE within the Hive CLI:SELECT elements.elementIdFROM foobar_orc;-- FAILED: RuntimeException java.lang.NullPointerExceptionA more real-world query produces a RuntimeException / NullPointerException in the mapper:SELECT uid, element.elementIdFROM foobar_orcLATERAL VIEW EXPLODE(elements) e AS element;Error: java.lang.RuntimeException: Error in configuring object at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:109)[...]Caused by: java.lang.NullPointerException at org.apache.hadoop.hive.ql.exec.ExprNodeFieldEvaluator.initialize(ExprNodeFieldEvaluator.java:61)[...]FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTaskBoth queries run fine on a non-orc table:CREATE TABLE `foobar`( `uid` bigint, `elements` array&lt;struct&lt;elementid:bigint,foo:struct&lt;bar:string&gt;&gt;&gt;); SELECT elements.elementIdFROM foobar;-- OK-- Time taken: 0.225 secondsSELECT uid, element.elementIdFROM foobarLATERAL VIEW EXPLODE(elements) e AS element;-- Total MapReduce CPU Time Spent: 1 seconds 920 msec-- OK-- Time taken: 25.905 seconds</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcStruct.java</file>
    </fixedFiles>
  </bug>
  <bug id="8875" opendate="2014-11-14 00:00:00" fixdate="2014-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hive.optimize.sort.dynamic.partition should be turned off for ACID</summary>
      <description>Turning this on causes ACID insert, updates, and deletes to produce non-optimal plans with extra reduce phases.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.dynpart.sort.optimization.acid.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8876" opendate="2014-11-14 00:00:00" fixdate="2014-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>incorrect upgrade script for Oracle (13-&gt;14)</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.scripts.upgrade.oracle.020-HIVE-7784.oracle.sql</file>
    </fixedFiles>
  </bug>
  <bug id="8877" opendate="2014-11-14 00:00:00" fixdate="2014-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>improve context logging during job submission via WebHCat</summary>
      <description>currently the logging includes env variables. it should also include contents of cur dir (helpful in tar shipping scenarios). contents of sqoop/lib (for pre-installed sqoop scenarios)java props (for general debugging)</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.tool.TrivialExecService.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.tool.TempletonUtils.java</file>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.AppConfig.java</file>
    </fixedFiles>
  </bug>
  <bug id="8879" opendate="2014-11-14 00:00:00" fixdate="2014-11-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Upgrade derby version to address race candition</summary>
      <description>DERBY-4160 describes the race condition that i sometimes notice.. particularly on windows. Below is the stack traceError Messagejava.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClientStacktracejava.lang.RuntimeException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:444) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1449) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) ... 29 moreCaused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) ... 34 moreCaused by: javax.jdo.JDODataStoreException: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP""NestedThrowables:java.sql.SQLNonTransientConnectionException: No current connection. at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:451) at org.datanucleus.api.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:732) at org.datanucleus.api.jdo.JDOPersistenceManager.makePersistent(JDOPersistenceManager.java:752) at org.apache.hadoop.hive.metastore.ObjectStore.setMetaStoreSchemaVersion(ObjectStore.java:6664) at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6574) at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98) at $Proxy12.verifySchema(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:539) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:591) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) ... 39 moreCaused by: java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.RDBMSStoreManager.getPropertiesForGenerator(RDBMSStoreManager.java:2045) at org.datanucleus.store.AbstractStoreManager.getStrategyValue(AbstractStoreManager.java:1365) at org.datanucleus.ExecutionContextImpl.newObjectId(ExecutionContextImpl.java:3827) at org.datanucleus.state.JDOStateManager.setIdentity(JDOStateManager.java:2571) at org.datanucleus.state.JDOStateManager.initialiseForPersistentNew(JDOStateManager.java:513) at org.datanucleus.state.ObjectProviderFactoryImpl.newForPersistentNew(ObjectProviderFactoryImpl.java:232) at org.datanucleus.ExecutionContextImpl.newObjectProviderForPersistentNew(ExecutionContextImpl.java:1414) at org.datanucleus.ExecutionContextImpl.persistObjectInternal(ExecutionContextImpl.java:2218) at org.datanucleus.ExecutionContextImpl.persistObjectWork(ExecutionContextImpl.java:2065) at org.datanucleus.ExecutionContextImpl.persistObject(ExecutionContextImpl.java:1913) at org.datanucleus.ExecutionContextThreadedImpl.persistObject(ExecutionContextThreadedImpl.java:217) at org.datanucleus.api.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:727) ... 57 moreCaused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 80 moreStandard Output2014-11-14 12:56:43,043 (main) [WARN - org.datanucleus.util.Log4JLogger.warn(Log4JLogger.java:106)] Query for candidates of org.apache.hadoop.hive.metastore.model.MDatabase and subclasses resulted in no possible candidatesSchema Transaction threw exception "Add classes to Catalog "", Schema "APP""org.datanucleus.exceptions.NucleusDataStoreException: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP"" at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:176) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.&lt;init&gt;(MetaStoreDirectSql.java:118) at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:270) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:233) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.hive.metastore.RawStoreProxy.&lt;init&gt;(RawStoreProxy.java:56) at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:65) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:560) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:538) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:587) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) ... 65 moreCaused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 73 moreNested Throwables StackTrace:java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.&lt;init&gt;(MetaStoreDirectSql.java:118) at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:270) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:233) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.hive.metastore.RawStoreProxy.&lt;init&gt;(RawStoreProxy.java:56) at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:65) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:560) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:538) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:587) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 73 more2014-11-14 12:56:43,047 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,048 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,089 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,089 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,128 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,128 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,162 (main) [WARN - org.datanucleus.util.Log4JLogger.warn(Log4JLogger.java:106)] Query for candidates of org.apache.hadoop.hive.metastore.model.MTableColumnStatistics and subclasses resulted in no possible candidatesSchema Transaction threw exception "Add classes to Catalog "", Schema "APP""org.datanucleus.exceptions.NucleusDataStoreException: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP"" at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:176) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.&lt;init&gt;(MetaStoreDirectSql.java:119) at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:270) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:233) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.hive.metastore.RawStoreProxy.&lt;init&gt;(RawStoreProxy.java:56) at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:65) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:560) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:538) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:587) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) ... 65 moreCaused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 73 moreNested Throwables StackTrace:java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.&lt;init&gt;(MetaStoreDirectSql.java:119) at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:270) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:233) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.hive.metastore.RawStoreProxy.&lt;init&gt;(RawStoreProxy.java:56) at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:65) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:560) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:538) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:587) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 73 more2014-11-14 12:56:43,165 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,165 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,203 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,203 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,240 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,242 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,278 (main) [WARN - org.datanucleus.util.Log4JLogger.warn(Log4JLogger.java:106)] Query for candidates of org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics and subclasses resulted in no possible candidatesSchema Transaction threw exception "Add classes to Catalog "", Schema "APP""org.datanucleus.exceptions.NucleusDataStoreException: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP"" at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:176) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.&lt;init&gt;(MetaStoreDirectSql.java:120) at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:270) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:233) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.hive.metastore.RawStoreProxy.&lt;init&gt;(RawStoreProxy.java:56) at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:65) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:560) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:538) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:587) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) ... 65 moreCaused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 73 moreNested Throwables StackTrace:java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.&lt;init&gt;(MetaStoreDirectSql.java:120) at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:270) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:233) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.hive.metastore.RawStoreProxy.&lt;init&gt;(RawStoreProxy.java:56) at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:65) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:560) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:538) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:587) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 73 more2014-11-14 12:56:43,281 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing2014-11-14 12:56:43,295 (main) [WARN - org.datanucleus.util.Log4JLogger.warn(Log4JLogger.java:106)] Query for candidates of org.apache.hadoop.hive.metastore.model.MVersionTable and subclasses resulted in no possible candidatesSchema Transaction threw exception "Add classes to Catalog "", Schema "APP""org.datanucleus.exceptions.NucleusDataStoreException: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP"" at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:176) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.ObjectStore.getMSchemaVersion(ObjectStore.java:6623) at org.apache.hadoop.hive.metastore.ObjectStore.getMetaStoreSchemaVersion(ObjectStore.java:6605) at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6564) at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98) at $Proxy12.verifySchema(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:539) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:587) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) ... 67 moreCaused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 75 moreNested Throwables StackTrace:java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.ObjectStore.getMSchemaVersion(ObjectStore.java:6623) at org.apache.hadoop.hive.metastore.ObjectStore.getMetaStoreSchemaVersion(ObjectStore.java:6605) at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6564) at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98) at $Proxy12.verifySchema(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:539) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:587) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 75 more2014-11-14 12:56:43,298 (main) [WARN - org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6570)] Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 0.14.02014-11-14 12:56:43,311 (main) [WARN - org.datanucleus.util.Log4JLogger.warn(Log4JLogger.java:106)] Query for candidates of org.apache.hadoop.hive.metastore.model.MVersionTable and subclasses resulted in no possible candidatesSchema Transaction threw exception "Add classes to Catalog "", Schema "APP""org.datanucleus.exceptions.NucleusDataStoreException: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP"" at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:176) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.ObjectStore.getMSchemaVersion(ObjectStore.java:6623) at org.apache.hadoop.hive.metastore.ObjectStore.setMetaStoreSchemaVersion(ObjectStore.java:6654) at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6574) at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98) at $Proxy12.verifySchema(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:539) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:587) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) ... 67 moreCaused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 75 moreNested Throwables StackTrace:java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.ObjectStore.getMSchemaVersion(ObjectStore.java:6623) at org.apache.hadoop.hive.metastore.ObjectStore.setMetaStoreSchemaVersion(ObjectStore.java:6654) at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6574) at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98) at $Proxy12.verifySchema(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:539) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:587) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 75 more2014-11-14 12:56:43,328 (main) [WARN - org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:589)] Retrying creating default database after error: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP""javax.jdo.JDODataStoreException: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP"" at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:451) at org.datanucleus.api.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:732) at org.datanucleus.api.jdo.JDOPersistenceManager.makePersistent(JDOPersistenceManager.java:752) at org.apache.hadoop.hive.metastore.ObjectStore.setMetaStoreSchemaVersion(ObjectStore.java:6664) at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6574) at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98) at $Proxy12.verifySchema(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:539) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:587) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)NestedThrowablesStackTrace:java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.RDBMSStoreManager.getPropertiesForGenerator(RDBMSStoreManager.java:2045) at org.datanucleus.store.AbstractStoreManager.getStrategyValue(AbstractStoreManager.java:1365) at org.datanucleus.ExecutionContextImpl.newObjectId(ExecutionContextImpl.java:3827) at org.datanucleus.state.JDOStateManager.setIdentity(JDOStateManager.java:2571) at org.datanucleus.state.JDOStateManager.initialiseForPersistentNew(JDOStateManager.java:513) at org.datanucleus.state.ObjectProviderFactoryImpl.newForPersistentNew(ObjectProviderFactoryImpl.java:232) at org.datanucleus.ExecutionContextImpl.newObjectProviderForPersistentNew(ExecutionContextImpl.java:1414) at org.datanucleus.ExecutionContextImpl.persistObjectInternal(ExecutionContextImpl.java:2218) at org.datanucleus.ExecutionContextImpl.persistObjectWork(ExecutionContextImpl.java:2065) at org.datanucleus.ExecutionContextImpl.persistObject(ExecutionContextImpl.java:1913) at org.datanucleus.ExecutionContextThreadedImpl.persistObject(ExecutionContextThreadedImpl.java:217) at org.datanucleus.api.jdo.JDOPersistenceManager.jdoMakePersistent(JDOPersistenceManager.java:727) at org.datanucleus.api.jdo.JDOPersistenceManager.makePersistent(JDOPersistenceManager.java:752) at org.apache.hadoop.hive.metastore.ObjectStore.setMetaStoreSchemaVersion(ObjectStore.java:6664) at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6574) at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98) at $Proxy12.verifySchema(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:539) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:587) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 80 more2014-11-14 12:56:43,382 (main) [WARN - org.datanucleus.util.Log4JLogger.warn(Log4JLogger.java:106)] Query for candidates of org.apache.hadoop.hive.metastore.model.MDatabase and subclasses resulted in no possible candidatesSchema Transaction threw exception "Add classes to Catalog "", Schema "APP""org.datanucleus.exceptions.NucleusDataStoreException: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP"" at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:176) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.&lt;init&gt;(MetaStoreDirectSql.java:118) at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:270) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:233) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.hive.metastore.RawStoreProxy.&lt;init&gt;(RawStoreProxy.java:56) at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:65) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:560) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:538) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:591) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) ... 65 moreCaused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 73 moreNested Throwables StackTrace:java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.&lt;init&gt;(MetaStoreDirectSql.java:118) at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:270) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:233) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.hive.metastore.RawStoreProxy.&lt;init&gt;(RawStoreProxy.java:56) at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:65) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:560) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:538) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:591) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 73 more2014-11-14 12:56:43,384 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,384 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,423 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,424 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,459 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,459 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,500 (main) [WARN - org.datanucleus.util.Log4JLogger.warn(Log4JLogger.java:106)] Query for candidates of org.apache.hadoop.hive.metastore.model.MTableColumnStatistics and subclasses resulted in no possible candidatesSchema Transaction threw exception "Add classes to Catalog "", Schema "APP""org.datanucleus.exceptions.NucleusDataStoreException: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP"" at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:176) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.&lt;init&gt;(MetaStoreDirectSql.java:119) at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:270) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:233) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.hive.metastore.RawStoreProxy.&lt;init&gt;(RawStoreProxy.java:56) at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:65) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:560) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:538) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:591) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) ... 65 moreCaused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 73 moreNested Throwables StackTrace:java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.&lt;init&gt;(MetaStoreDirectSql.java:119) at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:270) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:233) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.hive.metastore.RawStoreProxy.&lt;init&gt;(RawStoreProxy.java:56) at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:65) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:560) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:538) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:591) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 73 more2014-11-14 12:56:43,501 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,502 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,541 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,542 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,589 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,589 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.2014-11-14 12:56:43,633 (main) [WARN - org.datanucleus.util.Log4JLogger.warn(Log4JLogger.java:106)] Query for candidates of org.apache.hadoop.hive.metastore.model.MPartitionColumnStatistics and subclasses resulted in no possible candidatesSchema Transaction threw exception "Add classes to Catalog "", Schema "APP""org.datanucleus.exceptions.NucleusDataStoreException: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP"" at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:176) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.&lt;init&gt;(MetaStoreDirectSql.java:120) at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:270) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:233) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.hive.metastore.RawStoreProxy.&lt;init&gt;(RawStoreProxy.java:56) at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:65) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:560) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:538) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:591) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) ... 65 moreCaused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 73 moreNested Throwables StackTrace:java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.&lt;init&gt;(MetaStoreDirectSql.java:120) at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:270) at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:233) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:73) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.hive.metastore.RawStoreProxy.&lt;init&gt;(RawStoreProxy.java:56) at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:65) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:560) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:538) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:591) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 73 more2014-11-14 12:56:43,637 (main) [INFO - org.datanucleus.util.Log4JLogger.info(Log4JLogger.java:77)] Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing2014-11-14 12:56:43,647 (main) [WARN - org.datanucleus.util.Log4JLogger.warn(Log4JLogger.java:106)] Query for candidates of org.apache.hadoop.hive.metastore.model.MVersionTable and subclasses resulted in no possible candidatesSchema Transaction threw exception "Add classes to Catalog "", Schema "APP""org.datanucleus.exceptions.NucleusDataStoreException: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP"" at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:176) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.ObjectStore.getMSchemaVersion(ObjectStore.java:6623) at org.apache.hadoop.hive.metastore.ObjectStore.getMetaStoreSchemaVersion(ObjectStore.java:6605) at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6564) at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98) at $Proxy12.verifySchema(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:539) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:591) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) ... 67 moreCaused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 75 moreNested Throwables StackTrace:java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.ObjectStore.getMSchemaVersion(ObjectStore.java:6623) at org.apache.hadoop.hive.metastore.ObjectStore.getMetaStoreSchemaVersion(ObjectStore.java:6605) at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6564) at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98) at $Proxy12.verifySchema(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:539) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:591) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 75 more2014-11-14 12:56:43,649 (main) [WARN - org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6570)] Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 0.14.02014-11-14 12:56:43,662 (main) [WARN - org.datanucleus.util.Log4JLogger.warn(Log4JLogger.java:106)] Query for candidates of org.apache.hadoop.hive.metastore.model.MVersionTable and subclasses resulted in no possible candidatesSchema Transaction threw exception "Add classes to Catalog "", Schema "APP""org.datanucleus.exceptions.NucleusDataStoreException: Schema Transaction threw exception "Add classes to Catalog "", Schema "APP"" at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:176) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.ObjectStore.getMSchemaVersion(ObjectStore.java:6623) at org.apache.hadoop.hive.metastore.ObjectStore.setMetaStoreSchemaVersion(ObjectStore.java:6654) at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6574) at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98) at $Proxy12.verifySchema(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:539) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:591) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) ... 67 moreCaused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 75 moreNested Throwables StackTrace:java.sql.SQLNonTransientConnectionException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.noCurrentConnection(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.checkIfClosed(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.getAutoCommit(Unknown Source) at com.jolbox.bonecp.ConnectionHandle.getAutoCommit(ConnectionHandle.java:778) at org.datanucleus.store.rdbms.AbstractSchemaTransaction.execute(AbstractSchemaTransaction.java:131) at org.datanucleus.store.rdbms.RDBMSStoreManager.addClasses(RDBMSStoreManager.java:1605) at org.datanucleus.store.AbstractStoreManager.addClass(AbstractStoreManager.java:954) at org.datanucleus.store.rdbms.RDBMSStoreManager.getDatastoreClass(RDBMSStoreManager.java:679) at org.datanucleus.store.rdbms.query.RDBMSQueryUtils.getStatementForCandidates(RDBMSQueryUtils.java:408) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileQueryFull(JDOQLQuery.java:947) at org.datanucleus.store.rdbms.query.JDOQLQuery.compileInternal(JDOQLQuery.java:370) at org.datanucleus.store.query.Query.executeQuery(Query.java:1744) at org.datanucleus.store.query.Query.executeWithArray(Query.java:1672) at org.datanucleus.store.query.Query.execute(Query.java:1654) at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:221) at org.apache.hadoop.hive.metastore.ObjectStore.getMSchemaVersion(ObjectStore.java:6623) at org.apache.hadoop.hive.metastore.ObjectStore.setMetaStoreSchemaVersion(ObjectStore.java:6654) at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6574) at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98) at $Proxy12.verifySchema(Unknown Source) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:539) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:591) at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:429) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:66) at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72) at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5554) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:178) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:73) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1447) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:63) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:73) at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2689) at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2708) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:425) at org.apache.flume.sink.hive.TestHiveWriter.&lt;init&gt;(TestHiveWriter.java:96) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:187) at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:236) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:233) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)Caused by: java.sql.SQLException: No current connection. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 75 more</description>
      <version>0.13.1,0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8881" opendate="2014-11-15 00:00:00" fixdate="2014-11-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Receiving json "{"error":"Could not find job job_1415748506143_0002"}" when web client tries to fetch all jobs from webhcat where HDFS does not have the data.</summary>
      <description>when a job is deleted from HDFS and the curl call is executed http://localhost:50111/templeton/v1/jobs?user.name=hcat\&amp;showall=true\&amp;fields=*'Occasionally receiving json like this{"error":"Could not find job job_1415748506143_0002"}this is an intermittent issue that happens when Hadoop for some reason can't find the details for a given job id.This REST call should be more flexible since it is designed to return information about many jobs at once. It should just skip over "bad" IDs and produce as much output as it can.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.SimpleWebException.java</file>
    </fixedFiles>
  </bug>
  <bug id="8891" opendate="2014-11-16 00:00:00" fixdate="2014-11-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Another possible cause to NucleusObjectNotFoundException from drops/rollback</summary>
      <description>It might be another possible cause to org.datanucleus.exceptions.NucleusObjectNotFoundException: No such database row in drops and retries. The rollback might also fail for some reason (e.g. same as that for commit), and the detached objects should also be evicted for same reason as HIVE-3826. The evictAll needs to be put in the finally block.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.ObjectStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="8892" opendate="2014-11-16 00:00:00" fixdate="2014-11-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use MEMORY_AND_DISK for RDD caching [Spark Branch]</summary>
      <description>In HIVE-8844, we made the persistent policy for RDD caching configurable. We should do something simpler and don't add additional configurations.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.SparkPlanGenerator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.ShuffleTran.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.MapInput.java</file>
    </fixedFiles>
  </bug>
  <bug id="8893" opendate="2014-11-17 00:00:00" fixdate="2014-11-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Implement whitelist for builtin UDFs to avoid untrused code execution in multiuser mode</summary>
      <description>The udfs like reflect() or java_method() enables executing a java method as udf. While this offers lot of flexibility in the standalone mode, it can become a security loophole in a secure multiuser environment. For example, in HiveServer2 one can execute any available java code with user hive's credentials.We need a whitelist and blacklist to restrict builtin udfs in Hiveserver2.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.CLIService.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestFunctionRegistry.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestExpressionEvaluator.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestExecDriver.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.metastore.TestMetastoreExpr.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.FunctionSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.SqlFunctionConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionInfo.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniHS2.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="8898" opendate="2014-11-17 00:00:00" fixdate="2014-3-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove HIVE-8874 once HBASE-12493 is fixed</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
      <file type="M">hbase-handler.src.java.org.apache.hadoop.hive.hbase.HBaseStorageHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="8917" opendate="2014-11-19 00:00:00" fixdate="2014-11-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HIVE-5679 adds two thread safety problems</summary>
      <description>HIVE-5679 adds two static SimpleDateFormat objects and SimpleDateFormat is not thread safe. These should be converted to thread locals.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.parser.Filter.g</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.parser.ExpressionTree.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.MetaStoreDirectSql.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="8922" opendate="2014-11-20 00:00:00" fixdate="2014-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: assorted date and timestamp issues</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.TypeCheckCtx.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.SqlFunctionConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.RexNodeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.ExprNodeConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.ASTBuilder.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.lib.TaskGraphWalker.java</file>
    </fixedFiles>
  </bug>
  <bug id="8923" opendate="2014-11-20 00:00:00" fixdate="2014-12-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HIVE-8512 needs to be fixed also for CBO</summary>
      <description>Queries reverted to incorrect results.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.cbo.semijoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cbo.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cbo.gby.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cbo.semijoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cbo.limit.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cbo.gby.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.cbo.semijoin.q</file>
      <file type="M">ql.src.test.queries.clientpositive.cbo.limit.q</file>
      <file type="M">ql.src.test.queries.clientpositive.cbo.gby.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="8929" opendate="2014-11-20 00:00:00" fixdate="2014-11-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>incorrect error message for cbo path</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.optiq.translator.JoinCondTypeCheckProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="893" opendate="2009-10-20 00:00:00" fixdate="2009-10-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Thrift serde doesn&amp;#39;t work with the new version of thrift</summary>
      <description>The new version of thrift rename the __isset to __isset_bit_vector in the generated Thrift java code. This causes __isset_bit_vector passed as a field in ThriftSerDe.</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.objectinspector.ThriftStructObjectInspector.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="8931" opendate="2014-11-21 00:00:00" fixdate="2014-6-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Test TestAccumuloCliDriver is not completing</summary>
      <description>Tests are taking 3 hours due to TestAccumuloCliDriver not finishing.Logs:http://ec2-174-129-184-35.compute-1.amazonaws.com/logs/PreCommit-HIVE-TRUNK-Build-1848/failed/TestAccumuloCliDriver/</description>
      <version>None</version>
      <fixedVersion>1.2.1</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.qtest.pom.xml</file>
      <file type="M">itests.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="8933" opendate="2014-11-21 00:00:00" fixdate="2014-11-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Check release builds for SNAPSHOT dependencies</summary>
      <description>Hive 0.14.0 was released with SNAPSHOT dependencies. We should use the maven enforcer plugin to prevent this from happening again in the future.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="894" opendate="2009-10-20 00:00:00" fixdate="2009-2-20 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add UDAFs max_n(), min_n() to contrib</summary>
      <description>These 2 UDAFs should return the max n numbers, min n numbers in order.SELECT max_n(userid, 3) FROM src;[999,997,996]SELECT max_n(userid, 3)[1] FROM src;997SELECT min_n(userid, 3) FROM src;[0, 3, 8]SELECT min_n(userid, 3)[2] FROM src;8</description>
      <version>None</version>
      <fixedVersion>0.6.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBridge.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DefaultUDAFEvaluatorResolver.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9001" opendate="2014-12-1 00:00:00" fixdate="2014-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ship with log4j.properties file that has a reliable time based rolling policy</summary>
      <description>The hive log gets locked by the hive process and cannot be rolled in windows OS.Install Hive in Windows, start hive, try and rename hive log while Hive is running. Wait for log4j tries to rename it and it will throw the same error as it is locked by the process.The changes in https://issues.apache.org/bugzilla/show_bug.cgi?id=29726 should be integrated to Hive for a reliable rollover.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.common.pom.xml</file>
      <file type="M">ql.pom.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">data.conf.hive-log4j.properties</file>
      <file type="M">common.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9003" opendate="2014-12-2 00:00:00" fixdate="2014-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Vectorized IF expr broken for the scalar and scalar case</summary>
      <description>SELECT IF (bool_col, 'first', 'second') FROM ...is broken for Vectorization.</description>
      <version>0.14.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.expressions.IfExprStringScalarStringScalar.java</file>
    </fixedFiles>
  </bug>
  <bug id="9019" opendate="2014-12-4 00:00:00" fixdate="2014-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Avoid using SPARK_JAVA_OPTS [Spark Branch]</summary>
      <description>SPARK_JAVA_OPTS has been deprecated, see SparkConf.validateSettings.Using it together with spark.driver.extraJavaOptions will cause SparkContext fail to start.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.SparkClientImpl.java</file>
      <file type="M">data.conf.spark.log4j.properties</file>
      <file type="M">data.conf.spark.hive-site.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9035" opendate="2014-12-6 00:00:00" fixdate="2014-12-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO: Disable PPD when functions are non-deterministic (ppd_random.q - non-deterministic udf rand() pushed above join)</summary>
      <description>Not clear if this is a problem. Probably issue is in Optiq if it is, does it know the UDF is non-deterministic? We could disable Optiq for such UDFs if all else fails.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.translator.SqlFunctionConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.rules.HiveFilterJoinRule.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.HiveCalciteUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="9036" opendate="2014-12-6 00:00:00" fixdate="2014-12-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Replace akka for remote spark client RPC [Spark Branch]</summary>
      <description>We've had weird issues with akka, especially when something goes wrong and it becomes a little hard to debug. Let's replace it with a simple(r) RPC system built on top of netty.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.src.test.java.org.apache.hive.spark.client.TestSparkClient.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.counter.SparkCounters.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.counter.SparkCounterGroup.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.counter.SparkCounter.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.SparkClientImpl.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.SparkClientFactory.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.RemoteDriver.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.Protocol.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.ShuffleWriteMetrics.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.ShuffleReadMetrics.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.Metrics.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.metrics.InputMetrics.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.JobHandleImpl.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.ClientUtils.java</file>
      <file type="M">spark-client.pom.xml</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.status.impl.RemoteSparkJobStatus.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.RemoteHiveSparkClient.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.LocalHiveSparkClient.java</file>
      <file type="M">pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9037" opendate="2014-12-6 00:00:00" fixdate="2014-12-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve explain plan to show joining keys for shuffle join</summary>
      <description>Currently joining keys are displayed only for map side joins and not for shuffle joins.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.mapjoin.reduce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.left.outer.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vector.decimal.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.shufflejoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.nested.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.context.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.bucketmapjoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.top.level.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.remove.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.lateralview.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union34.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union32.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union27.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union24.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.case.column.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.mapjoin.reduce.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.left.outer.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.decimal.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.shufflejoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.nested.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.context.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.bucketmapjoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.union.group.by.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.smb.main.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.smb.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.join.tests.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.join.hash.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.joins.explain.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.bmj.schema.evolution.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.subquery.in.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.subquery.exists.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.skewjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.optimize.nullscan.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mrr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.metadataonly1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mapjoin.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mapjoin.decimal.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.limit.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.join.nullsafe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.join0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.filter.join.breaktask.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynamic.partition.pruning.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.product.check.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.product.check.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.correlationoptimizer1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.bucket.map.join.tez2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.bucket.map.join.tez1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.join0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.temp.table.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subq.where.serialization.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.views.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.unqualcolumnrefs.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.notin.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.notin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.notexists.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.notexists.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.multiinsert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.in.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.in.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.exists.having.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.exists.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stats11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.merge.join.desc.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.smb.mapjoin9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.union.remove.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.union.remove.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.noskew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.mapjoin9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.mapjoin8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.mapjoin7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.mapjoin6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.mapjoin5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.mapjoin4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.mapjoin3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.mapjoin2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.mapjoin11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.mapjoin10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.mapjoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoinopt1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.skewjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.semijoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.select.transform.hint.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.router.join.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.regex.col.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.reduce.deduplicate.extended.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.reduce.deduplicate.exclude.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.rcfile.null.value.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.quotedid.skew.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ql.rewrite.gbtoidx.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.vc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.union.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.udf.case.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.repeated.alias.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.random.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.outer.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.outer.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.outer.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.outer.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.outer.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.multi.insert.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join.filter.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.gby.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.clusterby.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.pcr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.parquet.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.outer.join.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.optional.outer.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.optimize.nullscan.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.no.hooks.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nonmr.fetch.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.nonblock.op.deduplicate.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.multi.join.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.multiMapJoin2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.multiMapJoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.metadataonly1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.merge.join.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mergejoins.mixed.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mergejoins.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.test.outer.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.subquery2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.subquery.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.memcheck.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.filter.on.outerjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.louter.join.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.lineage1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit.pushdown.negative.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.lateral.view.noalias.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.lateral.view.cp.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.vc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.thrift.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.star.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.reorder4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.reorder3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.reorder2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.reorder.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.rc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.nullsafe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.merging.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.merge.multi.expressions.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.map.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.hive.626.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.filters.overlap.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.unqual4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.unqual3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.unqual2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.unqual1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.cond.pushdown.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.alt.syntax.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join41.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join40.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join39.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join38.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join37.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join36.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join35.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join34.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join33.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join32.lessSize.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join32.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join31.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join30.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join29.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join28.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join27.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join25.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join18.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input39.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.innerjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.infer.bucket.sort.map.operators.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.bitmap.auto.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.bitmap3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.self.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.mult.tables.compact.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.index.auto.mult.tables.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.skew.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.sort.1.23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.position.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.grouping.sets4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.gby.star.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.filter.join.breaktask.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.explain.rearrange.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.explain.logical.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.decimal.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cross.product.check.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cross.product.check.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cross.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.constprog.partitioner.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.constprog2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.constantPropagateForSubQuery.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.complex.alias.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.column.access.stats.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cluster.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucket.map.join.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucket.map.join.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketsortoptimize.insert.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketsortoptimize.insert.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketsortoptimize.insert.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketsortoptimize.insert.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketsortoptimize.insert.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketsortoptimize.insert.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin.negative3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin.negative2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin.negative.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketmapjoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.bucketcontext.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.11.q.out</file>
      <file type="M">hbase-handler.src.test.results.positive.hbase.queries.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.CommonMergeJoinDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.HashTableSinkDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.JoinDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.MapJoinDesc.java</file>
      <file type="M">ql.src.test.results.clientnegative.bucket.mapjoin.mismatch1.q.out</file>
      <file type="M">ql.src.test.results.clientnegative.sortmerge.mapjoin.mismatch.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.allcolref.in.udf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ambiguous.col.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.annotate.stats.join.pkfk.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join11.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join12.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join13.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join16.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join18.multi.distinct.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join24.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join26.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join27.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join28.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join29.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join30.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join31.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join32.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join33.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join4.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join.reordering.values.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join.without.localtask.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.smb.mapjoin.14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.sortmerge.join.1.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="9038" opendate="2014-12-7 00:00:00" fixdate="2014-1-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Join tests fail on Tez</summary>
      <description>Tez doesn't run all tests. But, if you run them, following tests fail with runt time exception pointing to bugs. auto_join21.q auto_join29.q auto_join30.q auto_join_filters.q auto_join_nulls.q</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="9048" opendate="2014-12-9 00:00:00" fixdate="2014-12-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive build failed on hadoop-1 after HIVE-8828.</summary>
      <description>HIVE-8828 introduce org.apache.hadoop.tools.HadoopArchives which included in hadoop-tools(in hadoop-1)/hadoop-archives(in hadoop-2), while hadoop-tools is not added into hadoop-1 dependency. This lead to the following compile error:[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:compile (default-compile) on project hive-exec: Compilation failure: Compilation failure:[ERROR] /home/cxli/sources/github/chengxiangli/hive/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java:[175,30] error: package org.apache.hadoop.tools does not exist[ERROR] /home/cxli/sources/github/chengxiangli/hive/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java:[1322,8] error: cannot find symbol[ERROR] class DDLTask[ERROR] /home/cxli/sources/github/chengxiangli/hive/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java:[1322,33] error: cannot find symbol[ERROR] -&gt; [Help 1]</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9062" opendate="2014-12-10 00:00:00" fixdate="2014-12-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Explain plan doesn&amp;#39;t print join keys for Tez shuffle join</summary>
      <description>For map join, it already prints the keys, but not for shuffle join.</description>
      <version>0.13.0,0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.shufflejoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.ptf.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vectorized.bucketmapjoin1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.union.group.by.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.union.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.smb.main.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.join.tests.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.join.hash.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.tez.joins.explain.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.subquery.in.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.subquery.exists.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.skewjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.optimize.nullscan.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.mrr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.metadataonly1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.limit.pushdown.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.join.nullsafe.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.join1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.join0.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.filter.join.breaktask.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.dynamic.partition.pruning.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.product.check.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.correlationoptimizer1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.auto.sortmerge.join.6.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.CommonMergeJoinDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ConvertJoinMapJoin.java</file>
    </fixedFiles>
  </bug>
  <bug id="9081" opendate="2014-12-11 00:00:00" fixdate="2014-12-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Bucket mapjoin should use the new alias in posToAliasMap [Spark Branch]</summary>
      <description>In converting a mapjoin to a bucket mapjoin, the join aliases could be updated. So we should update the posToAliasMap accordingly.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.spark.SparkMapJoinOptimizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.BucketJoinProcCtx.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.AbstractBucketJoinProc.java</file>
    </fixedFiles>
  </bug>
  <bug id="9090" opendate="2014-12-12 00:00:00" fixdate="2014-12-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Rename "Tez File Merge Work" to smaller name</summary>
      <description>This is just a cosmetic change. The "Tez File Merge Work" vertex name is long that in-place update UI showing vertex name is out of place.</description>
      <version>0.14.0,0.14.1,0.15.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.orc.merge1.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezJobMonitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="9121" opendate="2014-12-16 00:00:00" fixdate="2014-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Enable beeline query progress information for Spark job[Spark Branch]</summary>
      <description>We could not get query progress information in Beeline as SparkJobMonitor is filtered out of operation log.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.operation.LogDivertAppender.java</file>
    </fixedFiles>
  </bug>
  <bug id="913" opendate="2009-11-4 00:00:00" fixdate="2009-12-4 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>no error if user specifies same output table mutliple times</summary>
      <description>The query:from srcinsert overwrite table dest1 select key, valueinsert overwrite table dest1 select key, value2;does not fail.</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ErrorMsg.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9130" opendate="2014-12-16 00:00:00" fixdate="2014-12-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>vector_partition_diff_num_cols result is not updated after CBO upgrade</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.vector.partition.diff.num.cols.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.vector.partition.diff.num.cols.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="9140" opendate="2014-12-17 00:00:00" fixdate="2014-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add Calcite&amp;#39;s ReduceExpressionRules to Hive</summary>
      <description>These rules provide a form of constant folding.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.CalcitePlanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="9158" opendate="2014-12-18 00:00:00" fixdate="2014-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Multiple LDAP server URLs in hive.server2.authentication.ldap.url</summary>
      <description>Support for multiple LDAP servers for failover in the event that one stops responding or is down for maintenance.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="916" opendate="2009-11-6 00:00:00" fixdate="2009-12-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>typedbytes: changes</summary>
      <description>1. probably use int for tinyint/shortint instead of bytes2. pick different typecode for eo-record marker: not 100/101/2553. use string when type not specified in AS clause</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">contrib.src.java.org.apache.hadoop.hive.contrib.util.typedbytes.Type.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9166" opendate="2014-12-18 00:00:00" fixdate="2014-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Place an upper bound for SARG CNF conversion</summary>
      <description>SARG creation in ORC, applies several optimizations to expression tree. In that CNF conversion is an exponential algorithm as it finds all combinations of expressions when converting from OR of AND form to AND of OR form (CNF). We need an upper bound for this algorithm to prevent it from running for long time and generating huge combinations list.</description>
      <version>0.14.0,0.15.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.sarg.TestSearchArgumentImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.sarg.SearchArgumentImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="9189" opendate="2014-12-22 00:00:00" fixdate="2014-1-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add ProjectRemove rule on CBO path</summary>
      <description>When these rules fire we will get shorter and tighter operator pipeline.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.vector.left.outer.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.nested.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.vectorized.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.product.check.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.product.check.1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.cross.join.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.subquery.views.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.router.join.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.vc.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.union.view.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.join.filter.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.multiMapJoin2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.metadataonly1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.mapjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.louter.join.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join35.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join34.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join32.lessSize.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.explain.logical.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.cross.product.check.2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.correlationoptimizer3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join.without.localtask.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join.nulls.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join9.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join8.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join33.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join27.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join22.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join16.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.CalcitePlanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="9202" opendate="2014-12-23 00:00:00" fixdate="2014-12-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Choose Kryo as the serializer for pTest [Spark Branch]</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">data.conf.spark.hive-site.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9205" opendate="2014-12-23 00:00:00" fixdate="2014-12-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Change default tez install directory to use /tmp instead of /user and create the directory if it does not exist</summary>
      <description>The common deployment scenario is to install the packages and start services. Creating the /user/&lt;user&gt; directory is currently an extra step during manual installation. In case the user tries to bring up the hive shell with tez enabled, this would result in an exception. The solution is to change the default install directory to /tmp (so that we have the permissions to create the directory /tmp/&lt;user&gt;) and create the /tmp/&lt;user&gt; directory if it did not exist earlier.</description>
      <version>0.14.0,0.15.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.DagUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="9207" opendate="2014-12-24 00:00:00" fixdate="2014-12-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add more log information for debug RSC[Spark Branch]</summary>
      <description>Currently, error message in certain scenerio is lost in RSC, and we need more log info in DEBUG level for debugging.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.SparkClientImpl.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.rpc.RpcDispatcher.java</file>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.RemoteDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="921" opendate="2009-11-10 00:00:00" fixdate="2009-11-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MapJoin output schema reordering</summary>
      <description>The FileSink operator following Map-side join sorts the output column names. This could results in wrong results if the number of columns of table is more than 10.</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.MapJoinFactory.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9211" opendate="2014-12-24 00:00:00" fixdate="2014-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Research on build mini HoS cluster on YARN for unit test[Spark Branch]</summary>
      <description>HoS on YARN is a common use case in product environment, we'd better enable unit test for this case.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.SparkClientImpl.java</file>
      <file type="M">shims.common.src.main.java.org.apache.hadoop.hive.shims.HadoopShims.java</file>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
      <file type="M">shims.0.20S.src.main.java.org.apache.hadoop.hive.shims.Hadoop20SShims.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.spark.RemoteHiveSparkClient.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.QTestUtil.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
      <file type="M">itests.qtest-spark.pom.xml</file>
      <file type="M">itests.pom.xml</file>
      <file type="M">data.conf.spark.hive-site.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9234" opendate="2014-12-30 00:00:00" fixdate="2014-1-30 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HiveServer2 leaks FileSystem objects in FileSystem.CACHE</summary>
      <description>Running over extended period (48+ hrs), we've noticed HiveServer2 leaking FileSystem objects in FileSystem.CACHE. Linked jiras were previous attempts to fix it, but the issue still seems to be there. A workaround is to disable the caching (by setting fs.hdfs.impl.disable.cache and fs.file.impl.disable.cache to true), but creating new FileSystem objects is expensive.</description>
      <version>0.12.0,0.12.1,0.13.0,0.13.1,0.14.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.SessionManager.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.HiveSessionImplwithUGI.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.HiveSessionImpl.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.HiveSessionBase.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.HiveSession.java</file>
    </fixedFiles>
  </bug>
  <bug id="9253" opendate="2015-1-5 00:00:00" fixdate="2015-2-5 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MetaStore server should support timeout for long running requests</summary>
      <description>In the description of HIVE-7195, one issue is that MetaStore client timeout is quite dumb. The client will timeout and the server has no idea the client is gone.The server should support timeout when the request from client runs a long time.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.RetryingHMSHandler.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.MetaStoreDirectSql.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="9267" opendate="2015-1-6 00:00:00" fixdate="2015-1-6 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Ensure custom UDF works with Spark [Spark Branch]</summary>
      <description>Create or add auto qtest if necessary.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="9272" opendate="2015-1-6 00:00:00" fixdate="2015-1-6 01:00:00" resolution="Unresolved">
    <buginformation>
      <summary>Tests for utf-8 support</summary>
      <description>Including some test cases for utf8 support in webhcat. The first four tests invoke hive, pig, mapred and streaming apis for testing the utf8 support for data processed, file names and job name. The last test case tests the filtering of job name with utf8 character</description>
      <version>0.14.0</version>
      <fixedVersion>None</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.src.test.e2e.templeton.drivers.TestDriverCurl.pm</file>
      <file type="M">hcatalog.src.test.e2e.templeton.deployers.deploy.e2e.artifacts.sh</file>
      <file type="M">hcatalog.src.test.e2e.templeton.build.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9277" opendate="2015-1-7 00:00:00" fixdate="2015-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hybrid Hybrid Grace Hash Join</summary>
      <description>We are proposing an enhanced hash join algorithm called “hybrid hybrid grace hash join”.We can benefit from this feature as illustrated below: The query will not fail even if the estimated memory requirement is slightly wrong Expensive garbage collection overhead can be avoided when hash table grows Join execution using a Map join operator even though the small table doesn't fit in memory as spilling some data from the build and probe sides will still be cheaper than having to shuffle the large fact tableThe design was based on Hadoop’s parallel processing capability and significant amount of memory available.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.WriteBuffers.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.persistence.TestBytesBytesMultiHashMap.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.MapJoinDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.ReduceSinkMapJoinProc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorMapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.HashTableLoader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.MapJoinBytesTableContainer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.HashMapWrapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.persistence.BytesBytesMultiHashMap.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.JoinUtil.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="9278" opendate="2015-1-7 00:00:00" fixdate="2015-1-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Cached expression feature broken in one case</summary>
      <description>Different query result depending on whether hive.cache.expr.evaluation is true or false. When true, no query results are produced (this is wrong).The q file:set hive.cache.expr.evaluation=true;CREATE TABLE cache_expr_repro (date_str STRING);LOAD DATA LOCAL INPATH '../../data/files/cache_expr_repro.txt' INTO TABLE cache_expr_repro;SELECT MONTH(date_str) AS `mon`, CAST((MONTH(date_str) - 1) / 3 + 1 AS int) AS `quarter`, YEAR(date_str) AS `year` FROM cache_expr_repro WHERE ((CAST((MONTH(date_str) - 1) / 3 + 1 AS int) = 1) AND (YEAR(date_str) = 2015)) GROUP BY MONTH(date_str), CAST((MONTH(date_str) - 1) / 3 + 1 AS int), YEAR(date_str) ;cache_expr_repro.txt2015-01-01 00:00:002015-02-01 00:00:002015-01-01 00:00:002015-02-01 00:00:002015-01-01 00:00:002015-01-01 00:00:002015-02-01 00:00:002015-02-01 00:00:002015-01-01 00:00:002015-01-01 00:00:00</description>
      <version>0.14.0</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExprNodeEvaluatorFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="9292" opendate="2015-1-7 00:00:00" fixdate="2015-2-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>CBO (Calcite Return Path): Inline GroupBy, Properties</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.TaskCompiler.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ParseContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndexCtx.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.index.RewriteParseContextGenerator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.OperatorUtils.java</file>
    </fixedFiles>
  </bug>
  <bug id="93" opendate="2008-12-2 00:00:00" fixdate="2008-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>dynamic serde does not handle &amp;#39;_&amp;#39; as the first character of a column name in a DDL</summary>
      <description>For example cannot initialize a dynamic serde with : struct result { string _c0}</description>
      <version>None</version>
      <fixedVersion>0.3.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.test.org.apache.hadoop.hive.serde2.dynamic.type.TestDynamicSerDe.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.dynamic.type.thrift.grammarTreeConstants.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.dynamic.type.thrift.grammarTokenManager.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.dynamic.type.thrift.grammarConstants.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.dynamic.type.thrift.grammar.jjt</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.dynamic.type.thrift.grammar.jj</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.dynamic.type.thrift.grammar.java</file>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.dynamic.type.JJTthrift.grammarState.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9316" opendate="2015-1-8 00:00:00" fixdate="2015-1-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>TestSqoop tests in WebHCat testsuite hardcode libdir path to hdfs</summary>
      <description>Currently the TestSqoop tests in WebHCat Perl based testsuite has hdfs:// prefix in the jdbc jar path in libdir, we should remove this to enable it to run against other file systems.NO PRECOMMIT TESTS</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.src.test.e2e.templeton.tests.jobsubmission.conf</file>
    </fixedFiles>
  </bug>
  <bug id="9318" opendate="2015-1-8 00:00:00" fixdate="2015-1-8 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Add UnionMerge rule on cbo path</summary>
      <description></description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.CalcitePlanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="9351" opendate="2015-1-12 00:00:00" fixdate="2015-1-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Running Hive Jobs with Tez cause templeton to never report percent complete</summary>
      <description>Currently, when submitting Hive jobs through WebHCat and Hive is configured to use Tez, the "percentComplete" field returned by WebHCat is empty.LaunchMapper in WebHCat parses stderr of the process that it launches to extract map = 100%, reduce = 100% for Map/Reduce case. With Tez the content of stderr looks like Map 1: -/- Reducer 2: 0/1 Map 1: -/- Reducer 2: 0(+1)/1 Map 1: -/- Reducer 2: 1/1WebHCat should handle that as well.WebHCat will follow HIVE-8495 and report (completed tasks)/(total tasks) as a percentage.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hcatalog.webhcat.svr.src.main.java.org.apache.hive.hcatalog.templeton.tool.TempletonUtils.java</file>
      <file type="M">hcatalog.src.test.e2e.templeton.tests.jobsubmission.conf</file>
      <file type="M">hcatalog.src.test.e2e.templeton.README.txt</file>
      <file type="M">hcatalog.src.test.e2e.templeton.drivers.TestDriverCurl.pm</file>
      <file type="M">hcatalog.src.test.e2e.templeton.deployers.env.sh</file>
      <file type="M">hcatalog.src.test.e2e.templeton.deployers.deploy.e2e.artifacts.sh</file>
    </fixedFiles>
  </bug>
  <bug id="9353" opendate="2015-1-13 00:00:00" fixdate="2015-1-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>make TABLE keyword optional in INSERT INTO TABLE foo...</summary>
      <description>standard SQL support INSERT INTO foo ...</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.parse.TestIUD.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.HiveParser.g</file>
    </fixedFiles>
  </bug>
  <bug id="9365" opendate="2015-1-13 00:00:00" fixdate="2015-5-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The Metastore should take port configuration from hive-site.xml</summary>
      <description>As opposed to the cli. Having this configuration in the launcher script create fragmentation and does is not consistent with the way the hive stack is configured.</description>
      <version>None</version>
      <fixedVersion>1.3.0,2.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="9369" opendate="2015-1-14 00:00:00" fixdate="2015-1-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fix arguments length checking in Upper and Lower UDF</summary>
      <description>currently initialize method checks that arguments.length &lt; 0it should check if arguments.length != 1</description>
      <version>0.14.0,0.14.1</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFUpper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFLower.java</file>
      <file type="M">ql.src.test.results.clientpositive.udf.dayofmonth.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.day.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.date.sub.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.date.add.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.udf.datediff.q.out</file>
      <file type="M">ql.src.test.results.beelinepositive.udf.to.date.q.out</file>
      <file type="M">ql.src.test.results.beelinepositive.udf.dayofmonth.q.out</file>
      <file type="M">ql.src.test.results.beelinepositive.udf.day.q.out</file>
      <file type="M">ql.src.test.results.beelinepositive.udf.date.sub.q.out</file>
      <file type="M">ql.src.test.results.beelinepositive.udf.date.add.q.out</file>
      <file type="M">ql.src.test.results.beelinepositive.udf.datediff.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.UDFYear.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.UDFMonth.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.UDFDayOfMonth.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFDateSub.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFDateDiff.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFDateAdd.java</file>
    </fixedFiles>
  </bug>
  <bug id="9383" opendate="2015-1-15 00:00:00" fixdate="2015-1-15 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Improve schema verification error message</summary>
      <description>Currently the error message just says the schema found. It should say the schema expected as well.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">beeline.src.java.org.apache.hive.beeline.HiveSchemaTool.java</file>
    </fixedFiles>
  </bug>
  <bug id="9402" opendate="2015-1-17 00:00:00" fixdate="2015-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Create GREATEST and LEAST udf</summary>
      <description>GREATEST function returns the greatest value in a list of valuesSignature: T greatest(T v1, T v2, ...)all values should be the same type (like in COALESCE)LEAST returns the least value in a list of valuesSignature: T least(T v1, T v2, ...)</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.show.functions.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FunctionRegistry.java</file>
    </fixedFiles>
  </bug>
  <bug id="9403" opendate="2015-1-17 00:00:00" fixdate="2015-1-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>File tests determinism with multiple reducers</summary>
      <description>If multiple reducers are used, some test result order need to be deterministic.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Test</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.join18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.union10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.transform.ppr2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.transform.ppr1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.union6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.transform.ppr2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.transform.ppr1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.scriptfile1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.join0.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.tez.groupby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.stats1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union19.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.union10.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.transform.ppr2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.transform.ppr1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.stats1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sort.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.semijoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.scriptfile1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.sample3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ptf.seqfile.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ptf.register.tblfn.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ptf.rcfile.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ptf.matchpath.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.ppd.transform.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.mapjoin.test.outer.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.mapjoin.filter.on.outerjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.limit.partition.metadataonly.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join.array.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join20.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join15.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.join0.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input.part2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.input14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby.multi.single.reducer2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.groupby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.join23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.spark.auto.join21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sort.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.semijoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.scriptfile1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample5.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.sample3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ptf.seqfile.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ptf.register.tblfn.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ptf.rcfile.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ptf.matchpath.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.ppd.transform.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.test.outer.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.mapjoin.filter.on.outerjoin.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.limit.partition.metadataonly.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join.array.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join7.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join20.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.auto.join21.q</file>
      <file type="M">ql.src.test.queries.clientpositive.auto.join23.q</file>
      <file type="M">ql.src.test.queries.clientpositive.groupby2.q</file>
      <file type="M">ql.src.test.queries.clientpositive.groupby.multi.single.reducer2.q</file>
      <file type="M">ql.src.test.queries.clientpositive.groupby.ppr.q</file>
      <file type="M">ql.src.test.queries.clientpositive.input14.q</file>
      <file type="M">ql.src.test.queries.clientpositive.input17.q</file>
      <file type="M">ql.src.test.queries.clientpositive.input18.q</file>
      <file type="M">ql.src.test.queries.clientpositive.input.part2.q</file>
      <file type="M">ql.src.test.queries.clientpositive.join0.q</file>
      <file type="M">ql.src.test.queries.clientpositive.join15.q</file>
      <file type="M">ql.src.test.queries.clientpositive.join18.q</file>
      <file type="M">ql.src.test.queries.clientpositive.join20.q</file>
      <file type="M">ql.src.test.queries.clientpositive.join21.q</file>
      <file type="M">ql.src.test.queries.clientpositive.join23.q</file>
      <file type="M">ql.src.test.queries.clientpositive.join6.q</file>
      <file type="M">ql.src.test.queries.clientpositive.join7.q</file>
      <file type="M">ql.src.test.queries.clientpositive.join.array.q</file>
      <file type="M">ql.src.test.queries.clientpositive.limit.partition.metadataonly.q</file>
      <file type="M">ql.src.test.queries.clientpositive.mapjoin.filter.on.outerjoin.q</file>
      <file type="M">ql.src.test.queries.clientpositive.mapjoin.test.outer.q</file>
      <file type="M">ql.src.test.queries.clientpositive.ppd.transform.q</file>
      <file type="M">ql.src.test.queries.clientpositive.ptf.matchpath.q</file>
      <file type="M">ql.src.test.queries.clientpositive.ptf.rcfile.q</file>
      <file type="M">ql.src.test.queries.clientpositive.ptf.register.tblfn.q</file>
      <file type="M">ql.src.test.queries.clientpositive.ptf.seqfile.q</file>
      <file type="M">ql.src.test.queries.clientpositive.sample3.q</file>
      <file type="M">ql.src.test.queries.clientpositive.sample5.q</file>
      <file type="M">ql.src.test.queries.clientpositive.scriptfile1.q</file>
      <file type="M">ql.src.test.queries.clientpositive.semijoin.q</file>
      <file type="M">ql.src.test.queries.clientpositive.sort.q</file>
      <file type="M">ql.src.test.queries.clientpositive.stats1.q</file>
      <file type="M">ql.src.test.queries.clientpositive.transform.ppr1.q</file>
      <file type="M">ql.src.test.queries.clientpositive.transform.ppr2.q</file>
      <file type="M">ql.src.test.queries.clientpositive.union10.q</file>
      <file type="M">ql.src.test.queries.clientpositive.union18.q</file>
      <file type="M">ql.src.test.queries.clientpositive.union19.q</file>
      <file type="M">ql.src.test.queries.clientpositive.union6.q</file>
      <file type="M">ql.src.test.queries.clientpositive.union.ppr.q</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join21.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.auto.join23.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.multi.single.reducer2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.ppr.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input14.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input17.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input18.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input.part2.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.join0.q.java1.7.out</file>
      <file type="M">ql.src.test.results.clientpositive.join15.q.out</file>
    </fixedFiles>
  </bug>
  <bug id="9438" opendate="2015-1-21 00:00:00" fixdate="2015-2-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>The standalone-jdbc jar missing some jars</summary>
      <description>The standalone-jdbc jar does not contain all the jars required for secure connections.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9440" opendate="2015-1-21 00:00:00" fixdate="2015-1-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Folders may not be pruned for Hadoop 2</summary>
      <description>HIVE-9367 is not a complete fix. It fixed for Hadoop 1. For Hadoop2, this method is not invoked.protected FileStatus[] listStatus(JobConf job) throws IOException;</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">shims.common.src.main.java.org.apache.hadoop.hive.shims.HadoopShimsSecure.java</file>
      <file type="M">shims.0.23.src.main.java.org.apache.hadoop.hive.shims.Hadoop23Shims.java</file>
      <file type="M">shims.0.20S.src.main.java.org.apache.hadoop.hive.shims.Hadoop20SShims.java</file>
    </fixedFiles>
  </bug>
  <bug id="9441" opendate="2015-1-22 00:00:00" fixdate="2015-1-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Remove call to deprecated Calcite method</summary>
      <description>The method RexLiteral.byteValue() was deprecated and will be remove in Calcite 1.0. The attached patch replaces it with a non-deprecated alternative.As soon as the patch is committed I will push to apache nexus a new calcite-1.0.0-snapshot that will be very close to proposed calcite-1.0 release.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder.java</file>
    </fixedFiles>
  </bug>
  <bug id="9446" opendate="2015-1-22 00:00:00" fixdate="2015-1-22 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>JDBC DatabaseMetadata.getColumns() does not work for temporary tables</summary>
      <description>After creating temporary table, calling DatabaseMetadData.getColumns() hits error "UnknownTableException(message:default.tmp_07 table not found)"</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStoreClient.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.TestJdbcWithMiniMr.java</file>
    </fixedFiles>
  </bug>
  <bug id="9447" opendate="2015-1-23 00:00:00" fixdate="2015-10-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Metastore: inefficient Oracle query for removing unused column descriptors when add/drop table/partition</summary>
      <description>Metastore needs removing unused column descriptors when drop/add partitions or tables. For query the unused column descriptor, the current implementation utilizes datanuleus' range function, which basically equals LIMIT syntax. However, Oracle does not support LIMIT, the query is converted as SQL&gt; SELECT * FROM (SELECT subq.*,ROWNUM rn FROM (SELECT'org.apache.hadoop.hive.metastore.model.MStorageDescriptor' ASNUCLEUS_TYPE,A0.INPUT_FORMAT,A0.IS_COMPRESSED,A0.IS_STOREDASSUBDIRECTORIES,A0.LOCATION,A0.NUM_BUCKETS,A0.OUTPUT_FORMAT,A0.SD_ID FROM drhcat.SDS A0 WHERE A0.CD_ID = ? ) subq ) WHERE rn &lt;= 1;Given that CD_ID is not very selective, this query may have to access large amount of rows (depends how many partitions the table has, millions of rows in our case). Metastore may become unresponsive because of this. Since Metastore only needs to know if the specific CD_ID is referenced in SDS table and does not need access the whole row. We can use select count(1) from SDS where SDS.CD_ID=?CD_ID is index column, the above query will do range scan for index, which is faster. For other DBs support LIMIT syntax such as MySQL, this problem does not exist. However, the new query does not hurt.</description>
      <version>0.14.0,1.0.0,1.1.0,1.2.0</version>
      <fixedVersion>3.0.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">standalone-metastore.src.main.java.org.apache.hadoop.hive.metastore.ObjectStore.java</file>
    </fixedFiles>
  </bug>
  <bug id="946" opendate="2009-11-19 00:00:00" fixdate="2009-12-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>pass context to custom mapper/reducer</summary>
      <description>It might be useful to pass some context to custom mapper/reducer process - the requirement is to identify the transform uniquely if there are multiple transforms in the same task.For that, we can pass the operator id of the script operator in some environment variable.If anything else is useful, please add to the list.</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ScriptOperator.java</file>
      <file type="M">conf.hive-default.xml</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9473" opendate="2015-1-26 00:00:00" fixdate="2015-1-26 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sql std auth should disallow built-in udfs that allow any java methods to be called</summary>
      <description>As mentioned in HIVE-8893, some udfs can be used to execute arbitrary java methods. This should be disallowed when sql standard authorization is used.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.SessionManager.java</file>
      <file type="M">service.src.java.org.apache.hive.service.cli.CLIService.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.plugin.SettableConfigUpdater.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hive.jdbc.authorization.TestJdbcWithSQLAuthorization.java</file>
    </fixedFiles>
  </bug>
  <bug id="9474" opendate="2015-1-27 00:00:00" fixdate="2015-1-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>truncate table changes permissions on the target</summary>
      <description>Create a table test(a string); Hive&gt; create table test(key string);Change the /user/hive/warehouse/test permission to something else other than the default, like 777.Hive&gt; dfs -chmod 777 /user/hive/warehouse/test;Hive&gt; dfs -ls -d /user/hive/warehouse/test;drwxrwxrwx - axu wheel 68 2015-01-26 18:45 /user/hive/warehouse/testThen truncate table test; Hive&gt; truncate table test;The permission goes back to the default.hive&gt; dfs -ls -d /user/hive/warehouse/test;drwxr-xr-x - axu wheel 68 2015-01-27 10:09 /user/hive/warehouse/test</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DDLTask.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.security.FolderPermissionBase.java</file>
    </fixedFiles>
  </bug>
  <bug id="9475" opendate="2015-1-27 00:00:00" fixdate="2015-1-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HiveMetastoreClient.tableExists does not work</summary>
      <description>We check the return value against null returning true if the return value is null. This is reversed, we should return true if the value is not null.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.TestHiveMetaStorePartitionSpecs.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStoreClient.java</file>
    </fixedFiles>
  </bug>
  <bug id="9481" opendate="2015-1-27 00:00:00" fixdate="2015-2-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>allow column list specification in INSERT statement</summary>
      <description>Given a table FOO(a int, b int, c int), ANSI SQL supports insert into FOO(c,b) select x,y from T. The expectation is that 'x' is written to column 'c' and 'y' is written column 'b' and 'a' is set to NULL, assuming column 'a' is NULLABLE.Hive does not support this. In Hive one has to ensure that the data producing statement has a schema that matches target table schema.Since Hive doesn't support DEFAULT value for columns in CREATE TABLE, when target schema is explicitly provided, missing columns will be set to NULL if they are NULLABLE, otherwise an error will be raised.If/when DEFAULT clause is supported, this can be enhanced to set default value rather than NULL.Thus, given create table source (a int, b int);create table target (x int, y int, z int);create table target2 (x int, y int, z int);insert into target(y,z) select * from source;will mean insert into target select null as x, a, b from source;and insert into target(z,y) select * from source;will meant insert into target select null as x, b, a from source;Also,from source insert into target(y,z) select null as x, * insert into target2(y,z) select null as x, source.*;and for partitioned tables, givenGiven:CREATE TABLE pageviews (userid VARCHAR(64), link STRING, "from" STRING) PARTITIONED BY (datestamp STRING) CLUSTERED BY (userid) INTO 256 BUCKETS STORED AS ORC;INSERT INTO TABLE pageviews PARTITION (datestamp = '2014-09-23')(userid,link) VALUES ('jsmith', 'mail.com');And dynamic partitioningINSERT INTO TABLE pageviews PARTITION (datestamp)(userid,datestamp,link) VALUES ('jsmith', '2014-09-23', 'mail.com');In all cases, the schema specification contains columns of the target table which are matched by position to the values produced by VALUES clause/SELECT statement. If the producer side provides values for a dynamic partition column, the column should be in the specified schema. Static partition values are part of the partition spec and thus are not produced by the producer and should not be part of the schema specification.</description>
      <version>0.14.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.parse.TestIUD.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.QBParseInfo.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.QBMetaData.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.HiveParser.g</file>
    </fixedFiles>
  </bug>
  <bug id="9493" opendate="2015-1-28 00:00:00" fixdate="2015-1-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Failed job may not throw exceptions [Spark Branch]</summary>
      <description>Currently remote driver assumes exception will be thrown when job fails to run. This may not hold since job is submitted asynchronously. And we have to check the futures before we decide the job is successful.</description>
      <version>None</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">spark-client.src.main.java.org.apache.hive.spark.client.RemoteDriver.java</file>
    </fixedFiles>
  </bug>
  <bug id="9496" opendate="2015-1-28 00:00:00" fixdate="2015-2-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Slf4j warning in hive command</summary>
      <description>Each time 'hive' command is ran, we have an Sl4J warning about multiple jars containing SL4J classes.This bug is similar to Hive-6162, but doesn't seems to be solved.Logging initialized using configuration in file:/etc/hive/conf/hive-log4j.propertiesSLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in &amp;#91;jar:file:/usr/hdp/2.2.0.0-1084/hadoop/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class&amp;#93;SLF4J: Found binding in &amp;#91;jar:file:/usr/hdp/2.2.0.0-1084/hive/lib/hive-jdbc-0.14.0.2.2.0.0-1084-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class&amp;#93;SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type &amp;#91;org.slf4j.impl.Log4jLoggerFactory&amp;#93;</description>
      <version>0.14.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">jdbc.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9499" opendate="2015-1-28 00:00:00" fixdate="2015-3-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>hive.limit.query.max.table.partition makes queries fail on non-partitioned tables</summary>
      <description>If you use hive.limit.query.max.table.partition to limit the amount of partitions that can be queried it makes queries on non-partitioned tables fail.Example:CREATE TABLE tmp(test INT);SELECT COUNT(*) FROM TMP; -- works fineSET hive.limit.query.max.table.partition=20;SELECT COUNT(*) FROM TMP; -- generates NPE (FAILED: NullPointerException null)SET hive.limit.query.max.table.partition=-1;SELECT COUNT(*) FROM TMP; -- works fine again</description>
      <version>0.14.0,1.0.0,1.1.0,1.2.0,2.0.0</version>
      <fixedVersion>2.0.1,2.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ParseContext.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.stats.annotation.StatsRulesProcFactory.java</file>
    </fixedFiles>
  </bug>
  <bug id="95" opendate="2008-12-2 00:00:00" fixdate="2008-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>improve cli error messages by lowering backtracking to 1</summary>
      <description>Stop antlr from backtracking so much should (and does) improve error messages since antlr will report the error closer to where it happened.</description>
      <version>None</version>
      <fixedVersion>0.3.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.compiler.errors.wrong.distinct2.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.Hive.g</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9502" opendate="2015-1-28 00:00:00" fixdate="2015-1-28 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parquet cannot read Map types from files written with Hive &lt;= 0.12</summary>
      <description>When reading a Parquet file written by Hive &lt;= 0.12, the following error is thrown:Caused by: java.lang.ArrayIndexOutOfBoundsException: 1 at org.apache.hadoop.hive.ql.io.parquet.serde.AbstractParquetMapInspector.getMap(AbstractParquetMapInspector.java:73) at org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.serialize(LazySimpleSerDe.java:519) at org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.serializeField(LazySimpleSerDe.java:443) at org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.serialize(LazySimpleSerDe.java:427) at org.apache.hadoop.hive.ql.exec.FileSinkOperator.processOp(FileSinkOperator.java:582) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:796) at org.apache.hadoop.hive.ql.exec.LimitOperator.processOp(LimitOperator.java:51) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:796) at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:87) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:796) at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:92) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:796) at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:539) ... 9 moreThis is because old versions of Hive (&lt;= 0.12) write Map types using the following schema:optional group m1 (MAP_KEY_VALUE) { repeated group map { required binary key; optional binary key; }} PARQUET-113 mentions new annotations for Parquet nested types. https://github.com/rdblue/incubator-parquet-format/blob/PARQUET-113-add-list-and-map-spec/LogicalTypes.md#mapsAnd now the correct schema is:optional group m1f (MAP) { repeated group map (MAP_KEY_VALUE) { required binary key; optional binary key; }}We should be backwards compatible to the old schema as well.</description>
      <version>0.14.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.parquet.convert.HiveGroupConverter.java</file>
    </fixedFiles>
  </bug>
  <bug id="9507" opendate="2015-1-29 00:00:00" fixdate="2015-2-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Make "LATERAL VIEW inline(expression) mytable" tolerant to nulls</summary>
      <description>I have tweets stored with avro on hdfs with the default twitter status (tweet) schema.There's an object called "entities" that contains arrays of structs.When I runSELECT mytable.*FROM tweetsLATERAL VIEW INLINE(entities.media) mytableI get the exception attached as partial_log.log, however, if I addWHERE entities.media IS NOT NULLit runs perfectly.</description>
      <version>0.14.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">serde.src.java.org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryArray.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDTFInline.java</file>
      <file type="M">itests.util.src.main.java.org.apache.hadoop.hive.ql.QTestUtil.java</file>
    </fixedFiles>
  </bug>
  <bug id="9508" opendate="2015-1-29 00:00:00" fixdate="2015-5-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>MetaStore client socket connection should have a lifetime</summary>
      <description>Currently HiveMetaStoreClient (or SessionHMSC) is connected to one Metastore server until the connection is closed or there is a problem. I would like to introduce the concept of a MetaStore client socket life time. The MS client will reconnect if the socket lifetime is reached. This will help during rolling upgrade of Metastore.When there are multiple Metastore servers behind a VIP (load balancer), it is easy to take one server out of rotation and wait for 10+ mins for all existing connections will die down (if the lifetime is 5mins say) and the server can be updated.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.java</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.metastore.TestHiveMetaStore.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="9509" opendate="2015-1-29 00:00:00" fixdate="2015-2-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Restore partition spec validation removed by HIVE-9445</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.java</file>
    </fixedFiles>
  </bug>
  <bug id="9513" opendate="2015-1-29 00:00:00" fixdate="2015-2-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>NULL POINTER EXCEPTION</summary>
      <description>NPE duting parsing of :select * from ( select * from ( select 1 as id , "foo" as str_1 from staging.dual ) f union all select * from ( select 2 as id , "bar" as str_2 from staging.dual ) g) e ;</description>
      <version>0.12.0,0.13.0,0.13.1,0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientnegative.union3.q.out</file>
      <file type="M">ql.src.test.queries.clientnegative.union3.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.CalcitePlanner.java</file>
    </fixedFiles>
  </bug>
  <bug id="9514" opendate="2015-1-29 00:00:00" fixdate="2015-1-29 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>schematool is broken in hive 1.0.0</summary>
      <description>Schematool gives following error - bin/schematool -dbType derby -initSchemaStarting metastore schema initialization to 1.0org.apache.hadoop.hive.metastore.HiveMetaException: Unknown version specified for initialization: 1.0Metastore schema hasn't changed from 0.14.0 to 1.0.0. So there is no need for new .sql files for 1.0.0. However, schematool needs to be made aware of the metastore schema equivalence.</description>
      <version>None</version>
      <fixedVersion>1.0.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.MetaStoreSchemaInfo.java</file>
    </fixedFiles>
  </bug>
  <bug id="9527" opendate="2015-1-31 00:00:00" fixdate="2015-1-31 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Include dot files in tarball</summary>
      <description>Ideally the source tarball exactly matches the svn tag. On item that is missing is the dot files.</description>
      <version>0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.1.0</fixedVersion>
      <type>Task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">packaging.src.main.assembly.src.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9617" opendate="2015-2-9 00:00:00" fixdate="2015-2-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>UDF from_utc_timestamp throws NPE if the second argument is null</summary>
      <description>UDF from_utc_timestamp throws NPE if the second argument is nullselect from_utc_timestamp('2015-02-06 10:30:00', cast(null as string));FAILED: NullPointerException null</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.udf.generic.GenericUDFFromUtcTimestamp.java</file>
    </fixedFiles>
  </bug>
  <bug id="962" opendate="2009-12-1 00:00:00" fixdate="2009-12-1 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>"show functions" does not work with unquoted string</summary>
      <description>If the function name is provided without quotation marks, we should also show the function correctly.hive&gt; show functions substr;OKTime taken: 0.168 secondshive&gt; show functions 'substr';OKsubstrTime taken: 0.164 secondshive&gt; describe function substr;OKsubstr(str, pos[, len]) - returns the substring of str that starts at pos and is of length lenTime taken: 0.188 seconds</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.Hive.g</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="963" opendate="2009-12-2 00:00:00" fixdate="2009-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>no out of memory errors for skewed join</summary>
      <description>Currently, in case of skew, hive runs out of memory.A simpler fix would be to use JDBM to store data and use that.It can be configurable and JDBM should only be triggered if the number of values for a given key exceed a given number.</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.compiler.plan.join8.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join7.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join6.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join5.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join4.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join3.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join2.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.join1.q.xml</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.exec.TestHashMapWrapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.joinDesc.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MRU.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinObjectValue.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinObjectKey.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.JoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.HashMapWrapper.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DCLLItem.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.CommonJoinOperator.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9647" opendate="2015-2-10 00:00:00" fixdate="2015-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Discrepancy in cardinality estimates between partitioned and un-partitioned tables</summary>
      <description>High-level summaryHiveRelMdSelectivity.computeInnerJoinSelectivity relies on per column number of distinct value to estimate join selectivity.The way statistics are aggregated for partitioned tables results in discrepancy in number of distinct values which results in different plans between partitioned and un-partitioned schemas.The table below summarizes the NDVs in computeInnerJoinSelectivity which are used to estimate selectivity of joins.Column Partitioned count distincts Un-Partitioned count distinctssr_customer_sk 71,245 1,415,625sr_item_sk 38,846 62,562sr_ticket_number 71,245 34,931,085ss_customer_sk 88,476 1,415,625ss_item_sk 38,846 62,562ss_ticket_number 100,756 56,256,175The discrepancy is because NDV calculation for a partitioned table assumes that the NDV range is contained within each partition and is calculates as "select max(NUM_DISTINCTS) from PART_COL_STATS” .This is problematic for columns like ticket number which are naturally increasing with the partitioned date column ss_sold_date_sk.SuggestionsUse Hyper Log Log as suggested by Gopal, there is an HLL implementation for HBASE co-porccessors which we can use as a reference here Using the global stats from TAB_COL_STATS and the per partition stats from PART_COL_STATS extrapolate the NDV for the qualified partitions as in :Max ( (NUM_DISTINCTS from TAB_COL_STATS) x (Number of qualified partitions) / (Number of Partitions), max(NUM_DISTINCTS) from PART_COL_STATS))More detailsWhile doing TPC-DS Partitioned vs. Un-Partitioned runs I noticed that many of the plans are different, then I dumped the CBO logical plan and I found that join estimates are drastically differentUnpartitioned schema :2015-02-10 11:33:27,624 DEBUG [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:apply(12624)) - Plan After Join Reordering:HiveProjectRel(store_sales_quantitycount=[$0], store_sales_quantityave=[$1], store_sales_quantitystdev=[$2], store_sales_quantitycov=[/($2, $1)], as_store_returns_quantitycount=[$3], as_store_returns_quantityave=[$4], as_store_returns_quantitystdev=[$5], store_returns_quantitycov=[/($5, $4)]): rowcount = 1.0, cumulative cost = {6.056835407771381E8 rows, 0.0 cpu, 0.0 io}, id = 2956 HiveAggregateRel(group=[{}], agg#0=[count($0)], agg#1=[avg($0)], agg#2=[stddev_samp($0)], agg#3=[count($1)], agg#4=[avg($1)], agg#5=[stddev_samp($1)]): rowcount = 1.0, cumulative cost = {6.056835407771381E8 rows, 0.0 cpu, 0.0 io}, id = 2954 HiveProjectRel($f0=[$4], $f1=[$8]): rowcount = 40.05611776795562, cumulative cost = {6.056835407771381E8 rows, 0.0 cpu, 0.0 io}, id = 2952 HiveProjectRel(ss_sold_date_sk=[$0], ss_item_sk=[$1], ss_customer_sk=[$2], ss_ticket_number=[$3], ss_quantity=[$4], sr_item_sk=[$5], sr_customer_sk=[$6], sr_ticket_number=[$7], sr_return_quantity=[$8], d_date_sk=[$9], d_quarter_name=[$10]): rowcount = 40.05611776795562, cumulative cost = {6.056835407771381E8 rows, 0.0 cpu, 0.0 io}, id = 2982 HiveJoinRel(condition=[=($9, $0)], joinType=[inner]): rowcount = 40.05611776795562, cumulative cost = {6.056835407771381E8 rows, 0.0 cpu, 0.0 io}, id = 2980 HiveJoinRel(condition=[AND(AND(=($2, $6), =($1, $5)), =($3, $7))], joinType=[inner]): rowcount = 28880.460910696, cumulative cost = {6.05654559E8 rows, 0.0 cpu, 0.0 io}, id = 2964 HiveProjectRel(ss_sold_date_sk=[$0], ss_item_sk=[$2], ss_customer_sk=[$3], ss_ticket_number=[$9], ss_quantity=[$10]): rowcount = 5.50076554E8, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 2920 HiveTableScanRel(table=[[tpcds_bin_orc_200.store_sales]]): rowcount = 5.50076554E8, cumulative cost = {0}, id = 2822 HiveProjectRel(sr_item_sk=[$2], sr_customer_sk=[$3], sr_ticket_number=[$9], sr_return_quantity=[$10]): rowcount = 5.5578005E7, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 2923 HiveTableScanRel(table=[[tpcds_bin_orc_200.store_returns]]): rowcount = 5.5578005E7, cumulative cost = {0}, id = 2823 HiveProjectRel(d_date_sk=[$0], d_quarter_name=[$15]): rowcount = 101.31622746185853, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 2948 HiveFilterRel(condition=[=($15, '2000Q1')]): rowcount = 101.31622746185853, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 2946 HiveTableScanRel(table=[[tpcds_bin_orc_200.date_dim]]): rowcount = 73049.0, cumulative cost = {0}, id = 2821Partitioned schema :2015-02-10 11:32:16,880 DEBUG [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:apply(12624)) - Plan After Join Reordering:HiveProjectRel(store_sales_quantitycount=[$0], store_sales_quantityave=[$1], store_sales_quantitystdev=[$2], store_sales_quantitycov=[/($2, $1)], as_store_returns_quantitycount=[$3], as_store_returns_quantityave=[$4], as_store_returns_quantitystdev=[$5], store_returns_quantitycov=[/($5, $4)]): rowcount = 1.0, cumulative cost = {6.064175958973647E8 rows, 0.0 cpu, 0.0 io}, id = 2791 HiveAggregateRel(group=[{}], agg#0=[count($0)], agg#1=[avg($0)], agg#2=[stddev_samp($0)], agg#3=[count($1)], agg#4=[avg($1)], agg#5=[stddev_samp($1)]): rowcount = 1.0, cumulative cost = {6.064175958973647E8 rows, 0.0 cpu, 0.0 io}, id = 2789 HiveProjectRel($f0=[$3], $f1=[$8]): rowcount = 100840.08570910375, cumulative cost = {6.064175958973647E8 rows, 0.0 cpu, 0.0 io}, id = 2787 HiveProjectRel(ss_item_sk=[$4], ss_customer_sk=[$5], ss_ticket_number=[$6], ss_quantity=[$7], ss_sold_date_sk=[$8], sr_item_sk=[$0], sr_customer_sk=[$1], sr_ticket_number=[$2], sr_return_quantity=[$3], d_date_sk=[$9], d_quarter_name=[$10]): rowcount = 100840.08570910375, cumulative cost = {6.064175958973647E8 rows, 0.0 cpu, 0.0 io}, id = 2817 HiveJoinRel(condition=[AND(AND(=($5, $1), =($4, $0)), =($6, $2))], joinType=[inner]): rowcount = 100840.08570910375, cumulative cost = {6.064175958973647E8 rows, 0.0 cpu, 0.0 io}, id = 2815 HiveProjectRel(sr_item_sk=[$1], sr_customer_sk=[$2], sr_ticket_number=[$8], sr_return_quantity=[$9]): rowcount = 5.5578005E7, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 2758 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200_orig.store_returns]]): rowcount = 5.5578005E7, cumulative cost = {0}, id = 2658 HiveJoinRel(condition=[=($5, $4)], joinType=[inner]): rowcount = 762935.5811373093, cumulative cost = {5.500766553162274E8 rows, 0.0 cpu, 0.0 io}, id = 2801 HiveProjectRel(ss_item_sk=[$1], ss_customer_sk=[$2], ss_ticket_number=[$8], ss_quantity=[$9], ss_sold_date_sk=[$22]): rowcount = 5.50076554E8, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 2755 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200_orig.store_sales]]): rowcount = 5.50076554E8, cumulative cost = {0}, id = 2657 HiveProjectRel(d_date_sk=[$0], d_quarter_name=[$15]): rowcount = 101.31622746185853, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 2783 HiveFilterRel(condition=[=($15, '2000Q1')]): rowcount = 101.31622746185853, cumulative cost = {0.0 rows, 0.0 cpu, 0.0 io}, id = 2781 HiveTableScanRel(table=[[tpcds_bin_partitioned_orc_200_orig.date_dim]]): rowcount = 73049.0, cumulative cost = {0}, id = 2656This was puzzling knowing that the stats for both tables are “identical” in TAB_COL_STATS.Column statistics from TAB_COL_STATS, notice how the column statistics are identical in both cases.DB_NAME COLUMN_NAME COLUMN_TYPE NUM_NULLS LONG_HIGH_VALUE LONG_LOW_VALUE MAX_COL_LEN NUM_DISTINCTStpcds_bin_orc_200 d_date_sk int 0 2,488,070 2,415,022 NULL 65,332tpcds_bin_partitioned_orc_200 d_date_sk int 0 2,488,070 2,415,022 NULL 65,332tpcds_bin_orc_200 d_quarter_name string 0 NULL NULL 6 721tpcds_bin_partitioned_orc_200 d_quarter_name string 0 NULL NULL 6 721tpcds_bin_orc_200 sr_customer_sk int 1,009,571 1,600,000 1 NULL 1,415,625tpcds_bin_partitioned_orc_200 sr_customer_sk int 1,009,571 1,600,000 1 NULL 1,415,625tpcds_bin_orc_200 sr_item_sk int 0 48,000 1 NULL 62,562tpcds_bin_partitioned_orc_200 sr_item_sk int 0 48,000 1 NULL 62,562tpcds_bin_orc_200 sr_ticket_number int 0 48,000,000 1 NULL 34,931,085tpcds_bin_partitioned_orc_200 sr_ticket_number int 0 48,000,000 1 NULL 34,931,085tpcds_bin_orc_200 ss_customer_sk int 12,960,424 1,600,000 1 NULL 1,415,625tpcds_bin_partitioned_orc_200 ss_customer_sk int 12,960,424 1,600,000 1 NULL 1,415,625tpcds_bin_orc_200 ss_item_sk int 0 48,000 1 NULL 62,562tpcds_bin_partitioned_orc_200 ss_item_sk int 0 48,000 1 NULL 62,562tpcds_bin_orc_200 ss_sold_date_sk int 0 2,452,642 2,450,816 NULL 2,226tpcds_bin_partitioned_orc_200 ss_sold_date_sk int 0 2,452,642 2,450,816 NULL 2,226tpcds_bin_orc_200 ss_ticket_number int 0 48,000,000 1 NULL 56,256,175tpcds_bin_partitioned_orc_200 ss_ticket_number int 0 48,000,000 1 NULL 56,256,175For partitioned tables we get the statistics using get_aggr_stats_for which eventually issues the query belowselect COLUMN_NAME, COLUMN_TYPE, … max(NUM_DISTINCTS), …from PART_COL_STATSWherewhere DB_NAME = and TABLE_NAME = and COLUMN_NAME in and PARTITION_NAME in (1 … N)group by COLUMN_NAME , COLUMN_TYPE; …</description>
      <version>0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.StatObjectConverter.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.ObjectStore.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.MetaStoreDirectSql.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.LinearExtrapolatePartStatus.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.IExtrapolatePartStatus.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="9652" opendate="2015-2-11 00:00:00" fixdate="2015-2-11 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Tez in place updates should detect redirection of STDERR</summary>
      <description>Tez in place updates detects STDOUT redirection and logs using old logging method. Similarly it should detect STDERR redirection as well. This will make sure following will log using old methodhive -e '&lt;some_query&gt;' 2&gt; err.log</description>
      <version>0.14.0,1.0.0,1.1.0,1.2.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.tez.TezJobMonitor.java</file>
    </fixedFiles>
  </bug>
  <bug id="9659" opendate="2015-2-12 00:00:00" fixdate="2015-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>&amp;#39;Error while trying to create table container&amp;#39; occurs during hive query case execution when hive.optimize.skewjoin set to &amp;#39;true&amp;#39; [Spark Branch]</summary>
      <description>We found that 'Error while trying to create table container' occurs during Big-Bench Q12 case execution when hive.optimize.skewjoin set to 'true'.If hive.optimize.skewjoin set to 'false', the case could pass.How to reproduce:1. set hive.optimize.skewjoin=true;2. Run BigBench case Q12 and it will fail. Check the executor log (e.g. /usr/lib/spark/work/app-XXXX/2/stderr) and you will found error 'Error while trying to create table container' in the log and also a NullPointerException near the end of the log.(a) Detail error message for 'Error while trying to create table container':15/02/12 01:29:49 ERROR SparkMapRecordHandler: Error processing row: org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Error while trying to create table containerorg.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hadoop.hive.ql.metadata.HiveException: Error while trying to create table container at org.apache.hadoop.hive.ql.exec.spark.HashTableLoader.load(HashTableLoader.java:118) at org.apache.hadoop.hive.ql.exec.MapJoinOperator.loadHashTable(MapJoinOperator.java:193) at org.apache.hadoop.hive.ql.exec.MapJoinOperator.cleanUpInputFileChangedOp(MapJoinOperator.java:219) at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1051) at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1055) at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1055) at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1055) at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:486) at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.processRow(SparkMapRecordHandler.java:141) at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.processNextRecord(HiveMapFunctionResultList.java:47) at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.processNextRecord(HiveMapFunctionResultList.java:27) at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:98) at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41) at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:217) at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:65) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41) at org.apache.spark.scheduler.Task.run(Task.scala:56) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Error while trying to create table container at org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainerSerDe.load(MapJoinTableContainerSerDe.java:158) at org.apache.hadoop.hive.ql.exec.spark.HashTableLoader.load(HashTableLoader.java:115) ... 21 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Error, not a directory: hdfs://bhx1:8020/tmp/hive/root/d22ef465-bff5-4edb-a822-0a9f1c25b66c/hive_2015-02-12_01-28-10_008_6897031694580088767-1/-mr-10009/HashTable-Stage-6/MapJoin-mapfile01--.hashtable at org.apache.hadoop.hive.ql.exec.persistence.MapJoinTableContainerSerDe.load(MapJoinTableContainerSerDe.java:106) ... 22 more15/02/12 01:29:49 INFO SparkRecordHandler: maximum memory = 4093902848015/02/12 01:29:49 INFO PerfLogger: &lt;PERFLOG method=SparkInitializeOperators from=org.apache.hadoop.hive.ql.exec.spark.SparkRecordHandler&gt;(b) Detail error message for NullPointerException:5/02/12 01:29:50 ERROR MapJoinOperator: Unexpected exception: nulljava.lang.NullPointerException at org.apache.hadoop.hive.ql.exec.MapJoinOperator.setMapJoinKey(MapJoinOperator.java:227) at org.apache.hadoop.hive.ql.exec.MapJoinOperator.processOp(MapJoinOperator.java:271) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815) at org.apache.hadoop.hive.ql.exec.FilterOperator.processOp(FilterOperator.java:120) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815) at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:95) at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:157) at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:493) at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.processRow(SparkMapRecordHandler.java:141) at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.processNextRecord(HiveMapFunctionResultList.java:47) at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.processNextRecord(HiveMapFunctionResultList.java:27) at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:98) at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41) at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:217) at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:65) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41) at org.apache.spark.scheduler.Task.run(Task.scala:56) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)15/02/12 01:29:50 INFO Executor: Executor is trying to kill task 144.2 in stage 3.0 (TID 1500)15/02/12 01:29:50 INFO MapOperator: Initializing Self MAP[1800]15/02/12 01:29:50 ERROR SparkMapRecordHandler: Error processing row: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"wcs_click_date_sk":37793,"wcs_click_time_sk":null,"wcs_sales_sk":null,"wcs_item_sk":51402,"wcs_web_page_sk":null,"wcs_user_sk":2541920}org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"wcs_click_date_sk":37793,"wcs_click_time_sk":null,"wcs_sales_sk":null,"wcs_item_sk":51402,"wcs_web_page_sk":null,"wcs_user_sk":2541920} at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:503) at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.processRow(SparkMapRecordHandler.java:141) at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.processNextRecord(HiveMapFunctionResultList.java:47) at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.processNextRecord(HiveMapFunctionResultList.java:27) at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:98) at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41) at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:217) at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:65) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41) at org.apache.spark.scheduler.Task.run(Task.scala:56) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unexpected exception: null at org.apache.hadoop.hive.ql.exec.MapJoinOperator.processOp(MapJoinOperator.java:314) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815) at org.apache.hadoop.hive.ql.exec.FilterOperator.processOp(FilterOperator.java:120) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815) at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:95) at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:157) at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:493) ... 14 moreCaused by: java.lang.NullPointerException at org.apache.hadoop.hive.ql.exec.MapJoinOperator.setMapJoinKey(MapJoinOperator.java:227) at org.apache.hadoop.hive.ql.exec.MapJoinOperator.processOp(MapJoinOperator.java:271) ... 20 more15/02/12 01:29:50 INFO MapOperator: MAP[1797]: records read - 115/02/12 01:29:50 INFO Executor: Executor is trying to kill task 96.3 in stage 3.0 (TID 1515)15/02/12 01:29:50 INFO PerfLogger: &lt;PERFLOG method=SparkInitializeOperators from=org.apache.hadoop.hive.ql.exec.spark.SparkRecordHandler&gt;15/02/12 01:29:50 INFO MapOperator: Initialization Done 1800 MAP15/02/12 01:29:50 INFO SparkRecordHandler: processing 1 rows: used memory = 1202378261615/02/12 01:29:50 ERROR Executor: Exception in task 16.2 in stage 3.0 (TID 1488)java.lang.RuntimeException: Error processing row: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"wcs_click_date_sk":37793,"wcs_click_time_sk":null,"wcs_sales_sk":null,"wcs_item_sk":51402,"wcs_web_page_sk":null,"wcs_user_sk":2541920} at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.processRow(SparkMapRecordHandler.java:153) at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.processNextRecord(HiveMapFunctionResultList.java:47) at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.processNextRecord(HiveMapFunctionResultList.java:27) at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:98) at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41) at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:217) at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:65) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41) at org.apache.spark.scheduler.Task.run(Task.scala:56) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"wcs_click_date_sk":37793,"wcs_click_time_sk":null,"wcs_sales_sk":null,"wcs_item_sk":51402,"wcs_web_page_sk":null,"wcs_user_sk":2541920} at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:503) at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.processRow(SparkMapRecordHandler.java:141) ... 13 moreCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unexpected exception: null at org.apache.hadoop.hive.ql.exec.MapJoinOperator.processOp(MapJoinOperator.java:314) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815) at org.apache.hadoop.hive.ql.exec.FilterOperator.processOp(FilterOperator.java:120) at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815) at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:95) at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:157) at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:493) ... 14 moreCaused by: java.lang.NullPointerException at org.apache.hadoop.hive.ql.exec.MapJoinOperator.setMapJoinKey(MapJoinOperator.java:227) at org.apache.hadoop.hive.ql.exec.MapJoinOperator.processOp(MapJoinOperator.java:271) ... 20 more</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.plan.SparkWork.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.spark.SparkSkewJoinResolver.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.spark.SparkSkewJoinProcFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.SparkMapJoinResolver.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.GenSparkSkewJoinProcessor.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.lib.PreOrderWalker.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="966" opendate="2009-12-2 00:00:00" fixdate="2009-12-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive command line should output log messages in 24-hour format</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ExecDriver.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9661" opendate="2015-2-12 00:00:00" fixdate="2015-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Refine debug log with schema information for the method of creating session directories</summary>
      <description>For a session, the scratch directory can be either a local path or a hdfs scratch path. The method name createRootHDFSDir is quite confusing. So add the schema information to the debug log for the troubleshooting need.</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
    </fixedFiles>
  </bug>
  <bug id="9664" opendate="2015-2-12 00:00:00" fixdate="2015-3-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Hive "add jar" command should be able to download and add jars from a repository</summary>
      <description>Currently Hive's "add jar" command takes a local path to the dependency jar. This clutters the local file-system as users may forget to remove this jar laterIt would be nice if Hive supported a Gradle like notation to download the jar from a repository.Example: add jar org:module:versionIt should also be backward compatible and should take jar from the local file-system as well. RB: https://reviews.apache.org/r/31628/</description>
      <version>0.14.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.session.SessionState.java</file>
      <file type="M">ql.pom.xml</file>
      <file type="M">pom.xml</file>
      <file type="M">packaging.src.main.assembly.bin.xml</file>
      <file type="M">itests.pom.xml</file>
    </fixedFiles>
  </bug>
  <bug id="9665" opendate="2015-2-12 00:00:00" fixdate="2015-2-12 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Parallel move task optimization causes race condition</summary>
      <description>The change in HIVE-8042 doesn't actually work. Running it at scale produces race conditions which lead to broken thrift messages and OOMs. E.g.:java.lang.OutOfMemoryError: Java heap space at org.apache.thrift.protocol.TBinaryProtocol.readStringBody(TBinaryProtocol.java:353) at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:215) at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69) at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_table(ThriftHiveMetastore.java:1122) at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_table(ThriftHiveMetastore.java:1108) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:1091) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.getTable(SessionHiveMetaStoreClient.java:131) at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:90) at com.sun.proxy.$Proxy9.getTable(Unknown Source) at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1064) at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1019) at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1006) at org.apache.hadoop.hive.ql.exec.MoveTask.execute(MoveTask.java:250) at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160) at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85) at org.apache.hadoop.hive.ql.exec.TaskRunner.run(TaskRunner.java:72)java.lang.OutOfMemoryError: Java heap space at org.apache.thrift.protocol.TBinaryProtocol.readStringBody(TBinaryProtocol.java:353) at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:215) at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69) at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_table(ThriftHiveMetastore.java:1122) at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_table(ThriftHiveMetastore.java:1108) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:1091) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.getTable(SessionHiveMetaStoreClient.java:131) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:90) at com.sun.proxy.$Proxy9.getTable(Unknown Source) at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1064) at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1019) at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1006) at org.apache.hadoop.hive.ql.exec.MoveTask.execute(MoveTask.java:250) at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160) at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85) at org.apache.hadoop.hive.ql.exec.TaskRunner.run(TaskRunner.java:72)java.lang.OutOfMemoryError: Java heap space at org.apache.thrift.protocol.TBinaryProtocol.readStringBody(TBinaryProtocol.java:353) at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:215) at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69) at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_table(ThriftHiveMetastore.java:1122) at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_table(ThriftHiveMetastore.java:1108) at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:1091) at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.getTable(SessionHiveMetaStoreClient.java:131) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:90) at com.sun.proxy.$Proxy9.getTable(Unknown Source) at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1064) at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1019) at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1006) at org.apache.hadoop.hive.ql.exec.MoveTask.execute(MoveTask.java:250) at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160) at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85) at org.apache.hadoop.hive.ql.exec.TaskRunner.run(TaskRunner.java:72)</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
    </fixedFiles>
  </bug>
  <bug id="968" opendate="2009-12-3 00:00:00" fixdate="2009-12-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>map join may lead to very large files</summary>
      <description>If the table under consideration is a very large file, it may lead to very large files on the mappers. The job may never complete, and the files will never be cleaned from the tmp directory. It would be great if the table can be placed in the distributed cache, but minimally the following should be added:If the table (source) being joined leads to a very big file, it should just throw an error.New configuration parameters can be added to limit the number of rows or for the size of the table.The mapper should not be tried 4 times, but it should fail immediately.I cant think of any better way for the mapper to communicate with the client, but for it to write in some well knownhdfs file - the client can read the file periodically (while polling), and if sees an error can just kill the job, but withappropriate error messages indicating to the client why the job died.</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>New Feature</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.util.jdbm.RecordManagerProvider.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.util.jdbm.RecordManagerOptions.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.util.jdbm.RecordManagerFactory.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.util.jdbm.recman.TransactionManager.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.util.jdbm.recman.RecordFile.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.util.jdbm.recman.Provider.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.util.jdbm.recman.BaseRecordManager.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinOperator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9681" opendate="2015-2-13 00:00:00" fixdate="2015-4-13 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Extend HiveAuthorizationProvider to support partition-sets.</summary>
      <description>HiveAuthorizationProvider allows only for the authorization of a single partition at a time. For instance, when the StorageBasedAuthProvider must authorize an operation on a set of partitions (say from a PreDropPartitionEvent), each partition's data-directory needs to be checked individually. For N partitions, this results in N namenode calls.I'd like to add authorize() overloads that accept multiple partitions. This will allow StorageBasedAuthProvider to make batched namenode calls. P.S. There's 2 further optimizations that are possible:1. In the ideal case, we'd have a single call in org.apache.hadoop.fs.FileSystem to check access for an array of Paths, something like:FileSystem.java@InterfaceAudience.LimitedPrivate({"HDFS", "Hive"}) public void access(Path [] paths, FsAction mode) throws AccessControlException, FileNotFoundException, IOException {...}2. We can go one better if we could retrieve partition-locations in DirectSQL and use those for authorization. The EventListener-abstraction behind which the AuthProviders operate make this difficult. I can attempt to solve this using a PartitionSpec and a call-back into the ObjectStore from StorageBasedAuthProvider. I'll save this rigmarole for later.</description>
      <version>0.14.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener.java</file>
    </fixedFiles>
  </bug>
  <bug id="9706" opendate="2015-2-17 00:00:00" fixdate="2015-2-17 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HBase handler support for snapshots should confirm properties before use</summary>
      <description>The HBase Handler's support for running over snapshots attempts to copy a number of hbase internal configurations into a job configuration.Some of these configuration keys are removed in HBase 1.0.0+ and the current implementation will fail when copying the resultant null value into a new configuration. Additionally, some internal configs added in later HBase 0.98 versions are not respected.Instead, setup should check for the presence of the keys it expects and then make the new configuration consistent with them.</description>
      <version>0.14.0,1.0.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">hbase-handler.src.java.org.apache.hadoop.hive.hbase.HBaseStorageHandler.java</file>
    </fixedFiles>
  </bug>
  <bug id="9727" opendate="2015-2-19 00:00:00" fixdate="2015-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>GroupingID translation from Calcite</summary>
      <description>The translation from Calcite back to Hive might produce wrong results while interacting with other Calcite optimization rules.</description>
      <version>0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.clientpositive.groupby.rollup1.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.groupby.cube1.q.out</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.CalcitePlanner.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTConverter.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveGroupingID.java</file>
    </fixedFiles>
  </bug>
  <bug id="9728" opendate="2015-2-19 00:00:00" fixdate="2015-2-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: add heap mode to allocator (for q files, YARN w/o direct buffer accounting support)</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.queries.clientpositive.orc.llap.q</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.InStream.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.EncodedReaderImpl.java</file>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.cache.TestLowLevelCacheImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataProducer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LowLevelCacheImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.BuddyAllocator.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.Allocator.java</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.llap.io.api.cache.LowLevelCache.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="9729" opendate="2015-2-19 00:00:00" fixdate="2015-3-19 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: design and implement proper metadata cache</summary>
      <description>Simple approach: add external priorities to data cache, read metadata parts of orc file into it. Advantage: simple; consistent management (no need to coordinate sizes and eviction between data and metadata caches, etc); disadvantage - have to decode every time.Maybe add decoded metadata cache on top - fixed size, small and opportunistic? Or some other approach.</description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.IncrementalObjectSizeEstimator.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.decode.OrcColumnVectorProducer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.decode.ColumnVectorProducer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat.java</file>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.cache.TestOrcMetadataCache.java</file>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.cache.TestIncrementalObjectSizeEstimator.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.MemoryManager.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LowLevelCacheMemoryManager.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestOrcFile.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.io.orc.TestColumnStatistics.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.util.JavaDataModel.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.Metadata.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.FileMetadata.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.FileDump.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.decode.EncodedDataConsumer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.EvictionListener.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.ReaderImpl.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.Reader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcSplit.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcNewSplit.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.OrcFile.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.MetadataReader.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.InStream.java</file>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.cache.TestLowLevelLrfuCachePolicy.java</file>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.cache.TestLowLevelCacheImpl.java</file>
      <file type="M">llap-server.src.test.org.apache.hadoop.hive.llap.cache.TestBuddyAllocator.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.orc.RecordReader.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.orc.Reader.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.orc.OrcFile.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.orc.LLAPRecordReaderImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.orc.LLAPReaderImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.metadata.OrcStripeMetadata.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.metadata.OrcMetadataLoader.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.decode.orc.stream.StreamUtils.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LowLevelLrfuCachePolicy.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LowLevelFifoCachePolicy.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LowLevelCachePolicy.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LowLevelCacheImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.LlapCacheableBuffer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.cache.BuddyAllocator.java</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.llap.io.api.cache.LowLevelCache.java</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.llap.io.api.cache.LlapMemoryBuffer.java</file>
    </fixedFiles>
  </bug>
  <bug id="9730" opendate="2015-2-19 00:00:00" fixdate="2015-1-19 01:00:00" resolution="Unresolved">
    <buginformation>
      <summary>make sure logging is never called when not needed in perf-sensitive places</summary>
      <description>log4j logging has really inefficient serialization</description>
      <version>None</version>
      <fixedVersion>None</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.LlapUtils.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.orc.InStream.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataProducer.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="9743" opendate="2015-2-21 00:00:00" fixdate="2015-5-21 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Incorrect result set for vectorized left outer join</summary>
      <description>This query is supposed to return 3 rows and will when run without Tez but returns 2 rows when run with Tez.select tjoin1.rnum, tjoin1.c1, tjoin1.c2, tjoin2.c2 as c2j2 from tjoin1 left outer join tjoin2 on ( tjoin1.c1 = tjoin2.c1 and tjoin1.c2 &gt; 15 )tjoin1.rnum tjoin1.c1 tjoin1.c2 c2j21 20 25 &lt;null&gt;2 &lt;null&gt; 50 &lt;null&gt;instead oftjoin1.rnum tjoin1.c1 tjoin1.c2 c2j20 10 15 &lt;null&gt;1 20 25 &lt;null&gt;2 &lt;null&gt; 50 &lt;null&gt;create table if not exists TJOIN1 (RNUM int , C1 int, C2 int) STORED AS orc ;0|10|151|20|252|\N|50create table if not exists TJOIN2 (RNUM int , C1 int, C2 char(2))ROW FORMAT DELIMITED FIELDS TERMINATED BY '|' LINES TERMINATED BY '\n' STORED AS TEXTFILE ;0|10|BB1|15|DD2|\N|EE3|10|FF</description>
      <version>0.14.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorMapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.mapjoin.VectorMapJoinGenerateResultOperator.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="9750" opendate="2015-2-23 00:00:00" fixdate="2015-2-23 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>avoid log locks in operators</summary>
      <description>Basically wrap all LOG.xx calls in isLogXXXEnabled to avoid unnecessary locks on these calls.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.UnionOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.TableScanOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.SMBMapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.SelectOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.ScriptOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.OrcFileMergeOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Operator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MuxOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MapJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.JoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.HashTableSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.GroupByOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.FileSinkOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.DemuxOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.CommonJoinOperator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.AppMasterEventOperator.java</file>
    </fixedFiles>
  </bug>
  <bug id="9770" opendate="2015-2-24 00:00:00" fixdate="2015-2-24 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Beeline ignores --showHeader for non-tablular output formats i.e csv,tsv,dsv</summary>
      <description>&amp;#91;root@s1 ~&amp;#93;# beeline --silent=true --showHeader=false --outputformat=table -u "jdbc:hive2://localhost:10000" -e "select * from t1;"--------+1--------+&amp;#91;root@s1 ~&amp;#93;# beeline --silent=true --showHeader=false --outputformat=vertical -u "jdbc:hive2://localhost:10000" -e "select * from t1;"t1.c1 1&amp;#91;root@s1 ~&amp;#93;# beeline --silent=true --showHeader=false --outputformat=csv -u "jdbc:hive2://localhost:10000" -e "select * from t1;"'t1.c1''1'&amp;#91;root@s1 ~&amp;#93;# beeline --silent=true --showHeader=false --outputformat=tsv -u "jdbc:hive2://localhost:10000" -e "select * from t1;"'t1.c1''1'&amp;#91;root@s1 ~&amp;#93;# beeline --silent=true --showHeader=false --outputformat=dsv -u "jdbc:hive2://localhost:10000" -e "select * from t1;"t1.c11&amp;#91;root@s1 ~&amp;#93;# beeline --silent=true --showHeader=false --outputformat=csv2 -u "jdbc:hive2://localhost:10000" -e "select * from t1;"t1.c11&amp;#91;root@s1 ~&amp;#93;# beeline --silent=true --showHeader=false --outputformat=tsv2 -u "jdbc:hive2://localhost:10000" -e "select * from t1;"t1.c11</description>
      <version>0.14.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">beeline.src.java.org.apache.hive.beeline.SeparatedValuesOutputFormat.java</file>
      <file type="M">beeline.src.java.org.apache.hive.beeline.DeprecatedSeparatedValuesOutputFormat.java</file>
    </fixedFiles>
  </bug>
  <bug id="9817" opendate="2015-2-27 00:00:00" fixdate="2015-3-27 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>fix DateFormat pattern in hive-exec</summary>
      <description>some classes use mm for month and hh for hoursit should be MM and HH</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.optimizer.calcite.translator.ASTBuilder.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Utilities.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask.java</file>
    </fixedFiles>
  </bug>
  <bug id="9831" opendate="2015-3-2 00:00:00" fixdate="2015-3-2 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HiveServer2 should use ConcurrentHashMap in ThreadFactory</summary>
      <description></description>
      <version>0.14.0,1.0.0,1.1.0,1.2.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.server.ThreadFactoryWithGarbageCleanup.java</file>
    </fixedFiles>
  </bug>
  <bug id="9839" opendate="2015-3-3 00:00:00" fixdate="2015-3-3 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>HiveServer2 leaks OperationHandle on async queries which fail at compile phase</summary>
      <description>Using beeline to connect to HiveServer2.And type the following:drop table if exists table_not_exists;select * from table_not_exists;There will be an OperationHandle object staying in HiveServer2's memory for ever even after quit from beeline .</description>
      <version>0.13.1,0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">service.src.java.org.apache.hive.service.cli.session.HiveSessionImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="9892" opendate="2015-3-7 00:00:00" fixdate="2015-3-7 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>various MSSQL upgrade scripts don&amp;#39;t work</summary>
      <description>Issue with GO statement when run through schematool - it results in syntax error. the create if not exists logic for PART_COL_STATS wasn't workingNO PRECOMMIT TESTS</description>
      <version>0.13.0,0.14.0,1.0.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">metastore.scripts.upgrade.mssql.005-HIVE-9296.mssql.sql</file>
      <file type="M">metastore.scripts.upgrade.mssql.004-HIVE-8550.mssql.sql</file>
      <file type="M">metastore.scripts.upgrade.mssql.002-HIVE-7784.mssql.sql</file>
      <file type="M">metastore.scripts.upgrade.mssql.pre-0-upgrade-0.12.0-to-0.13.0.mssql.sql</file>
    </fixedFiles>
  </bug>
  <bug id="9894" opendate="2015-3-9 00:00:00" fixdate="2015-3-9 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Use new parquet Types API builder to construct DATE data type</summary>
      <description>The DATE type was implemented in HIVE-8119. And new parquet Types API builder was used in HIVE-9657 for all data types. But DATE is missed.We should also use new Types API for DATE type.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.io.parquet.convert.HiveSchemaConverter.java</file>
    </fixedFiles>
  </bug>
  <bug id="9908" opendate="2015-3-10 00:00:00" fixdate="2015-5-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>vectorization error binary type not supported, group by with binary columns</summary>
      <description>I am observing run time exception with binary data, when vectorization is enabled and binary data is observed in Group By clause.The exception is unsupported type: binaryAs per document, exception should not come. Rather normal way of execution should continue.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.vector.VectorColumnSetInfo.java</file>
      <file type="M">itests.src.test.resources.testconfiguration.properties</file>
    </fixedFiles>
  </bug>
  <bug id="9909" opendate="2015-3-10 00:00:00" fixdate="2015-3-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Specify hive branch to use on jenkins hms tests</summary>
      <description>The HMS metastore upgrade scripts work with 'trunk' branch only. We should allow to checkout any branch specified on Jenkins job in order to allow branch users test their changes.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.metastore.execute-test-on-lxc.sh</file>
      <file type="M">dev-support.jenkins-execute-hms-test.sh</file>
    </fixedFiles>
  </bug>
  <bug id="991" opendate="2009-12-14 00:00:00" fixdate="2009-12-14 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>union with 200 kids fail</summary>
      <description>It throws an array out of bound exception</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.Operator.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
  <bug id="9911" opendate="2015-3-10 00:00:00" fixdate="2015-4-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: Clean up structures and intermediate data when a query completes</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.protobuf.LlapDaemonProtocol.proto</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.tezplugins.TaskCommunicator.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.shufflehandler.DirWatcher.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.LlapNodeId.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.LlapDaemonProtocolServerImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.LlapDaemonProtocolClientImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.ContainerRunner.java</file>
      <file type="M">llap-server.src.gen.protobuf.gen-java.org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.java</file>
      <file type="M">llap-client.src.java.org.apache.hadoop.hive.llap.configuration.LlapConfiguration.java</file>
    </fixedFiles>
  </bug>
  <bug id="9912" opendate="2015-3-10 00:00:00" fixdate="2015-3-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>LLAP: Improvements to the Shuffle handler to avoid unnecessary disk scans</summary>
      <description></description>
      <version>None</version>
      <fixedVersion>llap</fixedVersion>
      <type>Sub-task</type>
    </buginformation>
    <fixedFiles>
      <file type="M">llap-server.src.java.org.apache.tez.dag.app.rm.LlapTaskSchedulerService.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.LlapDaemonConfiguration.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.LlapDaemonProtocolServerImpl.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon.java</file>
      <file type="M">llap-server.src.java.org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl.java</file>
    </fixedFiles>
  </bug>
  <bug id="9914" opendate="2015-3-10 00:00:00" fixdate="2015-3-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Post success comments on Jira from Jenkins metastore upgrades scripts</summary>
      <description>Currently, the HMS upgrade testing post failure comments on Jira only. We need to post success comments as well so that users know that their upgrade changes are working.</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Improvement</type>
    </buginformation>
    <fixedFiles>
      <file type="M">testutils.ptest2.src.main.java.org.apache.hive.ptest.execution.JIRAService.java</file>
      <file type="M">testutils.metastore.metastore-upgrade-test.sh</file>
      <file type="M">dev-support.jenkins-execute-hms-test.sh</file>
    </fixedFiles>
  </bug>
  <bug id="9915" opendate="2015-3-10 00:00:00" fixdate="2015-3-10 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Allow specifying file format for managed tables</summary>
      <description>We already allow setting a system wide default format. In some cases it's useful though to specify this only for managed tables, or distinguish external and managed via two variables. You might want to set a more efficient (than text) format for managed tables, but leave external to text (as they often are log files etc.)</description>
      <version>None</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.StorageFormat.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.java</file>
      <file type="M">common.src.java.org.apache.hadoop.hive.conf.HiveConf.java</file>
    </fixedFiles>
  </bug>
  <bug id="9977" opendate="2015-3-16 00:00:00" fixdate="2015-3-16 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>Compactor not running on partitions after dynamic partitioned insert</summary>
      <description>When an insert, update, or delete is done using dynamic partitioning the lock is obtained on the table instead of on the individual partitions, since the partitions are not known at lock acquisition time. The compactor is using the locks to determine which partitions to check to see if they need compacted. Since the individual partitions aren't locked they aren't checked.</description>
      <version>0.14.0,1.0.0,1.1.0</version>
      <fixedVersion>1.2.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.txn.compactor.TestWorker.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.txn.compactor.TestInitiator.java</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.txn.compactor.Initiator.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.metadata.Hive.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.exec.MoveTask.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.Driver.java</file>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.txn.TestTxnHandler.java</file>
      <file type="M">metastore.src.test.org.apache.hadoop.hive.metastore.txn.TestCompactionTxnHandler.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.txn.TxnHandler.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.txn.CompactionInfo.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.IMetaStoreClient.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStoreClient.java</file>
      <file type="M">metastore.src.java.org.apache.hadoop.hive.metastore.HiveMetaStore.java</file>
      <file type="M">metastore.src.gen.thrift.gen-rb.thrift.hive.metastore.rb</file>
      <file type="M">metastore.src.gen.thrift.gen-rb.hive.metastore.types.rb</file>
      <file type="M">metastore.src.gen.thrift.gen-py.hive.metastore.ttypes.py</file>
      <file type="M">metastore.src.gen.thrift.gen-py.hive.metastore.ThriftHiveMetastore.py</file>
      <file type="M">metastore.src.gen.thrift.gen-py.hive.metastore.ThriftHiveMetastore-remote</file>
      <file type="M">metastore.src.gen.thrift.gen-php.metastore.Types.php</file>
      <file type="M">metastore.src.gen.thrift.gen-php.metastore.ThriftHiveMetastore.php</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.NotificationEventResponse.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.InsertEventRequestData.java</file>
      <file type="M">metastore.src.gen.thrift.gen-javabean.org.apache.hadoop.hive.metastore.api.FireEventRequest.java</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.ThriftHiveMetastore.server.skeleton.cpp</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.ThriftHiveMetastore.h</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.ThriftHiveMetastore.cpp</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.hive.metastore.types.h</file>
      <file type="M">metastore.src.gen.thrift.gen-cpp.hive.metastore.types.cpp</file>
      <file type="M">metastore.if.hive.metastore.thrift</file>
      <file type="M">itests.hive-unit.src.test.java.org.apache.hadoop.hive.ql.txn.compactor.TestCompactor.java</file>
    </fixedFiles>
  </bug>
  <bug id="999" opendate="2009-12-18 00:00:00" fixdate="2009-12-18 01:00:00" resolution="Fixed">
    <buginformation>
      <summary>sample pruning not working if denominator is not same as number of buckets</summary>
      <description>blocker for 0.5</description>
      <version>None</version>
      <fixedVersion>0.5.0</fixedVersion>
      <type>Bug</type>
    </buginformation>
    <fixedFiles>
      <file type="M">ql.src.test.results.compiler.plan.sample7.q.xml</file>
      <file type="M">ql.src.test.results.compiler.plan.sample6.q.xml</file>
      <file type="M">ql.src.test.results.clientpositive.sample6.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input3.q.out</file>
      <file type="M">ql.src.test.results.clientpositive.input2.q.out</file>
      <file type="M">ql.src.test.queries.clientpositive.sample6.q</file>
      <file type="M">ql.src.test.org.apache.hadoop.hive.ql.QTestUtil.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.java</file>
      <file type="M">ql.src.java.org.apache.hadoop.hive.ql.parse.ErrorMsg.java</file>
      <file type="M">CHANGES.txt</file>
    </fixedFiles>
  </bug>
</bugrepository>
